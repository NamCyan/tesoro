{"id":22,"comment_id":0,"comment":"\/\/ fixme: this is almost certainly boned. a reg could appear in the \/\/ address expressions.","code":"public boolean usesregs() { \/\/ fixme: this is almost certainly boned. a reg could appear in the \/\/ address expressions. for (int i=0;i<rhs().length;++i) { if (usesdirectly(i) && rhs()[i] instanceof reg) { return true; } } if (opcode.form().implicituses(head().code()).length!=0) { return true; } return false; }","classification":"DEFECT","isFinished":true,"code_context_2":"public boolean usesregs() { \/\/ fixme: this is almost certainly boned. a reg could appear in the \/\/ address expressions. for (int i=0;i<rhs().length;++i) { if (usesdirectly(i) && rhs()[i] instanceof reg) {","code_context_10":"public boolean usesregs() { \/\/ fixme: this is almost certainly boned. a reg could appear in the \/\/ address expressions. for (int i=0;i<rhs().length;++i) { if (usesdirectly(i) && rhs()[i] instanceof reg) { return true; } } if (opcode.form().implicituses(head().code()).length!=0) { return true; } return false; }","code_context_20":"public boolean usesregs() { \/\/ fixme: this is almost certainly boned. a reg could appear in the \/\/ address expressions. for (int i=0;i<rhs().length;++i) { if (usesdirectly(i) && rhs()[i] instanceof reg) { return true; } } if (opcode.form().implicituses(head().code()).length!=0) { return true; } return false; }","repo":"mihirlibran\/cse605"}
{"id":83,"comment_id":0,"comment":"\/\/ operator op = ((operatoritem) item0)._operator; \/\/ todo check this value if we can, somehow","code":"@test public void parsenegativeintegerliteral( ) throws expressionexception { linespecifier ls = new linespecifier(0, 10); locale locale = new locale(ls, 10); expressionparser parser = new expressionparser(\"-14458\", locale); expression exp = parser.parse(new assembler.builder().build()); assertequals(2, exp._items.size()); expressionitem item0 = exp._items.get(0); asserttrue(item0 instanceof operatoritem); \/\/ operator op = ((operatoritem) item0)._operator; \/\/ todo check this value if we can, somehow expressionitem item1 = exp._items.get(1); asserttrue(item1 instanceof valueitem); value v1 = ((valueitem)item1)._value; asserttrue(v1 instanceof integervalue); assertequals(14458l, ((integervalue)v1)._value.get().longvalue()); }","classification":"DESIGN","isFinished":true,"code_context_2":"expressionitem item0 = exp._items.get(0); asserttrue(item0 instanceof operatoritem); \/\/ operator op = ((operatoritem) item0)._operator; \/\/ todo check this value if we can, somehow expressionitem item1 = exp._items.get(1); asserttrue(item1 instanceof valueitem);","code_context_10":"@test public void parsenegativeintegerliteral( ) throws expressionexception { linespecifier ls = new linespecifier(0, 10); locale locale = new locale(ls, 10); expressionparser parser = new expressionparser(\"-14458\", locale); expression exp = parser.parse(new assembler.builder().build()); assertequals(2, exp._items.size()); expressionitem item0 = exp._items.get(0); asserttrue(item0 instanceof operatoritem); \/\/ operator op = ((operatoritem) item0)._operator; \/\/ todo check this value if we can, somehow expressionitem item1 = exp._items.get(1); asserttrue(item1 instanceof valueitem); value v1 = ((valueitem)item1)._value; asserttrue(v1 instanceof integervalue); assertequals(14458l, ((integervalue)v1)._value.get().longvalue()); }","code_context_20":"@test public void parsenegativeintegerliteral( ) throws expressionexception { linespecifier ls = new linespecifier(0, 10); locale locale = new locale(ls, 10); expressionparser parser = new expressionparser(\"-14458\", locale); expression exp = parser.parse(new assembler.builder().build()); assertequals(2, exp._items.size()); expressionitem item0 = exp._items.get(0); asserttrue(item0 instanceof operatoritem); \/\/ operator op = ((operatoritem) item0)._operator; \/\/ todo check this value if we can, somehow expressionitem item1 = exp._items.get(1); asserttrue(item1 instanceof valueitem); value v1 = ((valueitem)item1)._value; asserttrue(v1 instanceof integervalue); assertequals(14458l, ((integervalue)v1)._value.get().longvalue()); }","repo":"kduncan99\/em2200-java"}
{"id":118,"comment_id":0,"comment":"\/\/ bug report: cached geopoint is being returned as the first value. \/\/ wait for the 2nd value to be returned, which is hopefully not cached?","code":"@override public void onlocationchanged(location location) { mlocation = location; if (mlocation != null) { \/\/ bug report: cached geopoint is being returned as the first value. \/\/ wait for the 2nd value to be returned, which is hopefully not cached? ++mlocationcount; infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() + \" onlocationchanged(\" + mlocationcount + \") lat: \" + mlocation.getlatitude() + \" long: \" + mlocation.getlongitude() + \" acc: \" + mlocation.getaccuracy()); if (mlocationcount > 1) { mlocationdialog.setmessage(getstring(r.string.location_provider_accuracy, mlocation.getprovider(), truncatedouble(mlocation.getaccuracy()))); if (mlocation.getaccuracy() <= mlocationaccuracy) { returnlocation(); } } } else { infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() + \" onlocationchanged(\" + mlocationcount + \") null location\"); } }","classification":"DEFECT","isFinished":true,"code_context_2":"mlocation = location; if (mlocation != null) { \/\/ bug report: cached geopoint is being returned as the first value. \/\/ wait for the 2nd value to be returned, which is hopefully not cached? ++mlocationcount; infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() +","code_context_10":"@override public void onlocationchanged(location location) { mlocation = location; if (mlocation != null) { \/\/ bug report: cached geopoint is being returned as the first value. \/\/ wait for the 2nd value to be returned, which is hopefully not cached? ++mlocationcount; infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() + \" onlocationchanged(\" + mlocationcount + \") lat: \" + mlocation.getlatitude() + \" long: \" + mlocation.getlongitude() + \" acc: \" + mlocation.getaccuracy()); if (mlocationcount > 1) { mlocationdialog.setmessage(getstring(r.string.location_provider_accuracy, mlocation.getprovider(), truncatedouble(mlocation.getaccuracy()))); if (mlocation.getaccuracy() <= mlocationaccuracy) {","code_context_20":"@override public void onlocationchanged(location location) { mlocation = location; if (mlocation != null) { \/\/ bug report: cached geopoint is being returned as the first value. \/\/ wait for the 2nd value to be returned, which is hopefully not cached? ++mlocationcount; infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() + \" onlocationchanged(\" + mlocationcount + \") lat: \" + mlocation.getlatitude() + \" long: \" + mlocation.getlongitude() + \" acc: \" + mlocation.getaccuracy()); if (mlocationcount > 1) { mlocationdialog.setmessage(getstring(r.string.location_provider_accuracy, mlocation.getprovider(), truncatedouble(mlocation.getaccuracy()))); if (mlocation.getaccuracy() <= mlocationaccuracy) { returnlocation(); } } } else { infologger.geolog(\"geopointactivity: \" + system.currenttimemillis() + \" onlocationchanged(\" + mlocationcount + \") null location\"); } }","repo":"jorgepsendziuk\/novo_coletor"}
{"id":32955,"comment_id":0,"comment":"\/** * this thingy is crazy !! upgrading or improvements are forbidden ! coded to * ce truc est legacy de ouf !! alors on arr\u00eate les conneries et plus de nouveaux dev dessus ! * * @param spec * @param artifactname * @param groupid * @param artifactversion * @param implemname * @return * @throws exception *\/","code":"\/** * this thingy is crazy !! upgrading or improvements are forbidden ! coded to * ce truc est legacy de ouf !! alors on arr\u00eate les conneries et plus de nouveaux dev dessus ! * * @param spec * @param artifactname * @param groupid * @param artifactversion * @param implemname * @return * @throws exception *\/ @deprecated public filedatasource generatepythonimpl(file spec, string artifactname, string groupid, string artifactversion, string implemname) throws exception { yaml yaml = new yaml(); linkedhashmap swaggerfile = yaml.load(fileutils.openinputstream(spec)); string groupidapi = getpropinswaggerfile(swaggerfile, \"x-groupid\"); string artifactnameapi = getpropinswaggerfile(swaggerfile, \"x-artifactname\"); string artifactversionapi = getpropinswaggerfile(swaggerfile, \"version\"); string groupname = groupid.substring(groupid.lastindexof('.') + 1); stringbuilder artifactidsb = new stringbuilder().append(groupname).append(\"-\").append(artifactnameapi).append(\"-\"); artifactidsb.append(artifactname.replaceall(\"-\",\"\")); codegenconfigurator configurator = new codegenconfigurator(); string artifactid = artifactidsb.tostring(); initializeconfigurator(spec, \"kathrapython\", artifactnameapi, groupidapi, artifactversion, \"implem\", artifactid, configurator); configurator.setartifactversionapi(artifactversionapi); return getfiledatasource(spec, \"implem\", artifactidsb, artifactid, configurator); }","classification":"DESIGN","isFinished":true,"code_context_2":"@deprecated public filedatasource generatepythonimpl(file spec, string artifactname, string groupid, string artifactversion, string implemname) throws exception { yaml yaml = new yaml(); linkedhashmap swaggerfile = yaml.load(fileutils.openinputstream(spec)); string groupidapi = getpropinswaggerfile(swaggerfile, \"x-groupid\"); string artifactnameapi = getpropinswaggerfile(swaggerfile, \"x-artifactname\"); string artifactversionapi = getpropinswaggerfile(swaggerfile, \"version\"); string groupname = groupid.substring(groupid.lastindexof('.') + 1); stringbuilder artifactidsb = new stringbuilder().append(groupname).append(\"-\").append(artifactnameapi).append(\"-\"); artifactidsb.append(artifactname.replaceall(\"-\",\"\")); codegenconfigurator configurator = new codegenconfigurator(); string artifactid = artifactidsb.tostring(); initializeconfigurator(spec, \"kathrapython\", artifactnameapi, groupidapi, artifactversion, \"implem\", artifactid, configurator); configurator.setartifactversionapi(artifactversionapi); return getfiledatasource(spec, \"implem\", artifactidsb, artifactid, configurator); }","code_context_10":"@deprecated public filedatasource generatepythonimpl(file spec, string artifactname, string groupid, string artifactversion, string implemname) throws exception { yaml yaml = new yaml(); linkedhashmap swaggerfile = yaml.load(fileutils.openinputstream(spec)); string groupidapi = getpropinswaggerfile(swaggerfile, \"x-groupid\"); string artifactnameapi = getpropinswaggerfile(swaggerfile, \"x-artifactname\"); string artifactversionapi = getpropinswaggerfile(swaggerfile, \"version\"); string groupname = groupid.substring(groupid.lastindexof('.') + 1); stringbuilder artifactidsb = new stringbuilder().append(groupname).append(\"-\").append(artifactnameapi).append(\"-\"); artifactidsb.append(artifactname.replaceall(\"-\",\"\")); codegenconfigurator configurator = new codegenconfigurator(); string artifactid = artifactidsb.tostring(); initializeconfigurator(spec, \"kathrapython\", artifactnameapi, groupidapi, artifactversion, \"implem\", artifactid, configurator); configurator.setartifactversionapi(artifactversionapi); return getfiledatasource(spec, \"implem\", artifactidsb, artifactid, configurator); }","code_context_20":"@deprecated public filedatasource generatepythonimpl(file spec, string artifactname, string groupid, string artifactversion, string implemname) throws exception { yaml yaml = new yaml(); linkedhashmap swaggerfile = yaml.load(fileutils.openinputstream(spec)); string groupidapi = getpropinswaggerfile(swaggerfile, \"x-groupid\"); string artifactnameapi = getpropinswaggerfile(swaggerfile, \"x-artifactname\"); string artifactversionapi = getpropinswaggerfile(swaggerfile, \"version\"); string groupname = groupid.substring(groupid.lastindexof('.') + 1); stringbuilder artifactidsb = new stringbuilder().append(groupname).append(\"-\").append(artifactnameapi).append(\"-\"); artifactidsb.append(artifactname.replaceall(\"-\",\"\")); codegenconfigurator configurator = new codegenconfigurator(); string artifactid = artifactidsb.tostring(); initializeconfigurator(spec, \"kathrapython\", artifactnameapi, groupidapi, artifactversion, \"implem\", artifactid, configurator); configurator.setartifactversionapi(artifactversionapi); return getfiledatasource(spec, \"implem\", artifactidsb, artifactid, configurator); }","repo":"kathra-project\/kathra-codegen-swagger"}
{"id":16627,"comment_id":0,"comment":"\/\/todo: this could fail if an equals number of additions and removals happened within one second.","code":"\/\/todo: this could fail if an equals number of additions and removals happened within one second. public void checklist() { if(observed.size() != cachedsize) { cachedsize = observed.size(); listupdated(); } }","classification":"DEFECT","isFinished":true,"code_context_2":"public void checklist() { if(observed.size() != cachedsize) { cachedsize = observed.size(); listupdated(); } }","code_context_10":"public void checklist() { if(observed.size() != cachedsize) { cachedsize = observed.size(); listupdated(); } }","code_context_20":"public void checklist() { if(observed.size() != cachedsize) { cachedsize = observed.size(); listupdated(); } }","repo":"justin-espedal\/polydes"}
{"id":16754,"comment_id":0,"comment":"\/** * attach element identify name to class of \"use\" usage * * @param psielement phpclass used in \"use\" statement *\/","code":"\/** * attach element identify name to class of \"use\" usage * * @param psielement phpclass used in \"use\" statement *\/ @override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","code_context_10":"@override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","code_context_20":"@override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","repo":"meyerbaptiste\/idea-php-annotation-plugin"}
{"id":16754,"comment_id":1,"comment":"\/\/ @todo: namespace not supported","code":"@override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; }","code_context_10":"public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","code_context_20":"@override public boolean isreferenceto(psielement psielement) { if(!(psielement instanceof phpnamedelement)) { return false; } string text = getelement().gettext(); if(stringutils.isblank(text)) { return false; } psielement namespace = element.getprevsibling(); if(phppsiutil.isoftype(namespace, phpdoctokentypes.doc_namespace)) { \/\/ @todo: namespace not supported return false; } string classbycontext = phpelementsutil.getfqnforclassnamebycontext(element, text); if(classbycontext != null) { return stringutils.stripstart(((phpnamedelement) psielement).getfqn(), \"\\\\\") .equalsignorecase(stringutils.stripstart(fqn, \"\\\\\")); } return false; }","repo":"meyerbaptiste\/idea-php-annotation-plugin"}
{"id":16808,"comment_id":0,"comment":"\/\/ todo for now we only sync cloud ids during full sync. we should eventually allow more granular syncs (actor level and group level sync).","code":"public syncstatusdetail synchronizestack(stack stack, umsusersstate umsusersstate, usersyncoptions options) { mdcbuilder.buildmdccontext(stack); string environmentcrn = stack.getenvironmentcrn(); multimap<string, string> warnings = arraylistmultimap.create(); try { freeipaclient freeipaclient = freeipaclientfactory.getfreeipaclientforstack(stack); usersstatedifference usersstatedifferencebeforesync = compareumsandfreeipa(umsusersstate, options, freeipaclient); stateapplier.applydifference(umsusersstate, environmentcrn, warnings, usersstatedifferencebeforesync, options, freeipaclient); retrysyncifbatchcallhaswarnings(stack, umsusersstate, warnings, options, freeipaclient, usersstatedifferencebeforesync); if (options.isfullsync()) { \/\/ todo for now we only sync cloud ids during full sync. we should eventually allow more granular syncs (actor level and group level sync). if (entitlementservice.cloudidentitymappingenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", sync_cloud_identities); cloudidentitysyncservice.synccloudidentities(stack, umsusersstate, warnings::put); logger.debug(\"finished {}.\", sync_cloud_identities); } if (entitlementservice.isenvironmentprivilegeduserenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", add_sudo_rules); try { sudoruleservice.setupsudorule(stack, freeipaclient); } catch (exception e) { warnings.put(stack.getenvironmentcrn(), e.getmessage()); logger.error(\"{} failed for environment '{}'.\", add_sudo_rules, stack.getenvironmentcrn(), e); } logger.debug(\"finished {}.\", add_sudo_rules); } } return tosyncstatusdetail(environmentcrn, warnings); } catch (timeoutexception e) { logger.warn(\"timed out while synchronizing environment {}\", environmentcrn, e); return syncstatusdetail.fail(environmentcrn, \"timed out\", warnings); } catch (exception e) { logger.warn(\"failed to synchronize environment {}\", environmentcrn, e); return syncstatusdetail.fail(environmentcrn, e.getlocalizedmessage(), warnings); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"retrysyncifbatchcallhaswarnings(stack, umsusersstate, warnings, options, freeipaclient, usersstatedifferencebeforesync); if (options.isfullsync()) { \/\/ todo for now we only sync cloud ids during full sync. we should eventually allow more granular syncs (actor level and group level sync). if (entitlementservice.cloudidentitymappingenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", sync_cloud_identities);","code_context_10":"public syncstatusdetail synchronizestack(stack stack, umsusersstate umsusersstate, usersyncoptions options) { mdcbuilder.buildmdccontext(stack); string environmentcrn = stack.getenvironmentcrn(); multimap<string, string> warnings = arraylistmultimap.create(); try { freeipaclient freeipaclient = freeipaclientfactory.getfreeipaclientforstack(stack); usersstatedifference usersstatedifferencebeforesync = compareumsandfreeipa(umsusersstate, options, freeipaclient); stateapplier.applydifference(umsusersstate, environmentcrn, warnings, usersstatedifferencebeforesync, options, freeipaclient); retrysyncifbatchcallhaswarnings(stack, umsusersstate, warnings, options, freeipaclient, usersstatedifferencebeforesync); if (options.isfullsync()) { \/\/ todo for now we only sync cloud ids during full sync. we should eventually allow more granular syncs (actor level and group level sync). if (entitlementservice.cloudidentitymappingenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", sync_cloud_identities); cloudidentitysyncservice.synccloudidentities(stack, umsusersstate, warnings::put); logger.debug(\"finished {}.\", sync_cloud_identities); } if (entitlementservice.isenvironmentprivilegeduserenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", add_sudo_rules); try { sudoruleservice.setupsudorule(stack, freeipaclient); } catch (exception e) {","code_context_20":"public syncstatusdetail synchronizestack(stack stack, umsusersstate umsusersstate, usersyncoptions options) { mdcbuilder.buildmdccontext(stack); string environmentcrn = stack.getenvironmentcrn(); multimap<string, string> warnings = arraylistmultimap.create(); try { freeipaclient freeipaclient = freeipaclientfactory.getfreeipaclientforstack(stack); usersstatedifference usersstatedifferencebeforesync = compareumsandfreeipa(umsusersstate, options, freeipaclient); stateapplier.applydifference(umsusersstate, environmentcrn, warnings, usersstatedifferencebeforesync, options, freeipaclient); retrysyncifbatchcallhaswarnings(stack, umsusersstate, warnings, options, freeipaclient, usersstatedifferencebeforesync); if (options.isfullsync()) { \/\/ todo for now we only sync cloud ids during full sync. we should eventually allow more granular syncs (actor level and group level sync). if (entitlementservice.cloudidentitymappingenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", sync_cloud_identities); cloudidentitysyncservice.synccloudidentities(stack, umsusersstate, warnings::put); logger.debug(\"finished {}.\", sync_cloud_identities); } if (entitlementservice.isenvironmentprivilegeduserenabled(stack.getaccountid())) { logger.debug(\"starting {} ...\", add_sudo_rules); try { sudoruleservice.setupsudorule(stack, freeipaclient); } catch (exception e) { warnings.put(stack.getenvironmentcrn(), e.getmessage()); logger.error(\"{} failed for environment '{}'.\", add_sudo_rules, stack.getenvironmentcrn(), e); } logger.debug(\"finished {}.\", add_sudo_rules); } } return tosyncstatusdetail(environmentcrn, warnings); } catch (timeoutexception e) { logger.warn(\"timed out while synchronizing environment {}\", environmentcrn, e); return syncstatusdetail.fail(environmentcrn, \"timed out\", warnings);","repo":"mdvtlp\/cloudbreak"}
{"id":25017,"comment_id":0,"comment":"\/\/get process id","code":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0];","code_context_10":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","code_context_20":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","repo":"mgd-hin\/systemds"}
{"id":25017,"comment_id":1,"comment":"\/\/pid@hostname","code":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9","code_context_10":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","code_context_20":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","repo":"mgd-hin\/systemds"}
{"id":25017,"comment_id":2,"comment":"\/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid();","code":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","classification":"DESIGN","isFinished":true,"code_context_2":"string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","code_context_10":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","code_context_20":"public static string obtainprocessid() { \/\/get process id string pname = managementfactory.getruntimemxbean().getname(); \/\/pid@hostname string pid = pname.split(\"@\")[0]; \/\/ todo: change this as soon as we switch to a java version >= 9 \/\/ import java.lang.processhandle; \/\/ pid = processhandle.current().pid(); return pid; }","repo":"mgd-hin\/systemds"}
{"id":16892,"comment_id":0,"comment":"\/** * @param pathtomergeschema * string path to the mergeschema to be used on this document. note: will in future builds * replaced by pathtomergeschemas which leads to a directory containing mergeschemas for every * used namespace. * * if <b>null<\/b> the default mergeschemas will be used * @author sholzer (12.03.2015) * @return a lexemerger *\/","code":"\/** * @param pathtomergeschema * string path to the mergeschema to be used on this document. note: will in future builds * replaced by pathtomergeschemas which leads to a directory containing mergeschemas for every * used namespace. * * if <b>null<\/b> the default mergeschemas will be used * @author sholzer (12.03.2015) * @return a lexemerger *\/ public static lexemerger build(string pathtomergeschema) { if (builder == null) { builder = new genericlexemebuilder(); } return builder.build(pathtomergeschema); }","classification":"NONSATD","isFinished":true,"code_context_2":"public static lexemerger build(string pathtomergeschema) { if (builder == null) { builder = new genericlexemebuilder(); } return builder.build(pathtomergeschema); }","code_context_10":"public static lexemerger build(string pathtomergeschema) { if (builder == null) { builder = new genericlexemebuilder(); } return builder.build(pathtomergeschema); }","code_context_20":"public static lexemerger build(string pathtomergeschema) { if (builder == null) { builder = new genericlexemebuilder(); } return builder.build(pathtomergeschema); }","repo":"maybeec\/lexeme"}
{"id":16946,"comment_id":0,"comment":"\/\/================= runxmlreplayfile ======================================================","code":"\/\/================= runxmlreplayfile ====================================================== public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","code_context_10":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","code_context_20":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":1,"comment":"\/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir);","code_context_10":"string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){","code_context_20":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document);","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":2,"comment":"\/\/will check full path first, then checks relative to pwd.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\");","code_context_10":"list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; }","code_context_20":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap;","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":3,"comment":"\/\/controlfilename is just the short name, without the full path.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\"","code_context_10":"throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\"","code_context_20":"throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); }","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":4,"comment":"\/\/ used for expression language expansion from uri field.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap;","code_context_10":"+\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\");","code_context_20":"string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\");","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":5,"comment":"\/\/mapcontext(); \/\/get a new jexlcontext for each test group.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\");","code_context_10":"if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1;","code_context_20":"+ (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) {","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":6,"comment":"\/\/ \/\/ figure out if we will auto delete resources","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>();","code_context_10":"string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport;","code_context_20":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo;","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":7,"comment":"\/\/else just run with current from last loop;","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){","code_context_10":"if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\");","code_context_20":"string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir);","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":8,"comment":"\/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts);","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult;","code_context_10":"if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){","code_context_20":"} if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0);","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":9,"comment":"\/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){","code_context_10":"partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult);","code_context_20":"node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid;","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":10,"comment":"\/\/if (ispost){","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"} results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/}","code_context_10":"map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){","code_context_20":"testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0;","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":11,"comment":"\/\/puts do not return a location, so don't add puts to serviceresultsmap.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri);","code_context_10":"if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes;","code_context_20":"} if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid;","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":12,"comment":"\/\/}","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){","code_context_10":"vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; }","code_context_20":"if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl);","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":13,"comment":"\/\/gotexpectedresult depends on serviceresult.expectedcodes.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"} results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); }","code_context_10":"} else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid);","code_context_20":"serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":14,"comment":"\/\/todo: empty for now, later may pick up from xml control file.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"DESIGN","isFinished":true,"code_context_2":"} else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult);","code_context_10":"serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method;","code_context_20":"} } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; }","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":15,"comment":"\/\/===================================================== \/\/ all validation for all requests is done here: \/\/=====================================================","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct);","code_context_10":"if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); }","code_context_20":"serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) {","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":16,"comment":"\/\/=== now spit out the html report file ===","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory.","code_context_10":"serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results;","code_context_20":"if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":17,"comment":"\/\/don't instantiate, just use file to extract file name without directory.","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname);","code_context_10":"serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","code_context_20":"system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","repo":"litchfieldhistoricalsociety\/services"}
{"id":16946,"comment_id":18,"comment":"\/\/================================","code":"public static list<serviceresult> runxmlreplayfile(string xmlreplaybasedir, string controlfilename, string testgroupid, string onetestid, map<string, serviceresult> serviceresultsmap, boolean param_autodeleteposts, dump dump, string protohostportparam, authsmap defaultauths, list<string> reportslist, string reportsdir) throws exception { \/\/internally, we maintain two collections of serviceresult: \/\/ the first is the return value of this method. \/\/ the second is the serviceresultsmap, which is used for keeping track of csids created by posts, for later reference by delete, etc. list<serviceresult> results = new arraylist<serviceresult>(); xmlreplayreport report = new xmlreplayreport(reportsdir); string controlfile = tools.glue(xmlreplaybasedir, \"\/\", controlfilename); org.dom4j.document document; document = getdocument(controlfile); \/\/will check full path first, then checks relative to pwd. if (document==null){ throw new filenotfoundexception(\"xmlreplay control file (\"+controlfilename+\") not found in basedir: \"+xmlreplaybasedir+\" exiting test.\"); } string protohostport; if (tools.isempty(protohostportparam)){ protohostport = document.selectsinglenode(\"\/xmlreplay\/protohostport\").gettext().trim(); system.out.println(\"deprecated: using protohostport ('\"+protohostport+\"') from xmlreplay file ('\"+controlfile+\"'), not master.\"); } else { protohostport = protohostportparam; } if (tools.isempty(protohostport)){ throw new exception(\"xmlreplay control file must have a protohostport element\"); } string authsmapinfo; authsmap authsmap = readauths(document); if (authsmap.map.size()==0){ authsmap = defaultauths; authsmapinfo = \"using defaultauths from master file: \"+defaultauths; } else { authsmapinfo = \"using authsmap from control file: \"+authsmap; } report.addtestgroup(testgroupid, controlfilename); \/\/controlfilename is just the short name, without the full path. string xmlreplayheader = \"========================================================================\" +\"\\r\\nxmlreplay running:\" +\"\\r\\n controlfile: \"+ (new file(controlfile).getcanonicalpath()) +\"\\r\\n protohostport: \"+protohostport +\"\\r\\n testgroup: \"+testgroupid + (tools.notempty(onetestid) ? \"\\r\\n onetestid: \"+onetestid : \"\") +\"\\r\\n authsmap: \"+authsmapinfo +\"\\r\\n param_autodeleteposts: \"+param_autodeleteposts +\"\\r\\n dump info: \"+dump +\"\\r\\n========================================================================\" +\"\\r\\n\"; report.addruninfo(xmlreplayheader); system.out.println(xmlreplayheader); string autodeleteposts = \"\"; list<node> testgroupnodes; if (tools.notempty(testgroupid)){ testgroupnodes = document.selectnodes(\"\/\/testgroup[@id='\"+testgroupid+\"']\"); } else { testgroupnodes = document.selectnodes(\"\/\/testgroup\"); } jexlengine jexl = new jexlengine(); \/\/ used for expression language expansion from uri field. xmlreplayeval evalstruct = new xmlreplayeval(); evalstruct.serviceresultsmap = serviceresultsmap; evalstruct.jexl = jexl; for (node testgroup : testgroupnodes) { xmlreplayeval.mapcontextwkeys jc = new xmlreplayeval.mapcontextwkeys();\/\/mapcontext(); \/\/get a new jexlcontext for each test group. evalstruct.jc = jc; autodeleteposts = testgroup.valueof(\"@autodeleteposts\"); list<node> tests; if (tools.notempty(onetestid)){ tests = testgroup.selectnodes(\"test[@id='\"+onetestid+\"']\"); } else { tests = testgroup.selectnodes(\"test\"); } string authfortest = \"\"; int testelementindex = -1; for (node testnode : tests) { long starttime = system.currenttimemillis(); try { testelementindex++; string testid = testnode.valueof(\"@id\"); \/\/ \/\/ figure out if we will auto delete resources boolean autodelete = param_autodeleteposts; string autodeletevalue = testnode.valueof(\"@autodeleteposts\"); if (autodeletevalue != null && !autodeletevalue.trim().isempty()) { autodelete = boolean.valueof(autodeletevalue).booleanvalue(); } string testidlabel = tools.notempty(testid) ? (testgroupid+'.'+testid) : (testgroupid+'.'+testelementindex); string method = testnode.valueof(\"method\"); string contenttype = testnode.valueof(\"contenttype\"); string uri = testnode.valueof(\"uri\"); string fullurl = tools.glue(protohostport, \"\/\", uri); if (contenttype == null || contenttype.equals(\"\")) { contenttype = xmlreplaytransport.application_xml; } string currentauthfortest = null; string authidfortest = testnode.valueof(\"@auth\"); if (tools.notempty(authidfortest)){ currentauthfortest = authsmap.map.get(authidfortest); } else { string tokenauthexpression = testnode.valueof(\"@tokenauth\"); if (tools.notempty(tokenauthexpression)){ currentauthfortest = \"bearer \" + evalstruct.eval(tokenauthexpression, serviceresultsmap, null, jexl, jc); } } if (tools.notempty(currentauthfortest)){ authfortest = currentauthfortest; \/\/else just run with current from last loop; } if (tools.isempty(authfortest)){ authfortest = defaultauths.getdefaultauth(); } if (uri.indexof(\"$\")>-1){ uri = evalstruct.eval(uri, serviceresultsmap, null, jexl, jc); } fullurl = fixupfullurl(fullurl, protohostport, uri); list<integer> expectedcodes = new arraylist<integer>(); string expectedcodesstr = testnode.valueof(\"expectedcodes\"); if (tools.notempty(expectedcodesstr)){ string[] codesarray = expectedcodesstr.split(\",\"); for (string code : codesarray){ expectedcodes.add(new integer(code.trim())); } } node responsenode = testnode.selectsinglenode(\"response\"); partsstruct expectedresponseparts = null; if (responsenode!=null){ expectedresponseparts = partsstruct.readparts(responsenode, testid, xmlreplaybasedir); \/\/system.out.println(\"reponse parts: >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\"+expectedresponseparts); } serviceresult serviceresult; boolean ispost = method.equalsignorecase(\"post\"); boolean isput = method.equalsignorecase(\"put\"); if ( ispost || isput ) { partsstruct parts = partsstruct.readparts(testnode, testid, xmlreplaybasedir); if (tools.notempty(parts.overridetestid)) { testid = parts.overridetestid; } if (ispost){ string csid = csidfromtestid(testnode, serviceresultsmap); if (tools.notempty(csid)) uri = tools.glue(uri, \"\/\", csid+\"\/items\/\"); } else if (isput) { uri = fromtestid(uri, testnode, serviceresultsmap); } \/\/vars only make sense in two contexts: post\/put, because you are submitting another file with internal expressions, \/\/ and in <response> nodes. for get, delete, there is no payload, so all the urls with potential expressions are right there in the testnode. map<string,string> vars = null; if (parts.varslist.size()>0){ vars = parts.varslist.get(0); } serviceresult = xmlreplaytransport.dopost_putfromxml(parts.responsefilename, vars, protohostport, uri, method, contenttype, evalstruct, authfortest, testidlabel); serviceresult.autodelete = autodelete; if (vars!=null) { serviceresult.addvars(vars); } results.add(serviceresult); \/\/if (ispost){ serviceresultsmap.put(testid, serviceresult); \/\/puts do not return a location, so don't add puts to serviceresultsmap. \/\/} fullurl = fixupfullurl(fullurl, protohostport, uri); } else if (method.equalsignorecase(\"delete\")){ string fromtestid = testnode.valueof(\"fromtestid\"); serviceresult pr = serviceresultsmap.get(fromtestid); if (pr!=null){ serviceresult = xmlreplaytransport.dodelete(pr.deleteurl, authfortest, testidlabel, fromtestid); serviceresult.fromtestid = fromtestid; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } results.add(serviceresult); if (serviceresult.codeinsuccessrange(serviceresult.responsecode)){ \/\/gotexpectedresult depends on serviceresult.expectedcodes. serviceresultsmap.remove(fromtestid); } } else { if (tools.notempty(fromtestid)){ serviceresult = new serviceresult(); serviceresult.responsecode = 0; serviceresult.error = \"id not found in element fromtestid: \"+fromtestid; system.err.println(\"****\\r\\nserviceresult: \"+serviceresult.error+\". skipping test. full url: \"+fullurl); } else { serviceresult = xmlreplaytransport.dodelete(fullurl, authfortest, testid, fromtestid); } serviceresult.fromtestid = fromtestid; results.add(serviceresult); } } else if (method.equalsignorecase(\"get\")){ fullurl = fromtestid(fullurl, testnode, serviceresultsmap); serviceresult = xmlreplaytransport.doget(fullurl, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else if (method.equalsignorecase(\"list\")){ fullurl = fixupfullurl(fullurl, protohostport, uri); string listqueryparams = \"\"; \/\/todo: empty for now, later may pick up from xml control file. serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); } system.out.println(timestring()+\" \"+leader+serviceresultrow+\"\\r\\n\"); if (dump.payloads || (doingauto&&haserror) ) { if (tools.notblank(serviceresult.requestpayload)){ system.out.println(\"\\r\\n========== request payload ===============\"); system.out.println(serviceresult.requestpayload); system.out.println(\"==========================================\\r\\n\"); } } if (dump.payloads || (doingauto&&haserror)) { if (tools.notblank(serviceresult.result)){ system.out.println(\"\\r\\n========== response payload ==============\"); system.out.println(serviceresult.result); system.out.println(\"==========================================\\r\\n\"); } } } catch (throwable t) { string msg = \"error: xmlreplay experienced an error in a test node: \"+testnode+\" throwable: \"+t; system.out.println(msg); system.out.println(tools.getstacktrace(t)); serviceresult serviceresult = new serviceresult(); serviceresult.error = msg; serviceresult.failurereason = \" : system error; \"; results.add(serviceresult); } } if (tools.istrue(autodeleteposts) && param_autodeleteposts){ autodelete(serviceresultsmap, \"default\", 0); } } \/\/=== now spit out the html report file === file m = new file(controlfilename); string localname = m.getname();\/\/don't instantiate, just use file to extract file name without directory. string reportname = localname+'-'+testgroupid+\".html\"; file resultfile = report.savereport(xmlreplaybasedir, reportsdir, reportname); if (resultfile!=null) { string toc = report.gettoc(reportname); reportslist.add(toc); } \/\/================================ return results; }","classification":"NONSATD","isFinished":true,"code_context_2":"serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/=====================================================","code_context_10":"if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){","code_context_20":"serviceresult = xmlreplaytransport.dolist(fullurl, listqueryparams, authfortest, testidlabel); results.add(serviceresult); serviceresultsmap.put(testid, serviceresult); } else { throw new exception(\"http method not supported by xmlreplay: \"+method); } serviceresult.testid = testid; serviceresult.fullurl = fullurl; serviceresult.auth = authfortest; serviceresult.method = method; if (expectedcodes.size()>0){ serviceresult.expectedcodes = expectedcodes; } if (tools.isempty(serviceresult.testid)) serviceresult.testid = testidlabel; if (tools.isempty(serviceresult.testgroupid)) serviceresult.testgroupid = testgroupid; node expectedlevel = testnode.selectsinglenode(\"response\/expected\"); if (expectedlevel!=null){ string level = expectedlevel.valueof(\"@level\"); serviceresult.payloadstrictness = level; } \/\/===================================================== \/\/ all validation for all requests is done here: \/\/===================================================== boolean haserror = false; string verror = validateresponse(serviceresult, serviceresultsmap, expectedresponseparts, evalstruct); if (tools.notempty(verror)){ serviceresult.error = verror; serviceresult.failurereason = \" : validation error; \"; haserror = true; } if (haserror == false){ haserror = ! serviceresult.gotexpectedresult(); } boolean doingauto = (dump.dumpserviceresult == serviceresult.dump_options.auto); string serviceresultrow = serviceresult.dump(dump.dumpserviceresult, haserror)+\"; time:\"+(system.currenttimemillis()-starttime); string leader = (dump.dumpserviceresult == serviceresult.dump_options.detailed) ? \"xmlreplay:\"+testidlabel+\": \": \"\"; report.addtestresult(serviceresult); if ( (dump.dumpserviceresult == serviceresult.dump_options.detailed) || (dump.dumpserviceresult == serviceresult.dump_options.full) ){ system.out.println(\"\\r\\n#---------------------#\"); }","repo":"litchfieldhistoricalsociety\/services"}
{"id":25235,"comment_id":0,"comment":"\/\/ @issue(\"security-580\")","code":"\/\/ @issue(\"security-580\") @test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","classification":"NONSATD","isFinished":true,"code_context_2":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","code_context_10":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","code_context_20":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","repo":"maheshp\/gocd-groovy-dsl-config-plugin"}
{"id":25235,"comment_id":1,"comment":"\/\/ these go through a different code path:","code":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","classification":"NONSATD","isFinished":true,"code_context_2":"assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\");","code_context_10":"public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\");","code_context_20":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","repo":"maheshp\/gocd-groovy-dsl-config-plugin"}
{"id":25235,"comment_id":2,"comment":"\/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/","code":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","classification":"DESIGN","isFinished":true,"code_context_2":"assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\");","code_context_10":"assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","code_context_20":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","repo":"maheshp\/gocd-groovy-dsl-config-plugin"}
{"id":25235,"comment_id":3,"comment":"\/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/","code":"@test public void positionalconstructors() throws exception { assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"['true'] as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"['true'] as boolean\"); string cc = \"staticmethod org.kohsuke.groovy.sandbox.impl.checker checkedcast java.lang.class java.lang.object boolean boolean boolean\"; assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"boolean x = ['true']; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","code_context_10":"assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","code_context_20":"assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"boolean x = ['true']; x\"); assertrejected(new proxywhitelist(), \"new java.util.treemap java.util.map\", \"[k: 1] as treemap\"); assertevaluate(new staticwhitelist(\"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"[k: 1] as treemap\"); assertrejected(new staticwhitelist(cc), \"new java.util.treemap java.util.map\", \"treemap x = [k: 1]; x\"); assertevaluate(new staticwhitelist(cc, \"new java.util.treemap java.util.map\"), collections.singletonmap(\"k\", 1), \"treemap x = [k: 1]; x\"); \/\/ these go through a different code path: assertevaluate(new proxywhitelist(), arrays.aslist(1), \"[1] as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"['v'] as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(1), \"linkedlist x = [1]; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"linkedlist x = ['v']; x\"); assertevaluate(new proxywhitelist(), arrays.aslist(1), \"int[] a = [1]; a as linkedlist\"); assertevaluate(new proxywhitelist(), arrays.aslist(\"v\"), \"string[] a = ['v']; a as linkedlist\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); assertevaluate(new staticwhitelist(cc), arrays.aslist(\"v\"), \"string[] a = ['v']; linkedlist x = a; x\"); \/* todo casting arrays is not yet supported: assertrejected(new staticwhitelist(cc), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; boolean x = a; x\"); assertevaluate(new staticwhitelist(cc, \"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; boolean x = a; x\"); assertrejected(new proxywhitelist(), \"new java.lang.boolean java.lang.string\", \"string[] a = ['true']; a as boolean\"); assertevaluate(new staticwhitelist(\"new java.lang.boolean java.lang.string\"), true, \"string[] a = ['true']; a as boolean\"); *\/ \/* todo tuple assignment is not yet supported: assertrejected(new proxywhitelist(), \"new java.util.linkedlist java.util.collection\", \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); assertevaluate(new staticwhitelist(\"new java.util.linkedlist java.util.collection\"), arrays.aslist(\"v\"), \"string[] a = ['v']; def (linkedlist x, int y) = [a, 1]; x\"); *\/ }","repo":"maheshp\/gocd-groovy-dsl-config-plugin"}
{"id":685,"comment_id":0,"comment":"\/\/ todo show resulting document","code":"public static final int testelementparsing ( final printstream out, final bufferedreader in, final string ... args) { final string ans=getval(out, in, \"use owner document y\/[n]\/q\"); if (isquit(ans)) return 0; document owner=null; if ((ans != null) && (ans.length() > 0) && ('y' == character.tolowercase(ans.charat(0)))) { try { owner = domutils.createdefaultdocument(); } catch(parserconfigurationexception e) { system.err.println(e.getclass().getname() + \": \" + e.getmessage()); } } final int nerr=testelementparsing(out, in, owner, args); if (owner != null) { \/\/ todo show resulting document } return nerr; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"if (owner != null) { \/\/ todo show resulting document } return nerr;","code_context_10":"owner = domutils.createdefaultdocument(); } catch(parserconfigurationexception e) { system.err.println(e.getclass().getname() + \": \" + e.getmessage()); } } final int nerr=testelementparsing(out, in, owner, args); if (owner != null) { \/\/ todo show resulting document } return nerr; }","code_context_20":"final printstream out, final bufferedreader in, final string ... args) { final string ans=getval(out, in, \"use owner document y\/[n]\/q\"); if (isquit(ans)) return 0; document owner=null; if ((ans != null) && (ans.length() > 0) && ('y' == character.tolowercase(ans.charat(0)))) { try { owner = domutils.createdefaultdocument(); } catch(parserconfigurationexception e) { system.err.println(e.getclass().getname() + \": \" + e.getmessage()); } } final int nerr=testelementparsing(out, in, owner, args); if (owner != null) { \/\/ todo show resulting document } return nerr; }","repo":"lgoldstein\/communitychest"}
{"id":33498,"comment_id":0,"comment":"\/\/ special handling for escaped lines","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false);","code_context_10":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--;","code_context_20":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first?","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":1,"comment":"\/\/ noi18n","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else {","code_context_10":"c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out;","code_context_20":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out;","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":2,"comment":"\/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first?","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"DESIGN","isFinished":true,"code_context_2":"} else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': {","code_context_10":"if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out;","code_context_20":"while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment {","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":3,"comment":"\/\/ char literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\";","code_context_10":"} else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/':","code_context_20":"if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":4,"comment":"\/\/ in single-line or doxygen comment","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true);","code_context_10":"assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true);","code_context_20":"\/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":5,"comment":"\/\/ found \/=","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment","code_context_10":"return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash);","code_context_20":"return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') {","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":6,"comment":"\/\/ in multi-line or doxygen comment","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true);","code_context_10":"case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') {","code_context_20":"case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":7,"comment":"\/\/ end of switch()","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash);","code_context_10":"return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) {","code_context_20":"token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1);","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":8,"comment":"\/\/ >>","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq);","code_context_10":"backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt);","code_context_20":"} case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":9,"comment":"\/\/ >=","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); }","code_context_10":"backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+':","code_context_20":"assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) {","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":10,"comment":"\/\/ invalid comment end - *\/ or int*\/* *\/","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2);","code_context_10":"} backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1);","code_context_20":"} backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar);","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":11,"comment":"\/\/ ellipsis ...","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else {","code_context_10":"backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1);","code_context_20":"return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde);","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":12,"comment":"\/\/ float literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') {","code_context_10":"} backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope);","code_context_20":"} case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":13,"comment":"\/\/ in a number literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal","code_context_10":"case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3':","code_context_20":"case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":14,"comment":"\/\/ in hexadecimal (possibly floating-point) literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false;","code_context_10":"case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5':","code_context_20":"case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":15,"comment":"\/\/ in bianry literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) {","code_context_10":"return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6':","code_context_20":"return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":16,"comment":"\/\/ hex float literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true;","code_context_10":"case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p':","code_context_20":"case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal);","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":17,"comment":"\/\/ two dots in the float literal","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); }","code_context_10":"case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u':","code_context_20":"case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":18,"comment":"\/\/ 0x1234l or 0x1234l","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p':","code_context_10":"case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid","code_context_20":"case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":19,"comment":"\/\/ binary exponent","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u':","code_context_10":"if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); }","code_context_20":"case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7':","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":20,"comment":"\/\/ if float then before mandatory binary exponent => invalid","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal);","code_context_10":"case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4':","code_context_20":"case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline();","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":21,"comment":"\/\/ end of while(true)","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":": cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false);","code_context_10":"return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8':","code_context_20":"infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":22,"comment":"\/\/ noi18n","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else {","code_context_10":"c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out;","code_context_20":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out;","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":23,"comment":"\/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' ']","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b:","code_context_10":"case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true);","code_context_20":"} \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break;","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":24,"comment":"\/\/ return single space as flyweight token","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n","code_context_10":"case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; }","code_context_20":"return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r');","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":25,"comment":"\/\/ noi18n","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else {","code_context_10":"c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out;","code_context_20":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out;","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":26,"comment":"\/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar);","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c);","code_context_10":"} return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true);","code_context_20":"case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') {","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":27,"comment":"\/\/ ur, ur or lr","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true);","code_context_10":"case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); }","code_context_20":"return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\";","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":28,"comment":"\/\/ u8","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') {","code_context_10":"c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote();","code_context_20":"if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":29,"comment":"\/\/ u8r","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true);","code_context_10":"int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) {","code_context_20":"break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) {","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":30,"comment":"\/\/ string with l\/u\/u\/r prefixes","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\";","code_context_10":"} else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1);","code_context_20":"default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c);","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":31,"comment":"\/\/ char with l or u\/u prefix","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\";","code_context_10":"raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql();","code_context_20":"boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":32,"comment":"\/\/ invalid char","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); }","code_context_10":"token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","code_context_20":"\/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":33,"comment":"\/\/ end of switch (c)","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":"return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","code_context_10":"} } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","code_context_20":"return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","repo":"leginee\/netbeans"}
{"id":33498,"comment_id":34,"comment":"\/\/ end of while(true)","code":"@suppresswarnings(\"fallthrough\") @override public token<cpptokenid> nexttoken() { while (true) { \/\/ special handling for escaped lines if (lasttokenendedbyescapedline > 0) { int c = read(false); lasttokenendedbyescapedline--; assert c == '\\\\' : \"there must be \\\\\"; c = read(false); assert c == '\\n' || c == '\\r' : \"there must be \\r or \\n\"; if (c == '\\r') { lasttokenendedbyescapedline--; if (input.consumenewline()) { lasttokenendedbyescapedline--; } return token(cpptokenid.escaped_line); } else { lasttokenendedbyescapedline--; return token(cpptokenid.escaped_line, \"\\\\\\n\", parttype.complete); \/\/ noi18n } } else { int c = read(true); \/\/ if read of the first char caused skipping escaped line \/\/ do we need to backup and create escaped lines first? switch (c) { case '\"': { token<cpptokenid> out = finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } case '\\'': {\/\/ char literal token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } case '#': { token<cpptokenid> out = finishsharp(); assert out != null : \"not handled #\"; return out; } case '\/': switch (read(true)) { case '\/': \/\/ in single-line or doxygen comment { token<cpptokenid> out = finishlinecomment(true); assert out != null : \"not handled \/\/\"; return out; } case '=': \/\/ found \/= return token(cpptokenid.slasheq); case '*': \/\/ in multi-line or doxygen comment { token<cpptokenid> out = finishblockcomment(true); assert out != null : \"not handled \/*\"; return out; } } \/\/ end of switch() backup(1); return token(cpptokenid.slash); case '=': if (read(true) == '=') { return token(cpptokenid.eqeq); } backup(1); return token(cpptokenid.eq); case '>': switch (read(true)) { case '>': \/\/ >> if (read(true) == '=') { return token(cpptokenid.gtgteq); } backup(1); return token(cpptokenid.gtgt); case '=': \/\/ >= return token(cpptokenid.gteq); } backup(1); return token(cpptokenid.gt); case '<': { token<cpptokenid> out = finishlt(); assert out != null : \"not handled '<'\"; return out; } case '+': switch (read(true)) { case '+': return token(cpptokenid.plusplus); case '=': return token(cpptokenid.pluseq); } backup(1); return token(cpptokenid.plus); case '-': switch (read(true)) { case '-': return token(cpptokenid.minusminus); case '>': if (read(true) == '*') { return token(cpptokenid.arrowmbr); } backup(1); return token(cpptokenid.arrow); case '=': return token(cpptokenid.minuseq); } backup(1); return token(cpptokenid.minus); case '*': switch (read(true)) { case '\/': \/\/ invalid comment end - *\/ or int*\/* *\/ if (read(true) == '*') { backup(2); return token(cpptokenid.star); } backup(1); return token(cpptokenid.invalid_comment_end); case '=': return token(cpptokenid.stareq); } backup(1); return token(cpptokenid.star); case '|': switch (read(true)) { case '|': return token(cpptokenid.barbar); case '=': return token(cpptokenid.bareq); } backup(1); return token(cpptokenid.bar); case '&': switch (read(true)) { case '&': return token(cpptokenid.ampamp); case '=': return token(cpptokenid.ampeq); } backup(1); return token(cpptokenid.amp); case '%': { token<cpptokenid> out = finishpercent(); assert out != null : \"not handled %\"; return out; } case '^': if (read(true) == '=') { return token(cpptokenid.careteq); } backup(1); return token(cpptokenid.caret); case '!': if (read(true) == '=') { return token(cpptokenid.noteq); } backup(1); return token(cpptokenid.not); case '.': if ((c = read(true)) == '.') { if (read(true) == '.') { \/\/ ellipsis ... return token(cpptokenid.ellipsis); } else { input.backup(2); } } else if ('0' <= c && c <= '9') { \/\/ float literal return finishnumberliteral(read(true), true); } else if (c == '*') { return token(cpptokenid.dotmbr); } else { backup(1); } return token(cpptokenid.dot); case ':': if (read(true) == ':') { return token(cpptokenid.scope); } backup(1); return token(cpptokenid.colon); case '~': return token(cpptokenid.tilde); case ',': return token(cpptokenid.comma); case ';': return token(cpptokenid.semicolon); case '?': return token(cpptokenid.question); case '(': return token(cpptokenid.lparen); case ')': return token(cpptokenid.rparen); case '[': return token(cpptokenid.lbracket); case ']': return token(cpptokenid.rbracket); case '{': return token(cpptokenid.lbrace); case '}': return token(cpptokenid.rbrace); case '`': return token(cpptokenid.grave_accent); case '@': return token(cpptokenid.at); case '0': \/\/ in a number literal c = read(true); if (c == 'x' || c == 'x' || \/\/ in hexadecimal (possibly floating-point) literal c == 'b' || c == 'b' ) { \/\/ in bianry literal boolean infraction = false; while (true) { switch (read(true)) { case '0': case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': case 'a': case 'b': case 'c': case 'd': case 'e': case 'f': break; case '.': \/\/ hex float literal if (!infraction) { infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow \/\/ ['\\t' - '\\f'] and [0x1c - ' '] case '\\t': case 0x0b: case '\\f': case 0x1c: case 0x1d: case 0x1e: case 0x1f: return finishwhitespace(); case ' ': c = read(true); if (c == eof || !character.iswhitespace(c) || c == '\\n' || c == '\\r') { \/\/ return single space as flyweight token backup(1); return token(cpptokenid.whitespace, \" \", parttype.complete); \/\/ noi18n } return finishwhitespace(); case eof: if (istokensplittedbyescapedline()) { backup(1); assert lasttokenendedbyescapedline > 0 : \"lasttokenendedbyescapedline is \" + lasttokenendedbyescapedline; break; } return null; case '$': \/\/ dollar is extension in gcc and msvc $ is a valid start of identifiers \/\/ return token(cpptokenid.dollar); default: c = translatesurrogates(c); if (cndlexerutilities.iscppidentifierstart(c)) { if (c == 'l' || c == 'u' || c == 'u' || c == 'r') { int next = read(true); boolean raw_string = (c == 'r'); if (next == 'r' && (c == 'u' || c == 'u' || c == 'l')) { \/\/ ur, ur or lr raw_string = true; next = read(true); } else if (next == '8' && c == 'u') { \/\/ u8 next = read(true); if (next == 'r') { \/\/ u8r raw_string = true; next = read(true); } } if (next == '\"') { \/\/ string with l\/u\/u\/r prefixes token<cpptokenid> out = raw_string ? finishrawstring() : finishdblquote(); assert out != null : \"not handled dobule quote\"; return out; } else if (next == '\\'' && !raw_string) { \/\/ char with l or u\/u prefix token<cpptokenid> out = finishsinglequote(); assert out != null : \"not handled single quote\"; return out; } else { backup(1); } } if (c == 'e') { if(isexecsql(c)) { token<cpptokenid> out = finishexecsql(); assert out != null : \"not handled exec sql\"; return out; } } return keywordoridentifier(c); } if (character.iswhitespace(c)) { return finishwhitespace(); } \/\/ invalid char return token(cpptokenid.error); } } \/\/ end of switch (c) } \/\/ end of while(true) }","classification":"NONSATD","isFinished":true,"code_context_2":": cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false);","code_context_10":"return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8':","code_context_20":"infraction = true; } else { \/\/ two dots in the float literal return token(cpptokenid.float_literal_invalid); } break; case 'l': case 'l': \/\/ 0x1234l or 0x1234l return finishlongliteral(read(true)); case 'p': case 'p': \/\/ binary exponent return finishfloatexponent(); case 'u': case 'u': return finishunsignedliteral(read(true)); default: backup(1); \/\/ if float then before mandatory binary exponent => invalid return token(infraction ? cpptokenid.float_literal_invalid : cpptokenid.int_literal); } } \/\/ end of while(true) } return finishnumberliteral(c, false); case '1': case '2': case '3': case '4': case '5': case '6': case '7': case '8': case '9': return finishnumberliteral(read(true), false); case '\\\\': return token(cpptokenid.back_slash); case '\\r': consumenewline(); return token(cpptokenid.new_line); case '\\n': return token(cpptokenid.new_line, \"\\n\", parttype.complete); \/\/ noi18n \/\/ all character.iswhitespace(c) below 0x80 follow","repo":"leginee\/netbeans"}
{"id":25373,"comment_id":0,"comment":"\/\/todo[nik] implement?","code":"protected void evaluateandshowhint() { myevaluator.evaluate(myexpression, new xevaluationcallbackbase() { public void evaluated(@notnull final xvalue result) { result.computepresentation(new xvaluenode() { @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string value, boolean haschildren) { setpresentation(icon, type, xdebuggeruiconstants.eq_text, value, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string separator, @nonnls @notnull string value, boolean haschildren) { setpresentation(icon, type, separator, value, null, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string value, @nullable notnullfunction<string, string> valuepresenter, boolean haschildren) { setpresentation(icon, type, xdebuggeruiconstants.eq_text, value, valuepresenter, haschildren); } @override public void setgroupingpresentation(@nullable icon icon, @nonnls @nullable string value, @nullable xvaluepresenter valuepresenter, boolean expand) { setpresentation(icon, value, valuepresenter, true); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string value, @nullable xvaluepresenter valuepresenter, boolean haschildren) { dosetpresentation(icon, null, xdebuggeruiconstants.eq_text, value, valuepresenter, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, @nullable final notnullfunction<string, string> valuepresenter, final boolean haschildren) { dosetpresentation(icon, type, separator, value, valuepresenter == null ? null : new xvaluepresenteradapter(valuepresenter), haschildren); } private void dosetpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @nullable final string value, @nullable final xvaluepresenter valuepresenter, final boolean haschildren) { appuiutil.invokeonedt(new runnable() { public void run() { doshowhint(result, separator, value, type, valuepresenter == null ? xvaluenodeimpl.default_value_presenter : valuepresenter, haschildren); } }); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); } }, myexpressionposition); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() {","code_context_10":"public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); }","code_context_20":"dosetpresentation(icon, type, separator, value, valuepresenter == null ? null : new xvaluepresenteradapter(valuepresenter), haschildren); } private void dosetpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @nullable final string value, @nullable final xvaluepresenter valuepresenter, final boolean haschildren) { appuiutil.invokeonedt(new runnable() { public void run() { doshowhint(result, separator, value, type, valuepresenter == null ? xvaluenodeimpl.default_value_presenter : valuepresenter, haschildren); } }); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); } }, myexpressionposition); }","repo":"liveqmock\/platform-tools-idea"}
{"id":25373,"comment_id":1,"comment":"\/\/todo[nik]","code":"protected void evaluateandshowhint() { myevaluator.evaluate(myexpression, new xevaluationcallbackbase() { public void evaluated(@notnull final xvalue result) { result.computepresentation(new xvaluenode() { @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string value, boolean haschildren) { setpresentation(icon, type, xdebuggeruiconstants.eq_text, value, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string separator, @nonnls @notnull string value, boolean haschildren) { setpresentation(icon, type, separator, value, null, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string type, @nonnls @notnull string value, @nullable notnullfunction<string, string> valuepresenter, boolean haschildren) { setpresentation(icon, type, xdebuggeruiconstants.eq_text, value, valuepresenter, haschildren); } @override public void setgroupingpresentation(@nullable icon icon, @nonnls @nullable string value, @nullable xvaluepresenter valuepresenter, boolean expand) { setpresentation(icon, value, valuepresenter, true); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable string value, @nullable xvaluepresenter valuepresenter, boolean haschildren) { dosetpresentation(icon, null, xdebuggeruiconstants.eq_text, value, valuepresenter, haschildren); } @override public void setpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, @nullable final notnullfunction<string, string> valuepresenter, final boolean haschildren) { dosetpresentation(icon, type, separator, value, valuepresenter == null ? null : new xvaluepresenteradapter(valuepresenter), haschildren); } private void dosetpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @nullable final string value, @nullable final xvaluepresenter valuepresenter, final boolean haschildren) { appuiutil.invokeonedt(new runnable() { public void run() { doshowhint(result, separator, value, type, valuepresenter == null ? xvaluenodeimpl.default_value_presenter : valuepresenter, haschildren); } }); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); } }, myexpressionposition); }","classification":"NONSATD","isFinished":true,"code_context_2":"} public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() {","code_context_10":"public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); }","code_context_20":"dosetpresentation(icon, type, separator, value, valuepresenter == null ? null : new xvaluepresenteradapter(valuepresenter), haschildren); } private void dosetpresentation(@nullable icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @nullable final string value, @nullable final xvaluepresenter valuepresenter, final boolean haschildren) { appuiutil.invokeonedt(new runnable() { public void run() { doshowhint(result, separator, value, type, valuepresenter == null ? xvaluenodeimpl.default_value_presenter : valuepresenter, haschildren); } }); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, value, haschildren); } public void setpresentation(@nonnls final string name, @nullable final icon icon, @nonnls @nullable final string type, @nonnls @notnull final string separator, @nonnls @notnull final string value, final boolean haschildren) { setpresentation(icon, type, separator, value, haschildren); } public void setfullvalueevaluator(@notnull xfullvalueevaluator fullvalueevaluator) { \/\/todo[nik] implement? } public boolean isobsolete() { \/\/todo[nik] return false; } }, xvalueplace.tooltip); } public void erroroccurred(@notnull final string errormessage) { log.debug(\"cannot evaluate '\" + myexpression + \"':\" + errormessage); } }, myexpressionposition); }","repo":"liveqmock\/platform-tools-idea"}
{"id":25388,"comment_id":0,"comment":"\/\/ this method supports only guest network creation","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"DESIGN","isFinished":true,"code_context_2":"final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\");","code_context_10":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering","code_context_20":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate());","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":1,"comment":"\/\/check resource limits","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled);","code_context_10":"final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; }","code_context_20":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true;","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":2,"comment":"\/\/ validate network offering","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"_resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo","code_context_10":"\/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate());","code_context_20":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":3,"comment":"\/\/ see networkofferingvo","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\");","code_context_10":"s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex;","code_context_20":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\");","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":4,"comment":"\/\/ validate physical network","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java","code_context_10":"if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; }","code_context_20":"final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic);","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":5,"comment":"\/\/ see physicalnetworkvo.java","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\");","code_context_10":"} \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) {","code_context_20":"final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":6,"comment":"\/\/ validate zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true","code_context_10":"if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); }","code_context_20":"_resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true;","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":7,"comment":"\/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\");","code_context_10":"final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) {","code_context_20":"\/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\");","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":8,"comment":"\/\/ only one guest network is supported in basic zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) {","code_context_10":"boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) {","code_context_20":"ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":9,"comment":"\/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \"","code_context_10":"if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) {","code_context_20":"\/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":10,"comment":"\/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\");","code_context_10":"} else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic);","code_context_20":"if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":11,"comment":"\/\/don't allow eip\/elb networks in advance zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic);","code_context_10":"} \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null;","code_context_20":"vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":12,"comment":"\/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) {","code_context_10":"} } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk);","code_context_20":"if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \"","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":13,"comment":"\/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation","code_context_10":"final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname());","code_context_20":"\/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri));","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":14,"comment":"\/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \"","code_context_10":"if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){","code_context_20":"throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":15,"comment":"\/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) {","code_context_10":"if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) {","code_context_20":"throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":16,"comment":"\/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0);","code_context_10":"} if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool","code_context_20":"uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } }","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":17,"comment":"\/\/ fail network creation if specified vlan is dedicated to a different account","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid();","code_context_10":"if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) {","code_context_20":"+ zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } }","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":18,"comment":"\/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid());","code_context_10":"\/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } }","code_context_20":"if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } }","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":19,"comment":"\/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid);","code_context_10":"final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns);","code_context_20":"final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":20,"comment":"\/\/ if networkdomain is not specified, take it from the global configuration","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid),","code_context_10":"} } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else {","code_context_20":"if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid);","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":21,"comment":"\/\/ tbd: networkofferingid and zoneid. send uuids instead.","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"DESIGN","isFinished":true,"code_context_2":"if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); }","code_context_10":"} } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); }","code_context_20":"} } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\");","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":22,"comment":"\/\/ 1) get networkdomain from the corresponding account\/domain\/zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid);","code_context_10":"final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else {","code_context_20":"\/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":23,"comment":"\/\/ 2) if null, generate networkdomain using domain suffix from the global config variables","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid);","code_context_10":"throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); }","code_context_20":"} } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)));","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":24,"comment":"\/\/ validate network domain","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \"","code_context_10":"if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges","code_context_20":"service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\");","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":25,"comment":"\/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"DESIGN","isFinished":true,"code_context_2":"} } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest","code_context_10":"} else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); }","code_context_20":"\/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\");","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":26,"comment":"\/\/ no cidr can be specified in basic zone","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"} checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic);","code_context_10":"&& (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain;","code_context_20":"+ \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid);","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":27,"comment":"\/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) {","code_context_10":"throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override","code_context_20":"} \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr);","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":28,"comment":"\/\/logical router's uuid provided as vlan_id","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else {","code_context_10":"if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) {","code_context_20":"usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) {","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":29,"comment":"\/\/set transient field","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk);","code_context_10":"usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan);","code_context_20":"usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal +","repo":"leolleeooleo\/cloudstack"}
{"id":25388,"comment_id":30,"comment":"\/\/ for shared network","code":"@db private network createguestnetwork(final long networkofferingid, final string name, final string displaytext, final string gateway, final string cidr, string vlanid, boolean bypassvlanoverlapcheck, string networkdomain, final account owner, final long domainid, final physicalnetwork pntwk, final long zoneid, final acltype acltype, boolean subdomainaccess, final long vpcid, final string ip6gateway, final string ip6cidr, final boolean isdisplaynetworkenabled, final string isolatedpvlan, network.pvlantype isolatedpvlantype, string externalid, final boolean isprivatenetwork, string routerip, string routeripv6) throws concurrentoperationexception, insufficientcapacityexception, resourceallocationexception { final networkofferingvo ntwkoff = _networkofferingdao.findbyid(networkofferingid); final datacentervo zone = _dcdao.findbyid(zoneid); \/\/ this method supports only guest network creation if (ntwkoff.gettraffictype() != traffictype.guest) { s_logger.warn(\"only guest networks can be created using this method\"); return null; } final boolean updateresourcecount = resourcecountneedsupdate(ntwkoff, acltype); \/\/check resource limits if (updateresourcecount) { _resourcelimitmgr.checkresourcelimit(owner, resourcetype.network, isdisplaynetworkenabled); } \/\/ validate network offering if (ntwkoff.getstate() != networkoffering.state.enabled) { \/\/ see networkofferingvo final invalidparametervalueexception ex = new invalidparametervalueexception(\"can't use specified network offering id as its state is not \" + networkoffering.state.enabled); ex.addproxyobject(ntwkoff.getuuid(), \"networkofferingid\"); throw ex; } \/\/ validate physical network if (pntwk.getstate() != physicalnetwork.state.enabled) { \/\/ see physicalnetworkvo.java final invalidparametervalueexception ex = new invalidparametervalueexception(\"specified physical network id is\" + \" in incorrect state:\" + pntwk.getstate()); ex.addproxyobject(pntwk.getuuid(), \"physicalnetworkid\"); throw ex; } boolean ipv6 = false; if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { ipv6 = true; } \/\/ validate zone if (zone.getnetworktype() == networktype.basic) { \/\/ in basic zone the network should have acltype=domain, domainid=1, subdomainaccess=true if (acltype == null || acltype != acltype.domain) { throw new invalidparametervalueexception(\"only acltype=domain can be specified for network creation in basic zone\"); } \/\/ only one guest network is supported in basic zone final list<networkvo> guestnetworks = _networksdao.listbyzoneandtraffictype(zone.getid(), traffictype.guest); if (!guestnetworks.isempty()) { throw new invalidparametervalueexception(\"can't have more than one guest network in zone with network type \" + networktype.basic); } \/\/ if zone is basic, only shared network offerings w\/o source nat service are allowed if (!(ntwkoff.getguesttype() == guesttype.shared && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))) { throw new invalidparametervalueexception(\"for zone of type \" + networktype.basic + \" only offerings of \" + \"guesttype \" + guesttype.shared + \" with disabled \" + service.sourcenat.getname() + \" service are allowed\"); } if (domainid == null || domainid != domain.root_domain) { throw new invalidparametervalueexception(\"guest network in basic zone should be dedicated to root domain\"); } if (subdomainaccess == null) { subdomainaccess = true; } else if (!subdomainaccess) { throw new invalidparametervalueexception(\"subdomain access should be set to true for the\" + \" guest network in the basic zone\"); } if (vlanid == null) { vlanid = vlan.untagged; } else { if (!vlanid.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"only vlan \" + vlan.untagged + \" can be created in \" + \"the zone of type \" + networktype.basic); } } } else if (zone.getnetworktype() == networktype.advanced) { if (zone.issecuritygroupenabled()) { if (isolatedpvlan != null) { throw new invalidparametervalueexception(\"isolated private vlan is not supported with security group!\"); } \/\/ only account specific isolated network with sourcenat service disabled are allowed in security group \/\/ enabled zone if (ntwkoff.getguesttype() != guesttype.shared) { throw new invalidparametervalueexception(\"only shared guest network can be created in security group enabled zone\"); } if (_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat)) { throw new invalidparametervalueexception(\"service sourcenat is not allowed in security group enabled zone\"); } } \/\/don't allow eip\/elb networks in advance zone if (ntwkoff.iselasticip() || ntwkoff.iselasticlb()) { throw new invalidparametervalueexception(\"elastic ip and elastic lb services are supported in zone of type \" + networktype.basic); } } if (ipv6 && netutils.getip6cidrsize(ip6cidr) != 64) { throw new invalidparametervalueexception(\"ipv6 subnet should be exactly 64-bits in size\"); } \/\/todo(vxlan): support vni specified \/\/ vlanid can be specified only when network offering supports it final boolean vlanspecified = vlanid != null; if (vlanspecified != ntwkoff.isspecifyvlan()) { if (vlanspecified) { throw new invalidparametervalueexception(\"can't specify vlan; corresponding offering says specifyvlan=false\"); } else { throw new invalidparametervalueexception(\"vlan has to be specified; corresponding offering says specifyvlan=true\"); } } if (vlanspecified) { uri uri = encodevlanidintobroadcasturi(vlanid, pntwk); \/\/ aux: generate secondary uri for secondary vlan id (if provided) for performing checks uri secondaryuri = stringutils.isnotblank(isolatedpvlan) ? broadcastdomaintype.fromstring(isolatedpvlan) : null; \/\/don't allow to specify vlan tag used by physical network for dynamic vlan allocation if (!(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(uri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag to use for new guest network, \" + vlanid + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (secondaryuri != null && !(bypassvlanoverlapcheck && ntwkoff.getguesttype() == guesttype.shared) && _dcdao.findvnet(zoneid, pntwk.getid(), broadcastdomaintype.getvalue(secondaryuri)).size() > 0) { throw new invalidparametervalueexception(\"the vlan tag for isolated pvlan \" + isolatedpvlan + \" is already being used for dynamic vlan allocation for the guest network in zone \" + zone.getname()); } if (! uuidutils.validateuuid(vlanid)){ \/\/ for isolated and l2 networks, don't allow to create network with vlan that already exists in the zone if (!hasguestbypassvlanoverlapcheck(bypassvlanoverlapcheck, ntwkoff, isprivatenetwork)) { if (_networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanid + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else if (secondaryuri != null && _networksdao.listbyzoneanduriandguesttype(zoneid, secondaryuri.tostring(), null).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + isolatedpvlan + \" already exists or overlaps with other network vlans in zone \" + zoneid); } else { final list<datacentervnetvo> dcvnets = _datacentervnetdao.findvnet(zoneid, broadcastdomaintype.getvalue(uri)); \/\/for the network that is created as part of private gateway, \/\/the vnet is not coming from the data center vnet table, so the list can be empty if (!dcvnets.isempty()) { final datacentervnetvo dcvnet = dcvnets.get(0); \/\/ fail network creation if specified vlan is dedicated to a different account if (dcvnet.getaccountguestvlanmapid() != null) { final long accountguestvlanmapid = dcvnet.getaccountguestvlanmapid(); final accountguestvlanmapvo map = _accountguestvlanmapdao.findbyid(accountguestvlanmapid); if (map.getaccountid() != owner.getaccountid()) { throw new invalidparametervalueexception(\"vlan \" + vlanid + \" is dedicated to a different account\"); } \/\/ fail network creation if owner has a dedicated range of vlans but the specified vlan belongs to the system pool } else { final list<accountguestvlanmapvo> maps = _accountguestvlanmapdao.listaccountguestvlanmapsbyaccount(owner.getaccountid()); if (maps != null && !maps.isempty()) { final int vnetsallocatedtoaccount = _datacentervnetdao.countvnetsallocatedtoaccount(zoneid, owner.getaccountid()); final int vnetsdedicatedtoaccount = _datacentervnetdao.countvnetsdedicatedtoaccount(zoneid, owner.getaccountid()); if (vnetsallocatedtoaccount < vnetsdedicatedtoaccount) { throw new invalidparametervalueexception(\"specified vlan \" + vlanid + \" doesn't belong\" + \" to the vlan range dedicated to the owner \" + owner.getaccountname()); } } } } } } else { \/\/ don't allow to creating shared network with given vlan id, if there already exists a isolated network or \/\/ shared network with same vlan id in the zone if (!bypassvlanoverlapcheck && _networksdao.listbyzoneanduriandguesttype(zoneid, uri.tostring(), guesttype.isolated).size() > 0 ) { throw new invalidparametervalueexception(\"there is an existing isolated\/shared network that overlaps with vlan id:\" + vlanid + \" in zone \" + zoneid); } } } } \/\/ if networkdomain is not specified, take it from the global configuration if (_networkmodel.areservicessupportedbynetworkoffering(networkofferingid, service.dns)) { final map<network.capability, string> dnscapabilities = _networkmodel.getnetworkofferingservicecapabilities(_entitymgr.findbyid(networkoffering.class, networkofferingid), service.dns); final string isupdatednssupported = dnscapabilities.get(capability.allowdnssuffixmodification); if (isupdatednssupported == null || !boolean.valueof(isupdatednssupported)) { if (networkdomain != null) { \/\/ tbd: networkofferingid and zoneid. send uuids instead. throw new invalidparametervalueexception(\"domain name change is not supported by network offering id=\" + networkofferingid + \" in zone id=\" + zoneid); } } else { if (networkdomain == null) { \/\/ 1) get networkdomain from the corresponding account\/domain\/zone if (acltype == acltype.domain) { networkdomain = _networkmodel.getdomainnetworkdomain(domainid, zoneid); } else if (acltype == acltype.account) { networkdomain = _networkmodel.getaccountnetworkdomain(owner.getid(), zoneid); } \/\/ 2) if null, generate networkdomain using domain suffix from the global config variables if (networkdomain == null) { networkdomain = \"cs\" + long.tohexstring(owner.getid()) + guestdomainsuffix.valuein(zoneid); } } else { \/\/ validate network domain if (!netutils.verifydomainname(networkdomain)) { throw new invalidparametervalueexception(\"invalid network domain. total length shouldn't exceed 190 chars. each domain \" + \"label must be between 1 and 63 characters long, can contain ascii letters 'a' through 'z', the digits '0' through '9', \" + \"and the hyphen ('-'); can't start or end with \\\"-\\\"\"); } } } } \/\/ in advance zone cidr for shared networks and isolated networks w\/o source nat service can't be null - 2.2.x \/\/ limitation, remove after we introduce support for multiple ip ranges \/\/ with different cidrs for the same shared network final boolean cidrrequired = zone.getnetworktype() == networktype.advanced && ntwkoff.gettraffictype() == traffictype.guest && (ntwkoff.getguesttype() == guesttype.shared || (ntwkoff.getguesttype() == guesttype.isolated && !_networkmodel.areservicessupportedbynetworkoffering(ntwkoff.getid(), service.sourcenat))); if (cidr == null && ip6cidr == null && cidrrequired) { if (ntwkoff.getguesttype() == guesttype.shared) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask are required when create network of\" + \" type \" + network.guesttype.shared); } else { throw new invalidparametervalueexception(\"gateway\/netmask are required when create network of\" + \" type \" + guesttype.isolated + \" with service \" + service.sourcenat.getname() + \" disabled\"); } } checkl2offeringservices(ntwkoff); \/\/ no cidr can be specified in basic zone if (zone.getnetworktype() == networktype.basic && cidr != null) { throw new invalidparametervalueexception(\"startip\/endip\/gateway\/netmask can't be specified for zone of type \" + networktype.basic); } \/\/ check if cidr is rfc1918 compliant if the network is guest isolated for ipv4 if (cidr != null && ntwkoff.getguesttype() == network.guesttype.isolated && ntwkoff.gettraffictype() == traffictype.guest) { if (!netutils.validateguestcidr(cidr)) { throw new invalidparametervalueexception(\"virtual guest cidr \" + cidr + \" is not rfc 1918 or 6598 compliant\"); } } final string networkdomainfinal = networkdomain; final string vlanidfinal = vlanid; final boolean subdomainaccessfinal = subdomainaccess; final network network = transaction.execute(new transactioncallback<network>() { @override public network dointransaction(final transactionstatus status) { long physicalnetworkid = null; if (pntwk != null) { physicalnetworkid = pntwk.getid(); } final datacenterdeployment plan = new datacenterdeployment(zoneid, null, null, null, null, physicalnetworkid); final networkvo usernetwork = new networkvo(); usernetwork.setnetworkdomain(networkdomainfinal); if (cidr != null && gateway != null) { usernetwork.setcidr(cidr); usernetwork.setgateway(gateway); } if (stringutils.isnoneblank(ip6gateway, ip6cidr)) { usernetwork.setip6cidr(ip6cidr); usernetwork.setip6gateway(ip6gateway); } if (externalid != null) { usernetwork.setexternalid(externalid); } if (stringutils.isnotblank(routerip)) { usernetwork.setrouterip(routerip); } if (stringutils.isnotblank(routeripv6)) { usernetwork.setrouteripv6(routeripv6); } if (vlanidfinal != null) { if (isolatedpvlan == null) { uri uri = null; if (uuidutils.validateuuid(vlanidfinal)){ \/\/logical router's uuid provided as vlan_id usernetwork.setvlanidasuuid(vlanidfinal); \/\/set transient field } else { uri = encodevlanidintobroadcasturi(vlanidfinal, pntwk); } if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring()).size() > 0) { throw new invalidparametervalueexception(\"network with vlan \" + vlanidfinal + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); if (!vlanidfinal.equalsignorecase(vlan.untagged)) { usernetwork.setbroadcastdomaintype(broadcastdomaintype.vlan); } else { usernetwork.setbroadcastdomaintype(broadcastdomaintype.native); } } else { if (vlanidfinal.equalsignorecase(vlan.untagged)) { throw new invalidparametervalueexception(\"cannot support pvlan with untagged primary vlan!\"); } uri uri = netutils.generateuriforpvlan(vlanidfinal, isolatedpvlan, isolatedpvlantype.tostring()); if (_networksdao.listbyphysicalnetworkpvlan(physicalnetworkid, uri.tostring(), isolatedpvlantype).size() > 0) { throw new invalidparametervalueexception(\"network with primary vlan \" + vlanidfinal + \" and secondary vlan \" + isolatedpvlan + \" type \" + isolatedpvlantype + \" already exists or overlaps with other network pvlans in zone \" + zoneid); } usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","classification":"NONSATD","isFinished":true,"code_context_2":"network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); }","code_context_10":"} else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid());","code_context_20":"usernetwork.setbroadcasturi(uri); usernetwork.setbroadcastdomaintype(broadcastdomaintype.pvlan); usernetwork.setpvlantype(isolatedpvlantype); } } final list<? extends network> networks = setupnetwork(owner, ntwkoff, usernetwork, plan, name, displaytext, true, domainid, acltype, subdomainaccessfinal, vpcid, isdisplaynetworkenabled); network network = null; if (networks == null || networks.isempty()) { throw new cloudruntimeexception(\"fail to create a network\"); } else { if (networks.size() > 0 && networks.get(0).getguesttype() == network.guesttype.isolated && networks.get(0).gettraffictype() == traffictype.guest) { network defaultguestnetwork = networks.get(0); for (final network nw : networks) { if (nw.getcidr() != null && nw.getcidr().equals(zone.getguestnetworkcidr())) { defaultguestnetwork = nw; } } network = defaultguestnetwork; } else { \/\/ for shared network network = networks.get(0); } } if (updateresourcecount) { _resourcelimitmgr.incrementresourcecount(owner.getid(), resourcetype.network, isdisplaynetworkenabled); } return network; } }); callcontext.current().seteventdetails(\"network id: \" + network.getid()); callcontext.current().putcontextparameter(network.class, network.getuuid()); return network; }","repo":"leolleeooleo\/cloudstack"}
{"id":25403,"comment_id":0,"comment":"\/** * serializes a dom document to string. * * public for other transformation plugins * todo refactor out to own class * * @param document the document to serialize. * @param output the output to print errors to. * * @return the serialized document as string. *\/","code":"\/** * serializes a dom document to string. * * public for other transformation plugins * todo refactor out to own class * * @param document the document to serialize. * @param output the output to print errors to. * * @return the serialized document as string. *\/ public static string domtostring(document document) { source source = new domsource(document); try { transformerfactory factory = transformerfactory.newinstance(); transformer transformer = factory.newtransformer(); transformer.setoutputproperty(outputkeys. indent, \"yes\"); transformer.setoutputproperty(\"{http:\/\/xml.apache.org\/xslt}indent-amount\", \"1\"); stringwriter sw=new stringwriter(); streamresult resultstream = new streamresult(sw); transformer.transform(source, resultstream); return sw.tostring(); } catch (transformerexception e) { return e.tostring(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"public static string domtostring(document document) { source source = new domsource(document); try { transformerfactory factory = transformerfactory.newinstance(); transformer transformer = factory.newtransformer(); transformer.setoutputproperty(outputkeys. indent, \"yes\"); transformer.setoutputproperty(\"{http:\/\/xml.apache.org\/xslt}indent-amount\", \"1\"); stringwriter sw=new stringwriter(); streamresult resultstream = new streamresult(sw); transformer.transform(source, resultstream); return sw.tostring(); } catch (transformerexception e) { return e.tostring(); } }","code_context_10":"public static string domtostring(document document) { source source = new domsource(document); try { transformerfactory factory = transformerfactory.newinstance(); transformer transformer = factory.newtransformer(); transformer.setoutputproperty(outputkeys. indent, \"yes\"); transformer.setoutputproperty(\"{http:\/\/xml.apache.org\/xslt}indent-amount\", \"1\"); stringwriter sw=new stringwriter(); streamresult resultstream = new streamresult(sw); transformer.transform(source, resultstream); return sw.tostring(); } catch (transformerexception e) { return e.tostring(); } }","code_context_20":"public static string domtostring(document document) { source source = new domsource(document); try { transformerfactory factory = transformerfactory.newinstance(); transformer transformer = factory.newtransformer(); transformer.setoutputproperty(outputkeys. indent, \"yes\"); transformer.setoutputproperty(\"{http:\/\/xml.apache.org\/xslt}indent-amount\", \"1\"); stringwriter sw=new stringwriter(); streamresult resultstream = new streamresult(sw); transformer.transform(source, resultstream); return sw.tostring(); } catch (transformerexception e) { return e.tostring(); } }","repo":"mino98\/stix"}
{"id":25580,"comment_id":0,"comment":"\/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice()","code":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove(); if (key.isvalid() && key.isreadable()) { object attachment = key.attachment(); if (attachment instanceof device) { device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } } } } } catch (ioexception e) { if (mquit == false) { } } } while (mquit == false); }","classification":"NONSATD","isFinished":true,"code_context_2":"do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { }","code_context_10":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance();","code_context_20":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport();","repo":"lrscp\/ControlAndroidDeviceFromPC"}
{"id":25580,"comment_id":1,"comment":"\/* notify *\/","code":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove(); if (key.isvalid() && key.isreadable()) { object attachment = key.attachment(); if (attachment instanceof device) { device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } } } } } catch (ioexception e) { if (mquit == false) { } } } while (mquit == false); }","classification":"NONSATD","isFinished":true,"code_context_2":"device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake!","code_context_10":"if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list);","code_context_20":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) {","repo":"lrscp\/ControlAndroidDeviceFromPC"}
{"id":25580,"comment_id":2,"comment":"\/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake!","code":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove(); if (key.isvalid() && key.isreadable()) { object attachment = key.attachment(); if (attachment instanceof device) { device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } } } } } catch (ioexception e) { if (mquit == false) { } } } while (mquit == false); }","classification":"DESIGN","isFinished":true,"code_context_2":"int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client);","code_context_10":"return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear();","code_context_20":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove();","repo":"lrscp\/ControlAndroidDeviceFromPC"}
{"id":25580,"comment_id":3,"comment":"\/\/ restart the monitoring of that device","code":"private void deviceclientmonitorloop() { do { try { \/\/ this synchronized block stops us from doing the select() if a new \/\/ device is being added. \/\/ @see startmonitoringdevice() synchronized (mdevices) { } int count = mselector.select(); if (mquit) { return; } synchronized (mclientstoreopen) { if (mclientstoreopen.size() > 0) { set<client> clients = mclientstoreopen.keyset(); monitorthread monitorthread = monitorthread.getinstance(); for (client client : clients) { device device = client.getdeviceimpl(); int pid = client.getclientdata().getpid(); monitorthread.dropclient(client, false \/* notify *\/); \/\/ this is kinda bad, but if we don't wait a bit, the client \/\/ will never answer the second handshake! waitabit(); int port = mclientstoreopen.get(client); if (port == idebugportprovider.no_static_port) { port = getnextdebuggerport(); } log.d(\"devicemonitor\", \"reopening \" + client); openclient(device, pid, port, monitorthread); device.update(device.change_client_list); } mclientstoreopen.clear(); } } if (count == 0) { continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove(); if (key.isvalid() && key.isreadable()) { object attachment = key.attachment(); if (attachment instanceof device) { device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } } } } } catch (ioexception e) { if (mquit == false) { } } } while (mquit == false); }","classification":"NONSATD","isFinished":true,"code_context_2":"\"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) {","code_context_10":"device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } }","code_context_20":"continue; } set<selectionkey> keys = mselector.selectedkeys(); iterator<selectionkey> iter = keys.iterator(); while (iter.hasnext()) { selectionkey key = iter.next(); iter.remove(); if (key.isvalid() && key.isreadable()) { object attachment = key.attachment(); if (attachment instanceof device) { device device = (device)attachment; socketchannel socket = device.getclientmonitoringsocket(); if (socket != null) { try { int length = readlength(socket, mlengthbuffer2); processincomingjdwpdata(device, socket, length); } catch (ioexception ioe) { log.d(\"devicemonitor\", \"error reading jdwp list: \" + ioe.getmessage()); socket.close(); \/\/ restart the monitoring of that device synchronized (mdevices) { if (mdevices.contains(device)) { log.d(\"devicemonitor\", \"restarting monitoring service for \" + device); startmonitoringdevice(device); } } } } } } } } catch (ioexception e) { if (mquit == false) { } } } while (mquit == false); }","repo":"lrscp\/ControlAndroidDeviceFromPC"}
{"id":33797,"comment_id":0,"comment":"\/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms","code":"@post @path(\"\/services\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.create_service + \"\\\")\") public rangerservice createservice(rangerservice service) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.createservice(\" + service + \")\"); } rangerservice ret = null; rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.createservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.create); usersessionbase session = contextutil.getcurrentusersession(); xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); if(session != null && !session.isspnegoenabled()){ bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); } if(session != null && session.isspnegoenabled()){ if (session.iskeyadmin() && !xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"keyadmin can create\/update\/delete only kms \", messageenums.oper_no_permission); } if ((!session.iskeyadmin() && !session.isuseradmin()) && xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"user cannot create\/update\/delete kms service\", messageenums.oper_no_permission); } } ret = svcstore.createservice(service); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"createservice(\" + service + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf); } if(log.isdebugenabled()) { log.debug(\"<== servicerest.createservice(\" + service + \"): \" + ret); } return ret; }","classification":"DESIGN","isFinished":true,"code_context_2":"if(session != null && !session.isspnegoenabled()){ bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); }","code_context_10":"try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.createservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.create); usersessionbase session = contextutil.getcurrentusersession(); xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); if(session != null && !session.isspnegoenabled()){ bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); } if(session != null && session.isspnegoenabled()){ if (session.iskeyadmin() && !xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"keyadmin can create\/update\/delete only kms \", messageenums.oper_no_permission); } if ((!session.iskeyadmin() && !session.isuseradmin()) && xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"user cannot create\/update\/delete kms service\", messageenums.oper_no_permission);","code_context_20":"@post @path(\"\/services\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.create_service + \"\\\")\") public rangerservice createservice(rangerservice service) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.createservice(\" + service + \")\"); } rangerservice ret = null; rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.createservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.create); usersessionbase session = contextutil.getcurrentusersession(); xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); if(session != null && !session.isspnegoenabled()){ bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); } if(session != null && session.isspnegoenabled()){ if (session.iskeyadmin() && !xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"keyadmin can create\/update\/delete only kms \", messageenums.oper_no_permission); } if ((!session.iskeyadmin() && !session.isuseradmin()) && xxservicedef.getimplclassname().equals(embeddedservicedefsutil.kms_impl_class_name)) { throw resterrorutil.createrestexception(\"user cannot create\/update\/delete kms service\", messageenums.oper_no_permission); } } ret = svcstore.createservice(service); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"createservice(\" + service + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf);","repo":"lw-lin\/incubator-ranger"}
{"id":33798,"comment_id":0,"comment":"\/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms","code":"@put @path(\"\/services\/{id}\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.update_service + \"\\\")\") public rangerservice updateservice(rangerservice service) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.updateservice(): \" + service); } rangerservice ret = null; rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.updateservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.update); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); ret = svcstore.updateservice(service); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"updateservice(\" + service + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf); } if(log.isdebugenabled()) { log.debug(\"<== servicerest.updateservice(\" + service + \"): \" + ret); } return ret; }","classification":"DESIGN","isFinished":true,"code_context_2":"validator.validate(service, action.update); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname());","code_context_10":"} rangerservice ret = null; rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.updateservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.update); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); ret = svcstore.updateservice(service); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"updateservice(\" + service + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf);","code_context_20":"@put @path(\"\/services\/{id}\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.update_service + \"\\\")\") public rangerservice updateservice(rangerservice service) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.updateservice(): \" + service); } rangerservice ret = null; rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.updateservice(servicename=\" + service.getname() + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(service, action.update); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservicedef xxservicedef = daomanager.getxxservicedef().findbyname(service.gettype()); bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); ret = svcstore.updateservice(service); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"updateservice(\" + service + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf); } if(log.isdebugenabled()) { log.debug(\"<== servicerest.updateservice(\" + service + \"): \" + ret); } return ret; }","repo":"lw-lin\/incubator-ranger"}
{"id":33799,"comment_id":0,"comment":"\/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms","code":"@delete @path(\"\/services\/{id}\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.delete_service + \"\\\")\") public void deleteservice(@pathparam(\"id\") long id) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.deleteservice(\" + id + \")\"); } rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.deleteservice(serviceid=\" + id + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(id, action.delete); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservice service = daomanager.getxxservice().getbyid(id); embeddedservicedefsutil embeddedservicedefsutil = embeddedservicedefsutil.instance(); if (service.gettype().equals(embeddedservicedefsutil.gettagservicedefid())){ list<xxservice> referringservices=daomanager.getxxservice().findbytagserviceid(id); if(!collectionutils.isempty(referringservices)){ set<string> referringservicenames=new hashset<string>(); for(xxservice xxservice:referringservices){ referringservicenames.add(xxservice.getname()); if(referringservicenames.size()>=10){ break; } } if(referringservices.size()<=10){ throw resterrorutil.createrestexception(\"tag service '\" + service.getname() + \"' is being referenced by \" + referringservices.size() + \" services: \"+referringservicenames,messageenums.oper_not_allowed_for_state); }else{ throw resterrorutil.createrestexception(\"tag service '\" + service.getname() + \"' is being referenced by \" + referringservices.size() + \" services: \"+referringservicenames+\" and more..\",messageenums.oper_not_allowed_for_state); } } } xxservicedef xxservicedef = daomanager.getxxservicedef().getbyid(service.gettype()); bizutil.haskmspermissions(\"service\", xxservicedef.getimplclassname()); tagstore.deletealltagobjectsforservice(service.getname()); svcstore.deleteservice(id); } catch(webapplicationexception excp) { throw excp; } catch(throwable excp) { log.error(\"deleteservice(\" + id + \") failed\", excp); throw resterrorutil.createrestexception(excp.getmessage()); } finally { rangerperftracer.log(perf); } if(log.isdebugenabled()) { log.debug(\"<== servicerest.deleteservice(\" + id + \")\"); } }","classification":"DESIGN","isFinished":true,"code_context_2":"validator.validate(id, action.delete); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservice service = daomanager.getxxservice().getbyid(id); embeddedservicedefsutil embeddedservicedefsutil = embeddedservicedefsutil.instance();","code_context_10":"log.debug(\"==> servicerest.deleteservice(\" + id + \")\"); } rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.deleteservice(serviceid=\" + id + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(id, action.delete); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservice service = daomanager.getxxservice().getbyid(id); embeddedservicedefsutil embeddedservicedefsutil = embeddedservicedefsutil.instance(); if (service.gettype().equals(embeddedservicedefsutil.gettagservicedefid())){ list<xxservice> referringservices=daomanager.getxxservice().findbytagserviceid(id); if(!collectionutils.isempty(referringservices)){ set<string> referringservicenames=new hashset<string>(); for(xxservice xxservice:referringservices){ referringservicenames.add(xxservice.getname()); if(referringservicenames.size()>=10){ break;","code_context_20":"@delete @path(\"\/services\/{id}\") @produces({ \"application\/json\", \"application\/xml\" }) @preauthorize(\"@rangerpreauthsecurityhandler.isapiaccessible(\\\"\" + rangerapilist.delete_service + \"\\\")\") public void deleteservice(@pathparam(\"id\") long id) { if(log.isdebugenabled()) { log.debug(\"==> servicerest.deleteservice(\" + id + \")\"); } rangerperftracer perf = null; try { if(rangerperftracer.isperftraceenabled(perf_log)) { perf = rangerperftracer.getperftracer(perf_log, \"servicerest.deleteservice(serviceid=\" + id + \")\"); } rangerservicevalidator validator = validatorfactory.getservicevalidator(svcstore); validator.validate(id, action.delete); bizutil.hasadminpermissions(\"services\"); \/\/ todo: as of now we are allowing sys_admin to create all the \/\/ services including kms xxservice service = daomanager.getxxservice().getbyid(id); embeddedservicedefsutil embeddedservicedefsutil = embeddedservicedefsutil.instance(); if (service.gettype().equals(embeddedservicedefsutil.gettagservicedefid())){ list<xxservice> referringservices=daomanager.getxxservice().findbytagserviceid(id); if(!collectionutils.isempty(referringservices)){ set<string> referringservicenames=new hashset<string>(); for(xxservice xxservice:referringservices){ referringservicenames.add(xxservice.getname()); if(referringservicenames.size()>=10){ break; } } if(referringservices.size()<=10){ throw resterrorutil.createrestexception(\"tag service '\" + service.getname() + \"' is being referenced by \" + referringservices.size() + \" services: \"+referringservicenames,messageenums.oper_not_allowed_for_state); }else{ throw resterrorutil.createrestexception(\"tag service '\" + service.getname() + \"' is being referenced by \" + referringservices.size() + \" services: \"+referringservicenames+\" and more..\",messageenums.oper_not_allowed_for_state); } } } xxservicedef xxservicedef = daomanager.getxxservicedef().getbyid(service.gettype());","repo":"lw-lin\/incubator-ranger"}
{"id":9239,"comment_id":0,"comment":"\/\/ note: did not manage to reproduce cce until i changed expand to use \u2018for (toplevelitem item : items)\u2019 rather than \u2018for (item item : items)\u2019; perhaps a compiler-specific issue?","code":"@issue(\"jenkins-20415\") @test public void nontoplevelitemgroup() throws exception { matrixproject mp = j.jenkins.createproject(matrixproject.class, \"mp\"); mp.setaxes(new axislist(new textaxis(\"axis\", \"one\", \"two\"))); assertequals(2, mp.getitems().size()); listview v = new listview(\"v\"); j.jenkins.addview(v); v.setincluderegex(\".*\"); v.setrecurse(true); \/\/ note: did not manage to reproduce cce until i changed expand to use \u2018for (toplevelitem item : items)\u2019 rather than \u2018for (item item : items)\u2019; perhaps a compiler-specific issue? assertequals(collections.singletonlist(mp), v.getitems()); }","classification":"DEFECT","isFinished":true,"code_context_2":"v.setincluderegex(\".*\"); v.setrecurse(true); \/\/ note: did not manage to reproduce cce until i changed expand to use \u2018for (toplevelitem item : items)\u2019 rather than \u2018for (item item : items)\u2019; perhaps a compiler-specific issue? assertequals(collections.singletonlist(mp), v.getitems()); }","code_context_10":"@issue(\"jenkins-20415\") @test public void nontoplevelitemgroup() throws exception { matrixproject mp = j.jenkins.createproject(matrixproject.class, \"mp\"); mp.setaxes(new axislist(new textaxis(\"axis\", \"one\", \"two\"))); assertequals(2, mp.getitems().size()); listview v = new listview(\"v\"); j.jenkins.addview(v); v.setincluderegex(\".*\"); v.setrecurse(true); \/\/ note: did not manage to reproduce cce until i changed expand to use \u2018for (toplevelitem item : items)\u2019 rather than \u2018for (item item : items)\u2019; perhaps a compiler-specific issue? assertequals(collections.singletonlist(mp), v.getitems()); }","code_context_20":"@issue(\"jenkins-20415\") @test public void nontoplevelitemgroup() throws exception { matrixproject mp = j.jenkins.createproject(matrixproject.class, \"mp\"); mp.setaxes(new axislist(new textaxis(\"axis\", \"one\", \"two\"))); assertequals(2, mp.getitems().size()); listview v = new listview(\"v\"); j.jenkins.addview(v); v.setincluderegex(\".*\"); v.setrecurse(true); \/\/ note: did not manage to reproduce cce until i changed expand to use \u2018for (toplevelitem item : items)\u2019 rather than \u2018for (item item : items)\u2019; perhaps a compiler-specific issue? assertequals(collections.singletonlist(mp), v.getitems()); }","repo":"mahevpm\/Mahendran_Jenkins"}
{"id":33880,"comment_id":0,"comment":"\/\/ todo empty method, if you want to definition & registry , use it.","code":"@override public void postprocessbeandefinitionregistry(beandefinitionregistry beandefinitionregistry) throws beansexception { \/\/ todo empty method, if you want to definition & registry , use it. }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@override public void postprocessbeandefinitionregistry(beandefinitionregistry beandefinitionregistry) throws beansexception { \/\/ todo empty method, if you want to definition & registry , use it. }","code_context_10":"@override public void postprocessbeandefinitionregistry(beandefinitionregistry beandefinitionregistry) throws beansexception { \/\/ todo empty method, if you want to definition & registry , use it. }","code_context_20":"@override public void postprocessbeandefinitionregistry(beandefinitionregistry beandefinitionregistry) throws beansexception { \/\/ todo empty method, if you want to definition & registry , use it. }","repo":"liuziyuan\/retrofit-spring-boot-starter"}
{"id":33901,"comment_id":0,"comment":"\/\/ todo: test case for https:\/\/github.com\/jhy\/jsoup\/issues\/845. doesn't work yet.","code":"@ignore \/\/ todo: test case for https:\/\/github.com\/jhy\/jsoup\/issues\/845. doesn't work yet. @test public void handlesmisnestedaindivs() { string h = \"<a href='#1'><div><div><a href='#2'>child<\/a<\/div<\/div><\/a>\"; string w = \"<a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><a href=\\\"#2\\\">child<\/a><\/div><\/div>\"; document doc = jsoup.parse(h); assertequals( stringutil.normalisewhitespace(w), stringutil.normalisewhitespace(doc.body().html())); }","classification":"TEST","isFinished":true,"code_context_2":"@ignore \/\/ todo: test case for https:\/\/github.com\/jhy\/jsoup\/issues\/845. doesn't work yet. @test public void handlesmisnestedaindivs() { string h = \"<a href='#1'><div><div><a href='#2'>child<\/a<\/div<\/div><\/a>\";","code_context_10":"@ignore \/\/ todo: test case for https:\/\/github.com\/jhy\/jsoup\/issues\/845. doesn't work yet. @test public void handlesmisnestedaindivs() { string h = \"<a href='#1'><div><div><a href='#2'>child<\/a<\/div<\/div><\/a>\"; string w = \"<a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><a href=\\\"#2\\\">child<\/a><\/div><\/div>\"; document doc = jsoup.parse(h); assertequals( stringutil.normalisewhitespace(w), stringutil.normalisewhitespace(doc.body().html())); }","code_context_20":"@ignore \/\/ todo: test case for https:\/\/github.com\/jhy\/jsoup\/issues\/845. doesn't work yet. @test public void handlesmisnestedaindivs() { string h = \"<a href='#1'><div><div><a href='#2'>child<\/a<\/div<\/div><\/a>\"; string w = \"<a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><div><a href=\\\"#1\\\"><\/a><a href=\\\"#2\\\">child<\/a><\/div><\/div>\"; document doc = jsoup.parse(h); assertequals( stringutil.normalisewhitespace(w), stringutil.normalisewhitespace(doc.body().html())); }","repo":"mikiec84\/jsoup"}
{"id":1139,"comment_id":0,"comment":"\/** * transform the current time series and baselines. * * todo: apply chain-of-responsibility on the transformation chain * * @param metricname the name of the metric on which we apply transformation and prediction * @param anomalydetectioncontext anomaly detection context that contains the time series to be * transformed. *\/","code":"\/** * transform the current time series and baselines. * * todo: apply chain-of-responsibility on the transformation chain * * @param metricname the name of the metric on which we apply transformation and prediction * @param anomalydetectioncontext anomaly detection context that contains the time series to be * transformed. *\/ private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","code_context_10":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","code_context_20":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","repo":"kupl\/starlab-benchmarks"}
{"id":1139,"comment_id":1,"comment":"\/\/ transform the observed (current) time series","code":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname));","code_context_10":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext));","code_context_20":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) {","repo":"kupl\/starlab-benchmarks"}
{"id":1139,"comment_id":2,"comment":"\/\/ transform baseline time series","code":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname));","code_context_10":"} list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) {","code_context_20":"private void transformtimeseries(string metricname, anomalydetectioncontext anomalydetectioncontext) { \/\/ transform the observed (current) time series if (anomalydetectioncontext.gettransformedcurrent(metricname) == null) { anomalydetectioncontext.settransformedcurrent(metricname, anomalydetectioncontext.getcurrent(metricname)); } list<transformationfunction> currenttimeseriestransformationchain = getcurrenttimeseriestransformationchain(); if (collectionutils.isnotempty(currenttimeseriestransformationchain)) { for (transformationfunction tf : currenttimeseriestransformationchain) { anomalydetectioncontext .settransformedcurrent(metricname, tf.transform(anomalydetectioncontext.gettransformedcurrent(metricname), anomalydetectioncontext)); } } \/\/ transform baseline time series if (anomalydetectioncontext.gettransformedbaselines(metricname) == null) { anomalydetectioncontext.settransformedbaselines(metricname, anomalydetectioncontext.getbaselines(metricname)); } list<transformationfunction> baselinetimeseriestransformationchain = getbaselinetimeseriestransformationchain(); if (collectionutils.isnotempty(anomalydetectioncontext.gettransformedbaselines(metricname)) && collectionutils.isnotempty(baselinetimeseriestransformationchain)) { for (transformationfunction tf : baselinetimeseriestransformationchain) { list<timeseries> transformedbaselines = new arraylist<>(); for (timeseries ts : anomalydetectioncontext.gettransformedbaselines(metricname)) { timeseries transformedts = tf.transform(ts, anomalydetectioncontext); transformedbaselines.add(transformedts); } anomalydetectioncontext.settransformedbaselines(metricname, transformedbaselines); } } }","repo":"kupl\/starlab-benchmarks"}
{"id":17582,"comment_id":0,"comment":"\/\/ obtain representations for playback.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>();","code_context_10":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) {","code_context_20":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. }","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":1,"comment":"\/\/ the device isn't capable of playing this stream.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } }","code_context_10":"int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) {","code_context_20":"defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security.","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":2,"comment":"\/\/ check drm support if necessary.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) {","code_context_10":"if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback);","code_context_20":"for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } }","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":3,"comment":"\/\/ hd streams require l1 security.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); }","code_context_10":"if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource;","code_context_20":"\/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations);","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":4,"comment":"\/\/ build the video renderer.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource;","code_context_10":"drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations);","code_context_20":"drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000,","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":5,"comment":"\/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"DESIGN","isFinished":true,"code_context_2":"new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource,","code_context_10":"} } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource,","code_context_20":"pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null;","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":6,"comment":"\/\/ build the audio renderer.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource;","code_context_10":"new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()];","code_context_20":"chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); }","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":7,"comment":"\/\/ build the debug renderer.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null;","code_context_10":"audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer;","code_context_20":"} else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","repo":"malmstein\/ExoPlayer"}
{"id":17582,"comment_id":8,"comment":"\/\/ invoke the callback.","code":"@override public void onmanifest(string contentid, mediapresentationdescription manifest) { handler mainhandler = player.getmainhandler(); loadcontrol loadcontrol = new defaultloadcontrol(new bufferpool(buffer_segment_size)); defaultbandwidthmeter bandwidthmeter = new defaultbandwidthmeter(mainhandler, player); \/\/ obtain representations for playback. int maxdecodableframesize = mediacodecutil.maxh264decodableframesize(); arraylist<representation> audiorepresentationslist = new arraylist<representation>(); arraylist<representation> videorepresentationslist = new arraylist<representation>(); period period = manifest.periods.get(0); boolean hascontentprotection = false; for (int i = 0; i < period.adaptationsets.size(); i++) { adaptationset adaptationset = period.adaptationsets.get(i); hascontentprotection |= adaptationset.hascontentprotection(); int adaptationsettype = adaptationset.type; for (int j = 0; j < adaptationset.representations.size(); j++) { representation representation = adaptationset.representations.get(j); if (adaptationsettype == adaptationset.type_audio) { audiorepresentationslist.add(representation); } else if (adaptationsettype == adaptationset.type_video) { format format = representation.format; if (format.width * format.height <= maxdecodableframesize) { videorepresentationslist.add(representation); } else { \/\/ the device isn't capable of playing this stream. } } } } representation[] videorepresentations = new representation[videorepresentationslist.size()]; videorepresentationslist.toarray(videorepresentations); \/\/ check drm support if necessary. drmsessionmanager drmsessionmanager = null; if (hascontentprotection) { if (util.sdk_int < 18) { callback.onrendererserror(new unsupportedoperationexception( \"protected content not supported on api level \" + util.sdk_int)); return; } try { pair<drmsessionmanager, boolean> drmsessionmanagerdata = v18compat.getdrmsessionmanagerdata(player, drmcallback); drmsessionmanager = drmsessionmanagerdata.first; if (!drmsessionmanagerdata.second) { \/\/ hd streams require l1 security. videorepresentations = getsdrepresentations(videorepresentations); } } catch (exception e) { callback.onrendererserror(e); return; } } \/\/ build the video renderer. datasource videodatasource = new httpdatasource(useragent, null, bandwidthmeter); chunksource videochunksource; string mimetype = videorepresentations[0].format.mimetype; if (mimetype.equals(mimetypes.video_mp4)) { videochunksource = new dashmp4chunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else if (mimetype.equals(mimetypes.video_webm)) { \/\/ todo: figure out how to query supported vpx resolutions. for now, restrict to standard \/\/ definition streams. videorepresentations = getsdrepresentations(videorepresentations); videochunksource = new dashwebmchunksource(videodatasource, new adaptiveevaluator(bandwidthmeter), videorepresentations); } else { throw new illegalstateexception(\"unexpected mime type: \" + mimetype); } chunksamplesource videosamplesource = new chunksamplesource(videochunksource, loadcontrol, video_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_video); mediacodecvideotrackrenderer videorenderer = new mediacodecvideotrackrenderer(videosamplesource, drmsessionmanager, true, mediacodec.video_scaling_mode_scale_to_fit, 5000, mainhandler, player, 50); \/\/ build the audio renderer. final string[] audiotracknames; final multitrackchunksource audiochunksource; final mediacodecaudiotrackrenderer audiorenderer; if (audiorepresentationslist.isempty()) { audiotracknames = null; audiochunksource = null; audiorenderer = null; } else { datasource audiodatasource = new httpdatasource(useragent, null, bandwidthmeter); audiotracknames = new string[audiorepresentationslist.size()]; chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","classification":"NONSATD","isFinished":true,"code_context_2":"trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames;","code_context_10":"audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers);","code_context_20":"chunksource[] audiochunksources = new chunksource[audiorepresentationslist.size()]; formatevaluator audioevaluator = new formatevaluator.fixedevaluator(); for (int i = 0; i < audiorepresentationslist.size(); i++) { representation representation = audiorepresentationslist.get(i); format format = representation.format; audiotracknames[i] = format.id + \" (\" + format.numchannels + \"ch, \" + format.audiosamplingrate + \"hz)\"; audiochunksources[i] = new dashmp4chunksource(audiodatasource, audioevaluator, representation); } audiochunksource = new multitrackchunksource(audiochunksources); samplesource audiosamplesource = new chunksamplesource(audiochunksource, loadcontrol, audio_buffer_segments * buffer_segment_size, true, mainhandler, player, demoplayer.type_audio); audiorenderer = new mediacodecaudiotrackrenderer(audiosamplesource, drmsessionmanager, true, mainhandler, player); } \/\/ build the debug renderer. trackrenderer debugrenderer = debugtextview != null ? new debugtrackrenderer(debugtextview, videorenderer, videosamplesource) : null; \/\/ invoke the callback. string[][] tracknames = new string[demoplayer.renderer_count][]; tracknames[demoplayer.type_audio] = audiotracknames; multitrackchunksource[] multitrackchunksources = new multitrackchunksource[demoplayer.renderer_count]; multitrackchunksources[demoplayer.type_audio] = audiochunksource; trackrenderer[] renderers = new trackrenderer[demoplayer.renderer_count]; renderers[demoplayer.type_video] = videorenderer; renderers[demoplayer.type_audio] = audiorenderer; renderers[demoplayer.type_debug] = debugrenderer; callback.onrenderers(tracknames, multitrackchunksources, renderers); }","repo":"malmstein\/ExoPlayer"}
{"id":17679,"comment_id":0,"comment":"\/** * called when loading successfully finishes. *\/","code":"\/** * called when loading successfully finishes. *\/ public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","code_context_10":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","code_context_20":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","repo":"licehammer\/perun"}
{"id":17679,"comment_id":1,"comment":"\/\/ when there are no application form items","code":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","classification":"NONSATD","isFinished":true,"code_context_2":"applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\");","code_context_10":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\"));","code_context_20":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form","repo":"licehammer\/perun"}
{"id":17679,"comment_id":2,"comment":"\/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified.","code":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","classification":"DEFECT","isFinished":true,"code_context_2":"contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\"));","code_context_10":"applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft);","code_context_20":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","repo":"licehammer\/perun"}
{"id":17679,"comment_id":3,"comment":"\/\/ when there are no application form items","code":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","classification":"NONSATD","isFinished":true,"code_context_2":"applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\");","code_context_10":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\"));","code_context_20":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form","repo":"licehammer\/perun"}
{"id":17679,"comment_id":4,"comment":"\/\/ create application form","code":"public void onfinished(javascriptobject jso) { applformitems.clear(); applformitems.addall(jsonutils.<applicationformitemwithprefilledvalue>jsoaslist(jso)); applformgenerators.clear(); if (applformitems == null || applformitems.isempty()) { \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","classification":"NONSATD","isFinished":true,"code_context_2":"contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); }","code_context_10":"location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","code_context_20":"\/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.noformdefined()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else if (perunentity.virtual_organization.equals(entity) && \"extension\".equalsignorecase(type) && location.getparameter(\"targetexisting\") != null) { \/\/ fixme - this is probably not good, since it prevents vo extension when targetexisting is specified. if (location.getparameter(\"targetexisting\") != null) { location.replace(location.getparameter(\"targetexisting\")); } \/\/ when there are no application form items flextable ft = new flextable(); ft.setsize(\"100%\", \"300px\"); ft.sethtml(0, 0, new image(largeicons.instance.erroricon()) + applicationmessages.instance.alreadyvomember()); ft.getflexcellformatter().sethorizontalalignment(0, 0, hashorizontalalignment.align_center); ft.getflexcellformatter().setverticalalignment(0, 0, hasverticalalignment.align_middle); contents.setwidget(ft); } else { \/\/ create application form prepareapplicationform(); } session.getuielements().setlogtext(\"loading \" + type + \" application form items in selected vo finished:\" + applformitems.size()); events.onfinished(jso); loaderimage.loadingfinished(); }","repo":"licehammer\/perun"}
{"id":9531,"comment_id":0,"comment":"\/** * adds correction terms of the following form for variables v. * * <ul> * <li> if primed context has no v, conjoins v_1 = v_max (v doesn't change in this block) * <li> if primed context has index i &lt; max, conjoins v_i = v_max * <li> if unprimed context has has index i &gt; 1, conjoins v_1 = v_i * <\/ul> * * adds formulas for program counter before and after block transition. * * @return a path formula with the above mentioned adjustments to the block transition formula. * the ssa map contains the indices for all primed variables including those not in the * original block formula and the pc. the pointer target set is the same as before. *\/","code":"\/** * adds correction terms of the following form for variables v. * * <ul> * <li> if primed context has no v, conjoins v_1 = v_max (v doesn't change in this block) * <li> if primed context has index i &lt; max, conjoins v_i = v_max * <li> if unprimed context has has index i &gt; 1, conjoins v_1 = v_i * <\/ul> * * adds formulas for program counter before and after block transition. * * @return a path formula with the above mentioned adjustments to the block transition formula. * the ssa map contains the indices for all primed variables including those not in the * original block formula and the pc. the pointer target set is the same as before. *\/ private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"NONSATD","isFinished":true,"code_context_2":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","code_context_10":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","code_context_20":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","repo":"lembergerth\/cpachecker"}
{"id":9531,"comment_id":1,"comment":"\/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context),","code":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"NONSATD","isFinished":true,"code_context_2":"ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm =","code_context_10":"booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) {","code_context_20":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm);","repo":"lembergerth\/cpachecker"}
{"id":9531,"comment_id":2,"comment":"\/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1).","code":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"NONSATD","isFinished":true,"code_context_2":"extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) {","code_context_10":"ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname,","code_context_20":"block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa));","repo":"lembergerth\/cpachecker"}
{"id":9531,"comment_id":3,"comment":"\/\/ add high correction v_? = v_max if primed context for v has lower index (? < max)","code":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"NONSATD","isFinished":true,"code_context_2":"extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm =","code_context_10":"pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } }","code_context_20":"booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa),","repo":"lembergerth\/cpachecker"}
{"id":9531,"comment_id":4,"comment":"\/\/ add program counter","code":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation());","code_context_10":"if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa));","code_context_20":"makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","repo":"lembergerth\/cpachecker"}
{"id":9531,"comment_id":5,"comment":"\/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct?","code":"private pathformula withcorrectiontermsandpc( block pblock, formulamanagerview pfmgr, booleanformulamanagerview pbfmgr, bitvectorformulamanagerview pbvfmgr, pathformulamanager ppfmgr, cfa pcfa) { booleanformula extendedblockformula = pblock.getformula(); pathformula unprimedblockcontext = pblock.getunprimedcontext(); pathformula primedblockcontext = pblock.getprimedcontext(); ssamap unprimedssamap = unprimedblockcontext.getssa(); ssamap primedssamap = primedblockcontext.getssa(); for (string varname : programvariablenames) { \/\/ add general correction v_1 = v_max if v is not in block formula (= not in primed context), if (!primedssamap.containsvariable(varname)) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, this.unprimedcontext, varname, standard_unprimed_ssa), makevar(ppfmgr, pfmgr, this.primedcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } else { \/\/ add low correction v_1 = v_? if unprimed context for v has higher index (? > 1). if (unprimedssamap.containsvariable(varname) && unprimedssamap.getindex(varname) > standard_unprimed_ssa) { booleanformula correctionterm = pbvfmgr.equal( makevar(ppfmgr, pfmgr, unprimedblockcontext, varname, standard_unprimed_ssa), makevar( ppfmgr, pfmgr, unprimedblockcontext, varname, unprimedssamap.getindex(varname))); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } \/\/ add high correction v_? = v_max if primed context for v has lower index (? < max) if (primedssamap.getindex(varname) < highestssa) { booleanformula correctionterm = pbvfmgr.equal( makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","classification":"DEFECT","isFinished":true,"code_context_2":"extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula(","code_context_10":"booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","code_context_20":"makevar( ppfmgr, pfmgr, primedblockcontext, varname, primedssamap.getindex(varname)), makevar(ppfmgr, pfmgr, primedblockcontext, varname, highestssa)); extendedblockformula = pbfmgr.and(extendedblockformula, correctionterm); } } } \/\/ add program counter int predid = getid(pblock.getpredecessorlocation()); int succid = getid(pblock.getsuccessorlocation()); booleanformula pcbefore = pfmgr.instantiate( makeprogramcounterformula(predid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(standard_unprimed_ssa)); booleanformula pcafter = pfmgr.instantiate( makeprogramcounterformula(succid, pbvfmgr, pcfa), ssamap.emptyssamap().withdefault(pc_primed_ssa)); extendedblockformula = pbfmgr.and(pcbefore, extendedblockformula, pcafter); @suppresswarnings(\"deprecation\") \/\/ todo: seems buggy because it implicitly combines extendedblockformula and \/\/ primedcontext.getssa() with pointertargetset of primedblockcontext, is this correct? pathformula pathformula = ppfmgr.makenewpathformula( primedblockcontext.updateformula(extendedblockformula), this.primedcontext.getssa()); return pathformula; }","repo":"lembergerth\/cpachecker"}
{"id":1459,"comment_id":0,"comment":"\/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain","code":"@test public void testpredicatetypemismatch() { try (localqueryrunner queryrunner = createlocalqueryrunner( getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","classification":"NONSATD","isFinished":true,"code_context_2":"optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> {","code_context_10":"@test public void testpredicatetypemismatch() { try (localqueryrunner queryrunner = createlocalqueryrunner( getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","code_context_20":"@test public void testpredicatetypemismatch() { try (localqueryrunner queryrunner = createlocalqueryrunner( getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","repo":"liujiansxcd\/trino"}
{"id":1459,"comment_id":1,"comment":"\/\/ todo report source column name instead of columnhandle tostring","code":"@test public void testpredicatetypemismatch() { try (localqueryrunner queryrunner = createlocalqueryrunner( getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","classification":"DESIGN","isFinished":true,"code_context_2":"assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\");","code_context_10":"getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","code_context_20":"@test public void testpredicatetypemismatch() { try (localqueryrunner queryrunner = createlocalqueryrunner( getmockapplyredirectafterpredicatepushdown(type_mismatched_redirection_mapping_bc, optional.of(immutableset.of(source_column_handle_b))), optional.of(this::mockapplyprojection), optional.of(getmockapplyfilter(immutableset.of(source_column_handle_c))))) { \/\/ after 'source_col_c = 1' is pushed into source table scan, it's possible for 'source_col_c' table scan assignment to be pruned \/\/ redirection results in project('dest_col_b') -> filter('dest_col_c = 1') -> tablescan for such case \/\/ but dest_col_a has mismatched type compared to source domain transaction(queryrunner.gettransactionmanager(), queryrunner.getaccesscontrol()) .execute(mock_session, session -> { assertthatthrownby(() -> queryrunner.createplan(session, \"select source_col_b from test_table where source_col_c = 'foo'\", warningcollector.noop)) .isinstanceof(trinoexception.class) \/\/ todo report source column name instead of columnhandle tostring .hasmessagematching(\"redirected column mock_catalog.target_schema.target_table.destination_col_a has type integer, \" + \"different from source column mock_catalog.test_schema.test_table.mockconnectorcolumnhandle.*source_col_c.* type: varchar\"); }); } }","repo":"liujiansxcd\/trino"}
{"id":34339,"comment_id":0,"comment":"\/\/play selected song from playlist, to skip forward or back","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>();","code_context_10":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems();","code_context_20":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); }","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":1,"comment":"\/\/on double click of song, play it","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem()));","code_context_10":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); }","code_context_20":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist();","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":2,"comment":"\/\/on right click open context menu","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems();","code_context_10":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){","code_context_20":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny());","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":3,"comment":"\/\/allow for removal of selected songs from playlist","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids);","code_context_10":"if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable();","code_context_20":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row;","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":4,"comment":"\/\/allow for clearing entire playlist","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"} })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist();","code_context_10":"for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection();","code_context_20":"tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":5,"comment":"\/\/show context menu at location of click","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); }","code_context_10":"playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired","code_context_20":"} \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":6,"comment":"\/\/undo selection if user clicks away from focused row","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"NONSATD","isFinished":true,"code_context_2":"playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection();","code_context_10":"} })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","code_context_20":"observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","repo":"justinlautner\/Cassette"}
{"id":34339,"comment_id":7,"comment":"\/\/todo: add drag listener to move songs around as desired","code":"private void createrowfactory(){ \/\/play selected song from playlist, to skip forward or back tableview.setrowfactory( tv -> { tablerow<playlistsongdisplay> row = new tablerow<>(); row.setonmouseclicked(event -> { \/\/on double click of song, play it if (event.getclickcount() == 2 && (! row.isempty()) ) { playlist.playplaylistselection(songhashmap.get(row.getitem())); } \/\/on right click open context menu if (event.getbutton() == mousebutton.secondary) { observablelist<playlistsongdisplay> selecteditems = tableview.getselectionmodel().getselecteditems(); arraylist<song> selectedids = new arraylist<>(); for (playlistsongdisplay rowselected : selecteditems) { selectedids.add(songhashmap.get(rowselected)); } \/\/allow for removal of selected songs from playlist removeselected.setonaction((actionevent -> { playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return row; }); \/\/todo: add drag listener to move songs around as desired }","code_context_10":"\/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","code_context_20":"playlist.removeplaylistselection(selectedids); for (song s: selectedids){ playlistlist.remove(songhashmaprev.get(s)); } })); \/\/allow for clearing entire playlist clearplaylist.setonaction(actionevent -> { playlist.clearplaylist(); emptytable(); }); \/\/show context menu at location of click playlistcontextmenu.show(row, event.getscreenx(), event.getscreeny()); } \/\/undo selection if user clicks away from focused row if (event.getbutton() == mousebutton.primary && (row.isempty())){ tableview.getselectionmodel().clearselection(); } }); return row; }); \/\/todo: add drag listener to move songs around as desired }","repo":"justinlautner\/Cassette"}
{"id":34410,"comment_id":0,"comment":"\/\/ todo unsubscribe from everything? and resubscribe on resume?","code":"@override public void suspend() { \/\/ todo unsubscribe from everything? and resubscribe on resume? super.suspend(); if (executor != null) executor.shutdownnow(); executorqueued.set(false); }","classification":"DESIGN","isFinished":true,"code_context_2":"@override public void suspend() { \/\/ todo unsubscribe from everything? and resubscribe on resume? super.suspend(); if (executor != null) executor.shutdownnow();","code_context_10":"@override public void suspend() { \/\/ todo unsubscribe from everything? and resubscribe on resume? super.suspend(); if (executor != null) executor.shutdownnow(); executorqueued.set(false); }","code_context_20":"@override public void suspend() { \/\/ todo unsubscribe from everything? and resubscribe on resume? super.suspend(); if (executor != null) executor.shutdownnow(); executorqueued.set(false); }","repo":"kiuby88\/incubator-brooklyn"}
{"id":1656,"comment_id":0,"comment":"\/\/ todo(qinmin): pass the error code to native.","code":"private void onsessionerror(final int sessionid) { \/\/ todo(qinmin): pass the error code to native. mhandler.post(new runnable() { @override public void run() { nativeonsessionerror(mnativemediadrmbridge, sessionid); } }); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void onsessionerror(final int sessionid) { \/\/ todo(qinmin): pass the error code to native. mhandler.post(new runnable() { @override","code_context_10":"private void onsessionerror(final int sessionid) { \/\/ todo(qinmin): pass the error code to native. mhandler.post(new runnable() { @override public void run() { nativeonsessionerror(mnativemediadrmbridge, sessionid); } }); }","code_context_20":"private void onsessionerror(final int sessionid) { \/\/ todo(qinmin): pass the error code to native. mhandler.post(new runnable() { @override public void run() { nativeonsessionerror(mnativemediadrmbridge, sessionid); } }); }","repo":"kjthegod\/chromium"}
{"id":18096,"comment_id":0,"comment":"\/\/ todo: see if we are going to use this.","code":"\/\/ todo: see if we are going to use this. @suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","code_context_10":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","code_context_20":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","repo":"johnjardin\/ukuvuma-xpages-boilerplate"}
{"id":18096,"comment_id":1,"comment":"\/\/ login","code":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\";","code_context_10":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\";","code_context_20":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet));","repo":"johnjardin\/ukuvuma-xpages-boilerplate"}
{"id":18096,"comment_id":2,"comment":"\/\/ home","code":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\";","code_context_10":"facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay);","code_context_20":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace();","repo":"johnjardin\/ukuvuma-xpages-boilerplate"}
{"id":18096,"comment_id":3,"comment":"\/\/ formplaceholderfacet","code":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\";","code_context_10":"try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay);","code_context_20":"@suppresswarnings(\"unchecked\") public static void setpagefacet(int facettype, string facetname, long delay) { facescontext context = facescontext.getcurrentinstance(); map viewscope = context.getviewroot().getviewmap(); string previousfacet = \"\"; string selectedfacet = \"\"; try { switch (facettype) { case 1:\/\/ login previousfacet = \"previousloginfacet\"; selectedfacet = \"selectedloginfacet\"; break; case 2:\/\/ home previousfacet = \"previoushomefacet\"; selectedfacet = \"selectedhomefacet\"; break; case 3:\/\/ formplaceholderfacet previousfacet = \"previousformplaceholderfacet\"; selectedfacet = \"selectedformplaceholderfacet\"; break; } if (facetname.equals(\"previous\")) { setpagefacet(facettype, viewscope.get(previousfacet).tostring(), delay); } else if (!facetname.equals(viewscope.get(selectedfacet))) { if (delay > 0) { thread.currentthread(); thread.sleep(delay); } viewscope.put(previousfacet, viewscope.get(selectedfacet)); viewscope.put(selectedfacet, facetname); } } catch (interruptedexception e) { e.printstacktrace(); } }","repo":"johnjardin\/ukuvuma-xpages-boilerplate"}
{"id":9907,"comment_id":0,"comment":"\/\/ quicktime:","code":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","classification":"NONSATD","isFinished":true,"code_context_2":"if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); }","code_context_10":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\");","code_context_20":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","repo":"licaon-kter\/atalk-android"}
{"id":9907,"comment_id":1,"comment":"\/\/ directshow:","code":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); }","code_context_10":"contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\");","code_context_20":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","repo":"licaon-kter\/atalk-android"}
{"id":9907,"comment_id":2,"comment":"\/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow:","code":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); }","code_context_10":"if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist;","code_context_20":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","repo":"licaon-kter\/atalk-android"}
{"id":9907,"comment_id":3,"comment":"\/\/ none to add","code":"public static list<string> contentprefixlist(int flags) { final list<string> contentprefixlist = new arraylist<string>(); if ((flags & jmf) != 0) { contentprefixlist.add(\"javax\"); contentprefixlist.add(\"com.sun\"); contentprefixlist.add(\"com.ibm\"); } if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","classification":"NONSATD","isFinished":true,"code_context_2":"} if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist;","code_context_10":"if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","code_context_20":"} if ((flags & fmj_native) != 0) { if (osutils.ismacosx() || osutils.iswindows()) { \/\/ quicktime: contentprefixlist.add(\"net.sf.fmj.qt\"); } if (osutils.iswindows()) { \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.ds\"); } if (enable_gstreamer && osutils.islinux()) { \/\/ todo: we could add these for other os's, as gstreamer is cross-platform. \/\/ directshow: contentprefixlist.add(\"net.sf.fmj.gst\"); } } if ((flags & fmj) != 0) { contentprefixlist.add(\"net.sf.fmj\"); } if ((flags & third_party) != 0) { \/\/ none to add } return contentprefixlist; }","repo":"licaon-kter\/atalk-android"}
{"id":26295,"comment_id":0,"comment":"\/\/ todo add\/remove tag to invoice","code":"@test(groups = \"slow\", enabled = false) public void testoverduestateandwritten_offtag() throws exception { \/\/ todo add\/remove tag to invoice }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@test(groups = \"slow\", enabled = false) public void testoverduestateandwritten_offtag() throws exception { \/\/ todo add\/remove tag to invoice }","code_context_10":"@test(groups = \"slow\", enabled = false) public void testoverduestateandwritten_offtag() throws exception { \/\/ todo add\/remove tag to invoice }","code_context_20":"@test(groups = \"slow\", enabled = false) public void testoverduestateandwritten_offtag() throws exception { \/\/ todo add\/remove tag to invoice }","repo":"kevinpostlewaite\/killbill"}
{"id":26312,"comment_id":0,"comment":"\/\/ to-do rethink how to manage multiple servers","code":"private string getserverurl(openapi openapi, string pathinfo) { \/\/ to-do rethink how to manage multiple servers final string firstserver = openapiutils.mapserverstoendpoint(openapi.getservers()).get(0); final string apiidentifier = apimanagerservice.getapiidentifier(pathinfo); final string swaggerpath = pathinfo.substring(pathinfo.indexof(apiidentifier) + apiidentifier.length(), pathinfo.length()); return firstserver + swaggerpath; }","classification":"DESIGN","isFinished":true,"code_context_2":"private string getserverurl(openapi openapi, string pathinfo) { \/\/ to-do rethink how to manage multiple servers final string firstserver = openapiutils.mapserverstoendpoint(openapi.getservers()).get(0); final string apiidentifier = apimanagerservice.getapiidentifier(pathinfo);","code_context_10":"private string getserverurl(openapi openapi, string pathinfo) { \/\/ to-do rethink how to manage multiple servers final string firstserver = openapiutils.mapserverstoendpoint(openapi.getservers()).get(0); final string apiidentifier = apimanagerservice.getapiidentifier(pathinfo); final string swaggerpath = pathinfo.substring(pathinfo.indexof(apiidentifier) + apiidentifier.length(), pathinfo.length()); return firstserver + swaggerpath; }","code_context_20":"private string getserverurl(openapi openapi, string pathinfo) { \/\/ to-do rethink how to manage multiple servers final string firstserver = openapiutils.mapserverstoendpoint(openapi.getservers()).get(0); final string apiidentifier = apimanagerservice.getapiidentifier(pathinfo); final string swaggerpath = pathinfo.substring(pathinfo.indexof(apiidentifier) + apiidentifier.length(), pathinfo.length()); return firstserver + swaggerpath; }","repo":"marrmartin\/onesaitplatform-cloud"}
{"id":34553,"comment_id":0,"comment":"\/\/do not use getclass() here... a typical weld issue...","code":"@postconstruct public void setup(){ \/\/do not use getclass() here... a typical weld issue... endpointurl=appconfiguration.getbaseendpoint() + bulkwebservice.class.getannotation(path.class).value(); availablemethods= arrays.aslist(verb.values()); usersendpoint=userws.getendpointurl(); groupsendpoint=groupws.getendpointurl(); fidodevicesendpoint=fidodevicews.getendpointurl(); commonwsendpointprefix=usersendpoint.substring(0, usersendpoint.lastindexof(\"\/\")); }","classification":"DESIGN","isFinished":true,"code_context_2":"@postconstruct public void setup(){ \/\/do not use getclass() here... a typical weld issue... endpointurl=appconfiguration.getbaseendpoint() + bulkwebservice.class.getannotation(path.class).value(); availablemethods= arrays.aslist(verb.values());","code_context_10":"@postconstruct public void setup(){ \/\/do not use getclass() here... a typical weld issue... endpointurl=appconfiguration.getbaseendpoint() + bulkwebservice.class.getannotation(path.class).value(); availablemethods= arrays.aslist(verb.values()); usersendpoint=userws.getendpointurl(); groupsendpoint=groupws.getendpointurl(); fidodevicesendpoint=fidodevicews.getendpointurl(); commonwsendpointprefix=usersendpoint.substring(0, usersendpoint.lastindexof(\"\/\")); }","code_context_20":"@postconstruct public void setup(){ \/\/do not use getclass() here... a typical weld issue... endpointurl=appconfiguration.getbaseendpoint() + bulkwebservice.class.getannotation(path.class).value(); availablemethods= arrays.aslist(verb.values()); usersendpoint=userws.getendpointurl(); groupsendpoint=groupws.getendpointurl(); fidodevicesendpoint=fidodevicews.getendpointurl(); commonwsendpointprefix=usersendpoint.substring(0, usersendpoint.lastindexof(\"\/\")); }","repo":"linosgian\/oxTrust"}
{"id":10032,"comment_id":0,"comment":"\/\/ todo: need lightweight approach (start)","code":"private void onnetbegin( beginfw begin) { final long sequence = begin.sequence(); final long acknowledge = begin.acknowledge(); final int maximum = begin.maximum(); final long traceid = begin.traceid(); final long authorization = begin.authorization(); final long affinity = begin.affinity(); assert acknowledge <= sequence; assert sequence >= replyseq; assert acknowledge <= replyack; replyseq = sequence; replyack = acknowledge; assert replyack == replyseq; assert maximum == 0; boolean handshakehashok = false; final octetsfw extension = begin.extension(); if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>(); httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\"); final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) && objects.equals(this.protocol, protocol)) { sha1.reset(); sha1.update(key.getbytes(us_ascii)); final byte[] digest = sha1.digest(handshake_guid); final encoder encoder = base64.getencoder(); final string handshakehash = new string(encoder.encode(digest), us_ascii); handshakehashok = handshakehash.equals(hash); } } if (handshakehashok) { doappbegin(maximum, traceid, authorization, affinity); } else { doappreset(traceid, authorization); } }","classification":"DESIGN","isFinished":true,"code_context_2":"if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>();","code_context_10":"assert sequence >= replyseq; assert acknowledge <= replyack; replyseq = sequence; replyack = acknowledge; assert replyack == replyseq; assert maximum == 0; boolean handshakehashok = false; final octetsfw extension = begin.extension(); if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>(); httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\");","code_context_20":"private void onnetbegin( beginfw begin) { final long sequence = begin.sequence(); final long acknowledge = begin.acknowledge(); final int maximum = begin.maximum(); final long traceid = begin.traceid(); final long authorization = begin.authorization(); final long affinity = begin.affinity(); assert acknowledge <= sequence; assert sequence >= replyseq; assert acknowledge <= replyack; replyseq = sequence; replyack = acknowledge; assert replyack == replyseq; assert maximum == 0; boolean handshakehashok = false; final octetsfw extension = begin.extension(); if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>(); httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\"); final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) && objects.equals(this.protocol, protocol)) { sha1.reset(); sha1.update(key.getbytes(us_ascii)); final byte[] digest = sha1.digest(handshake_guid);","repo":"lukefallows\/zilla"}
{"id":10032,"comment_id":1,"comment":"\/\/ todo: need lightweight approach (end)","code":"private void onnetbegin( beginfw begin) { final long sequence = begin.sequence(); final long acknowledge = begin.acknowledge(); final int maximum = begin.maximum(); final long traceid = begin.traceid(); final long authorization = begin.authorization(); final long affinity = begin.affinity(); assert acknowledge <= sequence; assert sequence >= replyseq; assert acknowledge <= replyack; replyseq = sequence; replyack = acknowledge; assert replyack == replyseq; assert maximum == 0; boolean handshakehashok = false; final octetsfw extension = begin.extension(); if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>(); httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\"); final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) && objects.equals(this.protocol, protocol)) { sha1.reset(); sha1.update(key.getbytes(us_ascii)); final byte[] digest = sha1.digest(handshake_guid); final encoder encoder = base64.getencoder(); final string handshakehash = new string(encoder.encode(digest), us_ascii); handshakehashok = handshakehash.equals(hash); } } if (handshakehashok) { doappbegin(maximum, traceid, authorization, affinity); } else { doappreset(traceid, authorization); } }","classification":"DESIGN","isFinished":true,"code_context_2":"final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) &&","code_context_10":"httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\"); final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) && objects.equals(this.protocol, protocol)) { sha1.reset(); sha1.update(key.getbytes(us_ascii)); final byte[] digest = sha1.digest(handshake_guid); final encoder encoder = base64.getencoder(); final string handshakehash = new string(encoder.encode(digest), us_ascii); handshakehashok = handshakehash.equals(hash);","code_context_20":"replyack = acknowledge; assert replyack == replyseq; assert maximum == 0; boolean handshakehashok = false; final octetsfw extension = begin.extension(); if (extension.sizeof() != 0) { \/\/ todo: need lightweight approach (start) final httpbeginexfw httpbeginex = extension.get(httpbeginexro::wrap); final map<string, string> headers = new linkedhashmap<>(); httpbeginex.headers().foreach(header -> { final string name = header.name().asstring(); final string value = header.value().asstring(); headers.merge(name, value, (v1, v2) -> string.format(\"%s, %s\", v1, v2)); }); final string status = headers.get(\":status\"); final string upgrade = headers.get(\"upgrade\"); final string hash = headers.get(\"sec-websocket-accept\"); final string protocol = headers.get(\"sec-websocket-protocol\"); \/\/ todo: need lightweight approach (end) if (websocket_status.equals(status) && websocket_upgrade.equals(upgrade) && objects.equals(this.protocol, protocol)) { sha1.reset(); sha1.update(key.getbytes(us_ascii)); final byte[] digest = sha1.digest(handshake_guid); final encoder encoder = base64.getencoder(); final string handshakehash = new string(encoder.encode(digest), us_ascii); handshakehashok = handshakehash.equals(hash); } } if (handshakehashok) { doappbegin(maximum, traceid, authorization, affinity); } else { doappreset(traceid, authorization); }","repo":"lukefallows\/zilla"}
{"id":18250,"comment_id":0,"comment":"\/\/ todo: explain more","code":"@override public value evaluate(context context) { value operand1 = get(0, context); value operand2 = get(1, context); if (operand1.isnumber() && operand2.islist()) { bigdecimal value1 = operand1.getnumber(); list<value> value2 = operand2.getlist(); return value2.get(value1.intvalue()); } else if (operand1.isnumber() && operand2.isstring()) { bigdecimal value1 = operand1.getnumber(); string value2 = operand2.getstring(); return value.asstring(string.valueof(value2.charat(value1.intvalue()))); } \/\/ todo: explain more throw new runtimeexception(\"cannot perform operation '\" + token.lexeme + \"' at: [\" + token.line + \", \" + token.column + \"]\"); }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"return value.asstring(string.valueof(value2.charat(value1.intvalue()))); } \/\/ todo: explain more throw new runtimeexception(\"cannot perform operation '\" + token.lexeme + \"' at: [\" + token.line + \", \" + token.column + \"]\"); }","code_context_10":"bigdecimal value1 = operand1.getnumber(); list<value> value2 = operand2.getlist(); return value2.get(value1.intvalue()); } else if (operand1.isnumber() && operand2.isstring()) { bigdecimal value1 = operand1.getnumber(); string value2 = operand2.getstring(); return value.asstring(string.valueof(value2.charat(value1.intvalue()))); } \/\/ todo: explain more throw new runtimeexception(\"cannot perform operation '\" + token.lexeme + \"' at: [\" + token.line + \", \" + token.column + \"]\"); }","code_context_20":"@override public value evaluate(context context) { value operand1 = get(0, context); value operand2 = get(1, context); if (operand1.isnumber() && operand2.islist()) { bigdecimal value1 = operand1.getnumber(); list<value> value2 = operand2.getlist(); return value2.get(value1.intvalue()); } else if (operand1.isnumber() && operand2.isstring()) { bigdecimal value1 = operand1.getnumber(); string value2 = operand2.getstring(); return value.asstring(string.valueof(value2.charat(value1.intvalue()))); } \/\/ todo: explain more throw new runtimeexception(\"cannot perform operation '\" + token.lexeme + \"' at: [\" + token.line + \", \" + token.column + \"]\"); }","repo":"mauriciotogneri\/prefix"}
{"id":10131,"comment_id":0,"comment":"\/\/ todo(b\/181858113): this test is likely obsolete once main-dex-list support is removed.","code":"\/\/ todo(b\/181858113): this test is likely obsolete once main-dex-list support is removed. @test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","classification":"TEST","isFinished":true,"code_context_2":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","code_context_10":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","code_context_20":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","repo":"kami-lang\/madex-r8"}
{"id":10131,"comment_id":1,"comment":"\/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main).","code":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","classification":"NONSATD","isFinished":true,"code_context_2":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename());","code_context_10":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses()","code_context_20":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch(","repo":"kami-lang\/madex-r8"}
{"id":10131,"comment_id":2,"comment":"\/\/ the main dex classes should be the same as the input main dex list.","code":"@test public void test() throws exception { \/\/ the generated main dex list should contain main (which is a root) and a (which is a direct \/\/ dependency of main). assertequals(2, maindexlist.size()); assertequals(a.class.gettypename(), maindexlist.get(0).gettypename()); assertequals(main.class.gettypename(), maindexlist.get(1).gettypename()); r8testcompileresult compileresult = testforr8(parameters.getbackend()) .addinnerclasses(getclass()) .addinliningannotations() .addkeepclassandmembersrules(main.class) .addmaindexlistclassreferences(maindexlist) .collectmaindexclasses() .enableinliningannotations() .enablenohorizontalclassmergingannotations() .enablenohorizontalclassmergingannotations() .setminapi(parameters.getapilevel()) .allowdiagnosticmessages() .compilewithexpecteddiagnostics( diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","classification":"NONSATD","isFinished":true,"code_context_2":"assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()),","code_context_10":"classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","code_context_20":"diagnostics -> diagnostics .assertonlywarnings() .assertwarningsmatch( diagnostictype(unsupportedmaindexlistusagediagnostic.class))); codeinspector inspector = compileresult.inspector(); classsubject mainclasssubject = inspector.clazz(main.class); assertthat(mainclasssubject, ispresent()); methodsubject foomethodsubject = mainclasssubject.uniquemethodwithname(\"foo\"); assertthat(foomethodsubject, ispresent()); classsubject aclasssubject = inspector.clazz(a.class); assertthat(aclasssubject, ispresent()); methodsubject barmethodsubject = aclasssubject.uniquemethodwithname(\"bar\"); assertthat(barmethodsubject, ispresent()); classsubject bclasssubject = inspector.clazz(b.class); assertthat(bclasssubject, ispresent()); methodsubject bazmethodsubject = bclasssubject.uniquemethodwithname(\"baz\"); assertthat(bazmethodsubject, ispresent()); assertthat(foomethodsubject, invokesmethod(barmethodsubject)); assertthat(barmethodsubject, invokesmethod(bazmethodsubject)); \/\/ the main dex classes should be the same as the input main dex list. assertequals( immutableset.of(mainclasssubject.getfinalname(), aclasssubject.getfinalname()), compileresult.getmaindexclasses()); }","repo":"kami-lang\/madex-r8"}
{"id":18378,"comment_id":0,"comment":"\/** * gets abstractoption set. * @return the {@code abstractoption} set *\/","code":"\/** * gets abstractoption set. * @return the {@code abstractoption} set *\/ public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","classification":"NONSATD","isFinished":true,"code_context_2":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","code_context_10":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","code_context_20":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","repo":"kupl\/starlab-benchmarks"}
{"id":18378,"comment_id":1,"comment":"\/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying!","code":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","classification":"DEFECT","isFinished":true,"code_context_2":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","code_context_10":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","code_context_20":"public t getabstractoption() { \/\/ warning!! do not rename this method to getoption(). it breaks \/\/ beanutils, which will silently not call setoption. very annoying! return abstractoption; }","repo":"kupl\/starlab-benchmarks"}
{"id":18390,"comment_id":0,"comment":"\/\/ todo want to use classloader = mgmt.getcatalog().getrootclassloader();","code":"@override public brooklyn.management.internal.usagelistener apply(string input) { \/\/ todo want to use classloader = mgmt.getcatalog().getrootclassloader(); classloader classloader = localusagemanager.class.getclassloader(); optional<object> result = reflections.invokeconstructorwithargs(classloader, input); if (result.ispresent()) { if (result.get() instanceof brooklyn.management.internal.usagemanager.usagelistener) { return new brooklyn.management.internal.usagemanager.usagelistener.usagelisteneradapter((brooklyn.management.internal.usagemanager.usagelistener) result.get()); } else { return (brooklyn.management.internal.usagelistener) result.get(); } } else { throw new illegalstateexception(\"failed to create usagelistener from class name '\"+input+\"' using no-arg constructor\"); } }","classification":"DESIGN","isFinished":true,"code_context_2":"@override public brooklyn.management.internal.usagelistener apply(string input) { \/\/ todo want to use classloader = mgmt.getcatalog().getrootclassloader(); classloader classloader = localusagemanager.class.getclassloader(); optional<object> result = reflections.invokeconstructorwithargs(classloader, input);","code_context_10":"@override public brooklyn.management.internal.usagelistener apply(string input) { \/\/ todo want to use classloader = mgmt.getcatalog().getrootclassloader(); classloader classloader = localusagemanager.class.getclassloader(); optional<object> result = reflections.invokeconstructorwithargs(classloader, input); if (result.ispresent()) { if (result.get() instanceof brooklyn.management.internal.usagemanager.usagelistener) { return new brooklyn.management.internal.usagemanager.usagelistener.usagelisteneradapter((brooklyn.management.internal.usagemanager.usagelistener) result.get()); } else { return (brooklyn.management.internal.usagelistener) result.get(); } } else { throw new illegalstateexception(\"failed to create usagelistener from class name '\"+input+\"' using no-arg constructor\");","code_context_20":"@override public brooklyn.management.internal.usagelistener apply(string input) { \/\/ todo want to use classloader = mgmt.getcatalog().getrootclassloader(); classloader classloader = localusagemanager.class.getclassloader(); optional<object> result = reflections.invokeconstructorwithargs(classloader, input); if (result.ispresent()) { if (result.get() instanceof brooklyn.management.internal.usagemanager.usagelistener) { return new brooklyn.management.internal.usagemanager.usagelistener.usagelisteneradapter((brooklyn.management.internal.usagemanager.usagelistener) result.get()); } else { return (brooklyn.management.internal.usagelistener) result.get(); } } else { throw new illegalstateexception(\"failed to create usagelistener from class name '\"+input+\"' using no-arg constructor\"); } }","repo":"kiuby88\/incubator-brooklyn"}
{"id":2022,"comment_id":0,"comment":"\/\/ workaround for the db file deletion problem during the tests","code":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","classification":"DESIGN","isFinished":true,"code_context_2":"testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables","code_context_10":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade();","code_context_20":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","repo":"kimjand\/cxf"}
{"id":2022,"comment_id":1,"comment":"\/\/ use the old db definitions to create the tables","code":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables","code_context_10":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables","code_context_20":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","repo":"kimjand\/cxf"}
{"id":2022,"comment_id":2,"comment":"\/\/ verify the absence of the new columns in the tables","code":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true);","code_context_10":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false);","code_context_20":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","repo":"kimjand\/cxf"}
{"id":2022,"comment_id":3,"comment":"\/\/ upgrade the tables and add new columns to the old tables","code":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","classification":"NONSATD","isFinished":true,"code_context_2":"verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init();","code_context_10":"store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","code_context_20":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","repo":"kimjand\/cxf"}
{"id":2022,"comment_id":4,"comment":"\/\/ verify the presence of the new columns in the upgraded tables","code":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","classification":"NONSATD","isFinished":true,"code_context_2":"store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false);","code_context_10":"\/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","code_context_20":"@test public void testupgradetables() throws exception { testrmtxstore store = new testrmtxstore(); store.setdriverclassname(\"org.apache.derby.jdbc.embeddeddriver\"); \/\/ workaround for the db file deletion problem during the tests store.seturl(messageformat.format(\"jdbc:derby:{0};create=true\", test_db_name)); \/\/ use the old db definitions to create the tables store.init(); \/\/ verify the absence of the new columns in the tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, true); verifycolumns(store, inbound_msgs_table_name, new string[]{}, true); verifycolumns(store, outbound_msgs_table_name, new string[]{}, true); \/\/ upgrade the tables and add new columns to the old tables store.upgrade(); store.init(); \/\/ verify the presence of the new columns in the upgraded tables verifycolumns(store, \"cxf_rm_src_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, \"cxf_rm_dest_sequences\", new string[]{\"protocol_version\"}, false); verifycolumns(store, inbound_msgs_table_name, new string[]{}, false); verifycolumns(store, outbound_msgs_table_name, new string[]{}, false); }","repo":"kimjand\/cxf"}
{"id":2048,"comment_id":0,"comment":"\/** * get the http credential header we need from a new oauth2 accesstoken. *\/","code":"\/** * get the http credential header we need from a new oauth2 accesstoken. *\/ @visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","classification":"NONSATD","isFinished":true,"code_context_2":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","code_context_10":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","code_context_20":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","repo":"mbrukman\/java-bigtable-hbase"}
{"id":2048,"comment_id":1,"comment":"\/\/ optimize for the common case: do a volatile read to peek for a good cache value","code":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","classification":"NONSATD","isFinished":true,"code_context_2":"headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) {","code_context_10":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache;","code_context_20":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement(","repo":"mbrukman\/java-bigtable-hbase"}
{"id":2048,"comment_id":2,"comment":"\/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads","code":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","classification":"DESIGN","isFinished":true,"code_context_2":"return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate();","code_context_10":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception:","code_context_20":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } }","repo":"mbrukman\/java-bigtable-hbase"}
{"id":2048,"comment_id":3,"comment":"\/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock)","code":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","classification":"NONSATD","isFinished":true,"code_context_2":"case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break;","code_context_10":"synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds);","code_context_20":"@visiblefortesting headercacheelement getheader() throws executionexception, interruptedexception, timeoutexception { final future<headercacheelement> deferredresult; \/\/ optimize for the common case: do a volatile read to peek for a good cache value headercacheelement headercacheunsync = this.headercache; if (headercacheunsync.getcachestate() == cachestate.good) { return headercacheunsync; } \/\/ todo(igorbernstein2): figure out how to make this work with appengine request scoped threads synchronized (lock) { cachestate state = headercache.getcachestate(); switch (state) { case good: return headercache; case stale: asyncrefresh(); return headercache; case expired: case exception: \/\/ defer the future resolution (asyncrefresh will spin up a thread that will try to acquire the lock) deferredresult = asyncrefresh(); break; default: return new headercacheelement( status.unauthenticated .withcause(new illegalstateexception(\"could not process state: \" + state)) ); } } return deferredresult.get(5, timeunit.seconds); }","repo":"mbrukman\/java-bigtable-hbase"}
{"id":10315,"comment_id":0,"comment":"\/** * merge the events in the given list if they are within the same period * general algorithm is as follows: * * 1) sort them into a map from (type, description)-> list<aggevent> * 2) for each key in map, merge the events and accumulate them in a list to * return * * @param timeunitlength * @param premergedevents * * @return *\/","code":"\/** * merge the events in the given list if they are within the same period * general algorithm is as follows: * * 1) sort them into a map from (type, description)-> list<aggevent> * 2) for each key in map, merge the events and accumulate them in a list to * return * * @param timeunitlength * @param premergedevents * * @return *\/ static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","code_context_10":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":1,"comment":"\/\/effectively map from type to (map from description to events)","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) {","code_context_10":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ...","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":2,"comment":"\/\/result list to return","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":".put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events","code_context_10":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next();","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":3,"comment":"\/\/for each (type, description) key, merge agg events","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ...","code_context_10":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next();","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next;","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":4,"comment":"\/\/for each description ...","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events","code_context_10":"\/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":5,"comment":"\/\/run through the sorted events, merging together adjacent events","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis()))","code_context_10":"for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) {","code_context_20":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":6,"comment":"\/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"DESIGN","isFinished":true,"code_context_2":"eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them","code_context_10":"\/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current);","code_context_20":"\/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":7,"comment":"\/\/merge them","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else {","code_context_10":"iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } }","code_context_20":"typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":8,"comment":"\/\/done merging into current, set next as new current","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next;","code_context_10":"eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) {","code_context_20":"\/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","repo":"karlmortensen\/autopsy"}
{"id":10315,"comment_id":9,"comment":"\/\/merge clusters to stripes","code":"static private list<eventstripe> mergeclusterstostripes(period timeunitlength, list<eventcluster> premergedevents) { \/\/effectively map from type to (map from description to events) map<eventtype, setmultimap< string, eventcluster>> typemap = new hashmap<>(); for (eventcluster aggregateevent : premergedevents) { typemap.computeifabsent(aggregateevent.geteventtype(), eventtype -> hashmultimap.create()) .put(aggregateevent.getdescription(), aggregateevent); } \/\/result list to return arraylist<eventcluster> aggevents = new arraylist<>(); \/\/for each (type, description) key, merge agg events for (setmultimap<string, eventcluster> descrmap : typemap.values()) { \/\/for each description ... for (string descr : descrmap.keyset()) { \/\/run through the sorted events, merging together adjacent events iterator<eventcluster> iterator = descrmap.get(descr).stream() .sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) {","code_context_10":"current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","code_context_20":".sorted(comparator.comparing(event -> event.getspan().getstartmillis())) .iterator(); eventcluster current = iterator.next(); while (iterator.hasnext()) { eventcluster next = iterator.next(); interval gap = current.getspan().gap(next.getspan()); \/\/if they overlap or gap is less one quarter timeunitlength \/\/todo: 1\/4 factor is arbitrary. review! -jm if (gap == null || gap.toduration().getmillis() <= timeunitlength.todurationfrom(gap.getstart()).getmillis() \/ 4) { \/\/merge them current = eventcluster.merge(current, next); } else { \/\/done merging into current, set next as new current aggevents.add(current); current = next; } } aggevents.add(current); } } \/\/merge clusters to stripes map<immutablepair<eventtype, string>, eventstripe> stripedescmap = new hashmap<>(); for (eventcluster eventcluster : aggevents) { stripedescmap.merge(immutablepair.of(eventcluster.geteventtype(), eventcluster.getdescription()), new eventstripe(eventcluster, null), eventstripe::merge); } return stripedescmap.values().stream().sorted(comparator.comparing(eventstripe::getstartmillis)).collect(collectors.tolist()); }","repo":"karlmortensen\/autopsy"}
{"id":2162,"comment_id":0,"comment":"\/** * method to store an object field into the attached instance. * @param fieldnumber number of the field to store * @param value the value in the detached instance *\/","code":"\/** * method to store an object field into the attached instance. * @param fieldnumber number of the field to store * @param value the value in the detached instance *\/ public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","code_context_10":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","code_context_20":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":1,"comment":"\/\/ no value so nothing to do","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext();","code_context_10":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) {","code_context_20":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec);","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":2,"comment":"\/\/ 1-1 interface field","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes))","code_context_10":"classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) {","code_context_20":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) {","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":3,"comment":"\/\/ field is defined to not accept this type so just return","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; }","code_context_10":"datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true;","code_context_20":"{ if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin)","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":4,"comment":"\/\/ not join table so no supported schema updates","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (!hasjoin) { \/\/ not join table so no supported schema updates return; }","code_context_10":"else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) {","code_context_20":"} processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray())","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":5,"comment":"\/\/ update value mapping using first element. maybe we should do the same for all elements?","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec);","code_context_10":"if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements?","code_context_20":"} } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) {","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":6,"comment":"\/\/ update value mapping using first element. maybe we should do the same for all elements?","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec);","code_context_10":"if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements?","code_context_20":"} } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) {","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":7,"comment":"\/\/ not join table so no supported schema updates","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (!hasjoin) { \/\/ not join table so no supported schema updates return; }","code_context_10":"else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) {","code_context_20":"} processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray())","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":8,"comment":"\/\/ update key mapping using first key. maybe we should do the same for all keys?","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next();","code_context_10":"map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next();","code_context_20":"if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","repo":"meysam\/datanucleus-rdbms"}
{"id":2162,"comment_id":9,"comment":"\/\/ update value mapping using first value. maybe we should do the same for all values?","code":"public void storeobjectfield(int fieldnumber, object value) { if (value == null) { return; \/\/ no value so nothing to do } executioncontext ec = op.getexecutioncontext(); classloaderresolver clr = ec.getclassloaderresolver(); abstractmembermetadata mmd = op.getclassmetadata().getmetadataformanagedmemberatabsoluteposition(fieldnumber); if (mmd != null) { datastoreclass table = rdbmsmgr.getdatastoreclass(op.getobject().getclass().getname(), clr); javatypemapping fieldmapping = table.getmembermapping(mmd); if (fieldmapping != null) { if (fieldmapping instanceof interfacemapping) { \/\/ 1-1 interface field interfacemapping intfmapping = (interfacemapping)fieldmapping; if (mmd.getfieldtypes() != null || mmd.hasextension(metadata.extension_member_implementation_classes)) { \/\/ field is defined to not accept this type so just return return; } processinterfacemappingforvalue(intfmapping, value, mmd, ec); } else if (mmd.hascollection() || mmd.hasarray()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); elementcontainertable colltbl = (elementcontainertable)jointbl; javatypemapping elemmapping = colltbl.getelementmapping(); if (elemmapping instanceof interfacemapping) { interfacemapping intfmapping = (interfacemapping)elemmapping; if (mmd.hascollection()) { collection coll = (collection)value; if (coll.isempty()) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = coll.iterator().next(); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } else if (mmd.hasarray()) { if (array.getlength(value) == 0) { return; } \/\/ update value mapping using first element. maybe we should do the same for all elements? object elementvalue = array.get(value, 0); processinterfacemappingforvalue(intfmapping, elementvalue, mmd, ec); } } } else if (mmd.hasmap()) { boolean hasjoin = false; if (mmd.getjoinmetadata() != null) { hasjoin = true; } else { abstractmembermetadata[] relmmds = mmd.getrelatedmembermetadata(clr); if (relmmds != null && relmmds[0].getjoinmetadata() != null) { hasjoin = true; } } if (!hasjoin) { \/\/ not join table so no supported schema updates return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next();","code_context_10":"if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","code_context_20":"return; } map map = (map)value; if (map.isempty()) { return; } table jointbl = fieldmapping.getstoremanager().gettable(mmd); maptable maptbl = (maptable)jointbl; javatypemapping keymapping = maptbl.getkeymapping(); if (keymapping instanceof interfacemapping) { \/\/ update key mapping using first key. maybe we should do the same for all keys? interfacemapping intfmapping = (interfacemapping)keymapping; object keyvalue = map.keyset().iterator().next(); processinterfacemappingforvalue(intfmapping, keyvalue, mmd, ec); } javatypemapping valmapping = maptbl.getvaluemapping(); if (valmapping instanceof interfacemapping) { \/\/ update value mapping using first value. maybe we should do the same for all values? interfacemapping intfmapping = (interfacemapping)valmapping; object valvalue = map.values().iterator().next(); processinterfacemappingforvalue(intfmapping, valvalue, mmd, ec); } } } } }","repo":"meysam\/datanucleus-rdbms"}
{"id":2180,"comment_id":0,"comment":"\/\/menumanager menu = menumanager.getinstance();","code":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","classification":"NONSATD","isFinished":true,"code_context_2":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad);","code_context_10":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel);","code_context_20":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","repo":"maehem\/Thump"}
{"id":2180,"comment_id":1,"comment":"\/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults","code":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","classification":"NONSATD","isFinished":true,"code_context_2":"logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\");","code_context_10":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0;","code_context_20":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","repo":"maehem\/Thump"}
{"id":2180,"comment_id":2,"comment":"\/\/todo handled in r_planes.c","code":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","classification":"DESIGN","isFinished":true,"code_context_2":"r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables ();","code_context_10":"data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","code_context_20":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","repo":"maehem\/Thump"}
{"id":2180,"comment_id":3,"comment":"\/\/todo handled in r_sky.c","code":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","classification":"DESIGN","isFinished":true,"code_context_2":"r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c","code_context_10":"\/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","code_context_20":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","repo":"maehem\/Thump"}
{"id":2180,"comment_id":4,"comment":"\/\/todo handled in r_draw.c","code":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","classification":"DESIGN","isFinished":true,"code_context_2":"r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","code_context_10":"\/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","code_context_20":"public void r_init (wad wad, int screenblocks, boolean detaillevel) { \/\/menumanager menu = menumanager.getinstance(); logger.config(\"r_initdata\"); data.r_initdata (wad); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_initpointtoangle\"); \/\/r_initpointtoangle (); \/\/unused - gets points from a table. \/\/logger.config(\"\\nr_inittables\"); \/\/r_inittables (); \/\/ viewwidth \/ viewheight \/ detaillevel are set by the defaults r_setviewsize (screenblocks, detaillevel); logger.config(\"r_initplanes\"); plane.r_initplanes (); \/\/todo handled in r_planes.c logger.config(\"r_initlighttables\"); r_initlighttables (); logger.config(\"r_initskymap\"); r_initskymap (wad); \/\/todo handled in r_sky.c logger.config(\"r_inittranslationtables\"); draw.r_inittranslationtables (); \/\/todo handled in r_draw.c framecount = 0; }","repo":"maehem\/Thump"}
{"id":2227,"comment_id":0,"comment":"\/** * validate a document against an iepd. note that this does not require the xsi namespace location attributes to be set in the instance. * * @param schemapathlist * the paths to all schemas necessary to validate the instance; this is the equivalent of specifying these schemas in an xsi:schemalocation attribute in the instance * * @param never_used_todo_remove * * * @param rootschemafilename * the name of the document\/exchange schema * @param d * the document to validate * @param iepdresourceresolver * the resource resolver to use * @return the document that was validated * @throws exception * if the document is not valid *\/","code":"\/** * validate a document against an iepd. note that this does not require the xsi namespace location attributes to be set in the instance. * * @param schemapathlist * the paths to all schemas necessary to validate the instance; this is the equivalent of specifying these schemas in an xsi:schemalocation attribute in the instance * * @param never_used_todo_remove * * * @param rootschemafilename * the name of the document\/exchange schema * @param d * the document to validate * @param iepdresourceresolver * the resource resolver to use * @return the document that was validated * @throws exception * if the document is not valid *\/ public static void validateinstance(document d, lsresourceresolver iepdresourceresolver, list<string> schemapathlist) throws saxexception, exception { schemafactory schemafactory = schemafactory.newinstance(xmlconstants.w3c_xml_schema_ns_uri); schemafactory.setresourceresolver(iepdresourceresolver); list<source> sourcelist = new arraylist<source>(); for (string schemapath : schemapathlist) { inputstream schemainstream = xmlutils.class.getclassloader().getresourceasstream(schemapath); streamsource schemastreamsource = new streamsource(schemainstream); sourcelist.add(schemastreamsource); } source[] schemasourcesarray = sourcelist.toarray(new source[]{}); try { schema schema = schemafactory.newschema(schemasourcesarray); validator validator = schema.newvalidator(); validator.validate(new domsource(d)); } catch (exception e) { try { e.printstacktrace(); system.err.println(\"input document:\"); xmlutils.printnode(d); } catch (exception e1) { e1.printstacktrace(); } throw e; } }","classification":"NONSATD","isFinished":true,"code_context_2":"public static void validateinstance(document d, lsresourceresolver iepdresourceresolver, list<string> schemapathlist) throws saxexception, exception { schemafactory schemafactory = schemafactory.newinstance(xmlconstants.w3c_xml_schema_ns_uri); schemafactory.setresourceresolver(iepdresourceresolver); list<source> sourcelist = new arraylist<source>(); for (string schemapath : schemapathlist) { inputstream schemainstream = xmlutils.class.getclassloader().getresourceasstream(schemapath); streamsource schemastreamsource = new streamsource(schemainstream); sourcelist.add(schemastreamsource); } source[] schemasourcesarray = sourcelist.toarray(new source[]{}); try { schema schema = schemafactory.newschema(schemasourcesarray); validator validator = schema.newvalidator(); validator.validate(new domsource(d)); } catch (exception e) { try { e.printstacktrace(); system.err.println(\"input document:\"); xmlutils.printnode(d); } catch (exception e1) { e1.printstacktrace(); } throw e; } }","code_context_10":"public static void validateinstance(document d, lsresourceresolver iepdresourceresolver, list<string> schemapathlist) throws saxexception, exception { schemafactory schemafactory = schemafactory.newinstance(xmlconstants.w3c_xml_schema_ns_uri); schemafactory.setresourceresolver(iepdresourceresolver); list<source> sourcelist = new arraylist<source>(); for (string schemapath : schemapathlist) { inputstream schemainstream = xmlutils.class.getclassloader().getresourceasstream(schemapath); streamsource schemastreamsource = new streamsource(schemainstream); sourcelist.add(schemastreamsource); } source[] schemasourcesarray = sourcelist.toarray(new source[]{}); try { schema schema = schemafactory.newschema(schemasourcesarray); validator validator = schema.newvalidator(); validator.validate(new domsource(d)); } catch (exception e) { try { e.printstacktrace(); system.err.println(\"input document:\"); xmlutils.printnode(d); } catch (exception e1) { e1.printstacktrace(); } throw e; } }","code_context_20":"public static void validateinstance(document d, lsresourceresolver iepdresourceresolver, list<string> schemapathlist) throws saxexception, exception { schemafactory schemafactory = schemafactory.newinstance(xmlconstants.w3c_xml_schema_ns_uri); schemafactory.setresourceresolver(iepdresourceresolver); list<source> sourcelist = new arraylist<source>(); for (string schemapath : schemapathlist) { inputstream schemainstream = xmlutils.class.getclassloader().getresourceasstream(schemapath); streamsource schemastreamsource = new streamsource(schemainstream); sourcelist.add(schemastreamsource); } source[] schemasourcesarray = sourcelist.toarray(new source[]{}); try { schema schema = schemafactory.newschema(schemasourcesarray); validator validator = schema.newvalidator(); validator.validate(new domsource(d)); } catch (exception e) { try { e.printstacktrace(); system.err.println(\"input document:\"); xmlutils.printnode(d); } catch (exception e1) { e1.printstacktrace(); } throw e; } }","repo":"mark43\/nibrs"}
{"id":18713,"comment_id":0,"comment":"\/** todo this test works if we assume most recent version wins, but semantics tbc *\/","code":"@test \/** todo this test works if we assume most recent version wins, but semantics tbc *\/ public void testmoreentityv2thenv1givesv1() throws exception { testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.1.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.2.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-entities.jar\"); addcatalogitems(getlocalresource(\"more-entity-v2-osgi-catalog.yaml\")); forcecatalogupdate(); addcatalogitems(getlocalresource(\"more-entity-v1-osgi-catalog.yaml\")); entity app = createandstartapplication(\"services: [ { type: 'more-entity:1.0' } ]\"); entity moreentity = iterables.getonlyelement(app.getchildren()); osgiversionmoreentitytest.assertv1effectorcall(moreentity); osgiversionmoreentitytest.assertv1methodcall(moreentity); }","classification":"DEFECT","isFinished":true,"code_context_2":"@test \/** todo this test works if we assume most recent version wins, but semantics tbc *\/ public void testmoreentityv2thenv1givesv1() throws exception { testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.1.0.jar\");","code_context_10":"@test \/** todo this test works if we assume most recent version wins, but semantics tbc *\/ public void testmoreentityv2thenv1givesv1() throws exception { testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.1.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.2.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-entities.jar\"); addcatalogitems(getlocalresource(\"more-entity-v2-osgi-catalog.yaml\")); forcecatalogupdate(); addcatalogitems(getlocalresource(\"more-entity-v1-osgi-catalog.yaml\")); entity app = createandstartapplication(\"services: [ { type: 'more-entity:1.0' } ]\"); entity moreentity = iterables.getonlyelement(app.getchildren()); osgiversionmoreentitytest.assertv1effectorcall(moreentity);","code_context_20":"@test \/** todo this test works if we assume most recent version wins, but semantics tbc *\/ public void testmoreentityv2thenv1givesv1() throws exception { testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.1.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-more-entities_0.2.0.jar\"); testresourceunavailableexception.throwifresourceunavailable(getclass(), \"\/brooklyn\/osgi\/brooklyn-test-osgi-entities.jar\"); addcatalogitems(getlocalresource(\"more-entity-v2-osgi-catalog.yaml\")); forcecatalogupdate(); addcatalogitems(getlocalresource(\"more-entity-v1-osgi-catalog.yaml\")); entity app = createandstartapplication(\"services: [ { type: 'more-entity:1.0' } ]\"); entity moreentity = iterables.getonlyelement(app.getchildren()); osgiversionmoreentitytest.assertv1effectorcall(moreentity); osgiversionmoreentitytest.assertv1methodcall(moreentity); }","repo":"kiuby88\/incubator-brooklyn"}
{"id":10580,"comment_id":0,"comment":"\/** * take a normal (non-priority) task out of a job queue, marking it as completed so it will not be re-delivered. * todo maybe use unique delivery receipts instead of task ids to handle redelivered tasks independently * @return whether the task was found and removed. *\/","code":"\/** * take a normal (non-priority) task out of a job queue, marking it as completed so it will not be re-delivered. * todo maybe use unique delivery receipts instead of task ids to handle redelivered tasks independently * @return whether the task was found and removed. *\/ public synchronized boolean marktaskcompleted (int taskid) { job job = getjobfortask(taskid); if (job == null) { log.error(\"could not find a job containing task {}, and therefore could not mark the task as completed.\", taskid); return false; } job.completedtasks.add(taskid); return true; }","classification":"DESIGN","isFinished":true,"code_context_2":"public synchronized boolean marktaskcompleted (int taskid) { job job = getjobfortask(taskid); if (job == null) { log.error(\"could not find a job containing task {}, and therefore could not mark the task as completed.\", taskid); return false; } job.completedtasks.add(taskid); return true; }","code_context_10":"public synchronized boolean marktaskcompleted (int taskid) { job job = getjobfortask(taskid); if (job == null) { log.error(\"could not find a job containing task {}, and therefore could not mark the task as completed.\", taskid); return false; } job.completedtasks.add(taskid); return true; }","code_context_20":"public synchronized boolean marktaskcompleted (int taskid) { job job = getjobfortask(taskid); if (job == null) { log.error(\"could not find a job containing task {}, and therefore could not mark the task as completed.\", taskid); return false; } job.completedtasks.add(taskid); return true; }","repo":"mcheung610\/r5"}
{"id":10625,"comment_id":0,"comment":"\/\/ check that the type serializer is consistent","code":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","classification":"NONSATD","isFinished":true,"code_context_2":"final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) {","code_context_10":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode);","code_context_20":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","repo":"ljzzju\/incubator-flink"}
{"id":10625,"comment_id":1,"comment":"\/\/todo ??? need to create a new tezconfig ???","code":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","classification":"DESIGN","isFinished":true,"code_context_2":"final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast);","code_context_10":"typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","code_context_20":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","repo":"ljzzju\/incubator-flink"}
{"id":10625,"comment_id":2,"comment":"\/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node","code":"private int translatechannel(channel input, int inputindex, flinkvertex targetvertex, teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","classification":"NONSATD","isFinished":true,"code_context_2":"inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1;","code_context_10":"typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","code_context_20":"teztaskconfig targetvertexconfig, boolean isbroadcast) throws exception { final plannode inputplannode = input.getsource(); final iterator<channel> allinchannels; allinchannels = collections.singletonlist(input).iterator(); \/\/ check that the type serializer is consistent typeserializerfactory<?> typeserfact = null; while (allinchannels.hasnext()) { final channel inconn = allinchannels.next(); if (typeserfact == null) { typeserfact = inconn.getserializer(); } else if (!typeserfact.equals(inconn.getserializer())) { throw new compilerexception(\"conflicting types in union operator.\"); } final plannode sourcenode = inconn.getsource(); flinkvertex sourcevertex = this.vertices.get(sourcenode); teztaskconfig sourcevertexconfig = sourcevertex.getconfig(); \/\/todo ??? need to create a new tezconfig ??? connectjobvertices( inconn, inputindex, sourcevertex, sourcevertexconfig, targetvertex, targetvertexconfig, isbroadcast); } \/\/ the local strategy is added only once. in non-union case that is the actual edge, \/\/ in the union case, it is the edge between union and the target node addlocalinfofromchanneltoconfig(input, targetvertexconfig, inputindex, isbroadcast); return 1; }","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":0,"comment":"\/\/ -------------- configure the source task's ship strategy strategies in task config --------------","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"NONSATD","isFinished":true,"code_context_2":"final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy());","code_context_10":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution();","code_context_20":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber);","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":1,"comment":"\/\/ todo: inject code and configuration for automatic histogram generation","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } }","code_context_10":"} if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge;","code_context_20":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); }","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":2,"comment":"\/\/ ---------------- configure the receiver -------------------","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber);","code_context_10":"} if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) {","code_context_20":"final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); }","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":3,"comment":"\/\/----------------- connect source and target with edge ------------------------------","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"NONSATD","isFinished":true,"code_context_2":"targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy();","code_context_10":"throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer);","code_context_20":"sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex);","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":4,"comment":"\/\/ for forward edges, create as many tasks in upstream operator as in source operator","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"NONSATD","isFinished":true,"code_context_2":"if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); }","code_context_10":"targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\");","code_context_20":"final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","repo":"ljzzju\/incubator-flink"}
{"id":10626,"comment_id":5,"comment":"\/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs","code":"private void connectjobvertices(channel channel, int inputnumber, final flinkvertex sourcevertex, final teztaskconfig sourceconfig, final flinkvertex targetvertex, final teztaskconfig targetconfig, boolean isbroadcast) throws compilerexception { \/\/ -------------- configure the source task's ship strategy strategies in task config -------------- final int outputindex = sourceconfig.getnumoutputs(); sourceconfig.addoutputshipstrategy(channel.getshipstrategy()); if (outputindex == 0) { sourceconfig.setoutputserializer(channel.getserializer()); } if (channel.getshipstrategycomparator() != null) { sourceconfig.setoutputcomparator(channel.getshipstrategycomparator(), outputindex); } if (channel.getshipstrategy() == shipstrategytype.partition_range) { final datadistribution datadistribution = channel.getdatadistribution(); if(datadistribution != null) { sourceconfig.setoutputdatadistribution(datadistribution, outputindex); } else { throw new runtimeexception(\"range partitioning requires data distribution\"); \/\/ todo: inject code and configuration for automatic histogram generation } } \/\/ ---------------- configure the receiver ------------------- if (isbroadcast) { targetconfig.addbroadcastinputtogroup(inputnumber); } else { targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","classification":"DESIGN","isFinished":true,"code_context_2":"throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber);","code_context_10":"} else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","code_context_20":"targetconfig.addinputtogroup(inputnumber); } \/\/----------------- connect source and target with edge ------------------------------ flinkedge edge; shipstrategytype shipstrategy = channel.getshipstrategy(); typeserializer<?> serializer = channel.getserializer().getserializer(); if ((shipstrategy == shipstrategytype.forward) || (shipstrategy == shipstrategytype.none)) { edge = new flinkforwardedge(sourcevertex, targetvertex, serializer); \/\/ for forward edges, create as many tasks in upstream operator as in source operator targetvertex.setparallelism(sourcevertex.getparallelism()); } else if (shipstrategy == shipstrategytype.broadcast) { edge = new flinkbroadcastedge(sourcevertex, targetvertex, serializer); } else if (shipstrategy == shipstrategytype.partition_hash) { edge = new flinkpartitionedge(sourcevertex, targetvertex, serializer); } else { throw new compilerexception(\"ship strategy between nodes \" + sourcevertex.getvertex().getname() + \" and \" + targetvertex.getvertex().getname() + \" currently not supported\"); } \/\/ tez-specific bookkeeping \/\/ todo: this probably will not work for vertices with multiple outputs sourcevertex.addnumberofsubtasksinoutput(targetvertex.getparallelism(), outputindex); targetvertex.addinput(sourcevertex, inputnumber); edges.add(edge); }","repo":"ljzzju\/incubator-flink"}
{"id":10732,"comment_id":0,"comment":"\/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid()));","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport()));","code_context_10":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) {","code_context_20":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) {","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":1,"comment":"\/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"DEFECT","isFinished":true,"code_context_2":"int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) {","code_context_10":"if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield();","code_context_20":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) {","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":2,"comment":"\/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal)","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; }","code_context_10":"c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal);","code_context_20":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal);","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":3,"comment":"\/\/ character is dead, respawn request","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ?","code_context_10":"} chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) {","code_context_20":"if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho?","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":4,"comment":"\/\/ always 0","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte();","code_context_10":"chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats();","code_context_20":"chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false);","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":5,"comment":"\/\/ ?","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999","code_context_10":"} } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); }","code_context_20":"} else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp();","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":6,"comment":"\/\/ so far only got 0?","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"DESIGN","isFinished":true,"code_context_2":": chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) {","code_context_10":"return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount));","code_context_20":"if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) {","repo":"lynsone\/swordie"}
{"id":10732,"comment_id":7,"comment":"\/\/ attempt to respawn them where they died.. maybe portal 0 is better tho?","code":"@handler(op = inheader.user_transfer_field_request) public static void handleusertransferfieldrequest(client c, inpacket inpacket) { char chr = c.getchr(); if (inpacket.getunreadamount() == 0) { \/\/ coming back from the cash shop \/\/ chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfieldid())); c.getchannelinstance().addclientintransfer(c.getchannel(), chr.getid(), c); c.write(clientsocket.migratecommand(true, (short) c.getchannelinstance().getport())); return; } byte fieldkey = inpacket.decodebyte(); int targetfield = inpacket.decodeint(); if (targetfield == 106020100 || targetfield == 106020400) { \/\/ same issue as below, its in mushroom kingdom so maybe the maps are just outdated or w\/e targetfield = 106020403; } else if (targetfield == 106020402) { \/\/ warping from portal in 106020403 is unable to find defined portal (not a scripted portal) targetfield = 106020000; } int x = inpacket.decodeshort(); int y = inpacket.decodeshort(); string portalname = inpacket.decodestring(); if (portalname != null && !\"\".equals(portalname)) { field field = chr.getfield(); portal portal = field.getportalbyname(portalname); if (portal.getscript() != null && !portal.getscript().equals(\"\")) { chr.getscriptmanager().startscript(portal.getid(), portal.getscript(), scripttype.portal); } else { field tofield = chr.getorcreatefieldbycurrentinstancetype(portal.gettargetmapid()); if (tofield == null) { return; } portal toportal = tofield.getportalbyname(portal.gettargetportalname()); if (toportal == null) { toportal = tofield.getportalbyname(\"sp\"); } chr.warp(tofield, toportal); } } else if (chr.gethp() <= 0) { if (ingameeventmanager.getinstance().charineventmap(chr.getid())) { ingameeventmanager.getinstance().getactiveevent().onmigratedeath(chr); chr.heal(chr.getmaxhp()); chr.healmp(chr.getmaxmp()); return; } \/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); } }","classification":"DESIGN","isFinished":true,"code_context_2":"chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp();","code_context_10":"if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); }","code_context_20":"\/\/ character is dead, respawn request inpacket.decodebyte(); \/\/ always 0 byte tarfield = inpacket.decodebyte(); \/\/ ? byte revivetype = inpacket.decodebyte(); int returnmap = chr.getfield().getreturnmap() == 999999999 ? chr.getpreviousfieldid() : chr.getfield().getreturnmap(); switch (revivetype) { \/\/ so far only got 0? } if (!chr.hasbuffprotector()) { chr.gettemporarystatmanager().removeallstats(); } int deathcount = chr.getdeathcount(); if (deathcount != 0) { if (deathcount > 0) { deathcount--; chr.setdeathcount(deathcount); chr.write(userlocal.deathcountinfo(deathcount)); } chr.setnearestreturnportal(); \/\/ attempt to respawn them where they died.. maybe portal 0 is better tho? chr.warp(chr.getfieldid(), chr.getpreviousportalid(), false); chr.healhpmp(); return; } else if (chr.getinstance() != null) { chr.getinstance().removechar(chr); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) { chr.warp(tofield); } chr.settransferfield(0); return; } else { chr.warp(chr.getorcreatefieldbycurrentinstancetype(chr.getfield().getforcedreturn())); } chr.healhpmp(); chr.setbuffprotector(false); } else if (chr.gettransferfield() == targetfield && chr.gettransferfieldreq() == chr.getfield().getid()) { field tofield = chr.getorcreatefieldbycurrentinstancetype(chr.gettransferfield()); if (tofield != null && chr.gettransferfield() > 0) {","repo":"lynsone\/swordie"}
{"id":18957,"comment_id":0,"comment":"\/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se);","code":"private <t extends serializable> void sendobject(communicationpatternagent agent, connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","classification":"DEFECT","isFinished":true,"code_context_2":"connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) {","code_context_10":"connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","code_context_20":"private <t extends serializable> void sendobject(communicationpatternagent agent, connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","repo":"mica-gossip\/MiCA"}
{"id":18957,"comment_id":1,"comment":"\/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e);","code":"private <t extends serializable> void sendobject(communicationpatternagent agent, connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","classification":"DEFECT","isFinished":true,"code_context_2":"connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) {","code_context_10":"connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","code_context_20":"private <t extends serializable> void sendobject(communicationpatternagent agent, connection connection, string logmessagename, t obj) throws fatalerrorhalt, abortround { byte[] data = null; data = agent.serialize(obj); logjson(logflag.serialization, \"mica-serialize-bytes-\" + logmessagename, data.length); byte[] lengthbytes = serializeinteger(data.length); try { connection.getoutputstream().write(lengthbytes); connection.getoutputstream().write(data); } catch (socketexception se) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, se); handleerror(gossip_io_error, new abortround()); } catch (ioexception e) { \/\/ fixme: check that handleerror is aborting on gossip_io_error \/\/ handleerror(gossip_io_error, e); handleerror(gossip_io_error, new abortround()); } }","repo":"mica-gossip\/MiCA"}
{"id":2602,"comment_id":0,"comment":"\/\/ the following should probably provide the type of the list, \/\/ and report cardinality as array.","code":"@test public void testuniontype() throws exception { string sql =\"select typeof(a) as t, modeof(a) as m, drilltypeof(a) as dt\\n\" + \"from cp.`jsoninput\/union\/c.json`\"; try { testbuilder() .optionsettingqueriesfortestquery(\"alter session set `exec.enable_union_type` = true\") .sqlquery(sql) .ordered() .baselinecolumns(\"t\", \"m\", \"dt\") .baselinevalues( \"varchar\", \"nullable\", \"union\") .baselinevalues( \"bigint\", \"nullable\", \"union\") .baselinevalues( \"float8\", \"nullable\", \"union\") \/\/ the following should probably provide the type of the list, \/\/ and report cardinality as array. .baselinevalues( \"list\", \"nullable\", \"union\") .baselinevalues( \"null\", \"nullable\", \"union\") .go(); } finally { client.resetsession(execconstants.enable_union_type_key); } }","classification":"DESIGN","isFinished":true,"code_context_2":".baselinevalues( \"bigint\", \"nullable\", \"union\") .baselinevalues( \"float8\", \"nullable\", \"union\") \/\/ the following should probably provide the type of the list, \/\/ and report cardinality as array. .baselinevalues( \"list\", \"nullable\", \"union\") .baselinevalues( \"null\", \"nullable\", \"union\")","code_context_10":"\"from cp.`jsoninput\/union\/c.json`\"; try { testbuilder() .optionsettingqueriesfortestquery(\"alter session set `exec.enable_union_type` = true\") .sqlquery(sql) .ordered() .baselinecolumns(\"t\", \"m\", \"dt\") .baselinevalues( \"varchar\", \"nullable\", \"union\") .baselinevalues( \"bigint\", \"nullable\", \"union\") .baselinevalues( \"float8\", \"nullable\", \"union\") \/\/ the following should probably provide the type of the list, \/\/ and report cardinality as array. .baselinevalues( \"list\", \"nullable\", \"union\") .baselinevalues( \"null\", \"nullable\", \"union\") .go(); } finally { client.resetsession(execconstants.enable_union_type_key); } }","code_context_20":"@test public void testuniontype() throws exception { string sql =\"select typeof(a) as t, modeof(a) as m, drilltypeof(a) as dt\\n\" + \"from cp.`jsoninput\/union\/c.json`\"; try { testbuilder() .optionsettingqueriesfortestquery(\"alter session set `exec.enable_union_type` = true\") .sqlquery(sql) .ordered() .baselinecolumns(\"t\", \"m\", \"dt\") .baselinevalues( \"varchar\", \"nullable\", \"union\") .baselinevalues( \"bigint\", \"nullable\", \"union\") .baselinevalues( \"float8\", \"nullable\", \"union\") \/\/ the following should probably provide the type of the list, \/\/ and report cardinality as array. .baselinevalues( \"list\", \"nullable\", \"union\") .baselinevalues( \"null\", \"nullable\", \"union\") .go(); } finally { client.resetsession(execconstants.enable_union_type_key); } }","repo":"julien-faye\/drill"}
{"id":10862,"comment_id":0,"comment":"\/\/ the following exception was thrown during execution in test generation","code":"@test public void test20046() throws throwable { if (debug) system.out.format(\"%n%s%n\", \"regressiontest40.test20046\"); org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","classification":"NONSATD","isFinished":true,"code_context_2":"java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1);","code_context_10":"response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13);","code_context_20":"@test public void test20046() throws throwable { if (debug) system.out.format(\"%n%s%n\", \"regressiontest40.test20046\"); org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","repo":"leusonmario\/2022PhDThesis"}
{"id":10862,"comment_id":1,"comment":"\/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\");","code":"@test public void test20046() throws throwable { if (debug) system.out.format(\"%n%s%n\", \"regressiontest40.test20046\"); org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","classification":"DEFECT","isFinished":true,"code_context_2":"try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception.","code_context_10":"java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0);","code_context_20":"if (debug) system.out.format(\"%n%s%n\", \"regressiontest40.test20046\"); org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","repo":"leusonmario\/2022PhDThesis"}
{"id":10862,"comment_id":2,"comment":"\/\/ expected exception.","code":"@test public void test20046() throws throwable { if (debug) system.out.format(\"%n%s%n\", \"regressiontest40.test20046\"); org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5);","code_context_10":"response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","code_context_20":"org.jsoup.helper.httpconnection.response response0 = null; org.jsoup.helper.httpconnection.response response1 = new org.jsoup.helper.httpconnection.response(response0); org.jsoup.connection.request request2 = null; response1.req = request2; java.util.map.entry<java.lang.string, java.lang.string> strentry5 = response1.scanheaders(\"hi!\"); response1.charset = \"hi!\"; int int8 = response1.numredirects; response1.contenttype = \"hi!\"; java.nio.bytebuffer bytebuffer11 = response1.bytedata; java.util.map.entry<java.lang.string, java.lang.string> strentry13 = response1.scanheaders(\"\"); response1.numredirects = (short) 10; response1.contenttype = \"\"; boolean boolean19 = response1.hascookie(\"hi!\"); java.lang.string str20 = response1.statusmessage(); int int21 = response1.statuscode(); \/\/ the following exception was thrown during execution in test generation try { org.jsoup.helper.httpconnection.response response22 = new org.jsoup.helper.httpconnection.response(response1); \/\/ flaky: org.junit.assert.fail(\"expected exception of type java.io.ioexception; message: too many redirects occurred trying to load url null\"); } catch (java.io.ioexception e) { \/\/ expected exception. } org.junit.assert.assertnull(strentry5); org.junit.assert.asserttrue(\"'\" + int8 + \"' != '\" + 0 + \"'\", int8 == 0); org.junit.assert.assertnull(bytebuffer11); org.junit.assert.assertnull(strentry13); org.junit.assert.asserttrue(\"'\" + boolean19 + \"' != '\" + false + \"'\", boolean19 == false); org.junit.assert.assertnull(str20); org.junit.assert.asserttrue(\"'\" + int21 + \"' != '\" + 0 + \"'\", int21 == 0); }","repo":"leusonmario\/2022PhDThesis"}
{"id":10871,"comment_id":0,"comment":"\/** adds a warning if a {@link produces @produces} method is declared nullable. *\/ \/\/ todo(beder): properly handle nullable with producer methods.","code":"\/** adds a warning if a {@link produces @produces} method is declared nullable. *\/ \/\/ todo(beder): properly handle nullable with producer methods. private void checknullable() { if (configurationannotations.getnullabletype(element).ispresent()) { report.addwarning(\"@nullable on @produces methods does not do anything\"); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void checknullable() { if (configurationannotations.getnullabletype(element).ispresent()) { report.addwarning(\"@nullable on @produces methods does not do anything\"); } }","code_context_10":"private void checknullable() { if (configurationannotations.getnullabletype(element).ispresent()) { report.addwarning(\"@nullable on @produces methods does not do anything\"); } }","code_context_20":"private void checknullable() { if (configurationannotations.getnullabletype(element).ispresent()) { report.addwarning(\"@nullable on @produces methods does not do anything\"); } }","repo":"lynnfield\/dagger"}
{"id":19094,"comment_id":0,"comment":"\/\/ fixme: change to a better test of containment?","code":"private imrivaluelistener createvaluelistener() { return new imrivaluelistener() { @override public void valuechanged(mrivalueevent event) { if (event.getvalue() instanceof compositedata) { \/\/ fixme: change to a better test of containment? dispose(); m_repository.movepossiblechildsubscriptions(unavailablechildsubscriptions.this); } } }; }","classification":"DESIGN","isFinished":true,"code_context_2":"public void valuechanged(mrivalueevent event) { if (event.getvalue() instanceof compositedata) { \/\/ fixme: change to a better test of containment? dispose(); m_repository.movepossiblechildsubscriptions(unavailablechildsubscriptions.this);","code_context_10":"private imrivaluelistener createvaluelistener() { return new imrivaluelistener() { @override public void valuechanged(mrivalueevent event) { if (event.getvalue() instanceof compositedata) { \/\/ fixme: change to a better test of containment? dispose(); m_repository.movepossiblechildsubscriptions(unavailablechildsubscriptions.this); } } }; }","code_context_20":"private imrivaluelistener createvaluelistener() { return new imrivaluelistener() { @override public void valuechanged(mrivalueevent event) { if (event.getvalue() instanceof compositedata) { \/\/ fixme: change to a better test of containment? dispose(); m_repository.movepossiblechildsubscriptions(unavailablechildsubscriptions.this); } } }; }","repo":"meghasfdc\/jmc"}
{"id":19169,"comment_id":0,"comment":"\/\/ find next wildcard in the pattern.","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"} while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) {","code_context_10":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) {","code_context_20":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false;","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":1,"comment":"\/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text.","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1;","code_context_10":"boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) {","code_context_20":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) {","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":2,"comment":"\/\/ pattern ends with '*', we're all good.","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; }","code_context_10":"int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos;","code_context_20":"int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":3,"comment":"\/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match.","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"DESIGN","isFinished":true,"code_context_2":"return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) {","code_context_10":"} \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true;","code_context_20":"int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; }","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":4,"comment":"\/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) {","code_context_10":"} \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1;","code_context_20":"wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) {","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":5,"comment":"\/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1;","code_context_10":"int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the","code_context_20":"\/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok.","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":6,"comment":"\/\/ if we matched, we're all set, otherwise we failed","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false;","code_context_10":"if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; }","code_context_20":"if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":7,"comment":"\/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) {","code_context_10":"\/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) {","code_context_20":"while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":8,"comment":"\/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok.","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1;","code_context_10":"} else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","code_context_20":"\/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","repo":"kovyrin\/crawler-commons"}
{"id":19169,"comment_id":9,"comment":"\/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern)","code":"private boolean rulematches(string text, string pattern) { int patternpos = 0; int textpos = 0; int patternend = pattern.length(); int textend = text.length(); boolean containsendchar = pattern.endswith(\"$\"); if (containsendchar) { patternend -= 1; } while ((patternpos < patternend) && (textpos < textend)) { \/\/ find next wildcard in the pattern. int wildcardpos = pattern.indexof('*', patternpos); if (wildcardpos == -1) { wildcardpos = patternend; } \/\/ if we're at a wildcard in the pattern, find the place in the text \/\/ where the character(s) after the wildcard match up with what's in \/\/ the text. if (wildcardpos == patternpos) { patternpos += 1; if (patternpos >= patternend) { \/\/ pattern ends with '*', we're all good. return true; } \/\/ todo - don't worry about having two '*' in a row? \/\/ find the end of the pattern piece we need to match. int patternpieceend = pattern.indexof('*', patternpos); if (patternpieceend == -1) { patternpieceend = patternend; } boolean matched = false; int patternpiecelen = patternpieceend - patternpos; while ((textpos + patternpiecelen <= textend) && !matched) { \/\/ see if patternpiecelen chars from text at textpos match \/\/ chars from pattern at patternpos matched = true; for (int i = 0; i < patternpiecelen && matched; i++) { if (text.charat(textpos + i) != pattern.charat(patternpos + i)) { matched = false; } } \/\/ if we matched, we're all set, otherwise we have to \/\/ advance textpos if (!matched) { textpos += 1; } } \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","classification":"NONSATD","isFinished":true,"code_context_2":"patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","code_context_10":"return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","code_context_20":"} \/\/ if we matched, we're all set, otherwise we failed if (!matched) { return false; } } else { \/\/ see if the pattern from patternpos to wildcardpos matches the \/\/ text starting at textpos while ((patternpos < wildcardpos) && (textpos < textend)) { if (text.charat(textpos++) != pattern.charat(patternpos++)) { return false; } } } } \/\/ if we didn't reach the end of the pattern, make sure we're not at a \/\/ wildcard, that's a 0 or more match, so then we're still ok. while ((patternpos < patternend) && (pattern.charat(patternpos) == '*')) { patternpos += 1; } \/\/ we're at the end, so we have a match if the pattern was completely \/\/ consumed, and either we consumed all the text or we didn't have to \/\/ match it all (no '$' at end of the pattern) return (patternpos == patternend) && ((textpos == textend) || !containsendchar); }","repo":"kovyrin\/crawler-commons"}
{"id":11110,"comment_id":0,"comment":"\/\/ todo we should only validate versions that we have a match","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved)","code_context_10":"staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_20":"hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional);","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":1,"comment":"\/\/$non-nls-1$ \/\/$non-nls-2$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":2,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":3,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":4,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":5,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":6,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":7,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":11110,"comment_id":8,"comment":"\/\/$non-nls-1$","code":"private void validateimportpackage(iprogressmonitor monitor) { iheader header = getheader(constants.import_package); if (header == null) return; bundledescription desc = fmodel.getbundledescription(); if (desc == null) { manifestelement[] elements = header.getelements(); for (int i = 0; i < elements.length; i++) { validatespecificationversionattribute(header, elements[i]); validateimportpackageversion(header, elements[i]); } return; } boolean hasunresolved = false; versionconstraint[] constraints = desc.getcontainingstate().getstatehelper().getunsatisfiedconstraints(desc); for (int i = 0; i < constraints.length; i++) { if (constraints[i] instanceof importpackagespecification) { hasunresolved = true; break; } } hashmap<string, exportpackagedescription> exported = getavailableexportedpackages(desc.getcontainingstate()); importpackagespecification[] imports = desc.getimportpackages(); if (desc.hasdynamicimports()) { list<importpackagespecification> staticimportslist = new arraylist(); for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); } } else { report(nls.bind(pdecoremessages.bundleerrorreporter_unresolvedexporter, new string[] { export.getsupplier().getsymbolicname(), name }), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_other); } } else { imarker marker = report(nls.bind(pdecoremessages.bundleerrorreporter_packagenotexported, name), getpackageline(header, elements[i]), severity, pdemarkerfactory.m_import_pkg_not_available, pdemarkerfactory.cat_fatal); try { if (marker != null) { \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"packagename\", \/\/$non-nls-1$ name); if (optional) \/\/$non-nls-1$ marker.setattribute(\/\/$non-nls-1$ \"optional\", \/\/$non-nls-1$ true); } } catch (coreexception e) { } } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle);","code_context_10":"validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue;","code_context_20":"for (int i = 0; i < imports.length; ++i) { if (!imports[i].getdirective(constants.resolution_directive).equals(importpackagespecification.resolution_dynamic)) staticimportslist.add(imports[i]); } imports = staticimportslist.toarray(new importpackagespecification[staticimportslist.size()]); } manifestelement[] elements = header.getelements(); int index = 0; for (int i = 0; i < elements.length; i++) { checkcanceled(monitor); validatespecificationversionattribute(header, elements[i]); validateresolutiondirective(header, elements[i]); \/\/ todo we should only validate versions that we have a match validateimportpackageversion(header, elements[i]); if (!hasunresolved) continue; int length = elements[i].getvaluecomponents().length; for (int j = 0; j < length; j++) { importpackagespecification importspec = imports[index++]; string name = importspec.getname(); if (\/\/$non-nls-1$ \/\/$non-nls-2$ name.equals(\"java\") || name.startswith(\"java.\")) { iheader jreheader = getheader(icoreconstants.eclipse_jrebundle); if (jreheader == null || !\"true\".equals(\/\/$non-nls-1$ jreheader.getvalue())) { report(pdecoremessages.bundleerrorreporter_importnojre, getpackageline(header, elements[i]), compilerflags.error, pdemarkerfactory.m_java_package__ported, pdemarkerfactory.cat_fatal); continue; } } if (importspec.isresolved() || !ischeckunresolvedimports()) continue; boolean optional = isoptional(elements[i]); int severity = getrequirebundleseverity(elements[i], optional); exportpackagedescription export = exported.get(name); if (export != null) { if (export.getsupplier().isresolved()) { version version = export.getversion(); org.eclipse.osgi.service.resolver.versionrange range = importspec.getversionrange(); if (range != null && !range.isincluded(version)) { report(nls.bind(pdecoremessages.bundleerrorreporter_unsatisfiedconstraint, importspec.tostring()), getpackageline(header, elements[i]), severity, pdemarkerfactory.cat_fatal); }","repo":"masud-technope\/BLIZZARD-Replication-Package-ESEC-FSE2018"}
{"id":3341,"comment_id":0,"comment":"\/* todo: check for possibility to chain\/join\/combine xml menus todo: manage recurring funds (ie set monthly incomes\/payments) *\/","code":"@override public boolean onoptionsitemselected(menuitem item) { switch(item.getitemid()) { case r.id.clean_all: db.open(); db.drop(); db.close(); break; case r.id.manage_backup: db.backup(); break; case r.id.manage_funds: startactivityforresult(new intent(bilansview.this, bilansstatussetting.class), 1); break; \/* todo: check for possibility to chain\/join\/combine xml menus todo: manage recurring funds (ie set monthly incomes\/payments) *\/ default: log.e (tag, \"menu = wtf?\"); } return super.onoptionsitemselected(item); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"startactivityforresult(new intent(bilansview.this, bilansstatussetting.class), 1); break; \/* todo: check for possibility to chain\/join\/combine xml menus todo: manage recurring funds (ie set monthly incomes\/payments) *\/ default: log.e (tag, \"menu = wtf?\");","code_context_10":"db.open(); db.drop(); db.close(); break; case r.id.manage_backup: db.backup(); break; case r.id.manage_funds: startactivityforresult(new intent(bilansview.this, bilansstatussetting.class), 1); break; \/* todo: check for possibility to chain\/join\/combine xml menus todo: manage recurring funds (ie set monthly incomes\/payments) *\/ default: log.e (tag, \"menu = wtf?\"); } return super.onoptionsitemselected(item); }","code_context_20":"@override public boolean onoptionsitemselected(menuitem item) { switch(item.getitemid()) { case r.id.clean_all: db.open(); db.drop(); db.close(); break; case r.id.manage_backup: db.backup(); break; case r.id.manage_funds: startactivityforresult(new intent(bilansview.this, bilansstatussetting.class), 1); break; \/* todo: check for possibility to chain\/join\/combine xml menus todo: manage recurring funds (ie set monthly incomes\/payments) *\/ default: log.e (tag, \"menu = wtf?\"); } return super.onoptionsitemselected(item); }","repo":"kkrolczyk\/Schowek"}
{"id":3342,"comment_id":0,"comment":"\/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility","code":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","classification":"DESIGN","isFinished":true,"code_context_2":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match","code_context_10":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","code_context_20":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","repo":"kkrolczyk\/Schowek"}
{"id":3342,"comment_id":1,"comment":"\/\/ todo: remove hardcoded account names...crashes if names dont match","code":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","classification":"DEFECT","isFinished":true,"code_context_2":"\/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else {","code_context_10":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","code_context_20":"private void updatesingleaccount(double amount, string account_name) { \/\/ ok nasty hack here. currently account have no idea which direction money flows. \/\/ so for now - hardcoded for backwards compatiblility if (account_name.equals(\"bankomat\")){ status_disp.transfer_resources(\"karta konto 1\", \"gotowka\", (float) amount); \/\/ todo: remove hardcoded account names...crashes if names dont match } else { status_disp.reduce_wealth(account_name, (float) amount); log.e(tag, account_name + \" \" + amount); } }","repo":"kkrolczyk\/Schowek"}
{"id":19798,"comment_id":0,"comment":"\/\/ ------------------------------------------------------------------------ \/** * when the dragon dies: * * <ul> * <li>if the fight owner is online, put the dragon drops in that player's * inventory. if they are not online, * <\/ul> * * @param dragon the dragon that died. *\/","code":"\/\/ ------------------------------------------------------------------------ \/** * when the dragon dies: * * <ul> * <li>if the fight owner is online, put the dragon drops in that player's * inventory. if they are not online, * <\/ul> * * @param dragon the dragon that died. *\/ protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"NONSATD","isFinished":true,"code_context_2":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","code_context_10":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","code_context_20":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","repo":"kadenscott\/DragonFight"}
{"id":19798,"comment_id":1,"comment":"\/\/ bukkit.getofflineplayer() never returns null, even for non-existent.","code":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"NONSATD","isFinished":true,"code_context_2":"return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() +","code_context_10":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else {","code_context_20":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\");","repo":"kadenscott\/DragonFight"}
{"id":19798,"comment_id":2,"comment":"\/\/ fight owner is offline. record an unclaimed prize.","code":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"NONSATD","isFinished":true,"code_context_2":"player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\"));","code_context_10":"if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) {","code_context_20":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } }","repo":"kadenscott\/DragonFight"}
{"id":19798,"comment_id":3,"comment":"\/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops.","code":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"DESIGN","isFinished":true,"code_context_2":"dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes();","code_context_10":"offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" +","code_context_20":"log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","repo":"kadenscott\/DragonFight"}
{"id":19798,"comment_id":4,"comment":"\/\/ the item(s) did not fit, so player must claim with command.","code":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"NONSATD","isFinished":true,"code_context_2":"list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) +","code_context_10":"log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes","code_context_20":"log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","repo":"kadenscott\/DragonFight"}
{"id":19798,"comment_id":5,"comment":"\/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn.","code":"protected void ondragondeath(enderdragon dragon) { log(\"the dragon died.\"); if (_stagenumber != 11) { log(\"but we're not in stage 11, so it doesn't count.\"); return; } if (dragonfight.config.fight_owner == null) { log(\"but nobody owns the fight, so it doesn't count.\"); return; } \/\/ bukkit.getofflineplayer() never returns null, even for non-existent. offlineplayer offlineplayer = bukkit.getofflineplayer(dragonfight.config.fight_owner); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.light_purple + offlineplayer.getname() + chatcolor.dark_purple + \" was awarded the prize for defeating the dragon.\")); player player = offlineplayer.getplayer(); if (player == null) { \/\/ fight owner is offline. record an unclaimed prize. log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save();","code_context_10":"\/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","code_context_20":"log(\"an unclaimed prize was added to offline fight owner \" + offlineplayer.getname() + \".\"); getnearbyplayers().foreach(p -> p.sendmessage(chatcolor.dark_purple + \"they can claim it when they log in.\")); dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); } else { \/\/ select a single drop from the `df-dragon-drops` loot set. \/\/ todo: actually, multiple drops should be supported, once \/\/ beastmaster supports deferred item drops. log(\"generating dragon prizes for \" + player.getname()); list<itemstack> prizes = generateprizes(); if (!giveprizes(player, prizes)) { \/\/ the item(s) did not fit, so player must claim with command. dragonfight.config.incunclaimedprizes(offlineplayer.getuniqueid(), 1); string slots = chatcolor.light_purple + integer.tostring(prizes.size()) + chatcolor.dark_purple + \" inventory slot\" + (prizes.size() > 1 ? \"s\" : \"\"); player.sendmessage(chatcolor.dark_purple + \"you need at least \" + slots + \" empty.\"); player.sendmessage(chatcolor.dark_purple + \"run \" + chatcolor.light_purple + \"\/dragon prize\" + chatcolor.dark_purple + \" to claim your prize.\"); } } \/\/ clear the fight owner once prizes have been given or unclaimed prizes \/\/ recorded, to prevent extra prizes if spurious dragons spawn. dragonfight.config.fight_owner = null; dragonfight.config.save(); }","repo":"kadenscott\/DragonFight"}
{"id":11718,"comment_id":0,"comment":"\/** * this method are overridden for extra claim request to google end-point * * @param request * @param response * @param context * @throws authenticationfailedexception *\/","code":"\/** * this method are overridden for extra claim request to google end-point * * @param request * @param response * @param context * @throws authenticationfailedexception *\/ @override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"@override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","code_context_10":"@override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","code_context_20":"@override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","repo":"manjulaRathnayaka\/carbon-identity"}
{"id":11718,"comment_id":1,"comment":"\/\/ create oauth client that uses custom http client under the hood","code":"@override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse;","code_context_10":"oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); }","code_context_20":"if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded);","repo":"manjulaRathnayaka\/carbon-identity"}
{"id":11718,"comment_id":2,"comment":"\/\/ todo : return access token and id token to framework","code":"@override protected void processauthenticationresponse(httpservletrequest request, httpservletresponse response, authenticationcontext context) throws authenticationfailedexception { try { map<string, string> authenticatorproperties = context.getauthenticatorproperties(); string clientid = authenticatorproperties.get(oidcauthenticatorconstants.client_id); string clientsecret = authenticatorproperties.get(oidcauthenticatorconstants.client_secret); string tokenendpoint = gettokenendpoint(authenticatorproperties); if (tokenendpoint == null) { tokenendpoint = authenticatorproperties.get(oidcauthenticatorconstants.oauth2_token_url); } string callbackurl = authenticatorproperties.get(googleoauth2authenticationconstant.callback_url); log.debug(\"callbackurl : \" + callbackurl); if (callbackurl == null) { callbackurl = carbonuiutil.getadminconsoleurl(request); callbackurl = callbackurl.replace(\"commonauth\/carbon\/\", \"commonauth\"); } @suppresswarnings({\"unchecked\"}) map<string, string> paramvaluemap = (map<string, string>) context.getproperty(\"oidc:param.map\"); if (paramvaluemap != null && paramvaluemap.containskey(\"redirect_uri\")) { callbackurl = paramvaluemap.get(\"redirect_uri\"); } oauthauthzresponse authzresponse = oauthauthzresponse.oauthcodeauthzresponse(request); string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj); } else { if (log.isdebugenabled()) { log.debug(\"decoded json object is null\"); } throw new authenticationfailedexception(\"decoded json object is null\"); } } else { if (log.isdebugenabled()) { log.debug(\"authentication failed\"); } throw new authenticationfailedexception(\"authentication failed\"); } } else { throw new authenticationfailedexception(\"authentication failed\"); } } catch (oauthproblemexception e) { throw new authenticationfailedexception(\"error occurred while acquiring access token\", e); } catch (jsonexception e) { throw new authenticationfailedexception(\"error occurred while parsing json object\", e); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token);","code_context_10":"oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) {","code_context_20":"string code = authzresponse.getcode(); oauthclientrequest accessrequest; try { accessrequest = oauthclientrequest.tokenlocation(tokenendpoint) .setgranttype(granttype.authorization_code).setclientid(clientid).setclientsecret(clientsecret) .setredirecturi(callbackurl).setcode(code).buildbodymessage(); } catch (oauthsystemexception e) { throw new authenticationfailedexception(\"exception while building request for request access token\", e); } \/\/ create oauth client that uses custom http client under the hood oauthclient oauthclient = new oauthclient(new urlconnectionclient()); oauthclientresponse oauthresponse; try { oauthresponse = oauthclient.accesstoken(accessrequest); } catch (oauthsystemexception e) { if (log.isdebugenabled()) { log.debug(\"exception while requesting access token\", e); } throw new authenticationfailedexception(\"exception while requesting access token\", e); } \/\/ todo : return access token and id token to framework string accesstoken = oauthresponse.getparam(oidcauthenticatorconstants.access_token); string idtoken = oauthresponse.getparam(oidcauthenticatorconstants.id_token); if (accesstoken != null && (idtoken != null || !requiredidtoken(authenticatorproperties))) { context.setproperty(oidcauthenticatorconstants.access_token, accesstoken); if (idtoken != null) { context.setproperty(oidcauthenticatorconstants.id_token, idtoken); string base64body = idtoken.split(\"\\\\.\")[1]; byte[] decoded = base64.decodebase64(base64body.getbytes()); string json = new string(decoded); if (log.isdebugenabled()) { log.debug(\"id token json string : \" + json); } map<string, object> jsonobject = jsonutils.parsejson(json); if (jsonobject != null) { map<claimmapping, string> claims = getsubjectattributes(oauthresponse); string authenticateduser = (string) jsonobject.get(oidcauthenticatorconstants.claim.email); authenticateduser authenticateduserobj = authenticateduser .createfederateauthenticateduserfromsubjectidentifier(authenticateduser); authenticateduserobj.setuserattributes(claims); context.setsubject(authenticateduserobj);","repo":"manjulaRathnayaka\/carbon-identity"}
{"id":11781,"comment_id":0,"comment":"\/** * * @param q_cntl * @param index * @param h * @param xv * @param cntl * @throws metadatavalidationexception * @throws metadataexception *\/","code":"\/** * * @param q_cntl * @param index * @param h * @param xv * @param cntl * @throws metadatavalidationexception * @throws metadataexception *\/ public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","code_context_10":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","code_context_20":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","repo":"kef\/hieos"}
{"id":11781,"comment_id":1,"comment":"\/\/ no idea what to do here","code":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid();","code_context_10":"throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele);","code_context_20":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\";","repo":"kef\/hieos"}
{"id":11781,"comment_id":2,"comment":"\/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar","code":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl) + \" (\" + xv.build_xml_link(src_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(src_id) : \"\") + \"]\"); } else { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaces\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"appended to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transform of\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(tgt_id, cntl) + \" (\" + xv.build_xml_link(tgt_id, cntl) + \" \" + ((m.isretrievable_a(tgt_id)) ? xv.build_ret_a_link(tgt_id) + \" \" : \"\") + ((m.isretrievable_b(tgt_id)) ? xv.build_ret_b_link(tgt_id) + \" \" : \"\") + \") \" + \" [\" + ((q_cntl.hasendpoint()) ? xv.build_related_link(tgt_id) : \"\") + \"]\"); } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"+ ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele);","code_context_10":"} xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) {","code_context_20":"public void displaystructure(querycontrol q_cntl, int index, httputils h, xview xv, string cntl) throws metadatavalidationexception, metadataexception { system.out.println(\"related querycontents\"); this.displaystructureheader(index, xv); metadata m = getmetadata(); boolean object_refs = m.isobjectrefsonly(); if (m.getwrapper() == null) { return; } xv.getmetadata().addmetadata(m); if (object_refs) { \/\/ no idea what to do here } else { string ref_id = this.getreferenceid(); h.indent1(xv.build_details_link(ref_id, cntl) + \" (\" + xv.build_xml_link(ref_id, cntl) + \" \" + ((m.isretrievable_a(ref_id)) ? xv.build_ret_a_link(ref_id) + \" \" : \"\") + ((m.isretrievable_b(ref_id)) ? xv.build_ret_b_link(ref_id) + \" \" : \"\") + \")\"); \/\/ ams 04\/24\/2009 - fixme - refactor this - 'else-if' and 'else' are pretty similar for (omelement a_ele : m.getassociations()) { string src_id = m.getassocsource(a_ele); string a_type = m.getassoctype(a_ele); string a_id = m.getid(a_ele); string tgt_id = m.getassoctarget(a_ele); if (src_id == null) { } else if (src_id != null && !src_id.equals(this.getreferenceid())) { if (metadatasupport.xdsb_ihe_assoc_type_rplc.equals(a_type)) { a_type = \"replaced by\"; } else if (metadatasupport.xdsb_ihe_assoc_type_apnd.equals(a_type)) { a_type = \"has appended\"; } else if (metadatasupport.xdsb_ihe_assoc_type_xfrm.equals(a_type)) { a_type = \"transformed to\"; } else if (metadatasupport.xdsb_ihe_assoc_type_issnapshotof.equals(a_type)) { a_type = \"is snapshot of\"; } else { a_type = a_type + \" by\"; } h.indent2(xv.build_assoc_link(a_id, a_type, cntl) + \" \" + xv.build_details_link(src_id, cntl)","repo":"kef\/hieos"}
{"id":3600,"comment_id":0,"comment":"\/\/ inherit documentation from supertype","code":"\/\/ inherit documentation from supertype public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","code_context_10":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","code_context_20":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","repo":"mkleczek\/river"}
{"id":3600,"comment_id":1,"comment":"\/\/ check if empty","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception();","code_context_10":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null;","code_context_20":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done)","repo":"mkleczek\/river"}
{"id":3600,"comment_id":2,"comment":"\/\/ get the input stream","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"} try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event","code_context_10":"while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition)));","code_context_20":"arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true;","repo":"mkleczek\/river"}
{"id":3600,"comment_id":3,"comment":"\/\/ read the event","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition","code_context_10":"!done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown.","code_context_20":"loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) {","repo":"mkleczek\/river"}
{"id":3600,"comment_id":4,"comment":"\/\/ update readcount and readposition","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event","code_context_10":"if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) {","code_context_20":"printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \"","repo":"mkleczek\/river"}
{"id":3600,"comment_id":5,"comment":"\/\/ offset to next unread event","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata(","code_context_10":"log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest,","code_context_20":"persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); }","repo":"mkleczek\/river"}
{"id":3600,"comment_id":6,"comment":"\/\/generate new entry","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt,","code_context_10":"readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \");","code_context_20":"\"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount);","repo":"mkleczek\/river"}
{"id":3600,"comment_id":7,"comment":"\/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog.","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) {","code_context_10":"\/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest,","code_context_20":"!done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) {","repo":"mkleczek\/river"}
{"id":3600,"comment_id":8,"comment":"\/\/ stop processing events","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else {","code_context_10":"evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too","code_context_20":"try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) {","repo":"mkleczek\/river"}
{"id":3600,"comment_id":9,"comment":"\/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true;","code_context_10":"} \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled,","code_context_20":"rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset();","repo":"mkleczek\/river"}
{"id":3600,"comment_id":10,"comment":"\/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream.","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset();","code_context_10":"persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); }","code_context_20":"\"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader();","repo":"mkleczek\/river"}
{"id":3600,"comment_id":11,"comment":"\/\/generate new entry","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt,","code_context_10":"readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \");","code_context_20":"\"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount);","repo":"mkleczek\/river"}
{"id":3600,"comment_id":12,"comment":"\/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request.","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface","code_context_10":"readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null)","code_context_20":"persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) {","repo":"mkleczek\/river"}
{"id":3600,"comment_id":13,"comment":"\/\/todo (fcs) add close to interface \/\/eventreader.close();","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) {","code_context_10":"persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things","code_context_20":"\/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]);","repo":"mkleczek\/river"}
{"id":3600,"comment_id":14,"comment":"\/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/","code":"public remoteeventdata[] readahead(int maxevents) throws ioexception, classnotfoundexception { boolean ioexceptioncaught = false; statecheck(); if (debugstate) { assertinvariants(); } \/\/ check if empty if (isempty()) throw new nosuchelementexception(); long readcount = rcount; long readposition = rpos; long lognum = getlognum(readcount); file log = getlogfile(lognum); remoteevent evt = null; arraylist rdata = new arraylist(); int i = 0; loginputstream in = null; boolean done = false; printcontroldata(persistencelogger, \"before read::readahead\"); if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() maxevents = {0}\", new object[] {integer.valueof(maxevents)}); } while ((readcount < wcount) && (rdata.size() < maxevents) && !done) { if (lognum != getlognum(readcount)) { lognum = getlognum(readcount); log = getlogfile(lognum); readposition = 0; } try { \/\/ get the input stream in = streampool.getloginputstream(log, readposition); \/\/ read the event evt = eventreader.read(in); \/\/ update readcount and readposition readcount++; readposition = in.getoffset(); \/\/ offset to next unread event \/\/generate new entry rdata.add(new remoteeventdata( evt, new remoteeventdatacursor(readcount, readposition))); } catch (ioexception ie) { \/\/ we'll get interrupted when asked to shutdown. \/\/ in this case, we can skip the call to nextreadaheadlog. if (ie instanceof interruptedioexception) { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() interrupted \"); } \/\/ stop processing events done = true; } else { if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() received ioexception \" + \"... skipping to next read log\"); } readcount = nextreadaheadlog(readcount); \/\/ todo - rcount = readcount; \/\/ todo - if bump rcount you need to bump wcount too \/\/ todo - if bump counts then you need to persist them readposition = 0; ioexceptioncaught = true; if (persistencelogger.isloggable(level.finest)) { persistencelogger.log(level.finest, \"eventlog::readahead() new readcount is {0}\", long.valueof(readcount)); } } if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", ie); } } catch (classnotfoundexception cnfe) { \/\/ note that the read offset is still valid since the \/\/ marshalledobject extraction should always succeed. \/\/ it's just that the remoteevent within it could not \/\/ be reconstituted. therefore, just skip to the next \/\/ marshalledobject in the stream. readcount++; readposition = in.getoffset(); \/\/generate new entry rdata.add(new remoteeventdata( null, new remoteeventdatacursor(readcount, readposition))); if (persistencelogger.isloggable(levels.handled)) { persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } }","code_context_10":"\/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","code_context_20":"persistencelogger.log(levels.handled, \"exception: \", cnfe); } } finally { \/\/ if an ioexception occurs then the eventreader is in \/\/ a bad state. therefore, we get rid of our existing \/\/ reference and create a fresh one. the underlying \/\/ stream is also removed from from the pool, forcing \/\/ a fresh copy to be returned on the next \"get\" request. if (ioexceptioncaught) { \/\/todo (fcs) add close to interface \/\/eventreader.close(); eventreader = new eventreader(); if (in != null) { streampool.removelogstream(in); in = null; } } else { if (in != null) streampool.releaselogstream(in); \/* shouldn't have to release since we have exclusive * access, but the next getloginputstream assumes things * are on the freelist. *\/ } } } printcontroldata(persistencelogger, \"after event::readahead\"); if (debugstate) { assertinvariants(); } return (remoteeventdata[]) rdata.toarray(new remoteeventdata[0]); }","repo":"mkleczek\/river"}
{"id":11842,"comment_id":0,"comment":"\/** * authenticate given username and password through jaas (instead of java ee * security). * * @param user, * or null * @param password * cleartext password. after authentication will be cleared. * @param realm * jaas realm name * @return *\/","code":"\/** * authenticate given username and password through jaas (instead of java ee * security). * * @param user, * or null * @param password * cleartext password. after authentication will be cleared. * @param realm * jaas realm name * @return *\/ public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","classification":"NONSATD","isFinished":true,"code_context_2":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","code_context_10":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","code_context_20":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","repo":"luca-vercelli\/java-web-template"}
{"id":11842,"comment_id":1,"comment":"\/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun...","code":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","classification":"NONSATD","isFinished":true,"code_context_2":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc;","code_context_10":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that","code_context_20":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000');","repo":"luca-vercelli\/java-web-template"}
{"id":11842,"comment_id":2,"comment":"\/\/ referenced in jaas.conf","code":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","classification":"NONSATD","isFinished":true,"code_context_2":"logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e);","code_context_10":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication","code_context_20":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","repo":"luca-vercelli\/java-web-template"}
{"id":11842,"comment_id":3,"comment":"\/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails","code":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","classification":"NONSATD","isFinished":true,"code_context_2":"} try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) {","code_context_10":"\/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); }","code_context_20":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","repo":"luca-vercelli\/java-web-template"}
{"id":11842,"comment_id":4,"comment":"\/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter.","code":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","classification":"DEFECT","isFinished":true,"code_context_2":"lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null;","code_context_10":"lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","code_context_20":"public logincontext authenticate(string user, char[] password, string realm) { \/\/ consider modules: krb5loginmodule, ldaploginmodule, ntloginmodule, \/\/ jndiloginmodule \/\/ ...sun... passivecallbackhandler cbh = new passivecallbackhandler(user, password); logincontext lc; try { lc = new logincontext(realm, cbh); \/\/ referenced in jaas.conf } catch (loginexception e) { log.error(\"exception during new logincontext()\", e); return null; } try { \/\/ call callback to retrieve credentials, and checks that \/\/ authentication fails lc.login(); } catch (loginexception e) { \/\/ fixme. loginexception may happen either because authentication \/\/ failed, or for many other reasons. \/\/ we should ignore the first, and log the latter. log.error(\"exception while loggin-in\", e); return null; } finally { arrays.fill(password, '\\u0000'); } return lc; }","repo":"luca-vercelli\/java-web-template"}
{"id":11878,"comment_id":0,"comment":"\/\/todo: use the new widgetutils.showerrortouser method.","code":"@override public void runwithevent(iaction action, event event) { updateenablement(action); if (action.isenabled()) { iselection currentselection = getselection(); set<eplanelement> selected = planeditorutil.emffromselection(currentselection); final movetoorbitoperation op = new movetoorbitoperation(selected); string errormsg = op.analyzemistakenselection(); if (errormsg != null) { logutil.warn(errormsg); errordialog.openerror(widgetutils.getshell(), \"nothing to move to \" + orbiteventutil.orbit_name, \"no orbit-related plan elements selected.\", new exceptionstatus(editorplugin.id, errormsg, new executionexception(selected.tostring()))); return; } try { string orbitid = promptforvalue(); if (orbitid != null) { op.setorbitid(orbitid); iundocontext undocontext = getundocontext(); commonutils.execute(op, undocontext); string errormsg2 = op.analyzemissingorbitdestination(); if (errormsg2 != null) { logutil.warn(errormsg2); \/\/todo: use the new widgetutils.showerrortouser method. errordialog.openerror(widgetutils.getshell(), \"move to \" + orbiteventutil.orbit_name, \"move to \" + orbiteventutil.orbit_name + \" may not have done what you expected.\", new exceptionstatus(editorplugin.id, errormsg2, new executionexception(selected.tostring()))); return; } } } catch (exception e) { istatus error = new exceptionstatus(editorplugin.id, e.getmessage(), e); errordialog.openerror(widgetutils.getshell(), \"an error occurred\", \"that didn't work.\", error); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"if (errormsg2 != null) { logutil.warn(errormsg2); \/\/todo: use the new widgetutils.showerrortouser method. errordialog.openerror(widgetutils.getshell(), \"move to \" + orbiteventutil.orbit_name, \"move to \" + orbiteventutil.orbit_name + \" may not have done what you expected.\",","code_context_10":"} try { string orbitid = promptforvalue(); if (orbitid != null) { op.setorbitid(orbitid); iundocontext undocontext = getundocontext(); commonutils.execute(op, undocontext); string errormsg2 = op.analyzemissingorbitdestination(); if (errormsg2 != null) { logutil.warn(errormsg2); \/\/todo: use the new widgetutils.showerrortouser method. errordialog.openerror(widgetutils.getshell(), \"move to \" + orbiteventutil.orbit_name, \"move to \" + orbiteventutil.orbit_name + \" may not have done what you expected.\", new exceptionstatus(editorplugin.id, errormsg2, new executionexception(selected.tostring()))); return; } } } catch (exception e) { istatus error = new exceptionstatus(editorplugin.id, e.getmessage(), e); errordialog.openerror(widgetutils.getshell(), \"an error occurred\", \"that didn't work.\", error);","code_context_20":"iselection currentselection = getselection(); set<eplanelement> selected = planeditorutil.emffromselection(currentselection); final movetoorbitoperation op = new movetoorbitoperation(selected); string errormsg = op.analyzemistakenselection(); if (errormsg != null) { logutil.warn(errormsg); errordialog.openerror(widgetutils.getshell(), \"nothing to move to \" + orbiteventutil.orbit_name, \"no orbit-related plan elements selected.\", new exceptionstatus(editorplugin.id, errormsg, new executionexception(selected.tostring()))); return; } try { string orbitid = promptforvalue(); if (orbitid != null) { op.setorbitid(orbitid); iundocontext undocontext = getundocontext(); commonutils.execute(op, undocontext); string errormsg2 = op.analyzemissingorbitdestination(); if (errormsg2 != null) { logutil.warn(errormsg2); \/\/todo: use the new widgetutils.showerrortouser method. errordialog.openerror(widgetutils.getshell(), \"move to \" + orbiteventutil.orbit_name, \"move to \" + orbiteventutil.orbit_name + \" may not have done what you expected.\", new exceptionstatus(editorplugin.id, errormsg2, new executionexception(selected.tostring()))); return; } } } catch (exception e) { istatus error = new exceptionstatus(editorplugin.id, e.getmessage(), e); errordialog.openerror(widgetutils.getshell(), \"an error occurred\", \"that didn't work.\", error); } } }","repo":"mikiec84\/OpenSPIFe"}
{"id":20922,"comment_id":0,"comment":"\/** * add node to correct tree * * @param ctx cpntext * @param treetype tree type * @param record_id id * @param trxname transaction * @return true if node added *\/","code":"\/** * add node to correct tree * * @param ctx cpntext * @param treetype tree type * @param record_id id * @param trxname transaction * @return true if node added *\/ public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","code_context_10":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","code_context_20":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","repo":"metas-fresh\/fresh"}
{"id":20922,"comment_id":1,"comment":"\/\/ todo: check & refactor this \/\/ get tree","code":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx);","code_context_10":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype))","code_context_20":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype))","repo":"metas-fresh\/fresh"}
{"id":20922,"comment_id":2,"comment":"\/\/ insert tree in correct tree","code":"public static boolean addnode(properties ctx, string treetype, int record_id, string trxname) { \/\/ todo: check & refactor this \/\/ get tree int ad_tree_id = 0; mclient client = mclient.get(ctx); i_ad_clientinfo ci = client.getinfo(); if (treetype_activity.equals(treetype)) ad_tree_id = ci.getad_tree_activity_id(); else if (treetype_bom.equals(treetype)) throw new illegalargumentexception(\"bom trees not supported\"); else if (treetype_bpartner.equals(treetype)) ad_tree_id = ci.getad_tree_bpartner_id(); else if (treetype_campaign.equals(treetype)) ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save(); } return saved; }","classification":"NONSATD","isFinished":true,"code_context_2":"if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype))","code_context_10":"throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save();","code_context_20":"ad_tree_id = ci.getad_tree_campaign_id(); else if (treetype_elementvalue.equals(treetype)) throw new illegalargumentexception(\"elementvalue cannot use this api\"); else if (treetype_menu.equals(treetype)) ad_tree_id = ci.getad_tree_menu_id(); else if (treetype_organization.equals(treetype)) ad_tree_id = ci.getad_tree_org_id(); else if (treetype_product.equals(treetype)) ad_tree_id = ci.getad_tree_product_id(); else if (treetype_productcategory.equals(treetype)) throw new illegalargumentexception(\"product category trees not supported\"); else if (treetype_project.equals(treetype)) ad_tree_id = ci.getad_tree_project_id(); else if (treetype_salesregion.equals(treetype)) ad_tree_id = ci.getad_tree_salesregion_id(); if (ad_tree_id == 0) throw new illegalargumentexception(\"no tree found\"); mtree_base tree = mtree_base.get(ctx, ad_tree_id, trxname); if (tree.get_id() != ad_tree_id) throw new illegalargumentexception(\"tree found ad_tree_id=\" + ad_tree_id); \/\/ insert tree in correct tree boolean saved = false; if (treetype_menu.equals(treetype)) { mtree_nodemm node = new mtree_nodemm(tree, record_id); saved = node.save(); } else if (treetype_bpartner.equals(treetype)) { mtree_nodebp node = new mtree_nodebp(tree, record_id); saved = node.save(); } else if (treetype_product.equals(treetype)) { mtree_nodepr node = new mtree_nodepr(tree, record_id); saved = node.save(); } else { mtree_node node = new mtree_node(tree, record_id); saved = node.save();","repo":"metas-fresh\/fresh"}
{"id":12731,"comment_id":0,"comment":"\/\/ todo: make this method shorter, less than 100 lines","code":"\/\/ todo: make this method shorter, less than 100 lines public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","classification":"DESIGN","isFinished":true,"code_context_2":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","code_context_10":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","code_context_20":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","repo":"kyunghoj\/pigout"}
{"id":12731,"comment_id":1,"comment":"\/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source","code":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","classification":"NONSATD","isFinished":true,"code_context_2":"logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk","code_context_10":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan);","code_context_20":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators();","repo":"kyunghoj\/pigout"}
{"id":12731,"comment_id":2,"comment":"\/\/ create a new logical plan for the new chunk","code":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next(); op.setplan(newplan); } pigoutlogicalchunks chunk; chunk = new pigoutlogicalchunks(newplan, context, clusterinfo, datain, dataout); chunk.setalias(lro.getalias()); mapping.put( newplan, chunk ); } for (logicalplan lp : mapping.keyset()) { list<operator> succs = plansuccs.get(lp); list<operator> preds = planpreds.get(lp); pigoutlogicalchunks chunk = mapping.get(lp); if (succs != null) { for (operator succ : succs) { logicalplan succlp = (logicalplan) succ.getplan(); pigoutlogicalchunks succchunk = mapping.get(succlp); succchunk.addpredecessors(chunk); log.debug(succchunk.getalias() + \" depends on \" + chunk.getalias()); } } if (preds != null) { for (operator pred : preds) { logicalplan predlp = (logicalplan) pred.getplan(); pigoutlogicalchunks predchunk = mapping.get(predlp); chunk.addpredecessors(predchunk); log.debug(chunk.getalias() + \" depends on \" + predchunk.getalias()); } } } list<pigoutlogicalchunks> list_chunks = new linkedlist<>(); for (pigoutlogicalchunks chunk : mapping.values()) { list_chunks.add( chunk ); } return list_chunks; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s);","code_context_10":"set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0];","code_context_20":"public list<pigoutlogicalchunks> createlogicalchunks() throws frontendexception { set<operator> seenbydfs = new hashset<operator>(); map<logicalplan, pigoutlogicalchunks> mapping = new hashmap<>(); while ( !visitqueue.isempty() ) { operator s = visitqueue.poll(); logicalrelationaloperator lro = (logicalrelationaloperator) s; log.debug(\"visit: \" + lro); \/\/ for each s, we may need to create a new \"chunk\" \/\/ each partition is created by dfs from a source if (!seenbydfs.add(s)) continue; \/\/ create a new logical plan for the new chunk logicalplan newplan = new logicalplan(); newplan.add(s); subplans.put(s, newplan); list<operator> preds = this.plan.getpredecessors(s); if (preds != null) planpreds.put(newplan, new linkedlist<>(preds)); log.debug(lro.getalias() + \" is the root of new chunk\"); discoverpartition(s, seenbydfs, newplan); string namenode = this.siteassignment.get(s); string hostname = namenode.split(\":\")[0]; string portnum = this.context.getproperties().getproperty(hostname + \".job.tracker\").split(\":\")[1]; int port = new integer(portnum); pigoutcluster clusterinfo = getpigoutcluster(hostname, port); long datain = computedatainsize(newplan); long dataout = computedataoutsize(newplan); addstores(newplan); addloads(newplan); iterator<operator> it = newplan.getoperators(); while (it.hasnext()) { operator op = it.next();","repo":"kyunghoj\/pigout"}
{"id":21065,"comment_id":0,"comment":"\/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion.","code":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","classification":"DESIGN","isFinished":true,"code_context_2":"listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/,","code_context_10":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","code_context_20":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","repo":"mbreemhaar\/webcurator"}
{"id":21065,"comment_id":1,"comment":"\/\/,","code":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\",","code_context_10":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","code_context_20":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","repo":"mbreemhaar\/webcurator"}
{"id":21065,"comment_id":2,"comment":"\/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\"","code":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist);","code_context_10":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","code_context_20":"@bean public listfactorybean userdnlist() { listfactorybean bean = new listfactorybean(); bean.settargetlistclass(arraylist.class); \/\/ todo add values to this list to allow more distinguished name patterns. \/\/ if preferable, ldap.dn can be removed when there is more than one value to avoid confusion. list<string> sourcelist = new arraylist<string>(arrays.aslist(\"${ldap.dn}\", \"cn={0},ou=wct users,dc=webcurator,dc=org\") \/\/, \/\/ todo configuration \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\", \/\/\"cn={0},ou=wct users,dc=webcurator,dc=org\" ); bean.setsourcelist(sourcelist); return bean; }","repo":"mbreemhaar\/webcurator"}
{"id":21104,"comment_id":0,"comment":"\/\/ todo: make this way more safe","code":"private static string safeuri(string uri) { \/\/ todo: make this way more safe return uri.replace(\" \", \"%20\"); }","classification":"DESIGN","isFinished":true,"code_context_2":"private static string safeuri(string uri) { \/\/ todo: make this way more safe return uri.replace(\" \", \"%20\"); }","code_context_10":"private static string safeuri(string uri) { \/\/ todo: make this way more safe return uri.replace(\" \", \"%20\"); }","code_context_20":"private static string safeuri(string uri) { \/\/ todo: make this way more safe return uri.replace(\" \", \"%20\"); }","repo":"mikiec84\/blueprints"}
{"id":13004,"comment_id":0,"comment":"\/\/todo: at to get access to the cubelist and childmodel or not bother given we have already converted things \/*public static voxelshape getshapefrommodel(modelrenderer... models) { return getshapefrommodel(false, models); } public static voxelshape getshapefrommodel(boolean print, modelrenderer... models) { list<voxelshape> shapes = new arraylist<>(); for (modelrenderer model : models) { shapes.add(getshapefrommodel(print, model)); } return voxelshapeutils.combine(shapes); } public static voxelshape getshapefrommodel(boolean print, modelrenderer model) { list<voxelshape> shapes = new arraylist<>(); for (modelbox box : model.cubelist) { shapes.add(voxelshapeutils.getslope(box.posx1, box.posy1, box.posz1, box.posx2, box.posy2, box.posz2, model.rotationpointx, model.rotationpointy, model.rotationpointz, model.rotateanglex, model.rotateangley, model.rotateanglez, print)); } if (model.childmodels != null) { for (modelrenderer childmodel : model.childmodels) { shapes.add(getshapefrommodel(print, childmodel)); } } return voxelshapeutils.combine(shapes, false); }*\/","code":"\/\/todo: at to get access to the cubelist and childmodel or not bother given we have already converted things \/*public static voxelshape getshapefrommodel(modelrenderer... models) { return getshapefrommodel(false, models); } public static voxelshape getshapefrommodel(boolean print, modelrenderer... models) { list<voxelshape> shapes = new arraylist<>(); for (modelrenderer model : models) { shapes.add(getshapefrommodel(print, model)); } return voxelshapeutils.combine(shapes); } public static voxelshape getshapefrommodel(boolean print, modelrenderer model) { list<voxelshape> shapes = new arraylist<>(); for (modelbox box : model.cubelist) { shapes.add(voxelshapeutils.getslope(box.posx1, box.posy1, box.posz1, box.posx2, box.posy2, box.posz2, model.rotationpointx, model.rotationpointy, model.rotationpointz, model.rotateanglex, model.rotateangley, model.rotateanglez, print)); } if (model.childmodels != null) { for (modelrenderer childmodel : model.childmodels) { shapes.add(getshapefrommodel(print, childmodel)); } } return voxelshapeutils.combine(shapes, false); }*\/ public static void main(string[] args) { printoutmodelfile(\"\/users\/aidancbrady\/documents\/mekanism\/src\/main\/resources\/assets\/mekanism\/models\/block\/digital_miner.json\"); }","classification":"DESIGN","isFinished":true,"code_context_2":"public static void main(string[] args) { printoutmodelfile(\"\/users\/aidancbrady\/documents\/mekanism\/src\/main\/resources\/assets\/mekanism\/models\/block\/digital_miner.json\"); }","code_context_10":"public static void main(string[] args) { printoutmodelfile(\"\/users\/aidancbrady\/documents\/mekanism\/src\/main\/resources\/assets\/mekanism\/models\/block\/digital_miner.json\"); }","code_context_20":"public static void main(string[] args) { printoutmodelfile(\"\/users\/aidancbrady\/documents\/mekanism\/src\/main\/resources\/assets\/mekanism\/models\/block\/digital_miner.json\"); }","repo":"marcus8448\/Mekanism"}
{"id":13116,"comment_id":0,"comment":"\/\/## todo: use location to select more specifically (in java 9+ with the location's module)","code":"private string compoundproduce( javafilemanager.location location, set<itypemanifold> sps, string fqn, diagnosticlistener<javafileobject> errorhandler ) { itypemanifold found = null; string result = \"\"; for( itypemanifold sp: sps ) { if( sp.getcontributorkind() == primary || sp.getcontributorkind() == partial ) { if( found != null && (found.getcontributorkind() == primary || sp.getcontributorkind() == primary) ) { \/\/## todo: use location to select more specifically (in java 9+ with the location's module) list<ifile> files = sp.findfilesfortype( fqn ); javafileobject file = new sourcejavafileobject( files.get( 0 ).touri() ); errorhandler.report( new javacdiagnostic( file, diagnostic.kind.error, 0, 1, 1, \"the type, \" + fqn + \", has conflicting type manifolds:\\n\" + \"'\" + found.getclass().getname() + \"' and '\" + sp.getclass().getname() + \"'.\\n\" + \"either two or more resource files have the same base name or the project depends on two or more type manifolds that target the same resource type.\\n\" + \"if the former, consider renaming one or more of the resource files.\\n\" + \"if the latter, you must remove one or more of the type manifold libraries.\" ) ); } else { found = sp; result = sp.contribute( location, fqn, false, result, errorhandler ); } } } for( itypemanifold sp: sps ) { if( sp.getcontributorkind() == contributorkind.supplemental ) { result = sp.contribute( location, fqn, false, result, errorhandler ); } } return result; }","classification":"DESIGN","isFinished":true,"code_context_2":"if( found != null && (found.getcontributorkind() == primary || sp.getcontributorkind() == primary) ) { \/\/## todo: use location to select more specifically (in java 9+ with the location's module) list<ifile> files = sp.findfilesfortype( fqn ); javafileobject file = new sourcejavafileobject( files.get( 0 ).touri() );","code_context_10":"{ itypemanifold found = null; string result = \"\"; for( itypemanifold sp: sps ) { if( sp.getcontributorkind() == primary || sp.getcontributorkind() == partial ) { if( found != null && (found.getcontributorkind() == primary || sp.getcontributorkind() == primary) ) { \/\/## todo: use location to select more specifically (in java 9+ with the location's module) list<ifile> files = sp.findfilesfortype( fqn ); javafileobject file = new sourcejavafileobject( files.get( 0 ).touri() ); errorhandler.report( new javacdiagnostic( file, diagnostic.kind.error, 0, 1, 1, \"the type, \" + fqn + \", has conflicting type manifolds:\\n\" + \"'\" + found.getclass().getname() + \"' and '\" + sp.getclass().getname() + \"'.\\n\" + \"either two or more resource files have the same base name or the project depends on two or more type manifolds that target the same resource type.\\n\" + \"if the former, consider renaming one or more of the resource files.\\n\" + \"if the latter, you must remove one or more of the type manifold libraries.\" ) ); } else","code_context_20":"private string compoundproduce( javafilemanager.location location, set<itypemanifold> sps, string fqn, diagnosticlistener<javafileobject> errorhandler ) { itypemanifold found = null; string result = \"\"; for( itypemanifold sp: sps ) { if( sp.getcontributorkind() == primary || sp.getcontributorkind() == partial ) { if( found != null && (found.getcontributorkind() == primary || sp.getcontributorkind() == primary) ) { \/\/## todo: use location to select more specifically (in java 9+ with the location's module) list<ifile> files = sp.findfilesfortype( fqn ); javafileobject file = new sourcejavafileobject( files.get( 0 ).touri() ); errorhandler.report( new javacdiagnostic( file, diagnostic.kind.error, 0, 1, 1, \"the type, \" + fqn + \", has conflicting type manifolds:\\n\" + \"'\" + found.getclass().getname() + \"' and '\" + sp.getclass().getname() + \"'.\\n\" + \"either two or more resource files have the same base name or the project depends on two or more type manifolds that target the same resource type.\\n\" + \"if the former, consider renaming one or more of the resource files.\\n\" + \"if the latter, you must remove one or more of the type manifold libraries.\" ) ); } else { found = sp; result = sp.contribute( location, fqn, false, result, errorhandler ); } } } for( itypemanifold sp: sps ) { if( sp.getcontributorkind() == contributorkind.supplemental ) {","repo":"manifold-systems\/manifold"}
{"id":13241,"comment_id":0,"comment":"\/\/-----------------------------------------tools-----------------------------------------","code":"\/\/-----------------------------------------tools----------------------------------------- public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","code_context_10":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","code_context_20":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","repo":"linyingfa\/AnimatedPieView-master"}
{"id":13241,"comment_id":1,"comment":"\/\/ fix anim duration too short","code":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","classification":"DESIGN","isFinished":true,"code_context_2":"if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) {","code_context_10":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } }","code_context_20":"public void setcurpie(pieinfowrapperr infowrapper, float degree) { if (mdrawingpie != null) { if (degree >= mdrawingpie.toangle \/ 2) { if (!mdrawingpie.hascached) { \/\/ fix anim duration too short pieinfowrapperr prewrapper = mdrawingpie.prewrapper; if (prewrapper != null && !prewrapper.hascached) { prewrapper.hascached = true; mcacheddrawwrappers.add(prewrapper); } mcacheddrawwrappers.add(mdrawingpie); mdrawingpie.hascached = true; } } } mdrawingpie = infowrapper; animangle = degree; callinvalidate(); }","repo":"linyingfa\/AnimatedPieView-master"}
{"id":21553,"comment_id":0,"comment":"\/** * get line chart data option string to draw the chart * * @param filepath data file path * @param datatype data type * @param columns data all columns * @param columnnames select data columns( list data) * @return * @throws illegalargumentexception *\/","code":"\/** * get line chart data option string to draw the chart * * @param filepath data file path * @param datatype data type * @param columns data all columns * @param columnnames select data columns( list data) * @return * @throws illegalargumentexception *\/ public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","classification":"NONSATD","isFinished":true,"code_context_2":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","code_context_10":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","code_context_20":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","repo":"milkboylyf\/EasyML"}
{"id":21553,"comment_id":1,"comment":"\/\/ todo auto-generated method stub \/\/read data from hdfs","code":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>();","code_context_10":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); }","code_context_20":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","repo":"milkboylyf\/EasyML"}
{"id":21553,"comment_id":2,"comment":"\/\/only read limited line data(if the data length over max length)","code":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames)","code_context_10":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts;","code_context_20":"public list<linechart> linechartgen(string filepath, string datatype, list<string> columns, list<string> columnnames) throws illegalargumentexception { \/\/ todo auto-generated method stub \/\/read data from hdfs list<string> results = readalldata(filepath,true); \/\/only read limited line data(if the data length over max length) list<linechart> linecharts = new arraylist<linechart>(); for(string selectedcol : columnnames) { linechart linechart = singlelinegen(results, datatype, columns, selectedcol); if(linechart == null) continue; else linecharts.add(linechart); } return linecharts; }","repo":"milkboylyf\/EasyML"}
{"id":13513,"comment_id":0,"comment":"\/\/ method call on an object","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference?","code_context_10":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname);","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":1,"comment":"\/\/ self object reference?","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\");","code_context_10":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) {","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else {","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":2,"comment":"\/\/ parent object reference \/\/ find the caller object context","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\"));","code_context_10":"ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject)","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object);","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":3,"comment":"\/\/ get the parent object, if exists","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) {","code_context_10":"\/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname);","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object);","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":4,"comment":"\/\/ find the context that contains the function starting the parent","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object","code_context_10":"funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\");","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":5,"comment":"\/\/ the call context must be the same object as the caller object","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject)","code_context_10":"} else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else {","code_context_20":"public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":6,"comment":"\/\/ get the method from that context","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"&& (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); }","code_context_10":".orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) {","code_context_20":"if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); }","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":7,"comment":"\/\/ object reference","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object));","code_context_10":"if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname);","code_context_20":"\/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else {","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":8,"comment":"\/\/ get the object itself","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function","code_context_10":"throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object);","code_context_20":"\/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":9,"comment":"\/\/ find the context that contains the function","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object","code_context_10":"funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\");","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":10,"comment":"\/\/ get the method from the object","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else {","code_context_10":"throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context","code_context_20":"funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor();","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":11,"comment":"\/\/ simple method call syntax","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference","code_context_10":"if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object","code_context_20":"ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) {","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":12,"comment":"\/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\"));","code_context_10":"} \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor();","code_context_20":"if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); }","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":13,"comment":"\/\/ get the parent object, if exists","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) {","code_context_10":"\/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname);","code_context_20":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object);","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":14,"comment":"\/\/ todo check if it is called in a constructor","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object","code_context_10":"} } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context?","code_context_20":"\/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else {","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":15,"comment":"\/\/ context is the parent object","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context","code_context_10":"\/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) {","code_context_20":"if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname);","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":16,"comment":"\/\/ get the constructor from the parent context","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else {","code_context_10":"\/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname);","code_context_20":"} \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":17,"comment":"\/\/ pure function call or unqualified call in an object context?","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) {","code_context_10":"\/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else {","code_context_20":"} } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters();","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":18,"comment":"\/\/ function not found, or function exists only in subcontexts","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); }","code_context_10":"callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); }","code_context_20":"if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":19,"comment":"\/\/ we found the function, now we need to find the overrides, if it is on an object","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels","code_context_10":"} else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); }","code_context_20":"rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) {","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":20,"comment":"\/\/ search the function from the top of the object levels","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else {","code_context_10":"} } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue;","code_context_20":"\/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); }","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":21,"comment":"\/\/ find the containing context by name","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); }","code_context_10":"blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size());","code_context_20":"if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":22,"comment":"\/\/ retrieve the function code","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); }","code_context_10":"throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values);","code_context_20":"\/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":23,"comment":"\/\/ call the functon","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else {","code_context_10":"} \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","code_context_20":"\/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","repo":"mikesep\/rocky"}
{"id":13513,"comment_id":24,"comment":"\/\/ return the return value","code":"@override public value evaluate(blockcontext ctx) { ctx.beforeexpression(this); functionblock funcblock = null; blockcontext callcontext = ctx; if (object != null) { \/\/ method call on an object if (variablereference.isselfreference(object.getname())) { \/\/ self object reference? funcblock = callcontext.retrievelocalfunction(functionname); throw new rockstarruntimeexception(\"self reference\"); } else if (variablereference.isparentreference(object.getname())) { \/\/ parent object reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent reference in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); if (parentobj != null) { \/\/ find the context that contains the function starting the parent callcontext = parentobj.getcontextforfunction(functionname); \/\/ the call context must be the same object as the caller object if ((callcontext != null) && (callcontext instanceof rockobject) && (((rockobject) callcontext).getobjid() == callerobj.getobjid())) { \/\/ get the method from that context funcblock = callcontext.retrievelocalfunction(functionname); } } else { throw new rockstarruntimeexception(\"parent reference in non-inherited class\"); } } else { \/\/ object reference ctx.beforeexpression(object); value objvalue = ctx.afterexpression(object, ctx.getvariablevalue(object)); if (objvalue == null) { throw new rockstarruntimeexception(\"object not found: \" + object); } if (objvalue.isobject()) { \/\/ get the object itself rockobject objcontext = objvalue.getobject(); \/\/ find the context that contains the function callcontext = objcontext.getcontextforfunction(functionname); if (callcontext == null) { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } \/\/ get the method from the object funcblock = callcontext.retrievelocalfunction(functionname); } else { throw new rockstarruntimeexception(\"invalid method call \" + functionname + \" on a \" + objvalue.gettype().name() + \" type variable \" + object); } } } else { \/\/ simple method call syntax if (variablereference.isparentreference(functionname) && ctx.getthisobjectctx().ispresent()) { \/\/ unqualified \"parent\" function: must be a parent constructor reference \/\/ find the caller object context rockobject callerobj = ctx.getthisobjectctx() .orelsethrow(() -> new rockstarruntimeexception(\"parent constructor call in a non-object context\")); \/\/ get the parent object, if exists rockobject parentobj = callerobj.getsuperobject(); \/\/ todo check if it is called in a constructor if (parentobj != null) { \/\/ context is the parent object callcontext = parentobj; \/\/ get the constructor from the parent context funcblock = parentobj.getconstructor(); } else { throw new rockstarruntimeexception(\"parent constructor reference in non-inherited class\"); } } else { \/\/ pure function call or unqualified call in an object context? blockcontext funcctx = ctx.getcontextforfunction(functionname); if (funcctx == null) { \/\/ function not found, or function exists only in subcontexts throw new rockstarruntimeexception(\"undefined function: \" + functionname); } \/\/ we found the function, now we need to find the overrides, if it is on an object if (funcctx instanceof rockobject) { \/\/ search the function from the top of the object levels funcctx = ((rockobject) funcctx).gettopobject().getcontextforfunction(functionname); } else { \/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","classification":"NONSATD","isFinished":true,"code_context_2":"throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","code_context_10":"list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","code_context_20":"\/\/ find the containing context by name funcctx = ctx.getcontextforfunction(functionname); } \/\/ retrieve the function code funcblock = funcctx.retrievelocalfunction(functionname); } } value retvalue; if (funcblock != null) { list<expression> params = getparameters(); list<value> values = new arraylist<>(params.size()); params.foreach((expr) -> values.add(expr.evaluate(ctx).asparameter())); \/\/ call the functon retvalue = funcblock.call(callcontext, values); } else { if (object == null) { throw new rockstarruntimeexception(\"undefined function: \" + functionname); } throw new rockstarruntimeexception(\"undefined method: \" + functionname + \" on class \" + object.getname()); } \/\/ return the return value return ctx.afterexpression(this, retvalue == null ? value.null : retvalue); }","repo":"mikesep\/rocky"}
{"id":21954,"comment_id":0,"comment":"\/** * creates a sax2 inputsource object from a trax source object * * @param xsltc * todo * @param source * todo * @return todo * @throws transformerconfigurationexception * todo *\/","code":"\/** * creates a sax2 inputsource object from a trax source object * * @param xsltc * todo * @param source * todo * @return todo * @throws transformerconfigurationexception * todo *\/ public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","code_context_10":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","code_context_20":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":1,"comment":"\/\/ try to get inputsource from saxsource input","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source;","code_context_10":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if","code_context_20":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance();","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":2,"comment":"\/\/ pass the sax parser to the compiler","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader();","code_context_10":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try {","code_context_20":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true);","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":3,"comment":"\/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"DEFECT","isFinished":true,"code_context_2":"try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try {","code_context_10":"inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) {","code_context_20":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } }","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":4,"comment":"\/\/ incase there is an exception thrown \/\/ resort to jaxp","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"} catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true);","code_context_10":"* fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) {","code_context_20":"final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) {","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":5,"comment":"\/\/ handle domsource","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source;","code_context_10":"reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); }","code_context_20":"} catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream);","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":6,"comment":"\/\/ try to get sax inputsource from dom source.","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) {","code_context_10":"} catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader();","code_context_20":"} } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else {","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":7,"comment":"\/\/ try to get inputstream or reader from streamsource","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source;","code_context_10":"final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader);","code_context_20":"} catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\"));","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":8,"comment":"\/\/ clear old xml reader","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) {","code_context_10":"input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr());","code_context_20":"throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); }","repo":"lyca\/lyca-xslt"}
{"id":21954,"comment_id":9,"comment":"\/\/ create inputsource from reader or inputstream in source","code":"public static inputsource getinputsource(xsltc xsltc, source source) throws transformerconfigurationexception { inputsource input = null; final string systemid = source.getsystemid(); try { \/\/ try to get inputsource from saxsource input if (source instanceof saxsource) { final saxsource sax = (saxsource) source; input = sax.getinputsource(); \/\/ pass the sax parser to the compiler try { xmlreader reader = sax.getxmlreader(); \/* * fix for bug 24695 according to jaxp 1.2 specification if a * saxsource is created using a sax inputsource the transformer or * transformerfactory creates a reader via the xmlreaderfactory if * setxmlreader is not used *\/ if (reader == null) { try { reader = xmlreaderfactory.createxmlreader(); } catch (final exception e) { try { \/\/ incase there is an exception thrown \/\/ resort to jaxp final saxparserfactory parserfactory = saxparserfactory.newinstance(); parserfactory.setnamespaceaware(true); if (xsltc.issecureprocessing()) { try { parserfactory.setfeature(xmlconstants.feature_secure_processing, true); } catch (final saxexception se) { } } reader = parserfactory.newsaxparser().getxmlreader(); } catch (final parserconfigurationexception pce) { throw new transformerconfigurationexception(\"parserconfigurationexception\", pce); } } } reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespaces\", true); reader.setfeature(\"http:\/\/xml.org\/sax\/features\/namespace-prefixes\", false); xsltc.setxmlreader(reader); } catch (final saxnotrecognizedexception snre) { throw new transformerconfigurationexception(\"saxnotrecognizedexception \", snre); } catch (final saxnotsupportedexception snse) { throw new transformerconfigurationexception(\"saxnotsupportedexception \", snse); } catch (final saxexception se) { throw new transformerconfigurationexception(\"saxexception \", se); } } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input; }","classification":"NONSATD","isFinished":true,"code_context_2":"final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream);","code_context_10":"if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring());","code_context_20":"} } \/\/ handle domsource else if (source instanceof domsource) { final domsource domsrc = (domsource) source; final document dom = (document) domsrc.getnode(); final dom2sax dom2sax = new dom2sax(dom); xsltc.setxmlreader(dom2sax); \/\/ try to get sax inputsource from dom source. input = saxsource.sourcetoinputsource(source); if (input == null) { input = new inputsource(domsrc.getsystemid()); } } \/\/ try to get inputstream or reader from streamsource else if (source instanceof streamsource) { final streamsource stream = (streamsource) source; final inputstream istream = stream.getinputstream(); final reader reader = stream.getreader(); xsltc.setxmlreader(null); \/\/ clear old xml reader \/\/ create inputsource from reader or inputstream in source if (istream != null) { input = new inputsource(istream); } else if (reader != null) { input = new inputsource(reader); } else { input = new inputsource(systemid); } } else { final errormsg err = new errormsg(messages.get().jaxpunknownsourceerr()); throw new transformerconfigurationexception(err.tostring()); } input.setsystemid(systemid); } catch (final nullpointerexception e) { final errormsg err = new errormsg(messages.get().jaxpnosourceerr(\"transformerfactory.newtemplates()\")); throw new transformerconfigurationexception(err.tostring()); } catch (final securityexception e) { final errormsg err = new errormsg(messages.get().fileaccesserr(systemid), -1); throw new transformerconfigurationexception(err.tostring()); } return input;","repo":"lyca\/lyca-xslt"}
{"id":30244,"comment_id":0,"comment":"\/** * this method handle the keyboard input of the player. * it handles keeper moves. * @param code * @throws ioexception * @throws classnotfoundexception *\/","code":"\/** * this method handle the keyboard input of the player. * it handles keeper moves. * @param code * @throws ioexception * @throws classnotfoundexception *\/ public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","code_context_10":"public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","code_context_20":"public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","repo":"krisiney\/SOKOBANFX-DMS-2020"}
{"id":30244,"comment_id":1,"comment":"\/\/ todo: implement something funny.","code":"public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"break; default: \/\/ todo: implement something funny. } if (isdebugactive()) {","code_context_10":"case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","code_context_20":"public void handlekey(keycode code) throws ioexception, classnotfoundexception { switch (code) { case up: move(new point(-1, 0),\"\"); break; case right: move(new point(0, 1),\"\"); break; case down: move(new point(1, 0),\"\"); break; case left: move(new point(0, -1),\"\"); break; default: \/\/ todo: implement something funny. } if (isdebugactive()) { system.out.println(code); } }","repo":"krisiney\/SOKOBANFX-DMS-2020"}
{"id":22278,"comment_id":0,"comment":"\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528","code":"@override public void onnext(t o) { if (debug) log.i(tag, \"net onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } }","classification":"DEFECT","isFinished":true,"code_context_2":"if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } }","code_context_10":"@override public void onnext(t o) { if (debug) log.i(tag, \"net onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } }","code_context_20":"@override public void onnext(t o) { if (debug) log.i(tag, \"net onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } }","repo":"ming1991\/mingop"}
{"id":22279,"comment_id":0,"comment":"\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528","code":"@override public void onnext(t o) { if (debug) log.i(tag, \"cache onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (netlatch.getcount() > 0) { if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } } else { if (debug) log.e(tag, \"net result had been load,so cache is not need to load\"); } }","classification":"DEFECT","isFinished":true,"code_context_2":"if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } } else {","code_context_10":"@override public void onnext(t o) { if (debug) log.i(tag, \"cache onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (netlatch.getcount() > 0) { if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } } else { if (debug) log.e(tag, \"net result had been load,so cache is not need to load\"); } }","code_context_20":"@override public void onnext(t o) { if (debug) log.i(tag, \"cache onnext o:\" + o); observablewrapper.setdata(o); logthread(\"\"); if (netlatch.getcount() > 0) { if (debug) log.e(tag, \" check subscriber :\" + subscriber + \" isunsubscribed:\" + subscriber.isunsubscribed()); if (subscriber != null && !subscriber.isunsubscribed()) { subscriber.onnext(o);\/\/ fixme: issue a:\u5916\u9762\u5982\u679cobservableon \u5176\u4ed6\u7ebf\u7a0b,\u5c06\u4f1a\u662f\u5f02\u6b65\u64cd\u4f5c,\u5982\u679c\u5728\u5b9e\u9645\u7684onnext\u8c03\u7528\u4e4b\u524d,\u53d1\u751f\u4e86oncomplete\u6216\u8005onerror,\u5c06\u4f1aunsubscribe,\u5bfc\u81f4onnext\u6ca1\u6709\u88ab\u8c03\u7528 } } else { if (debug) log.e(tag, \"net result had been load,so cache is not need to load\"); } }","repo":"ming1991\/mingop"}
{"id":14123,"comment_id":0,"comment":"\/** * do work here * * @param v1 * @return *\/","code":"\/** * do work here * * @param v1 * @return *\/ public abstract iterable<tuple2<k, v>> docall(final t t) throws exception;","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public abstract iterable<tuple2<k, v>> docall(final t t) throws exception;","code_context_10":"public abstract iterable<tuple2<k, v>> docall(final t t) throws exception;","code_context_20":"public abstract iterable<tuple2<k, v>> docall(final t t) throws exception;","repo":"lordjoe\/SparkAccumulators"}
{"id":22556,"comment_id":0,"comment":"\/\/ compute the subnet mask address","code":"private boolean updateaddressfilter(string filter) { string[] pieces = filter.split(\"\/\"); if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white); return true; }","classification":"NONSATD","isFinished":true,"code_context_2":"try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]);","code_context_10":"if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); }","code_context_20":"private boolean updateaddressfilter(string filter) { string[] pieces = filter.split(\"\/\"); if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent();","repo":"kylekyle\/netgrok"}
{"id":22556,"comment_id":1,"comment":"\/\/ compute the mask address \/\/ there is probably a way easier way to do this","code":"private boolean updateaddressfilter(string filter) { string[] pieces = filter.split(\"\/\"); if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white); return true; }","classification":"NONSATD","isFinished":true,"code_context_2":"byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j);","code_context_10":"return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red);","code_context_20":"private boolean updateaddressfilter(string filter) { string[] pieces = filter.split(\"\/\"); if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white);","repo":"kylekyle\/netgrok"}
{"id":22556,"comment_id":2,"comment":"\/\/todo: make data listen to this so that we don't need this call","code":"private boolean updateaddressfilter(string filter) { string[] pieces = filter.split(\"\/\"); if(pieces.length != 2) { searchtextfield.setbackground(color.red); return false; } inetaddress new_filter_address; inetaddress new_filter_mask; boolean new_filter_enabled = !(pieces[1].equals(\"0\")); try { new_filter_address = inetaddress.getbyname(pieces[0]); \/\/ compute the subnet mask address byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white); return true; }","classification":"DESIGN","isFinished":true,"code_context_2":"filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\");","code_context_10":"new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white); return true; }","code_context_20":"byte[] byte_mask = new byte[4]; int slash = integer.parseint(pieces[1]); \/\/ compute the mask address \/\/ there is probably a way easier way to do this for (int j=0; slash-- > 0; j++) { if (j<8) byte_mask[0] += math.pow(2,j); if (j<16) byte_mask[1] += math.pow(2,j-8); if (j<24) byte_mask[2] += math.pow(2,j-16); if (j<32) byte_mask[3] += math.pow(2,j-24); } new_filter_mask = inetaddress.getbyaddress(byte_mask); } catch (exception e) { searchtextfield.setbackground(color.red); return false; } ip_filter_enabled = new_filter_enabled; filter_address = new_filter_address; filter_mask = new_filter_mask; fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); system.out.println(\"updating filter succeeded!\"); searchtextfield.setbackground(color.white); return true; }","repo":"kylekyle\/netgrok"}
{"id":22557,"comment_id":0,"comment":"\/\/ get the minimum degree rank","code":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); max_degree_rank = (float)(degreerangeslider.gethighvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum(); min_bandwidth_enabled = bandwidthrangeslider.getlowvalue() != bandwidthrangeslider.getminimum(); max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","classification":"NONSATD","isFinished":true,"code_context_2":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum());","code_context_10":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); max_degree_rank = (float)(degreerangeslider.gethighvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum();","code_context_20":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); max_degree_rank = (float)(degreerangeslider.gethighvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum(); min_bandwidth_enabled = bandwidthrangeslider.getlowvalue() != bandwidthrangeslider.getminimum(); max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","repo":"kylekyle\/netgrok"}
{"id":22557,"comment_id":1,"comment":"\/\/todo: make data listen to this so that we don't need this call","code":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); max_degree_rank = (float)(degreerangeslider.gethighvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum(); min_bandwidth_enabled = bandwidthrangeslider.getlowvalue() != bandwidthrangeslider.getminimum(); max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","classification":"DESIGN","isFinished":true,"code_context_2":"max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","code_context_10":"(float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum(); min_bandwidth_enabled = bandwidthrangeslider.getlowvalue() != bandwidthrangeslider.getminimum(); max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","code_context_20":"private void updateranges() { \/\/ get the minimum degree rank min_degree_rank = (float)(degreerangeslider.getlowvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); max_degree_rank = (float)(degreerangeslider.gethighvalue() - degreerangeslider.getminimum()) \/ (float)(degreerangeslider.getmaximum() - degreerangeslider.getminimum()); min_bandwidth_rank = (float)(bandwidthrangeslider.getlowvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); max_bandwidth_rank = (float)(bandwidthrangeslider.gethighvalue() - bandwidthrangeslider.getminimum()) \/ (float)(bandwidthrangeslider.getmaximum() - bandwidthrangeslider.getminimum()); min_degree_enabled = degreerangeslider.getlowvalue() != degreerangeslider.getminimum(); max_degree_enabled = degreerangeslider.gethighvalue() != degreerangeslider.getmaximum(); min_bandwidth_enabled = bandwidthrangeslider.getlowvalue() != bandwidthrangeslider.getminimum(); max_bandwidth_enabled = bandwidthrangeslider.gethighvalue() != bandwidthrangeslider.getmaximum(); fireexpressionchangedevent(); \/\/todo: make data listen to this so that we don't need this call data.setfilterpredicate(this); }","repo":"kylekyle\/netgrok"}
{"id":30751,"comment_id":0,"comment":"\/\/ resolve reference to constantpool by index in constants","code":"\/\/ resolve reference to constantpool by index in constants private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","code_context_10":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","code_context_20":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","repo":"k0kubun\/jjvm"}
{"id":30751,"comment_id":1,"comment":"\/\/ not needed","code":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"|| constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant;","code_context_10":"constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet","code_context_20":"info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","repo":"k0kubun\/jjvm"}
{"id":30751,"comment_id":2,"comment":"\/\/ not needed","code":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"|| constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant;","code_context_10":"constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet","code_context_20":"info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","repo":"k0kubun\/jjvm"}
{"id":30751,"comment_id":3,"comment":"\/\/ not used yet","code":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"|| constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant);","code_context_10":"\/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","code_context_20":"constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","repo":"k0kubun\/jjvm"}
{"id":30751,"comment_id":4,"comment":"\/\/ long\/double may leave create a blank space","code":"private void resolveconstantpoolreferences(constantinfo[] constantpool) { for (constantinfo constant : constantpool) { if (constant instanceof constantinfo.class) { constantinfo.class info = (constantinfo.class)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); } else if (constant instanceof constantinfo.fieldref) { constantinfo.fieldref info = (constantinfo.fieldref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.methodref) { constantinfo.methodref info = (constantinfo.methodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.interfacemethodref) { constantinfo.interfacemethodref info = (constantinfo.interfacemethodref)constant; info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"|| constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); }","code_context_10":"} else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","code_context_20":"info.setclassinfo((constantinfo.class)constantpool[info.getclassindex() - 1]); info.setnameandtype((constantinfo.nameandtype)constantpool[info.getnameandtypeindex() - 1]); } else if (constant instanceof constantinfo.string) { constantinfo.string info = (constantinfo.string)constant; info.setstring(((constantinfo.utf8)constantpool[info.getstringindex() - 1]).getstring()); } else if (constant instanceof constantinfo.integer || constant instanceof constantinfo.float || constant instanceof constantinfo.long || constant instanceof constantinfo.double) { \/\/ not needed } else if (constant instanceof constantinfo.nameandtype) { constantinfo.nameandtype info = (constantinfo.nameandtype)constant; info.setname(((constantinfo.utf8)constantpool[info.getnameindex() - 1]).getstring()); info.setdescriptor(((constantinfo.utf8)constantpool[info.getdescriptorindex() - 1]).getstring()); } else if (constant instanceof constantinfo.utf8) { \/\/ not needed } else if (constant instanceof constantinfo.methodhandle || constant instanceof constantinfo.methodtype || constant instanceof constantinfo.invokedynamic) { \/\/ not used yet } else if (constant != null) { \/\/ long\/double may leave create a blank space throw new unsupportedoperationexception(\"unhandled constanttype: \" + constant); } } }","repo":"k0kubun\/jjvm"}
{"id":22840,"comment_id":0,"comment":"\/** * send an ack * @throws forcereattemptexception if the peer is no longer available *\/","code":"\/** * send an ack * @throws forcereattemptexception if the peer is no longer available *\/ public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","classification":"NONSATD","isFinished":true,"code_context_2":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","code_context_10":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","code_context_20":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","repo":"karensmolermiller\/incubator-geode"}
{"id":22840,"comment_id":1,"comment":"\/\/ chunkentries returns false if didn't finish","code":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","classification":"NONSATD","isFinished":true,"code_context_2":"final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient);","code_context_10":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk","code_context_20":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last);","repo":"karensmolermiller\/incubator-geode"}
{"id":22840,"comment_id":2,"comment":"\/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/","code":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","classification":"NONSATD","isFinished":true,"code_context_2":"int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last)","code_context_10":"final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) {","code_context_20":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io);","repo":"karensmolermiller\/incubator-geode"}
{"id":22840,"comment_id":3,"comment":"\/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring());","code":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","classification":"NONSATD","isFinished":true,"code_context_2":"*\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0;","code_context_10":"boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } }","code_context_20":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\");","repo":"karensmolermiller\/incubator-geode"}
{"id":22840,"comment_id":4,"comment":"\/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\");","code":"public static void send(final internaldistributedmember recipient, final int processorid, final dm dm, set keys) throws forcereattemptexception { assert.asserttrue(recipient != null, \"fetchkeysreplymessage null reply message\"); final int numseries = 1; final int seriesnum = 0; \/\/ chunkentries returns false if didn't finish if (logger.isdebugenabled()) { logger.debug(\"starting pr keys chunking for {} kets to member {}\", keys.size(), recipient); } try { boolean finished = chunkset(recipient, keys, initialimageoperation.chunk_size_in_bytes, false, new objectintprocedure() { int msgnum = 0; boolean last = false; \/** * @param a byte[] chunk * @param b positive if last chunk * @return true to continue to next chunk *\/ public boolean executewith(object a, int b) { \/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","code_context_10":"} } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","code_context_20":"\/\/ if (this.last) \/\/ throw new internalgemfireerror(localizedstrings.fetchkeysmessage_already_processed_last_chunk.tolocalizedstring()); heapdataoutputstream chunk = (heapdataoutputstream)a; this.last = b > 0; try { boolean okay = sendchunk(recipient, processorid, dm, chunk, seriesnum, msgnum++, numseries, this.last); return okay; } catch (cancelexception e) { return false; } } }); if (logger.isdebugenabled()) { logger.debug(\"{} pr keys chunking\", (finished?\"finished\" : \"did not complete\")); } } catch (ioexception io) { throw new forcereattemptexception(localizedstrings.fetchkeysmessage_unable_to_send_response_to_fetch_keys_request.tolocalizedstring(), io); } \/\/ todo [bruce] pass a reference to the cache or region down here so we can do this test \/\/assert.asserttrue(!cache is closed, \"chunking interrupted but cache is still open\"); }","repo":"karensmolermiller\/incubator-geode"}
{"id":14744,"comment_id":0,"comment":"\/\/todo: actually implement barrier contract","code":"@override void processofmessage(controllerchannelhandler h, ofmessage m) throws ioexception { switch (m.gettype()) { case hello: processofhello(h, (ofhello) m); break; case echo_reply: break; case echo_request: processofechorequest(h, (ofechorequest) m); break; case features_request: processoffeaturesrequest(h, (offeaturesrequest) m); break; case barrier_request: \/\/todo: actually implement barrier contract ofbarrierreply breply = new ofbarrierreply(); breply.setxid(m.getxid()); h.channel.write(collections.singletonlist(breply)); break; case set_config: case error: case packet_out: case port_mod: case queue_get_config_request: case stats_request: case flow_mod: case get_config_request: h.sw.handleio(m); break; case vendor: unhandledmessagereceived(h, m); break; case features_reply: case flow_removed: case packet_in: case port_status: case barrier_reply: case get_config_reply: case stats_reply: case queue_get_config_reply: illegalmessagereceived(h, m); break; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"break; case barrier_request: \/\/todo: actually implement barrier contract ofbarrierreply breply = new ofbarrierreply(); breply.setxid(m.getxid());","code_context_10":"break; case echo_reply: break; case echo_request: processofechorequest(h, (ofechorequest) m); break; case features_request: processoffeaturesrequest(h, (offeaturesrequest) m); break; case barrier_request: \/\/todo: actually implement barrier contract ofbarrierreply breply = new ofbarrierreply(); breply.setxid(m.getxid()); h.channel.write(collections.singletonlist(breply)); break; case set_config: case error: case packet_out: case port_mod: case queue_get_config_request: case stats_request:","code_context_20":"@override void processofmessage(controllerchannelhandler h, ofmessage m) throws ioexception { switch (m.gettype()) { case hello: processofhello(h, (ofhello) m); break; case echo_reply: break; case echo_request: processofechorequest(h, (ofechorequest) m); break; case features_request: processoffeaturesrequest(h, (offeaturesrequest) m); break; case barrier_request: \/\/todo: actually implement barrier contract ofbarrierreply breply = new ofbarrierreply(); breply.setxid(m.getxid()); h.channel.write(collections.singletonlist(breply)); break; case set_config: case error: case packet_out: case port_mod: case queue_get_config_request: case stats_request: case flow_mod: case get_config_request: h.sw.handleio(m); break; case vendor: unhandledmessagereceived(h, m); break; case features_reply: case flow_removed: case packet_in:","repo":"mgerola\/OpenVirteX"}
{"id":14763,"comment_id":0,"comment":"\/\/metodo para consultar usuario","code":"\/\/metodo para consultar usuario private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","code_context_10":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","code_context_20":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14763,"comment_id":1,"comment":"\/\/a linha abaixo se refere ao combobox","code":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else {","code_context_10":"string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) {","code_context_20":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14763,"comment_id":2,"comment":"\/\/as linhas abaixo \"limpam os campos\"","code":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null);","code_context_10":"rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","code_context_20":"private void concultar() { string sql = \"select * from tbusuarios where iduser=?\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); rs = pst.executequery(); if (rs.next()) { txtusunome.settext(rs.getstring(2)); txtusufone.settext(rs.getstring(3)); txtusulogin.settext(rs.getstring(4)); txtususenha.settext(rs.getstring(5)); \/\/a linha abaixo se refere ao combobox cbousuperfil.setselecteditem(rs.getstring(6)); } else { joptionpane.showmessagedialog(null, \"usu\u00e1rio n\u00e3o cadastrado\"); \/\/as linhas abaixo \"limpam os campos\" txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14764,"comment_id":0,"comment":"\/\/metodo para adicionar usu\u00e1rio","code":"\/\/metodo para adicionar usu\u00e1rio private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","code_context_10":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","code_context_20":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14764,"comment_id":1,"comment":"\/\/validi\u00e7\u00e3o dos campos obrigatorios","code":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\");","code_context_10":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\");","code_context_20":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14764,"comment_id":2,"comment":"\/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario","code":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica","code_context_10":"pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); }","code_context_20":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14764,"comment_id":3,"comment":"\/\/ testando a logica \/\/system.out.println(adicionado);","code":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\");","code_context_10":"pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e);","code_context_20":"private void adicionar() { string sql = \"insert into tbusuarios(iduser, usuario, fone,login,senha,perfil) values(?,?,?,?,?,?)\"; try { pst = conexao.preparestatement(sql); pst.setstring(1, txtusuid.gettext()); pst.setstring(2, txtusunome.gettext()); pst.setstring(3, txtusufone.gettext()); pst.setstring(4, txtusulogin.gettext()); pst.setstring(5, txtususenha.gettext()); pst.setstring(6, cbousuperfil.getselecteditem().tostring()); \/\/validi\u00e7\u00e3o dos campos obrigatorios if ((txtusuid.gettext().isempty()) || (txtusunome.gettext().isempty()) || (txtusulogin.gettext().isempty()) || (txtususenha.gettext().isempty())) { joptionpane.showmessagedialog(null, \"preencha todos os campos obrigatorio\"); } else { \/\/a estrutura abaixo \u00e9 usada para confirmar a inser\u00e7\u00e3o dos dados na tabela \/\/a linha abaixo atualiza a tabela usuario com os dados do formulario int adicionado = pst.executeupdate(); \/\/ testando a logica \/\/system.out.println(adicionado); if (adicionado > 0) { joptionpane.showmessagedialog(null, \"usuario adicionado com sucesso\"); txtusunome.settext(null); txtusufone.settext(null); txtusulogin.settext(null); txtususenha.settext(null); } } } catch (exception e) { joptionpane.showmessagedialog(null, e); } }","repo":"marceloamorimcg\/Dr.InfoSystem"}
{"id":14786,"comment_id":0,"comment":"\/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough)","code":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl();","code_context_10":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer","code_context_20":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); }","repo":"mindscan-de\/BrightFlux"}
{"id":14786,"comment_id":1,"comment":"\/\/ use the name of a class and instantiate this tokenizer","code":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","classification":"NONSATD","isFinished":true,"code_context_2":"return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path...","code_context_10":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance();","code_context_20":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","repo":"mindscan-de\/BrightFlux"}
{"id":14786,"comment_id":2,"comment":"\/\/ use classloader and search for named class in class path...","code":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype );","code_context_10":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } }","code_context_20":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","repo":"mindscan-de\/BrightFlux"}
{"id":14786,"comment_id":3,"comment":"\/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer","code":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) {","code_context_10":"\/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); }","code_context_20":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","repo":"mindscan-de\/BrightFlux"}
{"id":14786,"comment_id":4,"comment":"\/\/ create the class using the unparametereized the constructor.","code":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","classification":"NONSATD","isFinished":true,"code_context_2":"class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); }","code_context_10":"} \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","code_context_20":"public datatokenizer buildtokenizerinstance( string tokenizertype ) { \/\/ use a predefined list of known tokenizers \/\/ todo: publish more tokenizers... (when they are ready\/good enough\/abstract enough) if (\"csvtokenizer\".equals( tokenizertype )) { return new csvtokenizerimpl(); } \/\/ use the name of a class and instantiate this tokenizer try { \/\/ use classloader and search for named class in class path... classloader classloader = this.getclass().getclassloader(); class<?> loadedclass = classloader.loadclass( tokenizertype ); \/\/ todo: check if superclass is registered as a datatokenizer.... \/\/ and check if it implements datatokenizer class<?>[] interfaces = loadedclass.getinterfaces(); if (arrays.aslist( interfaces ).contains( datatokenizer.class )) { \/\/ create the class using the unparametereized the constructor. return (datatokenizer) loadedclass.getdeclaredconstructor().newinstance(); } } catch (classnotfoundexception | instantiationexception | illegalaccessexception | illegalargumentexception | invocationtargetexception | nosuchmethodexception | securityexception e) { e.printstacktrace(); } throw new illegalargumentexception(); }","repo":"mindscan-de\/BrightFlux"}
{"id":23051,"comment_id":0,"comment":"\/\/ todo: update this logic to also handle the user logged in by email.","code":"@override protected void updateconnectbuttonstate() { \/\/ todo: update this logic to also handle the user logged in by email. boolean connected = getplusclient().isconnected(); msignoutbuttons.setvisibility(connected ? view.visible : view.gone); mplussigninbutton.setvisibility(connected ? view.gone : view.visible); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@override protected void updateconnectbuttonstate() { \/\/ todo: update this logic to also handle the user logged in by email. boolean connected = getplusclient().isconnected(); msignoutbuttons.setvisibility(connected ? view.visible : view.gone);","code_context_10":"@override protected void updateconnectbuttonstate() { \/\/ todo: update this logic to also handle the user logged in by email. boolean connected = getplusclient().isconnected(); msignoutbuttons.setvisibility(connected ? view.visible : view.gone); mplussigninbutton.setvisibility(connected ? view.gone : view.visible); }","code_context_20":"@override protected void updateconnectbuttonstate() { \/\/ todo: update this logic to also handle the user logged in by email. boolean connected = getplusclient().isconnected(); msignoutbuttons.setvisibility(connected ? view.visible : view.gone); mplussigninbutton.setvisibility(connected ? view.gone : view.visible); }","repo":"llanox\/EasyVote"}
{"id":23285,"comment_id":0,"comment":"\/\/note : this is actually a funcitonal test and does not belong here. it's just being used for dev purposes and should be removed \/\/ or refactored into a true unit test","code":"\/\/note : this is actually a funcitonal test and does not belong here. it's just being used for dev purposes and should be removed \/\/ or refactored into a true unit test @test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","classification":"TEST","isFinished":true,"code_context_2":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","code_context_10":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","code_context_20":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","repo":"krisglover\/cia"}
{"id":23285,"comment_id":1,"comment":"\/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/","code":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","classification":"NONSATD","isFinished":true,"code_context_2":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","code_context_10":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","code_context_20":"@test public void fetchtest(){ \/\/ fileconfigprovider fcp = new fileconfigprovider(\"overrides.json\"); \/\/ for(config config : fcp.getall(\"prod\", \"ssa\")){ \/\/ system.out.println(config); \/\/ } \/\/ restconfigprovider rcc = new restconfigprovider(\"http:\/\/localhost:8080\/configuration\"); \/\/ rcc.getall(\"prod\", \"ssa\"); \/\/ }","repo":"krisglover\/cia"}
{"id":31543,"comment_id":0,"comment":"\/** read from the mplayer standard output and error a line that starts with the given parameter and return it. * @param expected the expected starting string for the line * @return the entire line from the standard output or error of mplayer *\/","code":"\/** read from the mplayer standard output and error a line that starts with the given parameter and return it. * @param expected the expected starting string for the line * @return the entire line from the standard output or error of mplayer *\/ private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","classification":"NONSATD","isFinished":true,"code_context_2":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","code_context_10":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","code_context_20":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","repo":"jzerbe\/musiczones"}
{"id":31543,"comment_id":1,"comment":"\/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string","code":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) {","code_context_10":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; }","code_context_20":"private string waitforanswer(string expected) { \/\/ todo add the possibility to specify more options to be specified \/\/ todo use regexp matching instead of the beginning of a string string line = null; if (expected != null) { try { while ((line = mplayerouterr.readline()) != null) { if (musiczones.getisdebugon()) { logger.log(level.info, \"reading line: {0}\", line); } if (line.startswith(expected)) { return line; } } } catch (ioexception ex) { system.err.println(ex); } } return line; }","repo":"jzerbe\/musiczones"}
{"id":31583,"comment_id":0,"comment":"\/\/todo: fix annotation stuff \/\/log.println(\"[red team controller: \" + quote(game.getcontroller(team.red).getidstring()) + \"]\"); \/\/log.println(\"[blue team controller: \" + quote(game.getcontroller(team.blue).getidstring()) + \"]\");","code":"private void loggamestart(cfmap map) { log.println(\"=== codefray version 1 [capture the flag] official game log ===\\n\"); \/\/todo: fix annotation stuff \/\/log.println(\"[red team controller: \" + quote(game.getcontroller(team.red).getidstring()) + \"]\"); \/\/log.println(\"[blue team controller: \" + quote(game.getcontroller(team.blue).getidstring()) + \"]\"); log.println(); log.println(\"> game started.\"); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void loggamestart(cfmap map) { log.println(\"=== codefray version 1 [capture the flag] official game log ===\\n\"); \/\/todo: fix annotation stuff \/\/log.println(\"[red team controller: \" + quote(game.getcontroller(team.red).getidstring()) + \"]\"); \/\/log.println(\"[blue team controller: \" + quote(game.getcontroller(team.blue).getidstring()) + \"]\"); log.println(); log.println(\"> game started.\");","code_context_10":"private void loggamestart(cfmap map) { log.println(\"=== codefray version 1 [capture the flag] official game log ===\\n\"); \/\/todo: fix annotation stuff \/\/log.println(\"[red team controller: \" + quote(game.getcontroller(team.red).getidstring()) + \"]\"); \/\/log.println(\"[blue team controller: \" + quote(game.getcontroller(team.blue).getidstring()) + \"]\"); log.println(); log.println(\"> game started.\"); }","code_context_20":"private void loggamestart(cfmap map) { log.println(\"=== codefray version 1 [capture the flag] official game log ===\\n\"); \/\/todo: fix annotation stuff \/\/log.println(\"[red team controller: \" + quote(game.getcontroller(team.red).getidstring()) + \"]\"); \/\/log.println(\"[blue team controller: \" + quote(game.getcontroller(team.blue).getidstring()) + \"]\"); log.println(); log.println(\"> game started.\"); }","repo":"lg198\/CodeFray"}
{"id":31644,"comment_id":0,"comment":"\/** * obtains the priority of this rule. it actually is a dynamic priority * that depends on the question that was asked. * the priority is: * - 100% if the question asked is the same to the background of the rule. * - 50% if the question asked is an ordered subset of the filtered question. * - 0% otherwise. * @param questionasked question asked by the user, that underwent the filtering process. * @return the dynamic priority of the rule. *\/","code":"\/** * obtains the priority of this rule. it actually is a dynamic priority * that depends on the question that was asked. * the priority is: * - 100% if the question asked is the same to the background of the rule. * - 50% if the question asked is an ordered subset of the filtered question. * - 0% otherwise. * @param questionasked question asked by the user, that underwent the filtering process. * @return the dynamic priority of the rule. *\/ public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","classification":"NONSATD","isFinished":true,"code_context_2":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","code_context_10":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","code_context_20":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","repo":"melvidoni\/chatbot"}
{"id":31644,"comment_id":1,"comment":"\/\/ if the filtered question is the same than asked","code":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","classification":"NONSATD","isFinished":true,"code_context_2":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100;","code_context_10":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else","code_context_20":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","repo":"melvidoni\/chatbot"}
{"id":31644,"comment_id":2,"comment":"\/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working","code":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","classification":"DESIGN","isFinished":true,"code_context_2":"if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65;","code_context_10":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","code_context_20":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","repo":"melvidoni\/chatbot"}
{"id":31644,"comment_id":3,"comment":"\/\/ otherwise","code":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","classification":"NONSATD","isFinished":true,"code_context_2":"else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0;","code_context_10":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","code_context_20":"public int getprioritylevel(linkedlist<string> questionasked) { \/\/ if the filtered question is the same than asked if(normalizedquestion.equals(questionasked)) return 100; \/\/ if it is an ordered subset \/\/ todo i'm not sure if this is working else if(issubset(questionasked)) return 65; else if(containswords(questionasked)>0) return 30; \/\/ otherwise else return 0; }","repo":"melvidoni\/chatbot"}
{"id":31645,"comment_id":0,"comment":"\/** * evaluates if the normalized questions contains the words of the question asked * and returns the amount of words found. * todo i don't know if this is sloppy or it should work like this * @param questionasked the question to compare. * @return the amount of words of questionasked found in normalizedquestion. *\/","code":"\/** * evaluates if the normalized questions contains the words of the question asked * and returns the amount of words found. * todo i don't know if this is sloppy or it should work like this * @param questionasked the question to compare. * @return the amount of words of questionasked found in normalizedquestion. *\/ private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","classification":"DESIGN","isFinished":true,"code_context_2":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_10":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_20":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","repo":"melvidoni\/chatbot"}
{"id":31645,"comment_id":1,"comment":"\/\/ create a counter","code":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","classification":"NONSATD","isFinished":true,"code_context_2":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked","code_context_10":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_20":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","repo":"melvidoni\/chatbot"}
{"id":31645,"comment_id":2,"comment":"\/\/ for each word asked","code":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero","code_context_10":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_20":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","repo":"melvidoni\/chatbot"}
{"id":31645,"comment_id":3,"comment":"\/\/ if found, we add one, otherwise, we add zero","code":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; }","code_context_10":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_20":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","repo":"melvidoni\/chatbot"}
{"id":31645,"comment_id":4,"comment":"\/\/ return the value","code":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","classification":"NONSATD","isFinished":true,"code_context_2":"containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_10":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","code_context_20":"private int containswords(linkedlist<string> questionasked) { \/\/ create a counter int containedwords = 0; \/\/ for each word asked for(string wordasked : questionasked) { \/\/ if found, we add one, otherwise, we add zero containedwords += normalizedquestion.contains(wordasked) ? 1 : 0; } \/\/ return the value return containedwords; }","repo":"melvidoni\/chatbot"}
{"id":31742,"comment_id":0,"comment":"\/** * recolors map colors in the aether dimension to look nicer. * could be a redirect, but that would actually probably be less compatible with other mods. * however, if the game updates this won't break, which is a bad thing *\/","code":"\/** * recolors map colors in the aether dimension to look nicer. * could be a redirect, but that would actually probably be less compatible with other mods. * however, if the game updates this won't break, which is a bad thing *\/ @inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","code_context_10":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","code_context_20":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","repo":"kalucky0\/The-Aether"}
{"id":31742,"comment_id":1,"comment":"\/\/ mapcolor.clear","code":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please!","code_context_10":"value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel();","code_context_20":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","repo":"kalucky0\/The-Aether"}
{"id":31742,"comment_id":2,"comment":"\/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please!","code":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else {","code_context_10":"target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","code_context_20":"@inject( method = \"updatetexture()v\", at = @at( value = \"head\", target = \"net\/minecraft\/client\/render\/maprenderer$maptexture.updatetexture()v\" ), cancellable = true) private void updateaethertexture(callbackinfo ci) { if (this.state.dimension == aetherdimension.aether_world_key){ for (int i = 0; i < 128; ++i) { for (int j = 0; j < 128; ++j) { int k = j + i * 128; int l = this.state.colors[k] & 255; if (l >> 2 == 0) { \/\/ mapcolor.clear \/\/ who knows what this does? nothing, it seems. but just in case i'll let it stick around. \/\/ comment your code please! this.texture.getimage().setcolor(j, i, (k + k \/ 128 & 1) * 8 + 16 << 24); } else { this.texture.getimage().setcolor(j, i, aethermapcolorutil.getcolor(mapcolor.colors[l >> 2], l & 3)); } } } this.texture.upload(); ci.cancel(); } }","repo":"kalucky0\/The-Aether"}
{"id":31763,"comment_id":0,"comment":"\/\/ todo does not work with boot integeration tests:","code":"\/\/ todo does not work with boot integeration tests: @test public void test_echouser_resttemplate() { string firstname = \"chuck\"; string lastname = \"norris\"; string result = resttemplate.getforobject( \"http:\/\/localhost:8888\/\"+firstname+\"\/\"+lastname, string.class); string expected = \"{\\\"firstname\\\":\\\"\"+firstname+\"\\\",\\\"lastname\\\":\\\"\"+lastname+\"\\\"}\"; assertthat(result, containsstring(expected)); log.info(\"*** successfully echoed a user (\"+firstname+\" \"+lastname+\") through rest ***\"); }","classification":"DEFECT","isFinished":true,"code_context_2":"@test public void test_echouser_resttemplate() { string firstname = \"chuck\"; string lastname = \"norris\"; string result = resttemplate.getforobject( \"http:\/\/localhost:8888\/\"+firstname+\"\/\"+lastname, string.class); string expected = \"{\\\"firstname\\\":\\\"\"+firstname+\"\\\",\\\"lastname\\\":\\\"\"+lastname+\"\\\"}\"; assertthat(result, containsstring(expected)); log.info(\"*** successfully echoed a user (\"+firstname+\" \"+lastname+\") through rest ***\"); }","code_context_10":"@test public void test_echouser_resttemplate() { string firstname = \"chuck\"; string lastname = \"norris\"; string result = resttemplate.getforobject( \"http:\/\/localhost:8888\/\"+firstname+\"\/\"+lastname, string.class); string expected = \"{\\\"firstname\\\":\\\"\"+firstname+\"\\\",\\\"lastname\\\":\\\"\"+lastname+\"\\\"}\"; assertthat(result, containsstring(expected)); log.info(\"*** successfully echoed a user (\"+firstname+\" \"+lastname+\") through rest ***\"); }","code_context_20":"@test public void test_echouser_resttemplate() { string firstname = \"chuck\"; string lastname = \"norris\"; string result = resttemplate.getforobject( \"http:\/\/localhost:8888\/\"+firstname+\"\/\"+lastname, string.class); string expected = \"{\\\"firstname\\\":\\\"\"+firstname+\"\\\",\\\"lastname\\\":\\\"\"+lastname+\"\\\"}\"; assertthat(result, containsstring(expected)); log.info(\"*** successfully echoed a user (\"+firstname+\" \"+lastname+\") through rest ***\"); }","repo":"mickknutson\/spring-cloud-config"}
{"id":15506,"comment_id":0,"comment":"\/\/todo pass anything.may be object needed?","code":"public boolean validatebinaryexpr(binaryexpr node) { exprnode expr1 = node.getexpr1(); exprnode expr2 = node.getexpr2(); type t1 = expr1.gettype(); type t2 = expr2.gettype(); string op = node.getoperation(); switch (op) { case \"==\": case \"!=\": if (types.isnumber(t1)) { return this.requirenumber(expr2,t2); } else { return true; \/\/todo pass anything.may be object needed? } case \"+\": case \"-\": case \"*\": case \"\/\": case \"%\": case \">=\": case \"<=\": case \">\": case \"<\": case \"&\": case \"|\": case \"^\": case binaryexpr.op_shift_left: case binaryexpr.op_shift_right: case binaryexpr.op_unsigned_shift_right: return this.requirenumber(expr1, t1) && this.requirenumber(expr2, t2); case \"&&\": case \"||\": return requireboolean(expr1, t1) && requireboolean(expr2, t2); default: diagnosisreporter.report(diagnosis.kind.error, \"unsupported operation:\" + op, node.offset); return false; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} else { return true; \/\/todo pass anything.may be object needed? } case \"+\":","code_context_10":"type t1 = expr1.gettype(); type t2 = expr2.gettype(); string op = node.getoperation(); switch (op) { case \"==\": case \"!=\": if (types.isnumber(t1)) { return this.requirenumber(expr2,t2); } else { return true; \/\/todo pass anything.may be object needed? } case \"+\": case \"-\": case \"*\": case \"\/\": case \"%\": case \">=\": case \"<=\": case \">\": case \"<\":","code_context_20":"public boolean validatebinaryexpr(binaryexpr node) { exprnode expr1 = node.getexpr1(); exprnode expr2 = node.getexpr2(); type t1 = expr1.gettype(); type t2 = expr2.gettype(); string op = node.getoperation(); switch (op) { case \"==\": case \"!=\": if (types.isnumber(t1)) { return this.requirenumber(expr2,t2); } else { return true; \/\/todo pass anything.may be object needed? } case \"+\": case \"-\": case \"*\": case \"\/\": case \"%\": case \">=\": case \"<=\": case \">\": case \"<\": case \"&\": case \"|\": case \"^\": case binaryexpr.op_shift_left: case binaryexpr.op_shift_right: case binaryexpr.op_unsigned_shift_right: return this.requirenumber(expr1, t1) && this.requirenumber(expr2, t2); case \"&&\": case \"||\": return requireboolean(expr1, t1) && requireboolean(expr2, t2);","repo":"lbqh\/kalang"}
{"id":15600,"comment_id":0,"comment":"\/** * <p>project a point on the unit sphere stereographically from the north * pole to complex projective space.<\/p> * * <p><code>(0, 0, 1)<\/code> is projected to the point with homogeneous * coordinates <code>(1, 0)<\/code>.<br> <code>(0, 0, -1)<\/code> is * projected to the point with homogenous coordinates <code>(0, * 1)<\/code>.<\/p> * * @param cp the {@link complexprojective1} used to hand over the * result. must not be null. * * @throws illegalargumentexception if {@link #normsquared()} differs from * <code>1.0<\/code> by more than {@link #epsilon} *\/","code":"\/** * <p>project a point on the unit sphere stereographically from the north * pole to complex projective space.<\/p> * * <p><code>(0, 0, 1)<\/code> is projected to the point with homogeneous * coordinates <code>(1, 0)<\/code>.<br> <code>(0, 0, -1)<\/code> is * projected to the point with homogenous coordinates <code>(0, * 1)<\/code>.<\/p> * * @param cp the {@link complexprojective1} used to hand over the * result. must not be null. * * @throws illegalargumentexception if {@link #normsquared()} differs from * <code>1.0<\/code> by more than {@link #epsilon} *\/ public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","code_context_10":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":1,"comment":"\/* check if the point lies on the sphere. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" +","code_context_10":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result.","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":2,"comment":"\/* check if the point lies above or below the xy-plane. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad,","code_context_10":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":3,"comment":"\/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"DESIGN","isFinished":true,"code_context_2":"\/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre;","code_context_10":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y;","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim;","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":4,"comment":"\/* dummy variables *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"* result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim;","code_context_10":"throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z;","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre;","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":5,"comment":"\/* rotate by 180 degree around the x-axis. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z;","code_context_10":"\/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim;","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":6,"comment":"\/* project that point. now, z < -epsilon. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/","code_context_10":"* numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i","code_context_20":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp);","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":7,"comment":"\/* rotate back. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z;","code_context_10":"* result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are;","code_context_20":"\/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":8,"comment":"\/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"DESIGN","isFinished":true,"code_context_2":"y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim;","code_context_10":"final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); }","code_context_20":"\"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","repo":"jupsal\/schmies-jTEM"}
{"id":15600,"comment_id":9,"comment":"\/* point lies below xy-plane so we use *\/","code":"public void projectto(final complexprojective1 cp) throws illegalargumentexception { \/* check if the point lies on the sphere. *\/ if (math.abs(normsquared() - 1.0) > epsilon) { throw new illegalargumentexception(\"norm must be 1.0. \" + \"norm is \" + norm() + \". \"); } \/* check if the point lies above or below the xy-plane. *\/ if (z > 0.0) { \/* we might be close to the north pole. this would be bad, * numerically. so perform a 180 degree rotation around the * x-axis, project that point, and swap the entries of the * result. *\/ \/* dummy variables *\/ final double dummyre; final double dummyim; \/* rotate by 180 degree around the x-axis. *\/ y = -y; z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","classification":"NONSATD","isFinished":true,"code_context_2":"cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); }","code_context_10":"* because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","code_context_20":"z = -z; \/* project that point. now, z < -epsilon. *\/ belowxyprojectto(cp); \/* rotate back. *\/ y = -y; z = -z; \/* swap the entries of the result. * * todo: maybe complex2 should have a final method that swaps the * entries. this might speed up dereferencing the fields of cp, * because dereferencing fiels of other objects might be slower * than dereferencing fields of the same object. but actually, i * don't know if that is true or if it matters. *\/ dummyre = cp.are; dummyim = cp.aim; cp.are = cp.bre; cp.aim = cp.bim; cp.bre = dummyre; cp.bim = dummyim; } else { \/* point lies below xy-plane so we use *\/ belowxyprojectto(cp); } }","repo":"jupsal\/schmies-jTEM"}
{"id":32041,"comment_id":0,"comment":"\/\/ create a rev with an attachment, then update it keeping attachment \/\/ todo we need to somehow check the attachment wasn't re-downloaded","code":"@test public void dontpullattachmentalreadypulled() { try { \/\/ create a rev with an attachment, then update it keeping attachment \/\/ todo we need to somehow check the attachment wasn't re-downloaded createrevisionandbigtextattachment(); pull(); documentrevision docrev1 = datastore.getdocument(id, rev); attachment a1 = datastore.getattachment(docrev1, bigtextattachmentname); updaterevisionandkeepattachment(); updaterevisionandkeepattachment(); pull(); documentrevision docrev2 = datastore.getdocument(id, rev); attachment a2 = datastore.getattachment(docrev2, bigtextattachmentname); assert.assertnotnull(a2); } catch (exception e) { assert.fail(\"create\/pull error \" + e); } }","classification":"DESIGN","isFinished":true,"code_context_2":"public void dontpullattachmentalreadypulled() { try { \/\/ create a rev with an attachment, then update it keeping attachment \/\/ todo we need to somehow check the attachment wasn't re-downloaded createrevisionandbigtextattachment(); pull();","code_context_10":"@test public void dontpullattachmentalreadypulled() { try { \/\/ create a rev with an attachment, then update it keeping attachment \/\/ todo we need to somehow check the attachment wasn't re-downloaded createrevisionandbigtextattachment(); pull(); documentrevision docrev1 = datastore.getdocument(id, rev); attachment a1 = datastore.getattachment(docrev1, bigtextattachmentname); updaterevisionandkeepattachment(); updaterevisionandkeepattachment(); pull(); documentrevision docrev2 = datastore.getdocument(id, rev); attachment a2 = datastore.getattachment(docrev2, bigtextattachmentname); assert.assertnotnull(a2);","code_context_20":"@test public void dontpullattachmentalreadypulled() { try { \/\/ create a rev with an attachment, then update it keeping attachment \/\/ todo we need to somehow check the attachment wasn't re-downloaded createrevisionandbigtextattachment(); pull(); documentrevision docrev1 = datastore.getdocument(id, rev); attachment a1 = datastore.getattachment(docrev1, bigtextattachmentname); updaterevisionandkeepattachment(); updaterevisionandkeepattachment(); pull(); documentrevision docrev2 = datastore.getdocument(id, rev); attachment a2 = datastore.getattachment(docrev2, bigtextattachmentname); assert.assertnotnull(a2); } catch (exception e) { assert.fail(\"create\/pull error \" + e); } }","repo":"kiwiwearables\/sync-android"}
{"id":7632,"comment_id":0,"comment":"\/\/ fixme: flashing blank activity","code":"\/\/ fixme: flashing blank activity @override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","classification":"DEFECT","isFinished":true,"code_context_2":"@override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","code_context_10":"@override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","code_context_20":"@override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","repo":"memleakpl\/flat"}
{"id":7632,"comment_id":1,"comment":"\/\/ finish activity earlier","code":"@override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish();","code_context_10":"appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","code_context_20":"@override protected void oncreate(bundle savedinstancestate) { super.oncreate(savedinstancestate); bundle extras; log.d(tag, \"widget configuration activity created\"); setresult(result_canceled); extras = getintent().getextras(); if (extras != null) { mappwidgetid = extras.getint(appwidgetmanager.extra_appwidget_id, appwidgetmanager.invalid_appwidget_id); } if (mappwidgetid == appwidgetmanager.invalid_appwidget_id) { finish(); return; } resultvalue = new intent(); resultvalue.putextra(appwidgetmanager.extra_appwidget_id, mappwidgetid); setresult(result_ok, resultvalue); if(sessionmanager.hassessioninstore(this)) { \/\/ finish activity earlier log.d(tag, \"session already taken, leaving configuration activity\"); finish(); } }","repo":"memleakpl\/flat"}
{"id":24024,"comment_id":0,"comment":"\/\/ lets escape quotes","code":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); } buffer.append('>'); } else { buffer.append(object.getclass().getname()).append(\"@\").append(system.identityhashcode(object)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) {","code_context_10":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; }","code_context_20":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object);","repo":"laakhbeenor\/cayenne"}
{"id":24024,"comment_id":1,"comment":"\/\/ handle byte pretty formatting","code":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); } buffer.append('>'); } else { buffer.append(object.getclass().getname()).append(\"@\").append(system.identityhashcode(object)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue());","code_context_10":"int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) {","code_context_20":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) {","repo":"laakhbeenor\/cayenne"}
{"id":24024,"comment_id":2,"comment":"\/\/ process numeric value (do something smart in the future)","code":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); } buffer.append('>'); } else { buffer.append(object.getclass().getname()).append(\"@\").append(system.identityhashcode(object)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) {","code_context_10":"curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis();","code_context_20":"buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue();","repo":"laakhbeenor\/cayenne"}
{"id":24024,"comment_id":3,"comment":"\/\/ buffer.append(object.getclass().getname()).append(\".\");","code":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); } buffer.append('>'); } else { buffer.append(object.getclass().getname()).append(\"@\").append(system.identityhashcode(object)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) {","code_context_10":"long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal());","code_context_20":"else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold;","repo":"laakhbeenor\/cayenne"}
{"id":24024,"comment_id":4,"comment":"\/\/ fixme -- this isn't quite right","code":"void sqlliteralforobject(stringbuilder buffer, object object) { if (object == null) { buffer.append(\"null\"); } else if (object instanceof string) { buffer.append('\\''); \/\/ lets escape quotes string literal = (string) object; if (literal.length() > trim_values_threshold) { literal = literal.substring(0, trim_values_threshold) + \"...\"; } int curpos = 0; int endpos = 0; while ((endpos = literal.indexof('\\'', curpos)) >= 0) { buffer.append(literal.substring(curpos, endpos + 1)).append('\\''); curpos = endpos + 1; } if (curpos < literal.length()) buffer.append(literal.substring(curpos)); buffer.append('\\''); } \/\/ handle byte pretty formatting else if (object instanceof byte) { idutil.appendformattedbyte(buffer, ((byte) object).bytevalue()); } else if (object instanceof number) { \/\/ process numeric value (do something smart in the future) buffer.append(object); } else if (object instanceof java.sql.date) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.sql.time) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof java.util.date) { long time = ((java.util.date) object).gettime(); buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); } buffer.append('>'); } else { buffer.append(object.getclass().getname()).append(\"@\").append(system.identityhashcode(object)); } }","classification":"DEFECT","isFinished":true,"code_context_2":"} else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) {","code_context_10":"buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true;","code_context_20":"buffer.append('\\'').append(new java.sql.timestamp(time)).append('\\''); } else if (object instanceof java.util.calendar) { long time = ((java.util.calendar) object).gettimeinmillis(); buffer.append(object.getclass().getname()).append('(').append(new java.sql.timestamp(time)).append(')'); } else if (object instanceof character) { buffer.append(((character) object).charvalue()); } else if (object instanceof boolean) { buffer.append('\\'').append(object).append('\\''); } else if (object instanceof enum<?>) { \/\/ buffer.append(object.getclass().getname()).append(\".\"); buffer.append(((enum<?>) object).name()).append(\"=\"); if (object instanceof extendedenumeration) { object value = ((extendedenumeration) object).getdatabasevalue(); if (value instanceof string) buffer.append(\"'\"); buffer.append(value); if (value instanceof string) buffer.append(\"'\"); } else { buffer.append(((enum<?>) object).ordinal()); \/\/ fixme -- this isn't quite right } } else if (object instanceof sqlparameterbinding) { sqlliteralforobject(buffer, ((sqlparameterbinding) object).getvalue()); } else if (object.getclass().isarray()) { buffer.append(\"< \"); int len = array.getlength(object); boolean trimming = false; if (len > trim_values_threshold) { len = trim_values_threshold; trimming = true; } for (int i = 0; i < len; i++) { if (i > 0) { buffer.append(\",\"); } sqlliteralforobject(buffer, array.get(object, i)); } if (trimming) { buffer.append(\"...\"); }","repo":"laakhbeenor\/cayenne"}
{"id":15851,"comment_id":0,"comment":"\/\/ compiler complains unless i include the full classname!!! huh?","code":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","classification":"DESIGN","isFinished":true,"code_context_2":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable)","code_context_10":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","code_context_20":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","repo":"minhhn2910\/g-mason"}
{"id":15851,"comment_id":1,"comment":"\/\/ unknown","code":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","classification":"NONSATD","isFinished":true,"code_context_2":"else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","code_context_10":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","code_context_20":"protected double valuefor(object o) { if (o instanceof java.lang.number) \/\/ compiler complains unless i include the full classname!!! huh? return ((number)o).doublevalue(); else if (o instanceof valuable) return ((valuable)o).doublevalue(); else if (o instanceof boolean) return ((boolean)o).booleanvalue() ? 1 : 0; else return double.nan; \/\/ unknown }","repo":"minhhn2910\/g-mason"}
{"id":24088,"comment_id":0,"comment":"\/** * metodo que se encarga de crear un grid para la visualizacion de los datos de un movimiento * @return devuelve un grid con los campos para representar movimientos *\/","code":"\/** * metodo que se encarga de crear un grid para la visualizacion de los datos de un movimiento * @return devuelve un grid con los campos para representar movimientos *\/ private grid<cuenta> creategrid() { grid = new grid<>(); grid.setwidthfull(); grid.addthemevariants(gridvariant.lumo_no_border,gridvariant.lumo_row_stripes); simpledateformat dateformat = new simpledateformat(\"dd\/mm\/yyyy\"); grid.addcolumn(c -> c.getiban()).setheader(\"iban\").setflexgrow(1); grid.addcolumn(c -> c.getsaldo()).setheader(\"saldo\").setflexgrow(1); grid.addcolumn(c -> dateformat.format(c.getfechacreacion())).setheader(\"fecha creacion\").setwidth(\"250px\").setflexgrow(0); return grid; }","classification":"NONSATD","isFinished":true,"code_context_2":"private grid<cuenta> creategrid() { grid = new grid<>(); grid.setwidthfull(); grid.addthemevariants(gridvariant.lumo_no_border,gridvariant.lumo_row_stripes); simpledateformat dateformat = new simpledateformat(\"dd\/mm\/yyyy\"); grid.addcolumn(c -> c.getiban()).setheader(\"iban\").setflexgrow(1); grid.addcolumn(c -> c.getsaldo()).setheader(\"saldo\").setflexgrow(1); grid.addcolumn(c -> dateformat.format(c.getfechacreacion())).setheader(\"fecha creacion\").setwidth(\"250px\").setflexgrow(0); return grid; }","code_context_10":"private grid<cuenta> creategrid() { grid = new grid<>(); grid.setwidthfull(); grid.addthemevariants(gridvariant.lumo_no_border,gridvariant.lumo_row_stripes); simpledateformat dateformat = new simpledateformat(\"dd\/mm\/yyyy\"); grid.addcolumn(c -> c.getiban()).setheader(\"iban\").setflexgrow(1); grid.addcolumn(c -> c.getsaldo()).setheader(\"saldo\").setflexgrow(1); grid.addcolumn(c -> dateformat.format(c.getfechacreacion())).setheader(\"fecha creacion\").setwidth(\"250px\").setflexgrow(0); return grid; }","code_context_20":"private grid<cuenta> creategrid() { grid = new grid<>(); grid.setwidthfull(); grid.addthemevariants(gridvariant.lumo_no_border,gridvariant.lumo_row_stripes); simpledateformat dateformat = new simpledateformat(\"dd\/mm\/yyyy\"); grid.addcolumn(c -> c.getiban()).setheader(\"iban\").setflexgrow(1); grid.addcolumn(c -> c.getsaldo()).setheader(\"saldo\").setflexgrow(1); grid.addcolumn(c -> dateformat.format(c.getfechacreacion())).setheader(\"fecha creacion\").setwidth(\"250px\").setflexgrow(0); return grid; }","repo":"juansgonzalez\/ingenia-bank"}
{"id":7744,"comment_id":0,"comment":"\/\/ todo write me","code":"@ignore(\"this test was not writted due to lack of time. this is what should have been done:\\n\" + \"since this feature involves network calls, to properly unit test this it, is necessary\\n\" + \"to mock the network module and provide a fake json response. this way the test doesn't\\n\" + \"rely on an internet connection, a web service and the json response is always the same.\\n\" + \"once we have that it is possible tu use assertj-android to check if the data inside the\\n\" + \"recyclerview is the same as what we expecting from the json.\") @test public void hitlist_iscorrect() { \/\/ todo write me }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@test public void hitlist_iscorrect() { \/\/ todo write me }","code_context_10":"@ignore(\"this test was not writted due to lack of time. this is what should have been done:\\n\" + \"since this feature involves network calls, to properly unit test this it, is necessary\\n\" + \"to mock the network module and provide a fake json response. this way the test doesn't\\n\" + \"rely on an internet connection, a web service and the json response is always the same.\\n\" + \"once we have that it is possible tu use assertj-android to check if the data inside the\\n\" + \"recyclerview is the same as what we expecting from the json.\") @test public void hitlist_iscorrect() { \/\/ todo write me }","code_context_20":"@ignore(\"this test was not writted due to lack of time. this is what should have been done:\\n\" + \"since this feature involves network calls, to properly unit test this it, is necessary\\n\" + \"to mock the network module and provide a fake json response. this way the test doesn't\\n\" + \"rely on an internet connection, a web service and the json response is always the same.\\n\" + \"once we have that it is possible tu use assertj-android to check if the data inside the\\n\" + \"recyclerview is the same as what we expecting from the json.\") @test public void hitlist_iscorrect() { \/\/ todo write me }","repo":"leinardi\/Dagger2MVP"}
{"id":24143,"comment_id":0,"comment":"\/\/ todo: come up with a better implementation of this later","code":"@override public boolean equals(object obj) { \/\/ todo: come up with a better implementation of this later return false; }","classification":"DESIGN","isFinished":true,"code_context_2":"@override public boolean equals(object obj) { \/\/ todo: come up with a better implementation of this later return false; }","code_context_10":"@override public boolean equals(object obj) { \/\/ todo: come up with a better implementation of this later return false; }","code_context_20":"@override public boolean equals(object obj) { \/\/ todo: come up with a better implementation of this later return false; }","repo":"kaubster\/se-577-group-projects"}
{"id":7766,"comment_id":0,"comment":"\/\/fail(\"test not implemented yet.\"); \/\/todo: do later","code":"@test public void testpaginate() throws exception { \/\/fail(\"test not implemented yet.\"); \/\/todo: do later }","classification":"TEST","isFinished":true,"code_context_2":"@test public void testpaginate() throws exception { \/\/fail(\"test not implemented yet.\"); \/\/todo: do later }","code_context_10":"@test public void testpaginate() throws exception { \/\/fail(\"test not implemented yet.\"); \/\/todo: do later }","code_context_20":"@test public void testpaginate() throws exception { \/\/fail(\"test not implemented yet.\"); \/\/todo: do later }","repo":"mkalus\/segrada"}
{"id":7935,"comment_id":0,"comment":"\/\/ warning \/\/ incomplete see processsubtypeconstraints","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod());","code_context_10":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); }","code_context_20":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti));","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":1,"comment":"\/\/ the constraint s >> r', provided r is not void","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement()));","code_context_10":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) {","code_context_20":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f()));","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":2,"comment":"\/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference();","code_context_10":"typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement()));","code_context_20":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints();","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":3,"comment":"\/\/ jls: any equality constraints are resolved ...","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument","code_context_10":"constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); }","code_context_20":"} \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":4,"comment":"\/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk)","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred","code_context_10":"} for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param));","code_context_20":"for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":5,"comment":"\/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ].","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace())));","code_context_10":"} for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","code_context_20":"type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","repo":"markovandooren\/jnome"}
{"id":7935,"comment_id":6,"comment":"\/\/fixme perform substitution","code":"private void processunresolved(typereference sref) throws lookupexception { \/\/ warning \/\/ incomplete see processsubtypeconstraints typereference rref = (typereference) invokedgenericmethod().returntypereference(); firstphaseconstraintset constraints = new firstphaseconstraintset(invocation(), invokedgenericmethod()); view view = rref.view(); typereference sprimeref = box(sref); java7 java = view.language(java7.class); if(! rref.getelement().sameas(java.voidtype(rref.view().namespace()))) { \/\/ the constraint s >> r', provided r is not void typereference rprimeref = substitutedreference(rref); constraints.add(new ggconstraint(sprimeref, rprimeref.getelement())); } \/\/ additional constraints bi[t1=b(t1) ... tn=b(tn)] >> ti where bi is the declared bound of ti for(typeparameter param: typeparameters()) { typereference bi = param.upperboundreference(); typereference biaftersubstitution = substitutedreference(bi); type ti = (type) param.selectiondeclaration(); type bti = assignments().type(param); if(bti == null) { bti = ti; } constraints.add(new ggconstraint(biaftersubstitution, ti)); constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param));","code_context_10":"seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","code_context_20":"constraints.add(new ssconstraint(java.reference(bti), biaftersubstitution.getelement())); } for(ggconstraint constraint: _origin.generatedgg()) { constraints.add(new ggconstraint(substitutedreference(constraint.aref()), constraint.f())); } for(eqconstraint constraint: _origin.generatedeq()) { constraints.add(new eqconstraint(substitutedreference(constraint.aref()), constraint.f())); } secondphaseconstraintset seconds = constraints.secondphase(); \/\/ jls: any equality constraints are resolved ... seconds.processequalityconstraints(); \/\/ jls: ..., and then, for each remaining constraint of the form ti <: uk, the argument \/\/ ti is inferred to be glb(u1,...,uk) seconds.processsubtypeconstraints(); \/\/any remaining type variable t that has not yet been inferred is then inferred \/\/ to have type object . if a previously inferred type variable p uses t , then p is \/\/ inferred to be p [t =object ]. for(typeparameter param: seconds.unresolvedparameters()) { seconds.add(new actualtypeassignment(param, java.getdefaultsuperclass(view.namespace()))); } \/\/fixme perform substitution for(typeparameter param: unresolvedparameters()) { add(seconds.assignments().assignment(param)); } }","repo":"markovandooren\/jnome"}
