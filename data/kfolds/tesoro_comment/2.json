{"id":24717,"comment_id":0,"comment":"\/** * * @see org.springframework.web.servlet.mvc.controller#handlerequest(javax.servlet.http.httpservletrequest, * javax.servlet.http.httpservletresponse) *\/","code":"\/** * * @see org.springframework.web.servlet.mvc.controller#handlerequest(javax.servlet.http.httpservletrequest, * javax.servlet.http.httpservletresponse) *\/ public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","code_context_10":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","code_context_20":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":1,"comment":"\/\/ copy study information","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id","code_context_10":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) {","code_context_20":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis);","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":2,"comment":"\/\/ study from tbi do not contain submission_id","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid());","code_context_10":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller.","code_context_20":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } }","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":3,"comment":"\/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller.","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"DEFECT","isFinished":true,"code_context_2":"stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate();","code_context_10":"studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } }","code_context_20":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly();","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":4,"comment":"\/\/ save to db if the validated flag is updated:","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); }","code_context_10":"stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand();","code_context_20":"studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo();","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":5,"comment":"\/\/fixme: display err message in gui","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$","code_context_10":"if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>();","code_context_20":"if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) {","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":6,"comment":"\/\/$non-nls-1$","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/","code_context_10":"if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand();","code_context_20":"} list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) {","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":7,"comment":"\/\/ \/\/ analysis","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) {","code_context_10":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when","code_context_20":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); }","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":8,"comment":"\/\/ analysis steps for analysis and add algorithm type","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>();","code_context_10":"} } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) {","code_context_20":"\/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) {","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":9,"comment":"\/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo());","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string();","code_context_10":"\/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian;","code_context_20":"} if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":10,"comment":"\/\/ add algorithm type for analysisstepcommand","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step","code_context_10":"algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput);","code_context_20":"beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel());","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":11,"comment":"\/\/ analyzed data for each analysis step","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>();","code_context_10":"algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata;","code_context_20":"\/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid());","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":12,"comment":"\/\/ matrix or tree?","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand();","code_context_10":"} else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid());","code_context_20":"if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":13,"comment":"\/\/ end for","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"} analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator());","code_context_10":"analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist);","code_context_20":"\/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","repo":"TreeBASE\/treebasetest"}
{"id":24717,"comment_id":14,"comment":"\/\/ add analyzeddata for analysisstepcommand","code":"public modelandview handlerequest(httpservletrequest request, httpservletresponse response) throws exception { study study = controllerutil.findstudy(request, mstudyservice); submission submission = (submission) study.getsubmission(); studycommand studycommand = new studycommand(); \/\/ copy study information studycommand.setstudy(study); \/\/ study from tbi do not contain submission_id if (submission != null) { studycommand.setsubmission_id(submission.getid()); } list<analysis> analysislist = study.getanalyses(); list<analysiscommand> analysiscommandlist = new arraylist<analysiscommand>(); list<analysis> changedanalyses = new arraylist<analysis>(); stringbuilder errbuilder = new stringbuilder(); for (analysis analysis : analysislist) { \/\/ fixme: next if block needs to me moved to the onsumbit method when \/\/ we this controller will extend baseformcontroller. if (!analysis.getvalidated()) { executionresult result = analysis.validate(); if (!result.issuccessful()) { errbuilder.append(result.geterrormessage()); } if (analysis.getvalidated()) { \/\/ save to db if the validated flag is updated: changedanalyses.add(analysis); } } \/\/fixme: display err message in gui if (logger.isdebugenabled()) { logger.debug(errbuilder.tostring()); \/\/$non-nls-1$ } \/\/ \/\/ analysis analysiscommand analysiscommand = new analysiscommand(); beanutils.copyproperties(analysiscommand, analysis); \/\/ analysis steps for analysis and add algorithm type list<analysisstep> analysissteplist = analysis.getanalysisstepsreadonly(); list<analysisstepcommand> analysisstepcommandlist = new arraylist<analysisstepcommand>(); for (analysisstep analysisstep : analysissteplist) { analysisstepcommand analysisstepcommand = new analysisstepcommand(); beanutils.copyproperties(analysisstepcommand, analysisstep); \/\/ analysisstepcommand.setid(analysisstep.getid()); \/\/ analysisstepcommand.setsoftwareinfo(analysisstep.getsoftwareinfo()); algorithm algorithm = analysisstep.getalgorithminfo(); string algorithmtype = new string(); if (algorithm instanceof likelihoodalgorithm) { algorithmtype = constants.algorithm_likelihood; } else if (algorithm instanceof parsimonyalgorithm) { algorithmtype = constants.algorithm_parsimony; } else if (algorithm instanceof otheralgorithm) { algorithmtype = constants.algorithm_other; }else if (algorithm instanceof bayesianalgorithm) { algorithmtype = constants.algorithm_bayesian; } else if (algorithm instanceof evolutionalgorithm) { algorithmtype = constants.algorithm_evolution; } else if (algorithm instanceof joiningalgorithm) { algorithmtype = constants.algorithm_joining; } else if (algorithm instanceof upgmaalgorithm) { algorithmtype = constants.algorithm_upgma; } \/\/ add algorithm type for analysisstepcommand analysisstepcommand.setalgorithmtype(algorithmtype); \/\/ analyzed data for each analysis step list<analyzeddata> analyzeddataset = analysisstep.getdatasetreadonly(); list<analyzeddatacommand> analyzeddatacommandlist = new arraylist<analyzeddatacommand>(); \/\/ matrix or tree? for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","classification":"NONSATD","isFinished":true,"code_context_2":"analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist);","code_context_10":"analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand);","code_context_20":"for (analyzeddata analyzeddata : analyzeddataset) { analyzeddatacommand analyzeddatacommand = new analyzeddatacommand(); beanutils.copyproperties(analyzeddatacommand, analyzeddata); string inputoutput = (analyzeddata.isinputdata()) ? (\"input\") : (\"output\"); analyzeddatacommand.setinputoutputtype(inputoutput); if (analyzeddata instanceof analyzedmatrix) { analyzedmatrix analyzedmatrix = (analyzedmatrix) analyzeddata; analyzeddatacommand.setdatatype(constants.matrix_key); analyzeddatacommand.setdisplayname(analyzedmatrix.getmatrix().gettitle()); analyzeddatacommand.setid(analyzedmatrix.getid()); analyzeddatacommand.setdataid(analyzedmatrix.getmatrix().getid()); } else if (analyzeddata instanceof analyzedtree) { analyzedtree analyzedtree = (analyzedtree) analyzeddata; analyzeddatacommand.setdatatype(constants.tree_key); analyzeddatacommand.setdisplayname(analyzedtree.gettree().getlabel()); analyzeddatacommand.setid(analyzedtree.getid()); analyzeddatacommand.setdataid(analyzedtree.gettree().getid()); } analyzeddatacommandlist.add(analyzeddatacommand); } \/\/ end for \/\/ add analyzeddata for analysisstepcommand collections.sort(analyzeddatacommandlist, new analyzeddatacomparator()); analysisstepcommand.setanalyzeddatacommandlist(analyzeddatacommandlist); analysisstepcommandlist.add(analysisstepcommand); } analysiscommand.setanalysisstepcommandlist(analysisstepcommandlist); analysiscommandlist.add(analysiscommand); } getstudyservice().updatecollection(changedanalyses); studycommand.setanalysiscommandlist(analysiscommandlist); return new modelandview(\"analysissection\", constants.study_command_key, studycommand); }","repo":"TreeBASE\/treebasetest"}
{"id":148,"comment_id":0,"comment":"\/** todo: synchronize once per read, not once per varlet *\/","code":"\/** todo: synchronize once per read, not once per varlet *\/ private void addvar(varlet v){ long key=key(v.chromosome, v.beginloc); arraylist<varlet> list=keymap.get(key); assert(list!=null) : \"\\ncan't find \"+key+\" in \"+keymap.keyset()+\"\\n\"; synchronized(list){ list.add(v); if(list.size()>=write_buffer){ if(merge_equal_varlets){ mergeequalvarlets(list); }else{ collections.sort(list); } writelist(list); list.clear(); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"private void addvar(varlet v){ long key=key(v.chromosome, v.beginloc); arraylist<varlet> list=keymap.get(key); assert(list!=null) : \"\\ncan't find \"+key+\" in \"+keymap.keyset()+\"\\n\"; synchronized(list){ list.add(v); if(list.size()>=write_buffer){ if(merge_equal_varlets){ mergeequalvarlets(list); }else{ collections.sort(list); } writelist(list); list.clear(); } } }","code_context_10":"private void addvar(varlet v){ long key=key(v.chromosome, v.beginloc); arraylist<varlet> list=keymap.get(key); assert(list!=null) : \"\\ncan't find \"+key+\" in \"+keymap.keyset()+\"\\n\"; synchronized(list){ list.add(v); if(list.size()>=write_buffer){ if(merge_equal_varlets){ mergeequalvarlets(list); }else{ collections.sort(list); } writelist(list); list.clear(); } } }","code_context_20":"private void addvar(varlet v){ long key=key(v.chromosome, v.beginloc); arraylist<varlet> list=keymap.get(key); assert(list!=null) : \"\\ncan't find \"+key+\" in \"+keymap.keyset()+\"\\n\"; synchronized(list){ list.add(v); if(list.size()>=write_buffer){ if(merge_equal_varlets){ mergeequalvarlets(list); }else{ collections.sort(list); } writelist(list); list.clear(); } } }","repo":"SilasK\/BBMap"}
{"id":16664,"comment_id":0,"comment":"\/\/todo: make firefox subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass","code_context_10":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":1,"comment":"\/\/todo: make ie subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass","code_context_10":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":2,"comment":"\/\/todo: make edge subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass","code_context_10":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":3,"comment":"\/\/todo: make opera subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass","code_context_10":"switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":4,"comment":"\/\/todo: make safari subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass","code_context_10":"return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null;","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":5,"comment":"\/\/todo: make ios_iphone subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass","code_context_10":"return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":6,"comment":"\/\/todo: make ios_ipad subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass","code_context_10":"return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":7,"comment":"\/\/todo: make android subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass","code_context_10":"return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","code_context_20":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":16664,"comment_id":8,"comment":"\/\/todo: make htmlunit subclass","code":"private nicewebdriver getnicewebdriverinstance(drivertype drivertype, object[] oargs){ switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null;","code_context_10":"return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","code_context_20":"switch(drivertype) { case chrome: return new nicechrome().underloadednicewebdriverconstructor(oargs).getthiswithverbositysetto(outputisverbose); case firefox: return null; \/\/todo: make firefox subclass case ie: return null; \/\/todo: make ie subclass case edge: return null; \/\/todo: make edge subclass case opera: return null; \/\/todo: make opera subclass case safari: return null; \/\/todo: make safari subclass case ios_iphone: return null; \/\/todo: make ios_iphone subclass case ios_ipad: return null; \/\/todo: make ios_ipad subclass case android: return null; \/\/todo: make android subclass case htmlunit: return null; \/\/todo: make htmlunit subclass default: return null; } }","repo":"Skenvy\/SeleniumNG"}
{"id":33149,"comment_id":0,"comment":"\/\/hack: need to have padding at the end of the tag, or winamp won't see the last frame (at least 6 bytes seem to be required).","code":"private void tag() throws exception { string[] asfilename = (string[])m_ocmdlinemap.get(\"filenames\"); for (int i=0; i < asfilename.length; i++) { file osourcefile = new file(asfilename[i]); mp3file omp3file = new mp3file(osourcefile); if (m_ocmdlinemap.containskey(\"1\")) { id3v1_1tag oid3v1_1tag = new id3v1_1tag(); if (m_ocmdlinemap.containskey(\"album\")) { oid3v1_1tag.setalbum((string)m_ocmdlinemap.get(\"album\")); } if (m_ocmdlinemap.containskey(\"artist\")) { oid3v1_1tag.setartist((string)m_ocmdlinemap.get(\"artist\")); } if (m_ocmdlinemap.containskey(\"comment\")) { oid3v1_1tag.setcomment((string)m_ocmdlinemap.get(\"comment\")); } if (m_ocmdlinemap.containskey(\"genre\")) { string sgenre = (string)m_ocmdlinemap.get(\"genre\"); oid3v1_1tag.setgenre(id3v1tag.genre.lookupgenre(sgenre)); } if (m_ocmdlinemap.containskey(\"title\")) { oid3v1_1tag.settitle((string)m_ocmdlinemap.get(\"title\")); } if (m_ocmdlinemap.containskey(\"year\")) { oid3v1_1tag.setyear(((integer)m_ocmdlinemap.get(\"year\")).tostring()); } if (m_ocmdlinemap.containskey(\"track\")) { oid3v1_1tag.setalbumtrack(((integer)m_ocmdlinemap.get(\"track\")).intvalue()); } omp3file.setid3tag(oid3v1_1tag); } if (m_ocmdlinemap.containskey(\"2\")) { id3v2_3_0tag oid3v2_3_0tag = new id3v2_3_0tag(); \/\/hack: need to have padding at the end of the tag, or winamp won't see the last frame (at least 6 bytes seem to be required). oid3v2_3_0tag.setpaddinglength(16); if (m_ocmdlinemap.containskey(\"album\")) { oid3v2_3_0tag.setalbum((string)m_ocmdlinemap.get(\"album\")); } if (m_ocmdlinemap.containskey(\"artist\")) { oid3v2_3_0tag.setartist((string)m_ocmdlinemap.get(\"artist\")); } if (m_ocmdlinemap.containskey(\"comment\")) { oid3v2_3_0tag.setcomment((string)m_ocmdlinemap.get(\"comment\")); } if (m_ocmdlinemap.containskey(\"genre\")) { oid3v2_3_0tag.setgenre((string)m_ocmdlinemap.get(\"genre\")); } omp3file.setid3tag(oid3v2_3_0tag); if (m_ocmdlinemap.containskey(\"title\")) { oid3v2_3_0tag.settitle((string)m_ocmdlinemap.get(\"title\")); } if (m_ocmdlinemap.containskey(\"year\")) { oid3v2_3_0tag.setyear(((integer)m_ocmdlinemap.get(\"year\")).intvalue()); } if (m_ocmdlinemap.containskey(\"track\")) { if (m_ocmdlinemap.containskey(\"total\")) { oid3v2_3_0tag.settracknumber(((integer)m_ocmdlinemap.get(\"track\")).intvalue(), ((integer)m_ocmdlinemap.get(\"total\")).intvalue()); } else { oid3v2_3_0tag.settracknumber(((integer)m_ocmdlinemap.get(\"track\")).intvalue()); } } } omp3file.sync(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"{ id3v2_3_0tag oid3v2_3_0tag = new id3v2_3_0tag(); \/\/hack: need to have padding at the end of the tag, or winamp won't see the last frame (at least 6 bytes seem to be required). oid3v2_3_0tag.setpaddinglength(16); if (m_ocmdlinemap.containskey(\"album\"))","code_context_10":"} if (m_ocmdlinemap.containskey(\"track\")) { oid3v1_1tag.setalbumtrack(((integer)m_ocmdlinemap.get(\"track\")).intvalue()); } omp3file.setid3tag(oid3v1_1tag); } if (m_ocmdlinemap.containskey(\"2\")) { id3v2_3_0tag oid3v2_3_0tag = new id3v2_3_0tag(); \/\/hack: need to have padding at the end of the tag, or winamp won't see the last frame (at least 6 bytes seem to be required). oid3v2_3_0tag.setpaddinglength(16); if (m_ocmdlinemap.containskey(\"album\")) { oid3v2_3_0tag.setalbum((string)m_ocmdlinemap.get(\"album\")); } if (m_ocmdlinemap.containskey(\"artist\")) { oid3v2_3_0tag.setartist((string)m_ocmdlinemap.get(\"artist\")); } if (m_ocmdlinemap.containskey(\"comment\"))","code_context_20":"string sgenre = (string)m_ocmdlinemap.get(\"genre\"); oid3v1_1tag.setgenre(id3v1tag.genre.lookupgenre(sgenre)); } if (m_ocmdlinemap.containskey(\"title\")) { oid3v1_1tag.settitle((string)m_ocmdlinemap.get(\"title\")); } if (m_ocmdlinemap.containskey(\"year\")) { oid3v1_1tag.setyear(((integer)m_ocmdlinemap.get(\"year\")).tostring()); } if (m_ocmdlinemap.containskey(\"track\")) { oid3v1_1tag.setalbumtrack(((integer)m_ocmdlinemap.get(\"track\")).intvalue()); } omp3file.setid3tag(oid3v1_1tag); } if (m_ocmdlinemap.containskey(\"2\")) { id3v2_3_0tag oid3v2_3_0tag = new id3v2_3_0tag(); \/\/hack: need to have padding at the end of the tag, or winamp won't see the last frame (at least 6 bytes seem to be required). oid3v2_3_0tag.setpaddinglength(16); if (m_ocmdlinemap.containskey(\"album\")) { oid3v2_3_0tag.setalbum((string)m_ocmdlinemap.get(\"album\")); } if (m_ocmdlinemap.containskey(\"artist\")) { oid3v2_3_0tag.setartist((string)m_ocmdlinemap.get(\"artist\")); } if (m_ocmdlinemap.containskey(\"comment\")) { oid3v2_3_0tag.setcomment((string)m_ocmdlinemap.get(\"comment\")); } if (m_ocmdlinemap.containskey(\"genre\")) { oid3v2_3_0tag.setgenre((string)m_ocmdlinemap.get(\"genre\")); } omp3file.setid3tag(oid3v2_3_0tag); if (m_ocmdlinemap.containskey(\"title\")) {","repo":"ShahzaibAyyub\/Music-Player-Library-Java-SQL"}
{"id":8611,"comment_id":0,"comment":"\/\/ differentiate clones in this group","code":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){","code_context_10":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute();","code_context_20":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","repo":"UCLA-SEAL\/Grafter"}
{"id":8611,"comment_id":1,"comment":"\/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison","code":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1);","code_context_10":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","code_context_20":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","repo":"UCLA-SEAL\/Grafter"}
{"id":8611,"comment_id":2,"comment":"\/\/ }","code":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","classification":"NONSATD","isFinished":true,"code_context_2":"comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","code_context_10":"grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","code_context_20":"@override public void actionperformed(actionevent e) { if(currsel!= null && currsel instanceof grouptreenode){ \/\/ differentiate clones in this group grouptreenode gtn = (grouptreenode)currsel; \/\/ if(gtn.getchildcount() == 2){ \/\/ todo: currently we only support two way comparison clonetreenode ctn1 = (clonetreenode)gtn.getchildat(0); clonetreenode ctn2 = (clonetreenode)gtn.getchildat(1); string file1 = ctn1.getfile(); string file2 = ctn2.getfile(); clonecomparison comparison = new clonecomparison(panel, new file(file1), new file(file2), ctn1.start, ctn1.end, ctn2.start, ctn2.end); comparison.setopeninbackground(false); comparison.execute(); \/\/ } } }","repo":"UCLA-SEAL\/Grafter"}
{"id":25018,"comment_id":0,"comment":"\/\/ may happen only due to internal programming error","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery;","code_context_10":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) {","code_context_20":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath());","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":1,"comment":"\/\/ the query is a contradiction, there are no matches","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); }","code_context_10":"} if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null;","code_context_20":"throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false;","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":2,"comment":"\/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all","code_context_10":"if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) {","code_context_20":"if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i);","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":3,"comment":"\/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); }","code_context_10":"} } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p);","code_context_20":"propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":4,"comment":"\/\/ deduplicate sort fields","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) {","code_context_10":"if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } }","code_context_20":"boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":5,"comment":"\/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored.","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"DESIGN","isFinished":true,"code_context_2":"sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause);","code_context_10":"string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) {","code_context_20":"idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":6,"comment":"\/\/ identity comparison is intended here!","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) {","code_context_10":"} } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length];","code_context_20":"if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes);","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":7,"comment":"\/\/ all involved fields are indexed, so go the lucene way","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) {","code_context_10":"} } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0;","code_context_20":"\/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> {","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":8,"comment":"\/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) {","code_context_10":"} \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i];","code_context_20":"propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":9,"comment":"\/\/ but some projections are duplicated ...","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length];","code_context_10":"booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++;","code_context_20":"if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":10,"comment":"\/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1);","code_context_10":"} } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); }","code_context_20":"for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":11,"comment":"\/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); }","code_context_10":"} } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","code_context_20":"} else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","repo":"TomasHofman\/infinispan"}
{"id":25018,"comment_id":12,"comment":"\/\/ some fields are indexed, run a hybrid query","code":"private basequery buildquerynoaggregations(queryfactory queryfactory, string querystring, map<string, object> namedparameters, long startoffset, int maxresults, ickleparsingresult<typemetadata> parsingresult) { if (parsingresult.hasgroupingoraggregations()) { throw log.querymustnotusegroupingoraggregation(); \/\/ may happen only due to internal programming error } boolean isfulltextquery; if (parsingresult.getwhereclause() != null) { isfulltextquery = parsingresult.getwhereclause().acceptvisitor(fulltextvisitor.instance); if (!isindexed && isfulltextquery) { throw new illegalstateexception(\"the cache must be indexed in order to use full-text queries.\"); } } if (parsingresult.getsortfields() != null) { for (sortfield sortfield : parsingresult.getsortfields()) { propertypath<?> p = sortfield.getpath(); if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeusedinorderby(p.tostring()); } } } if (parsingresult.getprojectedpaths() != null) { for (propertypath<?> p : parsingresult.getprojectedpaths()) { if (propertyhelper.isrepeatedproperty(parsingresult.gettargetentitymetadata(), p.asarraypath())) { throw log.multivaluedpropertycannotbeprojected(p.asstringpath()); } } } booleanexpr normalizedwhereclause = booleanfilternormalizer.normalize(parsingresult.getwhereclause()); if (normalizedwhereclause == constantbooleanexpr.false) { \/\/ the query is a contradiction, there are no matches return new emptyresultquery(queryfactory, cache, querystring, namedparameters, startoffset, maxresults); } \/\/ if cache is indexed but there is no actual 'where' filter clause and we do have sorting or projections we should still use the index, otherwise just go for a non-indexed fetch-all if (!isindexed || (normalizedwhereclause == null || normalizedwhereclause == constantbooleanexpr.true) && parsingresult.getprojections() == null && parsingresult.getsortfields() == null) { \/\/ fully non-indexed execution because the filter matches everything or there is no indexing at all return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } indexedfieldprovider.fieldindexingmetadata fieldindexingmetadata = propertyhelper.getindexedfieldprovider().get(parsingresult.gettargetentitymetadata()); boolean allprojectionsarestored = true; linkedhashmap<propertypath, list<integer>> projectionsmap = null; if (parsingresult.getprojectedpaths() != null) { projectionsmap = new linkedhashmap<>(); for (int i = 0; i < parsingresult.getprojectedpaths().length; i++) { propertypath<?> p = parsingresult.getprojectedpaths()[i]; list<integer> idx = projectionsmap.get(p); if (idx == null) { idx = new arraylist<>(); projectionsmap.put(p, idx); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allprojectionsarestored = false; } } idx.add(i); } } boolean allsortfieldsarestored = true; sortfield[] sortfields = parsingresult.getsortfields(); if (sortfields != null) { \/\/ deduplicate sort fields linkedhashmap<string, sortfield> sortfieldmap = new linkedhashmap<>(); for (sortfield sf : sortfields) { propertypath<?> p = sf.getpath(); string asstringpath = p.asstringpath(); if (!sortfieldmap.containskey(asstringpath)) { sortfieldmap.put(asstringpath, sf); if (!fieldindexingmetadata.isstored(p.asarraypath())) { allsortfieldsarestored = false; } } } sortfields = sortfieldmap.values().toarray(new sortfield[sortfieldmap.size()]); } \/\/todo [anistor] do not allow hybrid queries with fulltext. exception, allow a fully indexed query followed by in-memory aggregation. the aggregated or 'having' field should not be analyzed \/\/todo [anistor] do we allow aggregation in fulltext queries? \/\/todo [anistor] do not allow hybrid fulltext queries. all 'where' fields must be indexed. all projections must be stored. booleshannonexpansion bse = new booleshannonexpansion(max_expansion_cofactors, fieldindexingmetadata); booleanexpr expansion = bse.expand(normalizedwhereclause); if (expansion == normalizedwhereclause) { \/\/ identity comparison is intended here! \/\/ all involved fields are indexed, so go the lucene way if (allsortfieldsarestored) { if (allprojectionsarestored) { \/\/ all projections are stored, so we can execute the query entirely against the index, and we can also sort using the index rowprocessor rowprocessor = null; if (parsingresult.getprojectedpaths() != null) { if (projectionsmap.size() != parsingresult.getprojectedpaths().length) { \/\/ but some projections are duplicated ... final class<?>[] projectedtypes = new class<?>[projectionsmap.size()]; final int[] map = new int[parsingresult.getprojectedpaths().length]; int j = 0; for (list<integer> idx : projectionsmap.values()) { int i = idx.get(0); projectedtypes[j] = parsingresult.getprojectedtypes()[i]; for (int k : idx) { map[k] = j; } j++; } rowprocessor projectionprocessor = makeprojectionprocessor(projectedtypes); rowprocessor = inrow -> { if (projectionprocessor != null) { inrow = projectionprocessor.process(inrow); } object[] outrow = new object[map.length]; for (int i = 0; i < map.length; i++) { outrow[i] = inrow[map[i]]; } return outrow; }; propertypath[] deduplicatedprojection = projectionsmap.keyset().toarray(new propertypath[projectionsmap.size()]); ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, deduplicatedprojection, projectedtypes, sortfields); return new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { rowprocessor = makeprojectionprocessor(parsingresult.getprojectedtypes()); } } return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","classification":"NONSATD","isFinished":true,"code_context_2":"return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1);","code_context_10":"ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","code_context_20":"} return new embeddedlucenequery<>(this, queryfactory, namedparameters, parsingresult, parsingresult.getprojections(), makeresultprocessor(rowprocessor), startoffset, maxresults); } else { ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, sortfields); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), startoffset, maxresults); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, null); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), -1, -1, indexquery); } } else { \/\/ projections may be stored but some sort fields are not so we need to query the index and then execute in-memory sorting and projecting in a second phase ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, normalizedwhereclause, null, null, null); query indexquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); string projectionquerystr = syntaxtreeprinter.printtree(parsingresult.gettargetentityname(), parsingresult.getprojectedpaths(), null, sortfields); return new hybridquery(queryfactory, cache, projectionquerystr, null, getobjectfilter(matcher, projectionquerystr, null, null), startoffset, maxresults, indexquery); } } if (expansion == constantbooleanexpr.true) { \/\/ expansion leads to a full non-indexed query or the expansion is too long\/complex return new embeddedquery(this, queryfactory, cache, querystring, namedparameters, parsingresult.getprojections(), startoffset, maxresults); } \/\/ some fields are indexed, run a hybrid query ickleparsingresult<typemetadata> fpr = makefilterparsingresult(parsingresult, expansion, null, null, null); query expandedquery = new embeddedlucenequery<>(this, queryfactory, namedparameters, fpr, null, makeresultprocessor(null), -1, -1); return new hybridquery(queryfactory, cache, querystring, namedparameters, getobjectfilter(matcher, querystring, namedparameters, null), startoffset, maxresults, expandedquery); }","repo":"TomasHofman\/infinispan"}
{"id":448,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(char[][], char)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(char[][], char)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static char[][] fill(char contents, int width, int height) { char[][] next = new char[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static char[][] fill(char contents, int width, int height) { char[][] next = new char[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_10":"public static char[][] fill(char contents, int width, int height) { char[][] next = new char[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_20":"public static char[][] fill(char contents, int width, int height) { char[][] next = new char[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","repo":"SquidPony\/SquidLib"}
{"id":449,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(float[][], float)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(float[][], float)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static float[][] fill(float contents, int width, int height) { float[][] next = new float[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static float[][] fill(float contents, int width, int height) { float[][] next = new float[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_10":"public static float[][] fill(float contents, int width, int height) { float[][] next = new float[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_20":"public static float[][] fill(float contents, int width, int height) { float[][] next = new float[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","repo":"SquidPony\/SquidLib"}
{"id":450,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(double[][], double)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(double[][], double)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static double[][] fill(double contents, int width, int height) { double[][] next = new double[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static double[][] fill(double contents, int width, int height) { double[][] next = new double[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_10":"public static double[][] fill(double contents, int width, int height) { double[][] next = new double[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_20":"public static double[][] fill(double contents, int width, int height) { double[][] next = new double[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","repo":"SquidPony\/SquidLib"}
{"id":451,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(int[][], int)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(int[][], int)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static int[][] fill(int contents, int width, int height) { int[][] next = new int[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static int[][] fill(int contents, int width, int height) { int[][] next = new int[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_10":"public static int[][] fill(int contents, int width, int height) { int[][] next = new int[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_20":"public static int[][] fill(int contents, int width, int height) { int[][] next = new int[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","repo":"SquidPony\/SquidLib"}
{"id":452,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(byte[][], byte)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(byte[][], byte)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static byte[][] fill(byte contents, int width, int height) { byte[][] next = new byte[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static byte[][] fill(byte contents, int width, int height) { byte[][] next = new byte[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_10":"public static byte[][] fill(byte contents, int width, int height) { byte[][] next = new byte[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","code_context_20":"public static byte[][] fill(byte contents, int width, int height) { byte[][] next = new byte[width][height]; for (int x = 0; x < width; x++) { arrays.fill(next[x], contents); } return next; }","repo":"SquidPony\/SquidLib"}
{"id":453,"comment_id":0,"comment":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(boolean[][], boolean)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/","code":"\/** * creates a 2d array of the given width and height, filled with entirely with the value contents. * you may want to use {@link #fill(boolean[][], boolean)} to modify an existing 2d array instead. * @param contents the value to fill the array with * @param width the desired width * @param height the desired height * @return a freshly allocated 2d array of the requested dimensions, filled entirely with contents *\/ public static boolean[][] fill(boolean contents, int width, int height) { boolean[][] next = new boolean[width][height]; if (contents) { for (int x = 0; x < width; x++) { arrays.fill(next[x], true); } } return next; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static boolean[][] fill(boolean contents, int width, int height) { boolean[][] next = new boolean[width][height]; if (contents) { for (int x = 0; x < width; x++) { arrays.fill(next[x], true); } } return next; }","code_context_10":"public static boolean[][] fill(boolean contents, int width, int height) { boolean[][] next = new boolean[width][height]; if (contents) { for (int x = 0; x < width; x++) { arrays.fill(next[x], true); } } return next; }","code_context_20":"public static boolean[][] fill(boolean contents, int width, int height) { boolean[][] next = new boolean[width][height]; if (contents) { for (int x = 0; x < width; x++) { arrays.fill(next[x], true); } } return next; }","repo":"SquidPony\/SquidLib"}
{"id":16885,"comment_id":0,"comment":"\/** getter * todo: write general description for this method *\/","code":"\/** getter * todo: write general description for this method *\/ @jsongetter(\"limit\") public string getlimit ( ) { return this.limit; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsongetter(\"limit\") public string getlimit ( ) { return this.limit; }","code_context_10":"@jsongetter(\"limit\") public string getlimit ( ) { return this.limit; }","code_context_20":"@jsongetter(\"limit\") public string getlimit ( ) { return this.limit; }","repo":"adams-okode\/chirpstack-rest-sdk"}
{"id":25078,"comment_id":0,"comment":"\/\/ import the image data into 1d arrays : to do","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata());","code_context_10":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2];","code_context_20":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d();","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":1,"comment":"\/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) {","code_context_10":"buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null;","code_context_20":"int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z;","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":2,"comment":"\/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) {","code_context_10":"int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel?","code_context_20":"intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z;","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":3,"comment":"\/\/ 2. build and invert the glm for each profile \/ voxel?","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz);","code_context_10":"\/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z;","code_context_20":"ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx);","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":4,"comment":"\/\/ get the next non-zero value","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location","code_context_10":"for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm);","code_context_20":"} \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } }","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":5,"comment":"\/\/ build a weighting function based on distance to the original location","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) {","code_context_10":"if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp);","code_context_20":"float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname();","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":6,"comment":"\/\/ invert the linear model","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data);","code_context_10":"for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } }","code_context_20":"float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual);","repo":"alaurent4\/nighres"}
{"id":25078,"comment_id":7,"comment":"\/\/ output","code":"@override protected void execute(calculationmonitor monitor){ \/\/ import the image data into 1d arrays : to do imagedatafloat layersimg = new imagedatafloat(layersimage.getimagedata()); imagedatafloat intensimg = new imagedatafloat(intensityimage.getimagedata()); int nx = layersimg.getrows(); int ny = layersimg.getcols(); int nz = layersimg.getslices(); int nlayers = layersimg.getcomponents()-1; int nxyz = nx*ny*nz; float rx = layersimg.getheader().getdimresolutions()[0]; float ry = layersimg.getheader().getdimresolutions()[1]; float rz = layersimg.getheader().getdimresolutions()[2]; float[][] layers = new float[nlayers+1][nxyz]; float[][][][] buffer4 = layersimg.toarray4d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) for (int l=0;l<=nlayers;l++) { int xyz = x+nx*y+nx*ny*z; layers[l][xyz] = buffer4[x][y][z][l]; } buffer4 = null; layersimg = null; float[] intensity = new float[nxyz]; float[][][] buffer3 = intensimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; intensity[xyz] = buffer3[x][y][z]; } buffer3 = null; intensimg = null; \/\/ create a mask for all the regions outside of the area where layer 1 is > 0 and layer 2 is < 0 boolean[] ctxmask = new boolean[nxyz]; if (maskimage.getimagedata()!=null) { imagedataubyte maskimg = new imagedataubyte(maskimage.getimagedata()); byte[][][] bufferbyte = maskimg.toarray3d(); for (int x=0;x<nx;x++) for (int y=0;y<ny;y++) for (int z=0;z<nz;z++) { int xyz = x+nx*y+nx*ny*z; ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0 && bufferbyte[x][y][z]>0); } bufferbyte = null; maskimg = null; } else { for (int xyz=0;xyz<nxyz;xyz++) { ctxmask[xyz] = (layers[0][xyz]>=0.0 && layers[nlayers][xyz]<=0.0); } } \/\/ main algorithm \/\/ 1. define partial voume for each layer, each voxel float[][] pvol = new float[nlayers+1][nxyz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { for (int l=0;l<=nlayers;l++) { pvol[l][xyz] = partialvolumefromsurface(x, y, z, layers[l], nx, ny, nz); } } } \/\/ 2. build and invert the glm for each profile \/ voxel? float delta = paramextent.getvalue().floatvalue()\/numerics.min(rx,ry,rz); float stdev = paramstdev.getvalue().floatvalue()\/numerics.min(rx,ry,rz); corticalprofile profile = new corticalprofile(nlayers, nx, ny, nz, rx, ry, rz); float maskval = 1e13f; float[][][][] mapping = new float[nx][ny][nz][nlayers]; float[][][] residual = new float[nx][ny][nz]; bitset sampled = new bitset(nx*ny*nz); float[] profiledist = new float[nx*ny*nz]; for (int x=0; x<nx; x++) for (int y=0; y<ny; y++) for (int z = 0; z<nz; z++) { int xyz = x + nx*y + nx*ny*z; if (ctxmask[xyz]) { findfastmarchingprofileneighborhood(sampled, profiledist, x,y,z, delta, layers, profile, ctxmask, nx, ny, nz, nlayers); int nsample = sampled.size(); if (nsample>=nlayers) { double[][] glm = new double[nlayers][nsample]; double[][] data = new double[nsample][1]; int idx = 0; for (int n=0;n<nsample;n++) { \/\/ get the next non-zero value idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping);","code_context_10":"matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\");","code_context_20":"idx = sampled.nextsetbit(idx); \/\/ build a weighting function based on distance to the original location double weight = fastmath.exp(-0.5*numerics.square(profiledist[idx]\/stdev)); for (int l=0;l<nlayers;l++) { glm[l][n] = weight*(pvol[l+1][idx]-pvol[l][idx]); } data[n][0] = weight*intensity[idx]; } \/\/ invert the linear model matrix mtx = new matrix(glm); matrix smp = new matrix(data); matrix val = mtx.solve(smp); for (int l=0;l<nlayers;l++) { mapping[x][y][z][l] = (float)val.get(l,0); } matrix res = mtx.times(val).minus(smp); residual[x][y][z] = (float)res.norminf(); } } } \/\/ output string imgname = intensityimage.getimagedata().getname(); imagedatafloat mapdata = new imagedatafloat(mapping); mapdata.setheader(layersimage.getimagedata().getheader()); mapdata.setname(imgname+\"_glmprofiles\"); mappedimage.setvalue(mapdata); mapdata = null; mapping = null; imagedatafloat resdata = new imagedatafloat(residual); resdata.setheader(layersimage.getimagedata().getheader()); resdata.setname(imgname+\"_glmresidual\"); residualimage.setvalue(resdata); resdata = null; residual = null; }","repo":"alaurent4\/nighres"}
{"id":16886,"comment_id":0,"comment":"\/** setter * todo: write general description for this method *\/","code":"\/** setter * todo: write general description for this method *\/ @jsonsetter(\"limit\") public void setlimit (string value) { this.limit = value; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsonsetter(\"limit\") public void setlimit (string value) { this.limit = value; }","code_context_10":"@jsonsetter(\"limit\") public void setlimit (string value) { this.limit = value; }","code_context_20":"@jsonsetter(\"limit\") public void setlimit (string value) { this.limit = value; }","repo":"adams-okode\/chirpstack-rest-sdk"}
{"id":16887,"comment_id":0,"comment":"\/** getter * todo: write general description for this method *\/","code":"\/** getter * todo: write general description for this method *\/ @jsongetter(\"offset\") public string getoffset ( ) { return this.offset; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsongetter(\"offset\") public string getoffset ( ) { return this.offset; }","code_context_10":"@jsongetter(\"offset\") public string getoffset ( ) { return this.offset; }","code_context_20":"@jsongetter(\"offset\") public string getoffset ( ) { return this.offset; }","repo":"adams-okode\/chirpstack-rest-sdk"}
{"id":16888,"comment_id":0,"comment":"\/** setter * todo: write general description for this method *\/","code":"\/** setter * todo: write general description for this method *\/ @jsonsetter(\"offset\") public void setoffset (string value) { this.offset = value; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsonsetter(\"offset\") public void setoffset (string value) { this.offset = value; }","code_context_10":"@jsonsetter(\"offset\") public void setoffset (string value) { this.offset = value; }","code_context_20":"@jsonsetter(\"offset\") public void setoffset (string value) { this.offset = value; }","repo":"adams-okode\/chirpstack-rest-sdk"}
{"id":25180,"comment_id":0,"comment":"\/** * static helper method that can be used instead of instantiating comparator * (used by unit tests, can be used by code too) *\/","code":"\/** * static helper method that can be used instead of instantiating comparator * (used by unit tests, can be used by code too) *\/ public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","code_context_10":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","code_context_20":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","repo":"andrebrait\/java-uuid-generator"}
{"id":25180,"comment_id":1,"comment":"\/\/ first: major sorting by types","code":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","classification":"NONSATD","isFinished":true,"code_context_2":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version();","code_context_10":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically","code_context_20":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); }","repo":"andrebrait\/java-uuid-generator"}
{"id":25180,"comment_id":2,"comment":"\/\/ second: for time-based variant, order by time stamp:","code":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","classification":"NONSATD","isFinished":true,"code_context_2":"return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp());","code_context_10":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits());","code_context_20":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","repo":"andrebrait\/java-uuid-generator"}
{"id":25180,"comment_id":3,"comment":"\/\/ or if that won't work, by other bits lexically","code":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","classification":"NONSATD","isFinished":true,"code_context_2":"diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); }","code_context_10":"\/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); }","code_context_20":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","repo":"andrebrait\/java-uuid-generator"}
{"id":25180,"comment_id":4,"comment":"\/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so:","code":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits());","code_context_10":"return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","code_context_20":"public static int staticcompare(uuid u1, uuid u2) { \/\/ first: major sorting by types int type = u1.version(); int diff = type - u2.version(); if (diff != 0) { return diff; } \/\/ second: for time-based variant, order by time stamp: if (type == uuidtype.time_based.raw()) { diff = compareulongs(u1.timestamp(), u2.timestamp()); if (diff == 0) { \/\/ or if that won't work, by other bits lexically diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } else { \/\/ note: java.util.uuids compares with sign extension, imo that's wrong, so: diff = compareulongs(u1.getmostsignificantbits(), u2.getmostsignificantbits()); if (diff == 0) { diff = compareulongs(u1.getleastsignificantbits(), u2.getleastsignificantbits()); } } return diff; }","repo":"andrebrait\/java-uuid-generator"}
{"id":653,"comment_id":0,"comment":"\/\/ todo: don't count entering the first five-way","code":"public playerpathdata populatestats() { this.playerentity = strongholdpath.getplayerentity(); strongholdgenerator.start start = this.strongholdpath.getstart(); strongholdtreeaccessor treeaccessor = (strongholdtreeaccessor) start; list<strongholdpathentry> history = this.strongholdpath.gethistory(); arraylist<structurepiece> solution = new arraylist<>(); strongholdgenerator.piece current = this.strongholdpath.gethistory().get(strongholdpath.gethistory().size() - 1).getcurrentpiece(); while (current != null) { solution.add(current); current = (strongholdgenerator.piece) treeaccessor.getparents().get(current); } list<strongholdpathentry> validentries = history.stream() .filter(entry -> validateentryforloss(strongholdpath, strongholdpath.getnextentry(entry))) .filter(entry -> !solution.contains(strongholdpath.getnextentry(entry).getcurrentpiece()) && solution.contains(entry.getcurrentpiece())) .collect(collectors.tolist()); list<pair<strongholdpathentry, double>> losses = new arraylist<>(); validentries.foreach(strongholdpathentry -> losses.add(new pair<>(strongholdpathentry, loss(strongholdpath, strongholdpath.getnextentry(strongholdpathentry), solution)))); this.inaccuracies = losses.stream().filter(pair -> pair.getright() >= inaccuracy_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); this.mistakes = losses.stream().filter(pair -> pair.getright() >= mistake_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); this.blunders = losses.stream().filter(pair -> pair.getright() >= blunder_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); inaccuracies.removeall(this.mistakes); mistakes.removeall(this.blunders); arraylist<pair<strongholdgenerator.piece, integer>> rooms = new arraylist<>(); history.foreach(pathentry -> { pair<strongholdgenerator.piece, integer> pair = new pair<>(pathentry.getcurrentpiece(), pathentry.getticksspentinpiece().get()); rooms.add(pair); }); return new playerpathdata( rooms, strongholdpath.gettotaltime(), computedifficulty(solution), history.stream() .filter(pathentry -> !solution.contains(pathentry.getcurrentpiece())) .map(strongholdpathentry::getticksspentinpiece) .maptoint(atomicinteger::get) .sum(), \/\/ todo: don't count entering the first five-way (int) history.stream() .map(strongholdpathentry -> strongholdpath.getnextentry(strongholdpathentry)) .filter(objects::nonnull) .map(strongholdpathentry::getcurrentpiece) .filter(solution::contains) .count(), this.inaccuracies.size(), this.mistakes.size(), this.blunders.size(), (int) history.stream() .filter(entry -> !(entry.getcurrentpiece() instanceof strongholdgenerator.portalroom)) .filter(entry -> !areadjacent(entry.getcurrentpiece(), strongholdpath.getnextentry(entry).getcurrentpiece(), treeaccessor)) .count(), history.size() - 1, history.stream() .filter(entry -> feinberg_avg_room_times.containskey(entry.getcurrentpiece().getclass())) .maptoint(value -> value.getticksspentinpiece().get() - feinberg_avg_room_times.get(value.getcurrentpiece().getclass())) .sum() ); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":".maptoint(atomicinteger::get) .sum(), \/\/ todo: don't count entering the first five-way (int) history.stream() .map(strongholdpathentry -> strongholdpath.getnextentry(strongholdpathentry))","code_context_10":"}); return new playerpathdata( rooms, strongholdpath.gettotaltime(), computedifficulty(solution), history.stream() .filter(pathentry -> !solution.contains(pathentry.getcurrentpiece())) .map(strongholdpathentry::getticksspentinpiece) .maptoint(atomicinteger::get) .sum(), \/\/ todo: don't count entering the first five-way (int) history.stream() .map(strongholdpathentry -> strongholdpath.getnextentry(strongholdpathentry)) .filter(objects::nonnull) .map(strongholdpathentry::getcurrentpiece) .filter(solution::contains) .count(), this.inaccuracies.size(), this.mistakes.size(), this.blunders.size(), (int) history.stream()","code_context_20":"validentries.foreach(strongholdpathentry -> losses.add(new pair<>(strongholdpathentry, loss(strongholdpath, strongholdpath.getnextentry(strongholdpathentry), solution)))); this.inaccuracies = losses.stream().filter(pair -> pair.getright() >= inaccuracy_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); this.mistakes = losses.stream().filter(pair -> pair.getright() >= mistake_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); this.blunders = losses.stream().filter(pair -> pair.getright() >= blunder_threshold).map(pair::getleft).map(strongholdpathentry::getcurrentpiece).collect(collectors.tolist()); inaccuracies.removeall(this.mistakes); mistakes.removeall(this.blunders); arraylist<pair<strongholdgenerator.piece, integer>> rooms = new arraylist<>(); history.foreach(pathentry -> { pair<strongholdgenerator.piece, integer> pair = new pair<>(pathentry.getcurrentpiece(), pathentry.getticksspentinpiece().get()); rooms.add(pair); }); return new playerpathdata( rooms, strongholdpath.gettotaltime(), computedifficulty(solution), history.stream() .filter(pathentry -> !solution.contains(pathentry.getcurrentpiece())) .map(strongholdpathentry::getticksspentinpiece) .maptoint(atomicinteger::get) .sum(), \/\/ todo: don't count entering the first five-way (int) history.stream() .map(strongholdpathentry -> strongholdpath.getnextentry(strongholdpathentry)) .filter(objects::nonnull) .map(strongholdpathentry::getcurrentpiece) .filter(solution::contains) .count(), this.inaccuracies.size(), this.mistakes.size(), this.blunders.size(), (int) history.stream() .filter(entry -> !(entry.getcurrentpiece() instanceof strongholdgenerator.portalroom)) .filter(entry -> !areadjacent(entry.getcurrentpiece(), strongholdpath.getnextentry(entry).getcurrentpiece(), treeaccessor)) .count(), history.size() - 1, history.stream() .filter(entry -> feinberg_avg_room_times.containskey(entry.getcurrentpiece().getclass())) .maptoint(value -> value.getticksspentinpiece().get() - feinberg_avg_room_times.get(value.getcurrentpiece().getclass())) .sum() ); }","repo":"ScribbleLP\/StrongholdTrainer"}
{"id":17055,"comment_id":0,"comment":"\/** * send an email to given email address * @param userid1 * @param userid2 * @param asgmtname * @param score * @param recipientmail * @param reportlink * @throws exception *\/","code":"\/** * send an email to given email address * @param userid1 * @param userid2 * @param asgmtname * @param score * @param recipientmail * @param reportlink * @throws exception *\/ public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","code_context_10":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","code_context_20":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","repo":"Stephen3333\/codesniffer"}
{"id":17055,"comment_id":1,"comment":"\/\/ to do add link in email","code":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"+ \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message);","code_context_10":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","code_context_20":"public void sendemail(string userid1, string userid2, string asgmtname, double score, string recipientmail, string reportlink) throws exception { mimemessage message = sender.createmimemessage(); mimemessagehelper helper = new mimemessagehelper(message); string stud1 = userservice.findbyid(userid1).getfname(); string stud2 = userservice.findbyid(userid2).getfname(); helper.setto(\"anubhuti.vyas.28@gmail.com\"); helper.settext(\"codesniffer found plagiarised submission with similarity score\" + score + \"click the below link to view the full report+\\n\" + \"https:\/\/s3.amazonaws.com\/codesniffer-reports\/\" + reportlink+ \"\/match0.html\"); \/\/ to do add link in email helper.setsubject(\"plag detected in \" + asgmtname + \" between \" + stud1 + \" and \" + stud2); sender.send(message); }","repo":"Stephen3333\/codesniffer"}
{"id":17081,"comment_id":0,"comment":"\/\/ todo: do we need to call logout() on the logincontext?","code":"@override public void refresh() throws loginexception, gssexception { \/\/ todo: do we need to call logout() on the logincontext? logincontext = new logincontext(\"\", null, null, new configuration() { @override public appconfigurationentry[] getappconfigurationentry(string name) { immutablemap.builder<string, string> options = immutablemap.builder(); options.put(\"refreshkrb5config\", \"true\"); options.put(\"donotprompt\", \"true\"); options.put(\"usekeytab\", \"true\"); if (getboolean(\"trino.client.debugkerberos\")) { options.put(\"debug\", \"true\"); } keytab.ifpresent(file -> options.put(\"keytab\", file.getabsolutepath())); credentialcache.ifpresent(file -> { options.put(\"ticketcache\", file.getabsolutepath()); options.put(\"renewtgt\", \"true\"); }); if (!keytab.ispresent() || credentialcache.ispresent()) { options.put(\"useticketcache\", \"true\"); } principal.ifpresent(value -> options.put(\"principal\", value)); return new appconfigurationentry[] { new appconfigurationentry(krb5loginmodule.class.getname(), required, options.buildorthrow()) }; } }); logincontext.login(); }","classification":"DESIGN","isFinished":true,"code_context_2":"throws loginexception, gssexception { \/\/ todo: do we need to call logout() on the logincontext? logincontext = new logincontext(\"\", null, null, new configuration() {","code_context_10":"@override public void refresh() throws loginexception, gssexception { \/\/ todo: do we need to call logout() on the logincontext? logincontext = new logincontext(\"\", null, null, new configuration() { @override public appconfigurationentry[] getappconfigurationentry(string name) { immutablemap.builder<string, string> options = immutablemap.builder(); options.put(\"refreshkrb5config\", \"true\"); options.put(\"donotprompt\", \"true\"); options.put(\"usekeytab\", \"true\"); if (getboolean(\"trino.client.debugkerberos\")) {","code_context_20":"@override public void refresh() throws loginexception, gssexception { \/\/ todo: do we need to call logout() on the logincontext? logincontext = new logincontext(\"\", null, null, new configuration() { @override public appconfigurationentry[] getappconfigurationentry(string name) { immutablemap.builder<string, string> options = immutablemap.builder(); options.put(\"refreshkrb5config\", \"true\"); options.put(\"donotprompt\", \"true\"); options.put(\"usekeytab\", \"true\"); if (getboolean(\"trino.client.debugkerberos\")) { options.put(\"debug\", \"true\"); } keytab.ifpresent(file -> options.put(\"keytab\", file.getabsolutepath())); credentialcache.ifpresent(file -> { options.put(\"ticketcache\", file.getabsolutepath()); options.put(\"renewtgt\", \"true\"); }); if (!keytab.ispresent() || credentialcache.ispresent()) { options.put(\"useticketcache\", \"true\"); }","repo":"SanjayTechGuru\/TRINO"}
{"id":17089,"comment_id":0,"comment":"\/\/ we only expect two values, a def and a reference, but there might be more.","code":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","classification":"DESIGN","isFinished":true,"code_context_2":"int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) {","code_context_10":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen","code_context_20":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); }","repo":"YCjia\/kudu"}
{"id":17089,"comment_id":1,"comment":"\/\/ todo check for more than one def, should not happen","code":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null;","code_context_10":"\/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); }","code_context_20":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else {","repo":"YCjia\/kudu"}
{"id":17089,"comment_id":2,"comment":"\/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes.","code":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","classification":"DESIGN","isFinished":true,"code_context_2":"} if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1);","code_context_10":"string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring()));","code_context_20":"if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","repo":"YCjia\/kudu"}
{"id":17089,"comment_id":3,"comment":"\/\/ node is defined but not referenced","code":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","classification":"NONSATD","isFinished":true,"code_context_2":"context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1);","code_context_10":"keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced","code_context_20":"refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","repo":"YCjia\/kudu"}
{"id":17089,"comment_id":4,"comment":"\/\/ node is defined and referenced","code":"@override public void reduce(byteswritable key, iterable<byteswritable> values, context context) throws ioexception, interruptedexception { int defcount = 0; refs.clear(); \/\/ we only expect two values, a def and a reference, but there might be more. for (byteswritable type : values) { if (type.getlength() == def.getlength()) { defcount++; } else { byte[] bytes = new byte[type.getlength()]; system.arraycopy(type.getbytes(), 0, bytes, 0, type.getlength()); refs.add(bytes); } } \/\/ todo check for more than one def, should not happen list<string> refslist = new arraylist<>(refs.size()); string keystring = null; if (defcount == 0 || refs.size() != 1) { for (byte[] ref : refs) { refslist.add(comma_joiner.join(bytes.getlong(ref), bytes.getlong(ref, 8))); } keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","classification":"NONSATD","isFinished":true,"code_context_2":"context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); }","code_context_10":"\/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","code_context_20":"keystring = comma_joiner.join(bytes.getlong(key.getbytes()), bytes.getlong(key.getbytes(), 8)); log.error(\"linked list error: key = \" + keystring + \" references = \" + refslist); } if (defcount == 0 && refs.size() > 0) { \/\/ this is bad, found a node that is referenced but not defined. it must have been \/\/ lost, emit some info about this node for debugging purposes. context.write(new text(keystring), new text(refslist.tostring())); context.getcounter(counts.undefined).increment(1); } else if (defcount > 0 && refs.size() == 0) { \/\/ node is defined but not referenced context.write(new text(keystring), new text(\"none\")); context.getcounter(counts.unreferenced).increment(1); } else { if (refs.size() > 1) { if (refslist != null) { context.write(new text(keystring), new text(refslist.tostring())); } context.getcounter(counts.extrareferences).increment(refs.size() - 1); } \/\/ node is defined and referenced context.getcounter(counts.referenced).increment(1); } }","repo":"YCjia\/kudu"}
{"id":748,"comment_id":0,"comment":"\/**method called from server when the 'api\/todos\/new'endpoint is recieved. * gets specified todo info from request and calls addnewtodo helper method * to append that info to a document * * @param req the http request * @param res the http response * @return a boolean as whether the todo was added successfully or not *\/","code":"\/**method called from server when the 'api\/todos\/new'endpoint is recieved. * gets specified todo info from request and calls addnewtodo helper method * to append that info to a document * * @param req the http request * @param res the http response * @return a boolean as whether the todo was added successfully or not *\/ public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) { ree.printstacktrace(); return false; } }","classification":"NONSATD","isFinished":true,"code_context_2":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) { ree.printstacktrace(); return false; } }","code_context_10":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) { ree.printstacktrace(); return false; } }","code_context_20":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) { ree.printstacktrace(); return false; } }","repo":"UMM-CSci-3601-S18\/lab-4-mongo-voyageurs-national-park"}
{"id":748,"comment_id":1,"comment":"\/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go","code":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) { ree.printstacktrace(); return false; } }","classification":"DEFECT","isFinished":true,"code_context_2":"basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\");","code_context_10":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false;","code_context_20":"public boolean addnewtodo(request req, response res) { res.type(\"application\/json\"); object o = json.parse(req.body()); try { if(o.getclass().equals(basicdbobject.class)) { try { basicdbobject dbo = (basicdbobject) o; string owner = dbo.getstring(\"owner\"); \/\/for some reason age is a string right now, caused by angular. \/\/this is a problem and should not be this way but here ya go boolean status = dbo.getboolean(\"status\"); string body = dbo.getstring(\"body\"); string category = dbo.getstring(\"category\"); system.err.println(\"adding new todo [owner=\" + owner + \", category=\" + category + \" body=\" + body + \" status=\" + status + ']'); return todocontroller.addnewtodo(owner, category, body, status); } catch(nullpointerexception e) { system.err.println(\"a value was malformed or omitted, new todo request failed.\"); return false; } } else { system.err.println(\"expected basicdbobject, received \" + o.getclass()); return false; } } catch(runtimeexception ree) {","repo":"UMM-CSci-3601-S18\/lab-4-mongo-voyageurs-national-park"}
{"id":25329,"comment_id":0,"comment":"\/\/ this isn't good, the jedis object is not thread safe","code":"public void shutdown() { try { logger.info(\"shutting down listener on \" + host + \":\" + port); running.set(false); \/\/ this isn't good, the jedis object is not thread safe jedis.disconnect(); } catch (exception e) { logger.error(\"caught exception while shutting down: \" + e.getmessage()); } }","classification":"DESIGN","isFinished":true,"code_context_2":"logger.info(\"shutting down listener on \" + host + \":\" + port); running.set(false); \/\/ this isn't good, the jedis object is not thread safe jedis.disconnect(); } catch (exception e) {","code_context_10":"public void shutdown() { try { logger.info(\"shutting down listener on \" + host + \":\" + port); running.set(false); \/\/ this isn't good, the jedis object is not thread safe jedis.disconnect(); } catch (exception e) { logger.error(\"caught exception while shutting down: \" + e.getmessage()); } }","code_context_20":"public void shutdown() { try { logger.info(\"shutting down listener on \" + host + \":\" + port); running.set(false); \/\/ this isn't good, the jedis object is not thread safe jedis.disconnect(); } catch (exception e) { logger.error(\"caught exception while shutting down: \" + e.getmessage()); } }","repo":"Samsung\/Spark-CEP"}
{"id":17260,"comment_id":0,"comment":"\/** * get the line number corresponding to the specified vertical position. * if you ask for a position above 0, you get 0; if you ask for a position * below the bottom of the text, you get the last line. *\/ \/\/ fixme: it may be faster to do a linear search for layouts without many lines.","code":"\/** * get the line number corresponding to the specified vertical position. * if you ask for a position above 0, you get 0; if you ask for a position * below the bottom of the text, you get the last line. *\/ \/\/ fixme: it may be faster to do a linear search for layouts without many lines. public int getlineforvertical(int vertical) { int high = getlinecount(), low = -1, guess; while (high - low > 1) { guess = (high + low) \/ 2; if (getlinetop(guess) > vertical) high = guess; else low = guess; } if (low < 0) return 0; else return low; }","classification":"DESIGN","isFinished":true,"code_context_2":"public int getlineforvertical(int vertical) { int high = getlinecount(), low = -1, guess; while (high - low > 1) { guess = (high + low) \/ 2; if (getlinetop(guess) > vertical) high = guess; else low = guess; } if (low < 0) return 0; else return low; }","code_context_10":"public int getlineforvertical(int vertical) { int high = getlinecount(), low = -1, guess; while (high - low > 1) { guess = (high + low) \/ 2; if (getlinetop(guess) > vertical) high = guess; else low = guess; } if (low < 0) return 0; else return low; }","code_context_20":"public int getlineforvertical(int vertical) { int high = getlinecount(), low = -1, guess; while (high - low > 1) { guess = (high + low) \/ 2; if (getlinetop(guess) > vertical) high = guess; else low = guess; } if (low < 0) return 0; else return low; }","repo":"VPeruS\/JotaTextEditor"}
{"id":9218,"comment_id":0,"comment":"\/\/ todo: the refactor","code":"@override public void visitelement(psielement element) { if (this.context.skip(element)) { return; } \/\/ todo: the refactor this.holder.registerproblem(element, this.context.getmessage()); }","classification":"DESIGN","isFinished":true,"code_context_2":"return; } \/\/ todo: the refactor this.holder.registerproblem(element, this.context.getmessage()); }","code_context_10":"@override public void visitelement(psielement element) { if (this.context.skip(element)) { return; } \/\/ todo: the refactor this.holder.registerproblem(element, this.context.getmessage()); }","code_context_20":"@override public void visitelement(psielement element) { if (this.context.skip(element)) { return; } \/\/ todo: the refactor this.holder.registerproblem(element, this.context.getmessage()); }","repo":"aarthibl\/intellibot"}
{"id":9220,"comment_id":0,"comment":"\/\/ todo: do these need to be hooked up for saving as well? currently they just load","code":"\/\/ todo: do these need to be hooked up for saving as well? currently they just load private static configurationoptions defaultoptions() { return configurationoptions.defaults() .serializers(spongecommon.game().configmanager().serializers()); }","classification":"DESIGN","isFinished":true,"code_context_2":"private static configurationoptions defaultoptions() { return configurationoptions.defaults() .serializers(spongecommon.game().configmanager().serializers()); }","code_context_10":"private static configurationoptions defaultoptions() { return configurationoptions.defaults() .serializers(spongecommon.game().configmanager().serializers()); }","code_context_20":"private static configurationoptions defaultoptions() { return configurationoptions.defaults() .serializers(spongecommon.game().configmanager().serializers()); }","repo":"SpongePowered\/Common"}
{"id":25606,"comment_id":0,"comment":"\/\/todo use .equals() once we ahve overridden appropriate methods","code":"@test public void testretrieveuserbyname() { em.gettransaction().begin(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (1, 'boom1', '1988-09-15', 'test user1');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (2, 'boom2', '1988-09-15', 'test user2');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (3, 'boom3', '1988-09-15', 'test user3');\").executeupdate(); em.gettransaction().commit(); list<user> users = null; try { \/\/todo use .equals() once we ahve overridden appropriate methods users = dao.getusers(); } catch (throwable th){ fail(th.getmessage()); } calendar cal = calendar.getinstance(); cal.set(1988, calendar.september, 15, 0, 0, 0); assertequals(3, users.size()); for (int i = 0; i < 3; i++) { assertequals(\"boom\" + users.get(i).getid(), users.get(i).getname()); assertequals(\"test user\" + users.get(i).getid(), users.get(i).getdescription()); assertequals(cal.gettime().tostring(), users.get(i).getdate().tostring()); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"list<user> users = null; try { \/\/todo use .equals() once we ahve overridden appropriate methods users = dao.getusers(); } catch (throwable th){","code_context_10":"em.gettransaction().begin(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (1, 'boom1', '1988-09-15', 'test user1');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (2, 'boom2', '1988-09-15', 'test user2');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (3, 'boom3', '1988-09-15', 'test user3');\").executeupdate(); em.gettransaction().commit(); list<user> users = null; try { \/\/todo use .equals() once we ahve overridden appropriate methods users = dao.getusers(); } catch (throwable th){ fail(th.getmessage()); } calendar cal = calendar.getinstance(); cal.set(1988, calendar.september, 15, 0, 0, 0); assertequals(3, users.size()); for (int i = 0; i < 3; i++) { assertequals(\"boom\" + users.get(i).getid(), users.get(i).getname()); assertequals(\"test user\" + users.get(i).getid(), users.get(i).getdescription());","code_context_20":"@test public void testretrieveuserbyname() { em.gettransaction().begin(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (1, 'boom1', '1988-09-15', 'test user1');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (2, 'boom2', '1988-09-15', 'test user2');\").executeupdate(); em.createnativequery(\"insert into t_users( user_id, name, date_added, description)\" + \" values (3, 'boom3', '1988-09-15', 'test user3');\").executeupdate(); em.gettransaction().commit(); list<user> users = null; try { \/\/todo use .equals() once we ahve overridden appropriate methods users = dao.getusers(); } catch (throwable th){ fail(th.getmessage()); } calendar cal = calendar.getinstance(); cal.set(1988, calendar.september, 15, 0, 0, 0); assertequals(3, users.size()); for (int i = 0; i < 3; i++) { assertequals(\"boom\" + users.get(i).getid(), users.get(i).getname()); assertequals(\"test user\" + users.get(i).getid(), users.get(i).getdescription()); assertequals(cal.gettime().tostring(), users.get(i).getdate().tostring()); } }","repo":"andrewflbarnes\/debt-tracker"}
{"id":1134,"comment_id":0,"comment":"\/** * restore the kv-state \/ columnfamily meta data for all key-groups referenced by the current state handle. * * @throws ioexception * @throws classnotfoundexception * @throws rocksdbexception *\/","code":"\/** * restore the kv-state \/ columnfamily meta data for all key-groups referenced by the current state handle. * * @throws ioexception * @throws classnotfoundexception * @throws rocksdbexception *\/ private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","code_context_10":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","code_context_20":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","repo":"alpinegizmo\/flink"}
{"id":1134,"comment_id":1,"comment":"\/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible","code":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(),","code_context_10":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); }","code_context_20":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) {","repo":"alpinegizmo\/flink"}
{"id":1134,"comment_id":2,"comment":"\/\/ todo replace with state migration; note that key hash codes need to remain the same after migration","code":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","classification":"DESIGN","isFinished":true,"code_context_2":"rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\");","code_context_10":"new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) {","code_context_20":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(),","repo":"alpinegizmo\/flink"}
{"id":1134,"comment_id":3,"comment":"\/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size());","code":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","classification":"NONSATD","isFinished":true,"code_context_2":"serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn =","code_context_10":".isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(),","code_context_20":"keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies }","repo":"alpinegizmo\/flink"}
{"id":1134,"comment_id":4,"comment":"\/\/ todo with eager state registration in place, check here for serializer migration strategies","code":"private void restorekvstatemetadata() throws ioexception, statemigrationexception, rocksdbexception { keyedbackendserializationproxy<k> serializationproxy = new keyedbackendserializationproxy<>(rocksdbkeyedstatebackend.usercodeclassloader); serializationproxy.read(currentstatehandleinview); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), rocksdbkeyedstatebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } this.keygroupstreamcompressiondecorator = serializationproxy.isusingkeygroupcompression() ? snappystreamcompressiondecorator.instance : uncompressedstreamcompressiondecorator.instance; list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> restoredmetainfos = serializationproxy.getstatemetainfosnapshots(); currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0);","code_context_10":"new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","code_context_20":"currentstatehandlekvstatecolumnfamilies = new arraylist<>(restoredmetainfos.size()); \/\/rocksdbkeyedstatebackend.restoredkvstatemetainfos = new hashmap<>(restoredmetainfos.size()); for (registeredkeyedbackendstatemetainfo.snapshot<?, ?> restoredmetainfo : restoredmetainfos) { tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>> registeredcolumn = rocksdbkeyedstatebackend.kvstateinformation.get(restoredmetainfo.getname()); if (registeredcolumn == null) { columnfamilydescriptor columnfamilydescriptor = new columnfamilydescriptor( restoredmetainfo.getname().getbytes(configconstants.default_charset), rocksdbkeyedstatebackend.columnoptions); registeredkeyedbackendstatemetainfo<?, ?> statemetainfo = new registeredkeyedbackendstatemetainfo<>( restoredmetainfo.getstatetype(), restoredmetainfo.getname(), restoredmetainfo.getnamespaceserializer(), restoredmetainfo.getstateserializer()); rocksdbkeyedstatebackend.restoredkvstatemetainfos.put(restoredmetainfo.getname(), restoredmetainfo); columnfamilyhandle columnfamily = rocksdbkeyedstatebackend.db.createcolumnfamily(columnfamilydescriptor); registeredcolumn = new tuple2<columnfamilyhandle, registeredkeyedbackendstatemetainfo<?, ?>>(columnfamily, statemetainfo); rocksdbkeyedstatebackend.kvstateinformation.put(statemetainfo.getname(), registeredcolumn); } else { \/\/ todo with eager state registration in place, check here for serializer migration strategies } currentstatehandlekvstatecolumnfamilies.add(registeredcolumn.f0); } }","repo":"alpinegizmo\/flink"}
{"id":1136,"comment_id":0,"comment":"\/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible","code":"private list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> readmetadata( streamstatehandle metastatehandle) throws exception { fsdatainputstream inputstream = null; try { inputstream = metastatehandle.openinputstream(); statebackend.cancelstreamregistry.registerclosable(inputstream); keyedbackendserializationproxy<t> serializationproxy = new keyedbackendserializationproxy<>(statebackend.usercodeclassloader); datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } return serializationproxy.getstatemetainfosnapshots(); } finally { if (inputstream != null) { statebackend.cancelstreamregistry.unregisterclosable(inputstream); inputstream.close(); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(),","code_context_10":"private list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> readmetadata( streamstatehandle metastatehandle) throws exception { fsdatainputstream inputstream = null; try { inputstream = metastatehandle.openinputstream(); statebackend.cancelstreamregistry.registerclosable(inputstream); keyedbackendserializationproxy<t> serializationproxy = new keyedbackendserializationproxy<>(statebackend.usercodeclassloader); datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); }","code_context_20":"private list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> readmetadata( streamstatehandle metastatehandle) throws exception { fsdatainputstream inputstream = null; try { inputstream = metastatehandle.openinputstream(); statebackend.cancelstreamregistry.registerclosable(inputstream); keyedbackendserializationproxy<t> serializationproxy = new keyedbackendserializationproxy<>(statebackend.usercodeclassloader); datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } return serializationproxy.getstatemetainfosnapshots(); } finally { if (inputstream != null) { statebackend.cancelstreamregistry.unregisterclosable(inputstream); inputstream.close(); } } }","repo":"alpinegizmo\/flink"}
{"id":1136,"comment_id":1,"comment":"\/\/ todo replace with state migration; note that key hash codes need to remain the same after migration","code":"private list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> readmetadata( streamstatehandle metastatehandle) throws exception { fsdatainputstream inputstream = null; try { inputstream = metastatehandle.openinputstream(); statebackend.cancelstreamregistry.registerclosable(inputstream); keyedbackendserializationproxy<t> serializationproxy = new keyedbackendserializationproxy<>(statebackend.usercodeclassloader); datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } return serializationproxy.getstatemetainfosnapshots(); } finally { if (inputstream != null) { statebackend.cancelstreamregistry.unregisterclosable(inputstream); inputstream.close(); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\");","code_context_10":"datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } return serializationproxy.getstatemetainfosnapshots(); } finally { if (inputstream != null) { statebackend.cancelstreamregistry.unregisterclosable(inputstream); inputstream.close(); } }","code_context_20":"private list<registeredkeyedbackendstatemetainfo.snapshot<?, ?>> readmetadata( streamstatehandle metastatehandle) throws exception { fsdatainputstream inputstream = null; try { inputstream = metastatehandle.openinputstream(); statebackend.cancelstreamregistry.registerclosable(inputstream); keyedbackendserializationproxy<t> serializationproxy = new keyedbackendserializationproxy<>(statebackend.usercodeclassloader); datainputview in = new datainputviewstreamwrapper(inputstream); serializationproxy.read(in); \/\/ check for key serializer compatibility; this also reconfigures the \/\/ key serializer to be compatible, if it is required and is possible if (compatibilityutil.resolvecompatibilityresult( serializationproxy.getkeyserializer(), unloadabledummytypeserializer.class, serializationproxy.getkeyserializerconfigsnapshot(), statebackend.keyserializer) .isrequiresmigration()) { \/\/ todo replace with state migration; note that key hash codes need to remain the same after migration throw new statemigrationexception(\"the new key serializer is not compatible to read previous keys. \" + \"aborting now since state migration is currently not available\"); } return serializationproxy.getstatemetainfosnapshots(); } finally { if (inputstream != null) { statebackend.cancelstreamregistry.unregisterclosable(inputstream); inputstream.close(); } } }","repo":"alpinegizmo\/flink"}
{"id":25762,"comment_id":0,"comment":"\/\/ 1. create connect context","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1","code_context_10":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx);","code_context_20":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl);","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":1,"comment":"\/\/ 2. create database db1","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx);","code_context_10":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work","code_context_20":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine());","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":2,"comment":"\/\/ 3. create table tbl1","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\";","code_context_10":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\");","code_context_20":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":3,"comment":"\/\/ must set replicas' path hash, or the tablet scheduler won't work","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table","code_context_10":"\/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine());","code_context_20":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2();","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":4,"comment":"\/\/ 4. get and test the created db and table","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db);","code_context_10":"createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally {","code_context_20":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) {","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":5,"comment":"\/\/ 5. process a schema change job","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx);","code_context_10":"olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000);","code_context_20":"\/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname());","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":6,"comment":"\/\/ 6. check alter job","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size());","code_context_10":"system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); }","code_context_20":"catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock();","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":7,"comment":"\/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"DESIGN","isFinished":true,"code_context_2":"tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr);","code_context_10":"tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode);","code_context_20":"assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","repo":"WilsonWangCS\/incubator-doris"}
{"id":25762,"comment_id":8,"comment":"\/\/ test show backends;","code":"@test public void testcreatedbandtable() throws exception { \/\/ 1. create connect context connectcontext ctx = utframeutils.createdefaultctx(); \/\/ 2. create database db1 string createdbstmtstr = \"create database db1;\"; createdbstmt createdbstmt = (createdbstmt) utframeutils.parseandanalyzestmt(createdbstmtstr, ctx); catalog.getcurrentcatalog().createdb(createdbstmt); system.out.println(catalog.getcurrentcatalog().getdbnames()); \/\/ 3. create table tbl1 string createtblstmtstr = \"create table db1.tbl1(k1 int) distributed by hash(k1) buckets 3 properties('replication_num' = '3',\" + \"'colocate_with' = 'g1');\"; createtablestmt createtablestmt = (createtablestmt) utframeutils.parseandanalyzestmt(createtblstmtstr, ctx); catalog.getcurrentcatalog().createtable(createtablestmt); \/\/ must set replicas' path hash, or the tablet scheduler won't work updatereplicapathhash(); \/\/ 4. get and test the created db and table database db = catalog.getcurrentcatalog().getdbnullable(\"default_cluster:db1\"); assert.assertnotnull(db); olaptable tbl = (olaptable) db.gettablenullable(\"tbl1\"); tbl.readlock(); try { assert.assertnotnull(tbl); system.out.println(tbl.getname()); assert.assertequals(\"doris\", tbl.getengine()); assert.assertequals(1, tbl.getbaseschema().size()); } finally { tbl.readunlock(); } \/\/ 5. process a schema change job string alterstmtstr = \"alter table db1.tbl1 add column k2 int default '1'\"; altertablestmt altertablestmt = (altertablestmt) utframeutils.parseandanalyzestmt(alterstmtstr, ctx); catalog.getcurrentcatalog().getalterinstance().processaltertable(altertablestmt); \/\/ 6. check alter job map<long, alterjobv2> alterjobs = catalog.getcurrentcatalog().getschemachangehandler().getalterjobsv2(); assert.assertequals(1, alterjobs.size()); for (alterjobv2 alterjobv2 : alterjobs.values()) { while (!alterjobv2.getjobstate().isfinalstate()) { system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is running. state: \" + alterjobv2.getjobstate()); thread.sleep(1000); } system.out.println(\"alter job \" + alterjobv2.getjobid() + \" is done. state: \" + alterjobv2.getjobstate()); assert.assertequals(alterjobv2.jobstate.finished, alterjobv2.getjobstate()); } olaptable tbl1 = (olaptable) db.gettablenullable(\"tbl1\"); tbl1.readlock(); try { assert.assertequals(2, tbl1.getbaseschema().size()); string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","classification":"NONSATD","isFinished":true,"code_context_2":"assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult();","code_context_10":"string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","code_context_20":"string baseindexname = tbl1.getindexnamebyid(tbl.getbaseindexid()); assert.assertequals(baseindexname, tbl1.getname()); materializedindexmeta indexmeta = tbl1.getindexmetabyindexid(tbl1.getbaseindexid()); assert.assertnotnull(indexmeta); } finally { tbl1.readunlock(); } \/\/ 7. query \/\/ todo: we can not process real query for now. so it has to be a explain query string querystr = \"explain select * from db1.tbl1\"; string a = utframeutils.getsqlplanorerrormsg(ctx, querystr); system.out.println(a); stmtexecutor stmtexecutor = new stmtexecutor(ctx, querystr); stmtexecutor.execute(); planner planner = stmtexecutor.planner(); list<planfragment> fragments = planner.getfragments(); assert.assertequals(2, fragments.size()); planfragment fragment = fragments.get(1); assert.asserttrue(fragment.getplanroot() instanceof olapscannode); assert.assertequals(0, fragment.getchildren().size()); \/\/ test show backends; backendsprocdir dir = new backendsprocdir(catalog.getcurrentsysteminfo()); procresult result = dir.fetchresult(); assert.assertequals(backendsprocdir.title_names.size(), result.getcolumnnames().size()); assert.assertequals(\"{\\\"location\\\" : \\\"default\\\"}\", result.getrows().get(0).get(19)); assert.assertequals(\"{\\\"lastsuccessreporttabletstime\\\":\\\"n\/a\\\",\\\"laststreamloadtime\\\":-1}\", result.getrows().get(0).get(backendsprocdir.title_names.size() - 1)); }","repo":"WilsonWangCS\/incubator-doris"}
{"id":17588,"comment_id":0,"comment":"\/** * add a line to the list of loaded feeds to record the snapshot and which feed the snapshot replicates. *\/","code":"\/** * add a line to the list of loaded feeds to record the snapshot and which feed the snapshot replicates. *\/ private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","code_context_10":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","code_context_20":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","repo":"Wilhansen\/gtfs-lib"}
{"id":17588,"comment_id":1,"comment":"\/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables?","code":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","classification":"DESIGN","isFinished":true,"code_context_2":"try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time?","code_context_10":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit();","code_context_20":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","repo":"Wilhansen\/gtfs-lib"}
{"id":17588,"comment_id":2,"comment":"\/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists.","code":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\");","code_context_10":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection);","code_context_20":"private void registersnapshot () { try { statement statement = connection.createstatement(); \/\/ todo copy over feed_id and feed_version from source namespace? \/\/ fixme do the following only on databases that support schemas. \/\/ sqlite does not support them. is there any advantage of schemas over flat tables? statement.execute(\"create schema \" + tableprefix); \/\/ todo: record total snapshot processing time? \/\/ simply insert into feeds table (no need for table creation) because making a snapshot presumes that the \/\/ feeds table already exists. preparedstatement insertstatement = connection.preparestatement( \"insert into feeds values (?, null, null, null, null, null, current_timestamp, ?)\"); insertstatement.setstring(1, tableprefix); insertstatement.setstring(2, feedidtosnapshot); insertstatement.execute(); connection.commit(); log.info(\"created new snapshot namespace: {}\", insertstatement); } catch (exception ex) { log.error(\"exception while registering snapshot namespace in feeds table: {}\", ex.getmessage()); dbutils.closequietly(connection); } }","repo":"Wilhansen\/gtfs-lib"}
{"id":9474,"comment_id":0,"comment":"\/\/ find proper device and raise event.","code":"@override protected void channelread0(channelhandlercontext ctx, coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel(); coapclient coapclient = (coapclient) reqchannel; coapclient.onresponsereceived(msg); } } catch (serverexception e) { ctx.writeandflush(messagebuilder.createresponse(msg, e.geterrorresponse())); log.f(ctx.channel(), e); } catch (clientexception e) { log.f(ctx.channel(), e); } catch (throwable t) { log.f(ctx.channel(), t); if (msg instanceof coaprequest) { ctx.writeandflush(messagebuilder.createresponse(msg, responsestatus.internal_server_error)); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) {","code_context_10":"@override protected void channelread0(channelhandlercontext ctx, coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice)","code_context_20":"@override protected void channelread0(channelhandlercontext ctx, coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel(); coapclient coapclient = (coapclient) reqchannel; coapclient.onresponsereceived(msg); } } catch (serverexception e) { ctx.writeandflush(messagebuilder.createresponse(msg, e.geterrorresponse())); log.f(ctx.channel(), e); } catch (clientexception e) { log.f(ctx.channel(), e);","repo":"SenthilKumarGS\/TizenRT"}
{"id":9474,"comment_id":1,"comment":"\/\/ todo: re-architecturing required","code":"@override protected void channelread0(channelhandlercontext ctx, coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel(); coapclient coapclient = (coapclient) reqchannel; coapclient.onresponsereceived(msg); } } catch (serverexception e) { ctx.writeandflush(messagebuilder.createresponse(msg, e.geterrorresponse())); log.f(ctx.channel(), e); } catch (clientexception e) { log.f(ctx.channel(), e); } catch (throwable t) { log.f(ctx.channel(), t); if (msg instanceof coaprequest) { ctx.writeandflush(messagebuilder.createresponse(msg, responsestatus.internal_server_error)); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel();","code_context_10":"try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel(); coapclient coapclient = (coapclient) reqchannel; coapclient.onresponsereceived(msg); } } catch (serverexception e) { ctx.writeandflush(messagebuilder.createresponse(msg, e.geterrorresponse())); log.f(ctx.channel(), e); } catch (clientexception e) {","code_context_20":"@override protected void channelread0(channelhandlercontext ctx, coapmessage msg) { try { \/\/ find proper device and raise event. device targetdevice = ctx.channel().attr(keydevice).get(); if (targetdevice == null) { throw new internalservererrorexception( \"unable to find device\"); } if (msg instanceof coaprequest) { onrequestreceived(targetdevice, (coaprequest) msg); } else if (msg instanceof coapresponse) { \/\/ todo: re-architecturing required irequestchannel reqchannel = ((coapdevice) targetdevice) .getrequestchannel(); coapclient coapclient = (coapclient) reqchannel; coapclient.onresponsereceived(msg); } } catch (serverexception e) { ctx.writeandflush(messagebuilder.createresponse(msg, e.geterrorresponse())); log.f(ctx.channel(), e); } catch (clientexception e) { log.f(ctx.channel(), e); } catch (throwable t) { log.f(ctx.channel(), t); if (msg instanceof coaprequest) { ctx.writeandflush(messagebuilder.createresponse(msg, responsestatus.internal_server_error)); } } }","repo":"SenthilKumarGS\/TizenRT"}
{"id":9490,"comment_id":0,"comment":"\/\/ this method takes a reference to the head of a linked list. \/\/ it returns the reference to the head of the linked list in the reversed order.","code":"\/\/ this method takes a reference to the head of a linked list. \/\/ it returns the reference to the head of the linked list in the reversed order. public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","classification":"NONSATD","isFinished":true,"code_context_2":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","code_context_10":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","code_context_20":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","repo":"Sailia\/data_structures"}
{"id":9490,"comment_id":1,"comment":"\/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/","code":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; }","code_context_10":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","code_context_20":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","repo":"Sailia\/data_structures"}
{"id":9490,"comment_id":2,"comment":"\/\/ replace this statement with your own return","code":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","code_context_10":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","code_context_20":"public lnode reverselistrec(lnode head) { \/\/ todo: implement this method \/*this method takes a reference to the head of a linked list and returns the reference to the head of the linked list in the reversed order. *\/ if(head == null) { return head; } if(head.getlink() == null) { return head; } head.getlink().setlink(head); head.setlink(null); return reverselistrec(head); \/\/ replace this statement with your own return }","repo":"Sailia\/data_structures"}
{"id":17706,"comment_id":0,"comment":"\/** * method to drive the robot using joystick info. * * @param xspeed speed of the robot in the x direction (forward). * @param yspeed speed of the robot in the y direction (sideways). * @param rot angular rate of the robot. * @param fieldrelative whether the provided x and y speeds are relative to the * field. *\/","code":"\/** * method to drive the robot using joystick info. * * @param xspeed speed of the robot in the x direction (forward). * @param yspeed speed of the robot in the y direction (sideways). * @param rot angular rate of the robot. * @param fieldrelative whether the provided x and y speeds are relative to the * field. *\/ @suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","classification":"NONSATD","isFinished":true,"code_context_2":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","code_context_10":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","code_context_20":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","repo":"Sammoore15\/Robot2022-2832-altencoderforingestor"}
{"id":17706,"comment_id":1,"comment":"\/\/ ask the kinematics to determine our swerve command","code":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","classification":"NONSATD","isFinished":true,"code_context_2":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) {","code_context_10":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module","code_context_20":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","repo":"Sammoore15\/Robot2022-2832-altencoderforingestor"}
{"id":17706,"comment_id":2,"comment":"\/\/ sometime the kinematics spits out too fast of speeds, so this will fix this","code":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","classification":"NONSATD","isFinished":true,"code_context_2":"} swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module","code_context_10":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative);","code_context_20":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","repo":"Sammoore15\/Robot2022-2832-altencoderforingestor"}
{"id":17706,"comment_id":3,"comment":"\/\/ command each swerve module","code":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]);","code_context_10":"\/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","code_context_20":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","repo":"Sammoore15\/Robot2022-2832-altencoderforingestor"}
{"id":17706,"comment_id":4,"comment":"\/\/ report our commands to the dashboard","code":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","classification":"NONSATD","isFinished":true,"code_context_2":"modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed);","code_context_10":"} else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","code_context_20":"@suppresswarnings(\"parametername\") public void drive(double xspeed, double yspeed, double rot, boolean fieldrelative) { \/\/ ask the kinematics to determine our swerve command chassisspeeds speeds; if (fieldrelative == true) { speeds = chassisspeeds.fromfieldrelativespeeds(xspeed, yspeed, rot, getheading()); } else { speeds = new chassisspeeds(xspeed, yspeed, rot); } swervemodulestate[] swervemodulestates = kinematics.toswervemodulestates(speeds); \/\/ sometime the kinematics spits out too fast of speeds, so this will fix this swervedrivekinematics.desaturatewheelspeeds(swervemodulestates, kmaxspeed); \/\/ command each swerve module for (int i = 0; i < modules.length; i++) { modules[i].setdesiredstate(swervemodulestates[i]); } \/\/ report our commands to the dashboard smartdashboard.putnumber(\"swervedrive\/xspeed\", xspeed); smartdashboard.putnumber(\"swervedrive\/yspeed\", yspeed); smartdashboard.putnumber(\"swervedrive\/rot\", rot); smartdashboard.putboolean(\"swervedrive\/fieldrelative\", fieldrelative); }","repo":"Sammoore15\/Robot2022-2832-altencoderforingestor"}
{"id":1344,"comment_id":0,"comment":"\/\/todo: this may take foreever. fix","code":"private int generatenewticketnumber() { \/\/todo: this may take foreever. fix int generated = numbergenerator.next(); while(purchased.containskey(generated)){ generated = numbergenerator.next(); } return generated; }","classification":"DEFECT","isFinished":true,"code_context_2":"private int generatenewticketnumber() { \/\/todo: this may take foreever. fix int generated = numbergenerator.next(); while(purchased.containskey(generated)){","code_context_10":"private int generatenewticketnumber() { \/\/todo: this may take foreever. fix int generated = numbergenerator.next(); while(purchased.containskey(generated)){ generated = numbergenerator.next(); } return generated; }","code_context_20":"private int generatenewticketnumber() { \/\/todo: this may take foreever. fix int generated = numbergenerator.next(); while(purchased.containskey(generated)){ generated = numbergenerator.next(); } return generated; }","repo":"aha0x0x\/LotteryApplication"}
{"id":17729,"comment_id":0,"comment":"\/** * place the cell within the grid layout at the specified row and column. * * @param parent - the cell's parent * @param row - the row that the cell will be set at * @param col - the column that the cell will be set at *\/","code":"\/** * place the cell within the grid layout at the specified row and column. * * @param parent - the cell's parent * @param row - the row that the cell will be set at * @param col - the column that the cell will be set at *\/ public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","code_context_10":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","code_context_20":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","repo":"SnoBoarder\/Sudoku-Solver"}
{"id":17729,"comment_id":1,"comment":"\/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column","code":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content;","code_context_10":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","code_context_20":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","repo":"SnoBoarder\/Sudoku-Solver"}
{"id":17729,"comment_id":2,"comment":"\/\/ set the row and column in the correct location of the sudoku board","code":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","classification":"NONSATD","isFinished":true,"code_context_2":"layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col);","code_context_10":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","code_context_20":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","repo":"SnoBoarder\/Sudoku-Solver"}
{"id":17729,"comment_id":3,"comment":"\/\/ set the layout params and add the edittext to the gridlayout parent","code":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","classification":"NONSATD","isFinished":true,"code_context_2":"layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text);","code_context_10":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","code_context_20":"public void setparentatrowandcolumn(gridlayout parent, int row, int col) { \/\/ prepare the layout parameters for the edittext \/\/ todo: consider caching the layout params and only changing the spec row and spec column layoutparams layoutparams = new gridlayout.layoutparams(); layoutparams.width = layoutparams.wrap_content; layoutparams.height = layoutparams.wrap_content; \/\/ set the row and column in the correct location of the sudoku board layoutparams.rowspec = gridlayout.spec(row); layoutparams.columnspec = gridlayout.spec(col); \/\/ set the layout params and add the edittext to the gridlayout parent _text.setlayoutparams(layoutparams); parent.addview(_text); }","repo":"SnoBoarder\/Sudoku-Solver"}
{"id":34188,"comment_id":0,"comment":"\/\/ todo: this could actually be true with low probability","code":"public void testzksmfalse() throws zksetmembershipexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\")}; encryptedinteger c = new encryptedinteger(new biginteger(\"10\"), pub); biginteger r = c.set(new biginteger(\"10\")); int msgindex = 2; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","classification":"DEFECT","isFinished":true,"code_context_2":"biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_10":"biginteger r = c.set(new biginteger(\"10\")); int msgindex = 2; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_20":"public void testzksmfalse() throws zksetmembershipexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\")}; encryptedinteger c = new encryptedinteger(new biginteger(\"10\"), pub); biginteger r = c.set(new biginteger(\"10\")); int msgindex = 2; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":34189,"comment_id":0,"comment":"\/\/ todo: this could actually be true with low probability","code":"public void testzksmsinglemembersetfalse() throws zksetmembershipexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\")}; encryptedinteger c = new encryptedinteger(biginteger.one, pub); biginteger r = c.set(biginteger.one); int msgindex = 0; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","classification":"DEFECT","isFinished":true,"code_context_2":"biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_10":"biginteger r = c.set(biginteger.one); int msgindex = 0; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_20":"public void testzksmsinglemembersetfalse() throws zksetmembershipexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\")}; encryptedinteger c = new encryptedinteger(biginteger.one, pub); biginteger r = c.set(biginteger.one); int msgindex = 0; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":34190,"comment_id":0,"comment":"\/\/ todo: this could actually be true with low probability","code":"public void testzksmaddtrue() throws zksetmembershipexception, publickeysnotequalexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\"), new biginteger(\"6\")}; encryptedinteger c1 = new encryptedinteger(new biginteger(\"2\"), pub); biginteger r1 = c1.set(new biginteger(\"2\")); encryptedinteger c2 = new encryptedinteger(new biginteger(\"3\"), pub); biginteger r2 = c2.set(new biginteger(\"3\")); encryptedinteger c = c1.add(c2); biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","classification":"DEFECT","isFinished":true,"code_context_2":"biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_10":"biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_20":"public void testzksmaddtrue() throws zksetmembershipexception, publickeysnotequalexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\"), new biginteger(\"6\")}; encryptedinteger c1 = new encryptedinteger(new biginteger(\"2\"), pub); biginteger r1 = c1.set(new biginteger(\"2\")); encryptedinteger c2 = new encryptedinteger(new biginteger(\"3\"), pub); biginteger r2 = c2.set(new biginteger(\"3\")); encryptedinteger c = c1.add(c2); biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":34191,"comment_id":0,"comment":"\/\/ todo: this could actually be true with low probability","code":"public void testzksmmanyoperations() throws zksetmembershipexception, publickeysnotequalexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\"), new biginteger(\"6\")}; encryptedinteger c1 = new encryptedinteger(new biginteger(\"2\"), pub); biginteger r1 = c1.set(new biginteger(\"2\")); encryptedinteger c2 = new encryptedinteger(new biginteger(\"3\"), pub); biginteger r2 = c2.set(new biginteger(\"3\")); encryptedinteger c = c1.add(c2); biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","classification":"DEFECT","isFinished":true,"code_context_2":"biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_10":"biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","code_context_20":"public void testzksmmanyoperations() throws zksetmembershipexception, publickeysnotequalexception, bigintegerclassnotvalid { biginteger[] theset = {new biginteger(\"0\"), new biginteger(\"1\"), new biginteger(\"2\"), new biginteger(\"3\"), new biginteger(\"4\"), new biginteger(\"6\")}; encryptedinteger c1 = new encryptedinteger(new biginteger(\"2\"), pub); biginteger r1 = c1.set(new biginteger(\"2\")); encryptedinteger c2 = new encryptedinteger(new biginteger(\"3\"), pub); biginteger r2 = c2.set(new biginteger(\"3\")); encryptedinteger c = c1.add(c2); biginteger r = r1.multiply(r2).mod(this.pub.getnsquared()); int msgindex = 5; for (int i=0; i<10; i++) { zksetmembershipprover prover = new zksetmembershipprover(pub, theset, msgindex, c); biginteger[] uvals = prover.gencommitments(); zksetmembershipverifier verifier = new zksetmembershipverifier(pub, c, uvals, theset); biginteger e = verifier.genchallenge(new biginteger(\"128\")); prover.computeresponse(e, r); biginteger[] evals = prover.getes(); biginteger[] vvals = prover.getvs(); assertfalse(verifier.checkresponse(evals, vvals)); \/\/ todo: this could actually be true with low probability } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":34311,"comment_id":0,"comment":"\/\/ like junit4, j2cl always counts errors as failures","code":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","classification":"NONSATD","isFinished":true,"code_context_2":"int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0;","code_context_10":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else {","code_context_20":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","repo":"VishrutMehta\/j2cl"}
{"id":34311,"comment_id":1,"comment":"\/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly","code":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","classification":"DEFECT","isFinished":true,"code_context_2":"fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct.","code_context_10":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","code_context_20":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","repo":"VishrutMehta\/j2cl"}
{"id":34311,"comment_id":2,"comment":"\/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct.","code":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); }","code_context_10":"int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","code_context_20":"private void asserttestsummary() { int fails = testresult.fails().size(); int errors = testresult.errors().size(); int succeeds = testresult.succeeds().size(); int testcount = fails + errors + succeeds; if (testmode.isj2cl()) { \/\/ like junit4, j2cl always counts errors as failures fails += errors; errors = 0; \/\/ todo(b\/32608089): jsunit_test does not report number of tests correctly testcount = 1; \/\/ since total number of tests cannot be asserted; ensure nummber of succeeds is correct. assertthat(consolelogs.stream().filter(x -> x.contains(\": passed\"))).hassize(succeeds); } if (fails + errors > 0) { asserttestsummaryforfailure(fails, errors, testcount); } else { asserttestsummaryforsuccess(testcount); } }","repo":"VishrutMehta\/j2cl"}
{"id":18084,"comment_id":0,"comment":"\/** * continuously attempts to connect for at least the indicated amount of time; or indefinitely if -1. this method * is useful when you are not sure if the system you are trying to connect to already is up and running. * * this method doesn't throw an exception, but returns true on success, false otherwise. * * todo: what happens if already connected? * * @param timeoutms * @return *\/","code":"\/** * continuously attempts to connect for at least the indicated amount of time; or indefinitely if -1. this method * is useful when you are not sure if the system you are trying to connect to already is up and running. * * this method doesn't throw an exception, but returns true on success, false otherwise. * * todo: what happens if already connected? * * @param timeoutms * @return *\/ public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","classification":"DESIGN","isFinished":true,"code_context_2":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","code_context_10":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","code_context_20":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","repo":"YYTVicky\/brooklyn-server"}
{"id":18084,"comment_id":1,"comment":"\/\/sleep 100 to prevent thrashing and facilitate interruption","code":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","classification":"NONSATD","isFinished":true,"code_context_2":"while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try {","code_context_10":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else {","code_context_20":"public boolean connect(long timeoutms) { if (log.isdebugenabled()) log.debug(\"connecting to jmx url: {} ({})\", url, ((timeoutms == -1) ? \"indefinitely\" : timeoutms+\"ms timeout\")); long startms = system.currenttimemillis(); long endms = (timeoutms == -1) ? long.max_value : (startms + timeoutms); long currenttime = startms; throwable lasterror = null; int attempt = 0; while (currenttime <= endms) { currenttime = system.currenttimemillis(); if (attempt != 0) sleep(100); \/\/sleep 100 to prevent thrashing and facilitate interruption if (log.istraceenabled()) log.trace(\"trying connection to {} at time {}\", url, currenttime); try { connect(); return true; } catch (exception e) { exceptions.propagateiffatal(e); if (!terminated.get() && shouldretryon(e)) { if (log.isdebugenabled()) log.debug(\"attempt {} failed connecting to {} ({})\", new object[] {attempt + 1, url, e.getmessage()}); lasterror = e; } else { throw exceptions.propagate(e); } } attempt++; } log.warn(\"unable to connect to jmx url: \"+url, lasterror); return false; }","repo":"YYTVicky\/brooklyn-server"}
{"id":34588,"comment_id":0,"comment":"\/** * make a json text string representation of this jsonobject. * think carefully before using this method! do you really need * a string in memory? since json is used as a data transport format * normally you are going to write the string out to some destination. * it is far more efficient to use the <code>write<\/code> operation * on this object directly. think about it: you have a tree of json * objects in memory. this method will make a copy of all that data * into a single string -- a second copy of the data in memory. * if all you are going to do is to write that string out to a file, * then use the write method to stream it directly to the file. * if you are going to send the data from a server to client browser, * the write directly to the output stream. this reduces memory usage. * sometimes you really do need a string, so the method is provided, * but use it sparingly. * <\/p><p> * the json is produced indented by an indentfactor amount specified. * if you specify zero indent, the output will be all on a single line. * the elements are alphabetized only if an indent is specified. * <\/p><p> * warning: this method assumes that the data structure is acyclical. * an exception will be thrown if you have a cycle. * * @param indentfactor the number of spaces to add to each level of * indentation. * @return a printable, displayable, portable, transmittable * representation of the object, beginning * with <code>{<\/code>&nbsp;<small>(left brace)<\/small> and ending * with <code>}<\/code>&nbsp;<small>(right brace)<\/small>. * @throws jsonexception if the object contains an invalid number. *\/","code":"\/** * make a json text string representation of this jsonobject. * think carefully before using this method! do you really need * a string in memory? since json is used as a data transport format * normally you are going to write the string out to some destination. * it is far more efficient to use the <code>write<\/code> operation * on this object directly. think about it: you have a tree of json * objects in memory. this method will make a copy of all that data * into a single string -- a second copy of the data in memory. * if all you are going to do is to write that string out to a file, * then use the write method to stream it directly to the file. * if you are going to send the data from a server to client browser, * the write directly to the output stream. this reduces memory usage. * sometimes you really do need a string, so the method is provided, * but use it sparingly. * <\/p><p> * the json is produced indented by an indentfactor amount specified. * if you specify zero indent, the output will be all on a single line. * the elements are alphabetized only if an indent is specified. * <\/p><p> * warning: this method assumes that the data structure is acyclical. * an exception will be thrown if you have a cycle. * * @param indentfactor the number of spaces to add to each level of * indentation. * @return a printable, displayable, portable, transmittable * representation of the object, beginning * with <code>{<\/code>&nbsp;<small>(left brace)<\/small> and ending * with <code>}<\/code>&nbsp;<small>(right brace)<\/small>. * @throws jsonexception if the object contains an invalid number. *\/ public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","code_context_10":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","code_context_20":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","repo":"agilepro\/purple"}
{"id":34588,"comment_id":1,"comment":"\/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it.","code":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); }","code_context_10":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","code_context_20":"public string tostring(int indentfactor) { try { stringwriter w = new stringwriter(); synchronized (w.getbuffer()) { return this.write(w, indentfactor, 0).tostring(); } } catch (exception e) { \/\/there is no conceivable exception that can come out of this, but throw something \/\/just in case. want the signature to not have exception in it. throw new runtimeexception(\"can not serialize jsonobject????\", e); } }","repo":"agilepro\/purple"}
{"id":18326,"comment_id":0,"comment":"\/** * ensure the builder is used with content we expect. * currently (this could change) we should only have one datetimeparser per datecomponentordering. *\/","code":"\/** * ensure the builder is used with content we expect. * currently (this could change) we should only have one datetimeparser per datecomponentordering. *\/ private void validate() throws illegalstateexception { set<datecomponentordering> orderings = sets.newhashset(); if(preferred != null) { orderings.add(preferred.getordering()); } for(datetimeparser parser : otherparsers) { if(!orderings.add(parser.getordering())) { throw new illegalstateexception(\"datecomponentordering can only be used once in a datetimemultiparser.\" + \"[\" + parser.getordering() + \"]\"); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"private void validate() throws illegalstateexception { set<datecomponentordering> orderings = sets.newhashset(); if(preferred != null) { orderings.add(preferred.getordering()); } for(datetimeparser parser : otherparsers) { if(!orderings.add(parser.getordering())) { throw new illegalstateexception(\"datecomponentordering can only be used once in a datetimemultiparser.\" + \"[\" + parser.getordering() + \"]\"); } } }","code_context_10":"private void validate() throws illegalstateexception { set<datecomponentordering> orderings = sets.newhashset(); if(preferred != null) { orderings.add(preferred.getordering()); } for(datetimeparser parser : otherparsers) { if(!orderings.add(parser.getordering())) { throw new illegalstateexception(\"datecomponentordering can only be used once in a datetimemultiparser.\" + \"[\" + parser.getordering() + \"]\"); } } }","code_context_20":"private void validate() throws illegalstateexception { set<datecomponentordering> orderings = sets.newhashset(); if(preferred != null) { orderings.add(preferred.getordering()); } for(datetimeparser parser : otherparsers) { if(!orderings.add(parser.getordering())) { throw new illegalstateexception(\"datecomponentordering can only be used once in a datetimemultiparser.\" + \"[\" + parser.getordering() + \"]\"); } } }","repo":"adam-collins\/parsers"}
{"id":18370,"comment_id":0,"comment":"\/\/later todo \/\/return super.getenumname(fieldname);","code":"public static string getenumname(string fieldname ) { \/\/later todo \/\/return super.getenumname(fieldname); return null; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public static string getenumname(string fieldname ) { \/\/later todo \/\/return super.getenumname(fieldname); return null; }","code_context_10":"public static string getenumname(string fieldname ) { \/\/later todo \/\/return super.getenumname(fieldname); return null; }","code_context_20":"public static string getenumname(string fieldname ) { \/\/later todo \/\/return super.getenumname(fieldname); return null; }","repo":"aloklal99\/apache-ranger"}
{"id":18422,"comment_id":0,"comment":"\/** * creates an instance of statsvalues which supports values from the specified {@link statsfield} * * @param statsfield {@link statsfield} whose statistics will be created by the resulting {@link * statsvalues} * @return instance of {@link statsvalues} that will create statistics from values from the * specified {@link statsfield} *\/","code":"\/** * creates an instance of statsvalues which supports values from the specified {@link statsfield} * * @param statsfield {@link statsfield} whose statistics will be created by the resulting {@link * statsvalues} * @return instance of {@link statsvalues} that will create statistics from values from the * specified {@link statsfield} *\/ public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","code_context_10":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","code_context_20":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","repo":"ackepenek\/solr"}
{"id":18422,"comment_id":1,"comment":"\/\/ function stats","code":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); }","code_context_10":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) {","code_context_20":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else {","repo":"ackepenek\/solr"}
{"id":18422,"comment_id":2,"comment":"\/\/ todo: allow fieldtype to provide impl.","code":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\"); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield);","code_context_10":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield);","code_context_20":"public static statsvalues createstatsvalues(statsfield statsfield) { final schemafield sf = statsfield.getschemafield(); if (null == sf) { \/\/ function stats return new numericstatsvalues(statsfield); } final fieldtype fieldtype = sf.gettype(); \/\/ todo: allow fieldtype to provide impl. if (triedatefield.class.isinstance(fieldtype) || datepointfield.class.isinstance(fieldtype)) { datestatsvalues statsvalues = new datestatsvalues(statsfield); if (sf.multivalued()) { return new sorteddatestatsvalues(statsvalues, statsfield); } return statsvalues; } else if (triefield.class.isinstance(fieldtype) || pointfield.class.isinstance(fieldtype)) { numericstatsvalues statsvalue = new numericstatsvalues(statsfield); if (sf.multivalued()) { return new sortednumericstatsvalues(statsvalue, statsfield); } return statsvalue; } else if (strfield.class.isinstance(fieldtype)) { return new stringstatsvalues(statsfield); } else if (abstractenumfield.class.isinstance(fieldtype)) { return new enumstatsvalues(statsfield); } else { throw new solrexception( solrexception.errorcode.bad_request, \"field type \" + fieldtype + \" is not currently supported\");","repo":"ackepenek\/solr"}
{"id":18424,"comment_id":0,"comment":"\/\/ todo: incompatible packs warning","code":"\/\/ todo: incompatible packs warning public void setselected(@nullable packlistwidget.packentry entry) { this.setselected(entry, true); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void setselected(@nullable packlistwidget.packentry entry) { this.setselected(entry, true); }","code_context_10":"public void setselected(@nullable packlistwidget.packentry entry) { this.setselected(entry, true); }","code_context_20":"public void setselected(@nullable packlistwidget.packentry entry) { this.setselected(entry, true); }","repo":"VanillaImprovements\/VVDownloader"}
{"id":2045,"comment_id":0,"comment":"\/** * returns an event indicating the current status of each active job, in the order they were * submitted. * todo: hook this up. *\/","code":"\/** * returns an event indicating the current status of each active job, in the order they were * submitted. * todo: hook this up. *\/ synchronized immutablelist<jobevent> getactiveevents() { immutablelist.builder<jobevent> builder = immutablelist.builder(); for (string id : activejobids) { jobevent p = eventsbyjobid.get(id); assert p != null; builder.add(p); } return builder.build(); }","classification":"DESIGN","isFinished":true,"code_context_2":"synchronized immutablelist<jobevent> getactiveevents() { immutablelist.builder<jobevent> builder = immutablelist.builder(); for (string id : activejobids) { jobevent p = eventsbyjobid.get(id); assert p != null; builder.add(p); } return builder.build(); }","code_context_10":"synchronized immutablelist<jobevent> getactiveevents() { immutablelist.builder<jobevent> builder = immutablelist.builder(); for (string id : activejobids) { jobevent p = eventsbyjobid.get(id); assert p != null; builder.add(p); } return builder.build(); }","code_context_20":"synchronized immutablelist<jobevent> getactiveevents() { immutablelist.builder<jobevent> builder = immutablelist.builder(); for (string id : activejobids) { jobevent p = eventsbyjobid.get(id); assert p != null; builder.add(p); } return builder.build(); }","repo":"TeamSPoon\/CYC_JRTL_with_CommonLisp_OLD"}
{"id":18433,"comment_id":0,"comment":"\/\/ fixme: kubevirt currently have only kubevirt_vmi_vcpu_seconds, which is total cpu time, \/\/ so we are setting it here only as system time, which is wrong.","code":"private vdsmvm appendstatistics(vdsmvm vm, v1virtualmachineinstance vmi) { vmstatistics statistics = new vmstatistics(); statistics.setid(vm.getid()); datetime creationtimestampdate = vmi.getmetadata().getcreationtimestamp(); if (creationtimestampdate != null) { datetime now = datetime.now(); seconds seconds = seconds.secondsbetween(creationtimestampdate, now); statistics.setelapsedtime((double) seconds.getseconds()); } prometheusclient promclient = getprometheusclient(); if (promclient != null) { \/\/ fixme: kubevirt currently have only kubevirt_vmi_vcpu_seconds, which is total cpu time, \/\/ so we are setting it here only as system time, which is wrong. statistics.setcpusys( promclient.getvmicpuusage(vmi.getmetadata().getname(), vmi.getmetadata().getnamespace()) ); } return vm.setvmstatistics(statistics) .setdiskstatistics(collections.emptylist()) .setvmjobs(collections.emptylist()); }","classification":"DEFECT","isFinished":true,"code_context_2":"prometheusclient promclient = getprometheusclient(); if (promclient != null) { \/\/ fixme: kubevirt currently have only kubevirt_vmi_vcpu_seconds, which is total cpu time, \/\/ so we are setting it here only as system time, which is wrong. statistics.setcpusys( promclient.getvmicpuusage(vmi.getmetadata().getname(), vmi.getmetadata().getnamespace())","code_context_10":"vmstatistics statistics = new vmstatistics(); statistics.setid(vm.getid()); datetime creationtimestampdate = vmi.getmetadata().getcreationtimestamp(); if (creationtimestampdate != null) { datetime now = datetime.now(); seconds seconds = seconds.secondsbetween(creationtimestampdate, now); statistics.setelapsedtime((double) seconds.getseconds()); } prometheusclient promclient = getprometheusclient(); if (promclient != null) { \/\/ fixme: kubevirt currently have only kubevirt_vmi_vcpu_seconds, which is total cpu time, \/\/ so we are setting it here only as system time, which is wrong. statistics.setcpusys( promclient.getvmicpuusage(vmi.getmetadata().getname(), vmi.getmetadata().getnamespace()) ); } return vm.setvmstatistics(statistics) .setdiskstatistics(collections.emptylist()) .setvmjobs(collections.emptylist()); }","code_context_20":"private vdsmvm appendstatistics(vdsmvm vm, v1virtualmachineinstance vmi) { vmstatistics statistics = new vmstatistics(); statistics.setid(vm.getid()); datetime creationtimestampdate = vmi.getmetadata().getcreationtimestamp(); if (creationtimestampdate != null) { datetime now = datetime.now(); seconds seconds = seconds.secondsbetween(creationtimestampdate, now); statistics.setelapsedtime((double) seconds.getseconds()); } prometheusclient promclient = getprometheusclient(); if (promclient != null) { \/\/ fixme: kubevirt currently have only kubevirt_vmi_vcpu_seconds, which is total cpu time, \/\/ so we are setting it here only as system time, which is wrong. statistics.setcpusys( promclient.getvmicpuusage(vmi.getmetadata().getname(), vmi.getmetadata().getnamespace()) ); } return vm.setvmstatistics(statistics) .setdiskstatistics(collections.emptylist()) .setvmjobs(collections.emptylist()); }","repo":"StevenCode\/ovirt-engine"}
{"id":18456,"comment_id":0,"comment":"\/** * this method tests accessing the dbpedia linked data service, which uses virtuoso and delivers rdf\/xml as * well as text\/turtle. * * @throws exception * @todo find a better way to deal with errors actually in the services and not in the code *\/","code":"\/** * this method tests accessing the dbpedia linked data service, which uses virtuoso and delivers rdf\/xml as * well as text\/turtle. * * @throws exception * @todo find a better way to deal with errors actually in the services and not in the code *\/ @test @ignore(\"dbpedia is not reliable\") public void testdbpedia() throws exception { testresource(dbpedia, \"dbpedia-berlin.sparql\" ); }","classification":"DESIGN","isFinished":true,"code_context_2":"@test @ignore(\"dbpedia is not reliable\") public void testdbpedia() throws exception { testresource(dbpedia, \"dbpedia-berlin.sparql\" ); }","code_context_10":"@test @ignore(\"dbpedia is not reliable\") public void testdbpedia() throws exception { testresource(dbpedia, \"dbpedia-berlin.sparql\" ); }","code_context_20":"@test @ignore(\"dbpedia is not reliable\") public void testdbpedia() throws exception { testresource(dbpedia, \"dbpedia-berlin.sparql\" ); }","repo":"YYTVicky\/marmotta"}
{"id":34925,"comment_id":0,"comment":"\/\/ todo: this test passes even when this line is removed","code":"@test public void cancompleteitself() throws ioexception { string jid = queue.put(\"foo\", null, null); queue.pop().complete(); \/\/ todo: this test passes even when this line is removed assert.assertequals(\"complete\", client.getjob(jid).getstate()); }","classification":"TEST","isFinished":true,"code_context_2":"public void cancompleteitself() throws ioexception { string jid = queue.put(\"foo\", null, null); queue.pop().complete(); \/\/ todo: this test passes even when this line is removed assert.assertequals(\"complete\", client.getjob(jid).getstate()); }","code_context_10":"@test public void cancompleteitself() throws ioexception { string jid = queue.put(\"foo\", null, null); queue.pop().complete(); \/\/ todo: this test passes even when this line is removed assert.assertequals(\"complete\", client.getjob(jid).getstate()); }","code_context_20":"@test public void cancompleteitself() throws ioexception { string jid = queue.put(\"foo\", null, null); queue.pop().complete(); \/\/ todo: this test passes even when this line is removed assert.assertequals(\"complete\", client.getjob(jid).getstate()); }","repo":"Zimbra\/qless-java"}
{"id":18643,"comment_id":0,"comment":"\/\/ last checked card this turn is no longer exiled, so you can't cast another with this effect \/\/ todo: handle if card was cast\/removed from exile with effect from another card. \/\/ if so, this effect could prevent player from casting although they should be able to use it","code":"@override public boolean applies(uuid objectid, ability source, uuid affectedcontrollerid, game game) { if (affectedcontrollerid.equals(source.getcontrollerid())) { card card = game.getcard(objectid); mageobject sourceobject = source.getsourceobject(game); if (card != null && !card.island() && sourceobject != null) { uuid exileid = cardutil.getexilezoneid(game, source.getsourceid(), source.getsourceobjectzonechangecounter()); if (exileid != null) { exilezone exilezone = game.getstate().getexile().getexilezone(exileid); if (exilezone != null && exilezone.contains(objectid)) { if (game.getturnnum() == turnnumber) { if (!exilezone.contains(cardid)) { \/\/ last checked card this turn is no longer exiled, so you can't cast another with this effect \/\/ todo: handle if card was cast\/removed from exile with effect from another card. \/\/ if so, this effect could prevent player from casting although they should be able to use it return false; } } this.turnnumber = game.getturnnum(); this.cardid = objectid; return true; } } } } return false; }","classification":"DEFECT","isFinished":true,"code_context_2":"if (game.getturnnum() == turnnumber) { if (!exilezone.contains(cardid)) { \/\/ last checked card this turn is no longer exiled, so you can't cast another with this effect \/\/ todo: handle if card was cast\/removed from exile with effect from another card. \/\/ if so, this effect could prevent player from casting although they should be able to use it return false; }","code_context_10":"if (affectedcontrollerid.equals(source.getcontrollerid())) { card card = game.getcard(objectid); mageobject sourceobject = source.getsourceobject(game); if (card != null && !card.island() && sourceobject != null) { uuid exileid = cardutil.getexilezoneid(game, source.getsourceid(), source.getsourceobjectzonechangecounter()); if (exileid != null) { exilezone exilezone = game.getstate().getexile().getexilezone(exileid); if (exilezone != null && exilezone.contains(objectid)) { if (game.getturnnum() == turnnumber) { if (!exilezone.contains(cardid)) { \/\/ last checked card this turn is no longer exiled, so you can't cast another with this effect \/\/ todo: handle if card was cast\/removed from exile with effect from another card. \/\/ if so, this effect could prevent player from casting although they should be able to use it return false; } } this.turnnumber = game.getturnnum(); this.cardid = objectid; return true; } } } }","code_context_20":"@override public boolean applies(uuid objectid, ability source, uuid affectedcontrollerid, game game) { if (affectedcontrollerid.equals(source.getcontrollerid())) { card card = game.getcard(objectid); mageobject sourceobject = source.getsourceobject(game); if (card != null && !card.island() && sourceobject != null) { uuid exileid = cardutil.getexilezoneid(game, source.getsourceid(), source.getsourceobjectzonechangecounter()); if (exileid != null) { exilezone exilezone = game.getstate().getexile().getexilezone(exileid); if (exilezone != null && exilezone.contains(objectid)) { if (game.getturnnum() == turnnumber) { if (!exilezone.contains(cardid)) { \/\/ last checked card this turn is no longer exiled, so you can't cast another with this effect \/\/ todo: handle if card was cast\/removed from exile with effect from another card. \/\/ if so, this effect could prevent player from casting although they should be able to use it return false; } } this.turnnumber = game.getturnnum(); this.cardid = objectid; return true; } } } } return false; }","repo":"amc8391\/mage"}
{"id":2359,"comment_id":0,"comment":"\/\/ this violates encapsulation but there is no convenience method to get a filename from \/\/ disklrucache. filename was derived from private class method entry#getcleanfile \/\/ in disklrucache.java","code":"public static string getfilepathdiskcache(final string key) { if (sdisklrucache == null) { return null; } \/\/ this violates encapsulation but there is no convenience method to get a filename from \/\/ disklrucache. filename was derived from private class method entry#getcleanfile \/\/ in disklrucache.java return sdisklrucache.getdirectory() + file.separator + createvaliddiskcachekey(key) + \".\" + disk_cache_index; }","classification":"DESIGN","isFinished":true,"code_context_2":"return null; } \/\/ this violates encapsulation but there is no convenience method to get a filename from \/\/ disklrucache. filename was derived from private class method entry#getcleanfile \/\/ in disklrucache.java return sdisklrucache.getdirectory() + file.separator","code_context_10":"public static string getfilepathdiskcache(final string key) { if (sdisklrucache == null) { return null; } \/\/ this violates encapsulation but there is no convenience method to get a filename from \/\/ disklrucache. filename was derived from private class method entry#getcleanfile \/\/ in disklrucache.java return sdisklrucache.getdirectory() + file.separator + createvaliddiskcachekey(key) + \".\" + disk_cache_index; }","code_context_20":"public static string getfilepathdiskcache(final string key) { if (sdisklrucache == null) { return null; } \/\/ this violates encapsulation but there is no convenience method to get a filename from \/\/ disklrucache. filename was derived from private class method entry#getcleanfile \/\/ in disklrucache.java return sdisklrucache.getdirectory() + file.separator + createvaliddiskcachekey(key) + \".\" + disk_cache_index; }","repo":"SinnerSchraderMobileMirrors\/mopub-android-sdk"}
{"id":18861,"comment_id":0,"comment":"\/\/todo display readings in mg\/dl","code":"private void setupviews() { glucometerattribution = findviewbyid(r.id.glucometerattribution); glucometerimg = findviewbyid(r.id.glucometerimg); insertstriptext = findviewbyid(r.id.insertstriptext); uparrow = findviewbyid(r.id.uparrow); droplet = findviewbyid(r.id.dropletimg); attributiontext = findviewbyid(r.id.attributiontext); placebloodsweatimg = findviewbyid(r.id.placebloodsweatimg); placebloodsweattext = findviewbyid(r.id.placebloodsweattext); waitforreadingtext = findviewbyid(r.id.waitforreadingtext); progressbar = findviewbyid(r.id.progressbar); unitstext = findviewbyid(r.id.unitstext); glucoseleveltext = findviewbyid(r.id.glucoseleveltext); descriptiontxt = findviewbyid(r.id.descriptiontxt); detailsbtn = findviewbyid(r.id.detailsbtn); anotherreadingbtn = findviewbyid(r.id.anotherreadingbtn); showbtn = findviewbyid(r.id.button7); dippedbtn = findviewbyid(r.id.button6); stripbtn = findviewbyid(r.id.button8); startbutton = findviewbyid(r.id.btnstripinserted); rgmode = findviewbyid(r.id.rgmode); rbblood = findviewbyid(r.id.rbblood); rbsweat = findviewbyid(r.id.rbsweat); rb_mg_dl = findviewbyid(r.id.rb_mg_dl); rb_mmol_l = findviewbyid(r.id.rb_mmol_l); glucometerswitch = findviewbyid(r.id.glucometerswitch); rgunits = findviewbyid(r.id.rgunits); startbutton.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { if (!rbsweat.ischecked() && !rbblood.ischecked()) { toast.maketext(glucometeractivity.this, \"please select a mode\", toast.length_short).show(); } else { instance.senddatatoarduino(\"start\"); instance.setreading(true); glucometerswitch.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); startbutton.setenabled(false); glucometerimg.setvisibility(view.visible); glucometerattribution.setvisibility(view.visible); insertstriptext.setvisibility(view.visible); uparrow.setvisibility(view.visible); } } }); rgmode.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rbblood: instance.senddatatoarduino(\"blood\"); droplet.setcolorfilter(color.parsecolor(\"#f44336\")); placebloodsweattext.settext(\"place blood on the test strip\"); break; case r.id.rbsweat: instance.senddatatoarduino(\"sweat\"); droplet.setcolorfilter(color.parsecolor(\"#1b95e0\")); placebloodsweattext.settext(\"place sweat on the test strip\"); break; } viewdelay(); } }); glucometerswitch.setoncheckedchangelistener(new compoundbutton.oncheckedchangelistener() { @override public void oncheckedchanged(compoundbutton buttonview, boolean ischecked) { if (ischecked){ instance.senddatatoarduino(\"g_on\"); viewdelay(); }else { instance.senddatatoarduino(\"g_off\"); startbutton.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); glucometerswitch.setenabled(false); viewhandler = new handler(); runnable delay = new runnable() { @override public void run() { glucometerswitch.setenabled(true); } }; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true); rbblood.setenabled(true); rbsweat.setenabled(true); rb_mg_dl.setenabled(true); rb_mmol_l.setenabled(true); startbutton.setenabled(true); instance.setstringdata(null); instance.setcommand(null); unitstext.setvisibility(view.invisible); glucoseleveltext.setvisibility(view.invisible); descriptiontxt.setvisibility(view.invisible); detailsbtn.setvisibility(view.invisible); anotherreadingbtn.setvisibility(view.invisible); } }); showbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"show\"); } }); stripbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"strip\"); } }); dippedbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"dipped\"); } }); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break;","code_context_10":"}; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } });","code_context_20":"rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); glucometerswitch.setenabled(false); viewhandler = new handler(); runnable delay = new runnable() { @override public void run() { glucometerswitch.setenabled(true); } }; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() {","repo":"W6WM9M\/VitalityMeter"}
{"id":18861,"comment_id":1,"comment":"\/\/todo display readings in mmol\/l","code":"private void setupviews() { glucometerattribution = findviewbyid(r.id.glucometerattribution); glucometerimg = findviewbyid(r.id.glucometerimg); insertstriptext = findviewbyid(r.id.insertstriptext); uparrow = findviewbyid(r.id.uparrow); droplet = findviewbyid(r.id.dropletimg); attributiontext = findviewbyid(r.id.attributiontext); placebloodsweatimg = findviewbyid(r.id.placebloodsweatimg); placebloodsweattext = findviewbyid(r.id.placebloodsweattext); waitforreadingtext = findviewbyid(r.id.waitforreadingtext); progressbar = findviewbyid(r.id.progressbar); unitstext = findviewbyid(r.id.unitstext); glucoseleveltext = findviewbyid(r.id.glucoseleveltext); descriptiontxt = findviewbyid(r.id.descriptiontxt); detailsbtn = findviewbyid(r.id.detailsbtn); anotherreadingbtn = findviewbyid(r.id.anotherreadingbtn); showbtn = findviewbyid(r.id.button7); dippedbtn = findviewbyid(r.id.button6); stripbtn = findviewbyid(r.id.button8); startbutton = findviewbyid(r.id.btnstripinserted); rgmode = findviewbyid(r.id.rgmode); rbblood = findviewbyid(r.id.rbblood); rbsweat = findviewbyid(r.id.rbsweat); rb_mg_dl = findviewbyid(r.id.rb_mg_dl); rb_mmol_l = findviewbyid(r.id.rb_mmol_l); glucometerswitch = findviewbyid(r.id.glucometerswitch); rgunits = findviewbyid(r.id.rgunits); startbutton.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { if (!rbsweat.ischecked() && !rbblood.ischecked()) { toast.maketext(glucometeractivity.this, \"please select a mode\", toast.length_short).show(); } else { instance.senddatatoarduino(\"start\"); instance.setreading(true); glucometerswitch.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); startbutton.setenabled(false); glucometerimg.setvisibility(view.visible); glucometerattribution.setvisibility(view.visible); insertstriptext.setvisibility(view.visible); uparrow.setvisibility(view.visible); } } }); rgmode.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rbblood: instance.senddatatoarduino(\"blood\"); droplet.setcolorfilter(color.parsecolor(\"#f44336\")); placebloodsweattext.settext(\"place blood on the test strip\"); break; case r.id.rbsweat: instance.senddatatoarduino(\"sweat\"); droplet.setcolorfilter(color.parsecolor(\"#1b95e0\")); placebloodsweattext.settext(\"place sweat on the test strip\"); break; } viewdelay(); } }); glucometerswitch.setoncheckedchangelistener(new compoundbutton.oncheckedchangelistener() { @override public void oncheckedchanged(compoundbutton buttonview, boolean ischecked) { if (ischecked){ instance.senddatatoarduino(\"g_on\"); viewdelay(); }else { instance.senddatatoarduino(\"g_off\"); startbutton.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); glucometerswitch.setenabled(false); viewhandler = new handler(); runnable delay = new runnable() { @override public void run() { glucometerswitch.setenabled(true); } }; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true); rbblood.setenabled(true); rbsweat.setenabled(true); rb_mg_dl.setenabled(true); rb_mmol_l.setenabled(true); startbutton.setenabled(true); instance.setstringdata(null); instance.setcommand(null); unitstext.setvisibility(view.invisible); glucoseleveltext.setvisibility(view.invisible); descriptiontxt.setvisibility(view.invisible); detailsbtn.setvisibility(view.invisible); anotherreadingbtn.setvisibility(view.invisible); } }); showbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"show\"); } }); stripbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"strip\"); } }); dippedbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"dipped\"); } }); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break;","code_context_10":"}); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity","code_context_20":"viewhandler = new handler(); runnable delay = new runnable() { @override public void run() { glucometerswitch.setenabled(true); } }; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true);","repo":"W6WM9M\/VitalityMeter"}
{"id":18861,"comment_id":2,"comment":"\/\/move to new activity","code":"private void setupviews() { glucometerattribution = findviewbyid(r.id.glucometerattribution); glucometerimg = findviewbyid(r.id.glucometerimg); insertstriptext = findviewbyid(r.id.insertstriptext); uparrow = findviewbyid(r.id.uparrow); droplet = findviewbyid(r.id.dropletimg); attributiontext = findviewbyid(r.id.attributiontext); placebloodsweatimg = findviewbyid(r.id.placebloodsweatimg); placebloodsweattext = findviewbyid(r.id.placebloodsweattext); waitforreadingtext = findviewbyid(r.id.waitforreadingtext); progressbar = findviewbyid(r.id.progressbar); unitstext = findviewbyid(r.id.unitstext); glucoseleveltext = findviewbyid(r.id.glucoseleveltext); descriptiontxt = findviewbyid(r.id.descriptiontxt); detailsbtn = findviewbyid(r.id.detailsbtn); anotherreadingbtn = findviewbyid(r.id.anotherreadingbtn); showbtn = findviewbyid(r.id.button7); dippedbtn = findviewbyid(r.id.button6); stripbtn = findviewbyid(r.id.button8); startbutton = findviewbyid(r.id.btnstripinserted); rgmode = findviewbyid(r.id.rgmode); rbblood = findviewbyid(r.id.rbblood); rbsweat = findviewbyid(r.id.rbsweat); rb_mg_dl = findviewbyid(r.id.rb_mg_dl); rb_mmol_l = findviewbyid(r.id.rb_mmol_l); glucometerswitch = findviewbyid(r.id.glucometerswitch); rgunits = findviewbyid(r.id.rgunits); startbutton.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { if (!rbsweat.ischecked() && !rbblood.ischecked()) { toast.maketext(glucometeractivity.this, \"please select a mode\", toast.length_short).show(); } else { instance.senddatatoarduino(\"start\"); instance.setreading(true); glucometerswitch.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); startbutton.setenabled(false); glucometerimg.setvisibility(view.visible); glucometerattribution.setvisibility(view.visible); insertstriptext.setvisibility(view.visible); uparrow.setvisibility(view.visible); } } }); rgmode.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rbblood: instance.senddatatoarduino(\"blood\"); droplet.setcolorfilter(color.parsecolor(\"#f44336\")); placebloodsweattext.settext(\"place blood on the test strip\"); break; case r.id.rbsweat: instance.senddatatoarduino(\"sweat\"); droplet.setcolorfilter(color.parsecolor(\"#1b95e0\")); placebloodsweattext.settext(\"place sweat on the test strip\"); break; } viewdelay(); } }); glucometerswitch.setoncheckedchangelistener(new compoundbutton.oncheckedchangelistener() { @override public void oncheckedchanged(compoundbutton buttonview, boolean ischecked) { if (ischecked){ instance.senddatatoarduino(\"g_on\"); viewdelay(); }else { instance.senddatatoarduino(\"g_off\"); startbutton.setenabled(false); rbblood.setenabled(false); rbsweat.setenabled(false); rb_mg_dl.setenabled(false); rb_mmol_l.setenabled(false); glucometerswitch.setenabled(false); viewhandler = new handler(); runnable delay = new runnable() { @override public void run() { glucometerswitch.setenabled(true); } }; viewhandler.postdelayed(delay, 1000); } } }); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true); rbblood.setenabled(true); rbsweat.setenabled(true); rb_mg_dl.setenabled(true); rb_mmol_l.setenabled(true); startbutton.setenabled(true); instance.setstringdata(null); instance.setcommand(null); unitstext.setvisibility(view.invisible); glucoseleveltext.setvisibility(view.invisible); descriptiontxt.setvisibility(view.invisible); detailsbtn.setvisibility(view.invisible); anotherreadingbtn.setvisibility(view.invisible); } }); showbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"show\"); } }); stripbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"strip\"); } }); dippedbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setcommand(\"dipped\"); } }); }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation);","code_context_10":"\/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true);","code_context_20":"}); rgunits.setoncheckedchangelistener(new radiogroup.oncheckedchangelistener() { @override public void oncheckedchanged(radiogroup group, int checkedid) { switch (checkedid) { case r.id.rb_mg_dl: \/\/todo display readings in mg\/dl unitstext.settext(\"mg\/dl\"); break; case r.id.rb_mmol_l: \/\/todo display readings in mmol\/l unitstext.settext(\"mmol\/l\"); break; } viewdelay(); } }); detailsbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { \/\/move to new activity intent intent = new intent(glucometeractivity.this, glucosereadingdetailsactivity.class); intent.addflags(intent.flag_activity_no_animation); startactivity(intent); } }); anotherreadingbtn.setonclicklistener(new view.onclicklistener() { @override public void onclick(view v) { instance.setreading(false); glucometerswitch.setenabled(true); rbblood.setenabled(true); rbsweat.setenabled(true); rb_mg_dl.setenabled(true); rb_mmol_l.setenabled(true); startbutton.setenabled(true); instance.setstringdata(null); instance.setcommand(null); unitstext.setvisibility(view.invisible); glucoseleveltext.setvisibility(view.invisible); descriptiontxt.setvisibility(view.invisible);","repo":"W6WM9M\/VitalityMeter"}
{"id":10671,"comment_id":0,"comment":"\/\/ todo: draw a game over message \/\/ feel free to get more creative with this screen. perhaps you could cover the screen in enemy robots?","code":"public void render(spritebatch batch) { viewport.apply(); batch.setprojectionmatrix(viewport.getcamera().combined); batch.begin(); \/\/ todo: draw a game over message \/\/ feel free to get more creative with this screen. perhaps you could cover the screen in enemy robots? float timeelapsed = utils.secondssince(starttime); int enemiestoshow = (int) (constants.enemy_count * (timeelapsed \/ constants.level_end_duration)); for (int i = 0; i < enemiestoshow; i++){ enemy enemy = enemies.get(i); enemy.update(0); enemy.render(batch); } font.draw(batch, constants.game_over_message, viewport.getworldwidth() \/ 2, viewport.getworldheight() \/ 2.5f, 0, align.center, false); batch.end(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"batch.setprojectionmatrix(viewport.getcamera().combined); batch.begin(); \/\/ todo: draw a game over message \/\/ feel free to get more creative with this screen. perhaps you could cover the screen in enemy robots? float timeelapsed = utils.secondssince(starttime); int enemiestoshow = (int) (constants.enemy_count * (timeelapsed \/ constants.level_end_duration));","code_context_10":"public void render(spritebatch batch) { viewport.apply(); batch.setprojectionmatrix(viewport.getcamera().combined); batch.begin(); \/\/ todo: draw a game over message \/\/ feel free to get more creative with this screen. perhaps you could cover the screen in enemy robots? float timeelapsed = utils.secondssince(starttime); int enemiestoshow = (int) (constants.enemy_count * (timeelapsed \/ constants.level_end_duration)); for (int i = 0; i < enemiestoshow; i++){ enemy enemy = enemies.get(i); enemy.update(0); enemy.render(batch); } font.draw(batch, constants.game_over_message, viewport.getworldwidth() \/ 2, viewport.getworldheight() \/ 2.5f, 0, align.center, false); batch.end(); }","code_context_20":"public void render(spritebatch batch) { viewport.apply(); batch.setprojectionmatrix(viewport.getcamera().combined); batch.begin(); \/\/ todo: draw a game over message \/\/ feel free to get more creative with this screen. perhaps you could cover the screen in enemy robots? float timeelapsed = utils.secondssince(starttime); int enemiestoshow = (int) (constants.enemy_count * (timeelapsed \/ constants.level_end_duration)); for (int i = 0; i < enemiestoshow; i++){ enemy enemy = enemies.get(i); enemy.update(0); enemy.render(batch); } font.draw(batch, constants.game_over_message, viewport.getworldwidth() \/ 2, viewport.getworldheight() \/ 2.5f, 0, align.center, false); batch.end(); }","repo":"Sceptres\/ud406"}
{"id":2527,"comment_id":0,"comment":"\/\/ todo: doc","code":"\/\/ todo: doc public static <t extends enum> string getenumi18n(locale locale, string base, t enumtoget) { return language.i18n(locale, base + \".\" + enumtoget.name().tolowercase()); }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"public static <t extends enum> string getenumi18n(locale locale, string base, t enumtoget) { return language.i18n(locale, base + \".\" + enumtoget.name().tolowercase()); }","code_context_10":"public static <t extends enum> string getenumi18n(locale locale, string base, t enumtoget) { return language.i18n(locale, base + \".\" + enumtoget.name().tolowercase()); }","code_context_20":"public static <t extends enum> string getenumi18n(locale locale, string base, t enumtoget) { return language.i18n(locale, base + \".\" + enumtoget.name().tolowercase()); }","repo":"TortleWortle\/CascadeBot"}
{"id":10747,"comment_id":0,"comment":"\/** * todo need implementation i think * @param comments * @return *\/","code":"\/** * todo need implementation i think * @param comments * @return *\/ public jsonobject setmaxcomments(int comments){ jsonobject result = new jsonobject(); if( dbservices.setmaxcommentspervideo(comments)) { result.addproperty(\"msg\", \"max comments to collect for each video is now: \" + comments); } else result.addproperty(\"error\",\"failed to set max comments per video\"); return result; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public jsonobject setmaxcomments(int comments){ jsonobject result = new jsonobject(); if( dbservices.setmaxcommentspervideo(comments)) { result.addproperty(\"msg\", \"max comments to collect for each video is now: \" + comments); } else result.addproperty(\"error\",\"failed to set max comments per video\"); return result; }","code_context_10":"public jsonobject setmaxcomments(int comments){ jsonobject result = new jsonobject(); if( dbservices.setmaxcommentspervideo(comments)) { result.addproperty(\"msg\", \"max comments to collect for each video is now: \" + comments); } else result.addproperty(\"error\",\"failed to set max comments per video\"); return result; }","code_context_20":"public jsonobject setmaxcomments(int comments){ jsonobject result = new jsonobject(); if( dbservices.setmaxcommentspervideo(comments)) { result.addproperty(\"msg\", \"max comments to collect for each video is now: \" + comments); } else result.addproperty(\"error\",\"failed to set max comments per video\"); return result; }","repo":"UCY-LINC-LAB\/YouTube-Twitter-Analysis"}
{"id":2557,"comment_id":0,"comment":"\/\/ todo: if you don't have om ha configured, change the following as appropriate.","code":"static ozoneclient getozoneclient(boolean secure) throws ioexception { ozoneconfiguration conf = new ozoneconfiguration(); \/\/ todo: if you don't have om ha configured, change the following as appropriate. conf.set(\"ozone.om.address\", \"9.29.173.57:9862\"); if (disablechecksum) conf.set(\"ozone.client.checksum.type\", \"none\"); return ozoneclientfactory.getrpcclient(conf); }","classification":"DESIGN","isFinished":true,"code_context_2":"static ozoneclient getozoneclient(boolean secure) throws ioexception { ozoneconfiguration conf = new ozoneconfiguration(); \/\/ todo: if you don't have om ha configured, change the following as appropriate. conf.set(\"ozone.om.address\", \"9.29.173.57:9862\"); if (disablechecksum)","code_context_10":"static ozoneclient getozoneclient(boolean secure) throws ioexception { ozoneconfiguration conf = new ozoneconfiguration(); \/\/ todo: if you don't have om ha configured, change the following as appropriate. conf.set(\"ozone.om.address\", \"9.29.173.57:9862\"); if (disablechecksum) conf.set(\"ozone.client.checksum.type\", \"none\"); return ozoneclientfactory.getrpcclient(conf); }","code_context_20":"static ozoneclient getozoneclient(boolean secure) throws ioexception { ozoneconfiguration conf = new ozoneconfiguration(); \/\/ todo: if you don't have om ha configured, change the following as appropriate. conf.set(\"ozone.om.address\", \"9.29.173.57:9862\"); if (disablechecksum) conf.set(\"ozone.client.checksum.type\", \"none\"); return ozoneclientfactory.getrpcclient(conf); }","repo":"SincereXIA\/ozonerpc2"}
{"id":10797,"comment_id":0,"comment":"\/* temp buffer for storing labels *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/","code_context_10":"@doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1);","code_context_20":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) {","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":1,"comment":"\/* always use rankdir to determine how records are laid out *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text;","code_context_10":"@original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text);","code_context_20":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text.","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":2,"comment":"\/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1);","code_context_10":"st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));;","code_context_20":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y);","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":3,"comment":"\/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text);","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf);","code_context_10":"\/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text.","code_context_20":"@original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides);","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":4,"comment":"\/\/ reclblp = \"\\\\n\";","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); }","code_context_10":"flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n));","code_context_20":"public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x));","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":5,"comment":"\/\/ info = parse_reclbl(n, flip, not(0), textbuf);","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf);","code_context_10":"z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/","code_context_20":"entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":6,"comment":"\/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) {","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n));","code_context_10":"if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/","code_context_20":"int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":7,"comment":"\/\/ \/* should check that the record really won't fit, e.g., there may be no text.","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/","code_context_10":"unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides);","code_context_20":"\/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":8,"comment":"\/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n));","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ }","code_context_10":"unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x));","code_context_20":"flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":9,"comment":"\/\/ *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else {","code_context_10":"unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering","code_context_20":"z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":10,"comment":"\/\/ }","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"NONSATD","isFinished":true,"code_context_2":"unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x);","code_context_10":"} memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/","code_context_20":"len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":11,"comment":"\/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"DEFECT","isFinished":true,"code_context_2":"} resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x));","code_context_10":"unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","code_context_20":"if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":10797,"comment_id":12,"comment":"\/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/","code":"@unused @doc(\"init 'record' node\") @reviewed(when = \"02\/12\/2020\") @original(version=\"2.38.0\", path=\"lib\/common\/shapes.c\", name=\"record_init\", key=\"h2lcuthzwljbcjwdeidw1jiv\", definition=\"static void record_init(node_t * n)\") public static void record_init(st_agnode_s n) { entering(\"h2lcuthzwljbcjwdeidw1jiv\",\"record_init\"); try { st_field_t info; final st_pointf ul = new st_pointf(), sz = new st_pointf(); boolean flip; int len; cstring textbuf; \/* temp buffer for storing labels *\/ int sides = bottom | right | top | left; \/* always use rankdir to determine how records are laid out *\/ flip = not(gd_realflip(agraphof(n))); z.z().reclblp = nd_label(n).text; len = strlen(z.z().reclblp); \/* for some forgotten reason, an empty label is parsed into a space, so * we need at least two bytes in textbuf. *\/ len = max(len, 1); textbuf = cstring.gmalloc(len + 1); if (n(info = parse_reclbl(n, flip, not(0), textbuf))) { unsupported(\"7iezaksu9hyxhmv3r4cp4o529\"); \/\/ agerr(agerr, \"bad label format %s\\n\", nd_label(n)->text); unsupported(\"8f1id7rqm71svssnxbjo0uwcu\"); \/\/ reclblp = \"\\\\n\"; unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","classification":"DESIGN","isFinished":true,"code_context_2":"pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally {","code_context_10":"unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","code_context_20":"unsupported(\"2wv3zfqhq53941rwk4vu9p9th\"); \/\/ info = parse_reclbl(n, flip, not(0), textbuf); } memory.free(textbuf); size_reclbl(n, info); sz.x = points(nd_width(n));; sz.y = points(nd_height(n)); if (mapbool(late_string(n, z.z().n_fixed, new cstring(\"false\")))) { unsupported(\"8iu51xbtntpdf5sc00g91djym\"); \/\/ if ((sz.x < info->size.x) || (sz.y < info->size.y)) { unsupported(\"4vs5u30jzsrn6fpjd327xjf7r\"); \/\/ \/* should check that the record really won't fit, e.g., there may be no text. unsupported(\"7k6yytek9nu1ihxix2880667g\"); \/\/ agerr(agwarn, \"node '%s' size may be too small\\n\", agnameof(n)); unsupported(\"bnetqzovnscxile7ao44kc0qd\"); \/\/ *\/ unsupported(\"flupwh3kosf3fkhkxllllt1\"); \/\/ } } else { sz.x = max(info.size.x, sz.x); sz.y = max(info.size.y, sz.y); } resize_reclbl(info, sz, mapbool(late_string(n, z.z().n_nojustify, new cstring(\"false\")))); ul.___(pointfof(-sz.x \/ 2., sz.y \/ 2.)); \/* fixme - is this still true: suspected to introduce ronding error - see kluge below *\/ pos_reclbl(info, ul, sides); nd_width(n, ps2inch(info.size.x)); nd_height(n, ps2inch(info.size.y + 1)); \/* kluge!! +1 to fix rounding diff between layout and rendering otherwise we can get -1 coords in output *\/ nd_shape_info(n, info); } finally { leaving(\"h2lcuthzwljbcjwdeidw1jiv\",\"poly_init\"); } }","repo":"SandraBSofiaH\/Final-UMldoclet"}
{"id":19017,"comment_id":0,"comment":"\/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support","code":"private table buildheader() { skin skin = getskin(); squarebutton ffback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); ffback.fliphorizontal(); playback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); playback.fliphorizontal(); play = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); squarebutton ffforward = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); repeatbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-repeat\"), true); newbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-new\")); newbtn.geticoncell().padtop(2).padleft(1); squarebutton deletebtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-delete\")); upbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); upbtn.flipvertical(); downbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); downbtn.flipvertical(); downbtn.fliphorizontal(); table header = new table(); header.setbackground(skin.getdrawable(\"timeline-top-bar-bg\")); table toppart = new table(); table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left(); toppart.add(repeatbtn).padleft(6).left(); toppart.add().growx().minwidth(20); toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin); typelabel.setcolor(colorlibrary.font_gray); bottompart.add(typelabel).padbottom(2).padleft(5).left().expandx(); header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptostart); } }); ffforward.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptoend); } }); playback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.rewind); } }); play.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.play); } }); repeatbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.toggleloop); } }); deletebtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.deleteselection); } }); newbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.newitem); } }); upbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.up); } }); downbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.down); } }); return header; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left();","code_context_10":"squarebutton deletebtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-delete\")); upbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); upbtn.flipvertical(); downbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); downbtn.flipvertical(); downbtn.fliphorizontal(); table header = new table(); header.setbackground(skin.getdrawable(\"timeline-top-bar-bg\")); table toppart = new table(); table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left(); toppart.add(repeatbtn).padleft(6).left(); toppart.add().growx().minwidth(20); toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin);","code_context_20":"skin skin = getskin(); squarebutton ffback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); ffback.fliphorizontal(); playback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); playback.fliphorizontal(); play = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); squarebutton ffforward = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); repeatbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-repeat\"), true); newbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-new\")); newbtn.geticoncell().padtop(2).padleft(1); squarebutton deletebtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-delete\")); upbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); upbtn.flipvertical(); downbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); downbtn.flipvertical(); downbtn.fliphorizontal(); table header = new table(); header.setbackground(skin.getdrawable(\"timeline-top-bar-bg\")); table toppart = new table(); table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left(); toppart.add(repeatbtn).padleft(6).left(); toppart.add().growx().minwidth(20); toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin); typelabel.setcolor(colorlibrary.font_gray); bottompart.add(typelabel).padbottom(2).padleft(5).left().expandx(); header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) {","repo":"TheSenPie\/talos"}
{"id":19017,"comment_id":1,"comment":"\/** * build header actions *\/","code":"private table buildheader() { skin skin = getskin(); squarebutton ffback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); ffback.fliphorizontal(); playback = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); playback.fliphorizontal(); play = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\"), true); squarebutton ffforward = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-ff\")); repeatbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-repeat\"), true); newbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-new\")); newbtn.geticoncell().padtop(2).padleft(1); squarebutton deletebtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-delete\")); upbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); upbtn.flipvertical(); downbtn = new squarebutton(skin, skin.getdrawable(\"timeline-btn-icon-play\")); downbtn.flipvertical(); downbtn.fliphorizontal(); table header = new table(); header.setbackground(skin.getdrawable(\"timeline-top-bar-bg\")); table toppart = new table(); table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left(); toppart.add(repeatbtn).padleft(6).left(); toppart.add().growx().minwidth(20); toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin); typelabel.setcolor(colorlibrary.font_gray); bottompart.add(typelabel).padbottom(2).padleft(5).left().expandx(); header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptostart); } }); ffforward.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptoend); } }); playback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.rewind); } }); play.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.play); } }); repeatbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.toggleloop); } }); deletebtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.deleteselection); } }); newbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.newitem); } }); upbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.up); } }); downbtn.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.down); } }); return header; }","classification":"NONSATD","isFinished":true,"code_context_2":"header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override","code_context_10":"toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin); typelabel.setcolor(colorlibrary.font_gray); bottompart.add(typelabel).padbottom(2).padleft(5).left().expandx(); header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptostart); } }); ffforward.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptoend);","code_context_20":"table header = new table(); header.setbackground(skin.getdrawable(\"timeline-top-bar-bg\")); table toppart = new table(); table bottompart = new table(); toppart.add(ffback).padleft(6).left(); \/\/toppart.add(playback).padleft(6).left(); \/\/ todo: add this back when we can support toppart.add(play).padleft(6).left(); toppart.add(ffforward).padleft(6).left(); toppart.add(repeatbtn).padleft(6).left(); toppart.add().growx().minwidth(20); toppart.add(upbtn).padright(6).right(); toppart.add(downbtn).padright(10).right(); toppart.add(newbtn).right().padright(6); toppart.add(deletebtn).right().padright(6); topactioncell = toppart.add().right(); typelabel = new label(\"items\", skin); typelabel.setcolor(colorlibrary.font_gray); bottompart.add(typelabel).padbottom(2).padleft(5).left().expandx(); header.add(toppart).height(33).padbottom(1).growx().row(); header.add(bottompart).height(16).growx().row(); \/** * build header actions *\/ ffback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptostart); } }); ffforward.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.skiptoend); } }); playback.addlistener(new clicklistener() { @override public void clicked(inputevent event, float x, float y) { timeline.onactionbuttonclicked(timelinelistener.type.rewind); } }); play.addlistener(new clicklistener() { @override","repo":"TheSenPie\/talos"}
{"id":10974,"comment_id":0,"comment":"\/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model.","code":"public map<string, double> classifyimagevgg16(iplimage iplimage) throws ioexception { nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","classification":"DESIGN","isFinished":true,"code_context_2":"bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image);","code_context_10":"public map<string, double> classifyimagevgg16(iplimage iplimage) throws ioexception { nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_20":"public map<string, double> classifyimagevgg16(iplimage iplimage) throws ioexception { nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","repo":"ShaunHolt\/myrobotlab"}
{"id":10974,"comment_id":1,"comment":"\/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions);","code":"public map<string, double> classifyimagevgg16(iplimage iplimage) throws ioexception { nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","classification":"DESIGN","isFinished":true,"code_context_2":"indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_10":"nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_20":"public map<string, double> classifyimagevgg16(iplimage iplimage) throws ioexception { nativeimageloader loader = new nativeimageloader(224, 224, 3); bufferedimage buffimg = opencv.tobufferedimage(iplimage); indarray image = loader.asmatrix(buffimg); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); log.info(\"complete with output from vgg16..\"); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","repo":"ShaunHolt\/myrobotlab"}
{"id":10975,"comment_id":0,"comment":"\/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model.","code":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","classification":"DESIGN","isFinished":true,"code_context_2":"nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image);","code_context_10":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_20":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","repo":"ShaunHolt\/myrobotlab"}
{"id":10975,"comment_id":1,"comment":"\/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions);","code":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","classification":"DESIGN","isFinished":true,"code_context_2":"scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_10":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","code_context_20":"public map<string, double> classifyimagefilevgg16(string filename) throws ioexception { file file = new file(filename); nativeimageloader loader = new nativeimageloader(224, 224, 3); indarray image = loader.asmatrix(file); \/\/ todo: we should consider the model as not only the model, but also the \/\/ input transforms \/\/ for that model. datanormalization scaler = new vgg16imagepreprocessor(); scaler.transform(image); indarray[] output = vgg16.output(false, image); \/\/ todo: return a more native datastructure! \/\/ string predictions = trainedmodels.vgg16.decodepredictions(output[0]); \/\/ log.info(\"image predictions: {}\", predictions); return decodevgg16predictions(output[0]); }","repo":"ShaunHolt\/myrobotlab"}
{"id":10994,"comment_id":0,"comment":"\/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache...","code":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","classification":"DESIGN","isFinished":true,"code_context_2":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0;","code_context_10":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","code_context_20":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","repo":"Y-D-Lu\/rr_frameworks_base"}
{"id":10994,"comment_id":1,"comment":"\/\/ regular equals because of null","code":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","classification":"NONSATD","isFinished":true,"code_context_2":"storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else {","code_context_10":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","code_context_20":"private long getreservedcachesize(string uuid) { \/\/ todo: revisit the cache size after running more storage tests. \/\/ todo: figure out how to ensure extservices has the permissions to call \/\/ storagestatsmanager, because this is ignoring the cache... storagemanager storagemanager = getsystemservice(storagemanager.class); long freebytes = 0; if (uuid == storagemanager.uuid_private_internal) { \/\/ regular equals because of null freebytes = environment.getdatadirectory().getusablespace(); } else { final volumeinfo vol = storagemanager.findvolumebyuuid(uuid); freebytes = vol.getpath().getusablespace(); } return math.round(freebytes * cache_reserve_ratio); }","repo":"Y-D-Lu\/rr_frameworks_base"}
{"id":11115,"comment_id":0,"comment":"\/** * create an intent for emailing attendees of an event. * * @param resources the resources for translating strings. * @param eventtitle the title of the event to use as the email subject. * @param body the default text for the email body. * @param toemails the list of emails for the 'to' line. * @param ccemails the list of emails for the 'cc' line. * @param owneraccount the owner account to use as the email sender. *\/","code":"\/** * create an intent for emailing attendees of an event. * * @param resources the resources for translating strings. * @param eventtitle the title of the event to use as the email subject. * @param body the default text for the email body. * @param toemails the list of emails for the 'to' line. * @param ccemails the list of emails for the 'cc' line. * @param owneraccount the owner account to use as the email sender. *\/ public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","code_context_10":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","code_context_20":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":1,"comment":"\/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients).","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); }","code_context_10":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) {","code_context_20":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":2,"comment":"\/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"DEFECT","isFinished":true,"code_context_2":"throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null;","code_context_10":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense","code_context_20":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) {","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":3,"comment":"\/\/ use the event title as the email subject (prepended with 're: ').","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) {","code_context_10":"if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder();","code_context_20":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":4,"comment":"\/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does).","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\");","code_context_10":"\/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i));","code_context_20":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":5,"comment":"\/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) {","code_context_10":"if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject);","code_context_20":"\/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":6,"comment":"\/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); }","code_context_10":"\/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body);","code_context_20":"tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring();","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":7,"comment":"\/\/ add the subject parameter.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject);","code_context_10":"\/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) {","code_context_20":"if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring();","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":8,"comment":"\/\/ add the subject parameter.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject);","code_context_10":"\/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) {","code_context_20":"if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring();","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":9,"comment":"\/\/ add the cc parameters.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) {","code_context_10":"} } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri);","code_context_20":"uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) {","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":10,"comment":"\/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) {","code_context_10":"\/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount);","code_context_20":"for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":11,"comment":"\/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount);","code_context_10":"} } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","code_context_20":"uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11115,"comment_id":12,"comment":"\/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body.","code":"public static intent createemailattendeesintent(resources resources, string eventtitle, string body, list<string> toemails, list<string> ccemails, string owneraccount) { list<string> tolist = toemails; list<string> cclist = ccemails; if (toemails.size() <= 0) { if (ccemails.size() <= 0) { \/\/ todo: return a send intent if no one to email to, to at least populate \/\/ a draft email with the subject (and no recipients). throw new illegalargumentexception(\"both toemails and ccemails are empty.\"); } \/\/ email app does not work with no \"to\" recipient. move all 'cc' to 'to' \/\/ in this case. tolist = ccemails; cclist = null; } \/\/ use the event title as the email subject (prepended with 're: '). string subject = null; if (eventtitle != null) { subject = resources.getstring(r.string.email_subject_prefix) + eventtitle; } \/\/ use the sendto intent with a 'mailto' uri, because using send will cause \/\/ the picker to show apps like text messaging, which does not make sense \/\/ for email addresses. we put all data in the uri instead of using the extra \/\/ intent fields (ie. extra_cc, etc) because some email apps might not handle \/\/ those (though gmail does). uri.builder uribuilder = new uri.builder(); uribuilder.scheme(\"mailto\"); \/\/ we will append the first email to the 'mailto' field later (because the \/\/ current state of the email app requires it). add the remaining 'to' values \/\/ here. when the email codebase is updated, we can simplify this. if (tolist.size() > 1) { for (int i = 1; i < tolist.size(); i++) { \/\/ the email app requires repeated parameter settings instead of \/\/ a single comma-separated list. uribuilder.appendqueryparameter(\"to\", tolist.get(i)); } } \/\/ add the subject parameter. if (subject != null) { uribuilder.appendqueryparameter(\"subject\", subject); } \/\/ add the subject parameter. if (body != null) { uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","classification":"NONSATD","isFinished":true,"code_context_2":"intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body);","code_context_10":"string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","code_context_20":"uribuilder.appendqueryparameter(\"body\", body); } \/\/ add the cc parameters. if (cclist != null && cclist.size() > 0) { for (string email : cclist) { uribuilder.appendqueryparameter(\"cc\", email); } } \/\/ insert the first email after 'mailto:' in the uri manually since uri.builder \/\/ doesn't seem to have a way to do this. string uri = uribuilder.tostring(); if (uri.startswith(\"mailto:\")) { stringbuilder builder = new stringbuilder(uri); builder.insert(7, uri.encode(tolist.get(0))); uri = builder.tostring(); } \/\/ start the email intent. email from the account of the calendar owner in case there \/\/ are multiple email accounts. intent emailintent = new intent(intent.action_sendto, uri.parse(uri)); emailintent.putextra(\"fromaccountstring\", owneraccount); \/\/ workaround a email bug that overwrites the body with this intent extra. if not \/\/ set, it clears the body. if (body != null) { emailintent.putextra(intent.extra_text, body); } return intent.createchooser(emailintent, resources.getstring(r.string.email_picker_label)); }","repo":"Shusshu\/Android-RecurrencePicker"}
{"id":11181,"comment_id":0,"comment":"\/** * return the biome which should be present at the provided location. * <p> * notes: * <p> * this method <b>must<\/b> be completely thread safe and able to handle * multiple concurrent callers. * <p> * this method should only return biomes which are present in the list * returned by {@link #getbiomes(worldinfo)} * <p> * this method should <b>never<\/b> return {@link biome#custom}. * * @param worldinfo the world info of the world the biome will be used for * @param x the x-coordinate from world origin * @param y the y-coordinate from world origin * @param z the z-coordinate from world origin * @return biome for the given location *\/","code":"\/** * return the biome which should be present at the provided location. * <p> * notes: * <p> * this method <b>must<\/b> be completely thread safe and able to handle * multiple concurrent callers. * <p> * this method should only return biomes which are present in the list * returned by {@link #getbiomes(worldinfo)} * <p> * this method should <b>never<\/b> return {@link biome#custom}. * * @param worldinfo the world info of the world the biome will be used for * @param x the x-coordinate from world origin * @param y the y-coordinate from world origin * @param z the z-coordinate from world origin * @return biome for the given location *\/ @notnull public abstract biome getbiome(@notnull worldinfo worldinfo, int x, int y, int z);","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@notnull public abstract biome getbiome(@notnull worldinfo worldinfo, int x, int y, int z);","code_context_10":"@notnull public abstract biome getbiome(@notnull worldinfo worldinfo, int x, int y, int z);","code_context_20":"@notnull public abstract biome getbiome(@notnull worldinfo worldinfo, int x, int y, int z);","repo":"abcd1234-byte\/spigot2"}
{"id":3159,"comment_id":0,"comment":"\/\/ todo: array types not supported yet ...","code":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","classification":"DESIGN","isFinished":true,"code_context_2":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type);","code_context_10":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type","code_context_20":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","repo":"Stratio\/spark-solr"}
{"id":3159,"comment_id":1,"comment":"\/\/ treat strings with multiple terms as text only if using the default!","code":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","classification":"NONSATD","isFinished":true,"code_context_2":"if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value;","code_context_10":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","code_context_20":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","repo":"Stratio\/spark-solr"}
{"id":3159,"comment_id":2,"comment":"\/\/ don't auto-map if we don't have a type","code":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","code_context_10":"return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","code_context_20":"private static void addfield(solrinputdocument doc, string fieldname, object value, class type, string dynamicfieldsuffix) { if (type.isarray()) return; \/\/ todo: array types not supported yet ... if (dynamicfieldsuffix == null) { dynamicfieldsuffix = getdefaultdynamicfieldmapping(type); \/\/ treat strings with multiple terms as text only if using the default! if (\"_s\".equals(dynamicfieldsuffix)) { string str = (string)value; if (str.indexof(\" \") != -1) dynamicfieldsuffix = \"_t\"; } } if (dynamicfieldsuffix != null) \/\/ don't auto-map if we don't have a type doc.addfield(fieldname + dynamicfieldsuffix, value); }","repo":"Stratio\/spark-solr"}
{"id":11407,"comment_id":0,"comment":"\/\/ todo: voir comment le nommer. voir si le deplacer dans une autre classe","code":"\/\/ todo: voir comment le nommer. voir si le deplacer dans une autre classe protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","classification":"DESIGN","isFinished":true,"code_context_2":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","code_context_10":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","code_context_20":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","repo":"abarhub\/tinyvfs"}
{"id":11407,"comment_id":1,"comment":"\/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname());","code":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","classification":"NONSATD","isFinished":true,"code_context_2":"path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else {","code_context_10":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/","code_context_20":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ }","repo":"abarhub\/tinyvfs"}
{"id":11407,"comment_id":2,"comment":"\/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) {","code":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","classification":"NONSATD","isFinished":true,"code_context_2":"string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first);","code_context_10":"for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","code_context_20":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","repo":"abarhub\/tinyvfs"}
{"id":11407,"comment_id":3,"comment":"\/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ }","code":"protected path getrealpath2(tvfsabstractpath path) { list<string> list = new arraylist<>(); for (string s : path.path) { list.add(s); } path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p;","code_context_10":"\/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","code_context_20":"} path p; if (list.isempty()) { \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname()); p = filesystem.getrootpath(); } else { string first = \"\"; string others[] = null; \/\/ if (list.size() >= 1) { \/\/ first = list.get(0); \/\/ } \/\/ if (list.size() > 1) { \/\/ others = new string[list.size() - 1]; \/\/ \/\/ for (int i = 1; i < list.size(); i++) { \/\/ others[i - 1] = list.get(i); \/\/ } \/\/ } \/\/if (others == null) { p = filesystem.getrootpath().resolve(list.stream().collect(collectors.joining(filesystem.getseparator()))); \/\/p = virtualfs.gettvfilesystem().getpath(virtualfs.getname().getname(),first); \/\/ } else { \/\/ p = virtualfs.gettvfilesystem().getpath(first, others); \/\/ } } return p; }","repo":"abarhub\/tinyvfs"}
{"id":11482,"comment_id":0,"comment":"\/\/ filler","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void populategui() { \/\/ filler this.getfiller(); \/\/ items","code_context_10":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist());","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":1,"comment":"\/\/ items","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) {","code_context_10":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event ->","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) {","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":2,"comment":"\/\/ args","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue();","code_context_10":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true);","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":3,"comment":"\/\/ add","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> {","code_context_10":"this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d)","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update();","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":4,"comment":"\/\/ cancel","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args","code_context_10":"{ \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return;","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":5,"comment":"\/\/ args","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue();","code_context_10":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true);","code_context_20":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":6,"comment":"\/\/ check","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) {","code_context_10":"list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update","code_context_20":"\/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":7,"comment":"\/\/ todo: make it so collectors don't pick up items which can't be sold","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; }","code_context_10":"{ \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); }","code_context_20":"for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":8,"comment":"\/\/ deposit & inform","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\");","code_context_10":"\/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next()));","code_context_20":"material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":9,"comment":"\/\/ update","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); }));","code_context_10":"\/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","code_context_20":"list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","repo":"Workinq\/AsyncCollectors"}
{"id":11482,"comment_id":10,"comment":"\/\/ navigation","code":"@override public void populategui() { \/\/ filler this.getfiller(); \/\/ items for (map.entry<material, integer> entry : collector.getcontents().entryset()) { \/\/ args material material = entry.getkey(); int startamount = entry.getvalue(); double startvalue = plugin.getcollectormanager().value(collector, material); list<string> lore = color.color(plugin.getconfig().getstringlist(\"guis.contents.item.lore\").stream().map(text -> text.replace(\"%amount%\", string.format(\"%,d\", startamount)).replace(\"%value%\", string.format(\"%,.1f\", startvalue))).collect(collectors.tolist())); list<component> components = lore.stream().map(component::text).collect(collectors.tolist()); \/\/ add this.additem(itembuilder.from(material).name(component.text(this.getnicedenumstring(material.name()))).lore(components).asguiitem(event -> { \/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","classification":"NONSATD","isFinished":true,"code_context_2":"})); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next()));","code_context_10":"return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","code_context_20":"\/\/ cancel event.setcancelled(true); \/\/ args player player = (player) event.getwhoclicked(); int amount = collector.getmaterialamount(material); double total = plugin.getcollectormanager().sell(collector, material); \/\/ check if (total == 0.0d) { \/\/ todo: make it so collectors don't pick up items which can't be sold return; } \/\/ deposit & inform plugin.getmoneymanager().pay(player.getuniqueid(), total); string message = plugin.getconfig().getstring(\"messages.material-sold\"); if (message != null && !message.isempty()) player.sendmessage(color.color(message.replace(\"%amount%\", string.format(\"%,d\", amount)).replace(\"%material%\", this.getnicedenumstring(material.name())).replace(\"%total%\", string.format(\"%.1f\", total)))); \/\/ update this.update(); })); } \/\/ navigation this.setitem(3, 3, itembuilder.from(material.arrow).name(component.text(color.color(\"previous\"))).asguiitem(event -> this.previous())); this.setitem(3, 7, itembuilder.from(material.arrow).name(component.text(color.color(\"next\"))).asguiitem(event -> this.next())); }","repo":"Workinq\/AsyncCollectors"}
{"id":3400,"comment_id":0,"comment":"\/\/ lets switch to gravia's mvn coordinates","code":"protected list<string> updateprovisioning(map<string, file> artifacts, provisioner provisionservice) throws exception { resourceinstaller resourceinstaller = provisionservice.getresourceinstaller(); map<resourceidentity, resource> installedresources = getinstalledresources(provisionservice); map<requirement, resource> requirements = new hashmap<requirement, resource>(); set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\"); set<resourcehandle> resourcehandles = new linkedhashset<>(); resourceinstaller.context context = new defaultinstallercontext(resourcestoinstall, requirements); for (resource resource : resourcestoinstall) { resourcehandles.add(resourceinstaller.installresource(context, resource)); } logger.info(\"got \" + resourcehandles.size() + \" resource handle(s)\"); for (resourcehandle resourcehandle : resourcehandles) { resourcehandlemap.put(resourcehandle.getresource().getidentity(), resourcehandle); } } return resourceurisinstalled; }","classification":"NONSATD","isFinished":true,"code_context_2":"coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords);","code_context_10":"list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared);","code_context_20":"protected list<string> updateprovisioning(map<string, file> artifacts, provisioner provisionservice) throws exception { resourceinstaller resourceinstaller = provisionservice.getresourceinstaller(); map<resourceidentity, resource> installedresources = getinstalledresources(provisionservice); map<requirement, resource> requirements = new hashmap<requirement, resource>(); set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity);","repo":"WillemJiang\/fabric8"}
{"id":3400,"comment_id":1,"comment":"\/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly?","code":"protected list<string> updateprovisioning(map<string, file> artifacts, provisioner provisionservice) throws exception { resourceinstaller resourceinstaller = provisionservice.getresourceinstaller(); map<resourceidentity, resource> installedresources = getinstalledresources(provisionservice); map<requirement, resource> requirements = new hashmap<requirement, resource>(); set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\"); set<resourcehandle> resourcehandles = new linkedhashset<>(); resourceinstaller.context context = new defaultinstallercontext(resourcestoinstall, requirements); for (resource resource : resourcestoinstall) { resourcehandles.add(resourceinstaller.installresource(context, resource)); } logger.info(\"got \" + resourcehandles.size() + \" resource handle(s)\"); for (resourcehandle resourcehandle : resourcehandles) { resourcehandlemap.put(resourcehandle.getresource().getidentity(), resourcehandle); } } return resourceurisinstalled; }","classification":"DESIGN","isFinished":true,"code_context_2":"continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared);","code_context_10":"coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them","code_context_20":"set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } }","repo":"WillemJiang\/fabric8"}
{"id":3400,"comment_id":2,"comment":"\/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;)","code":"protected list<string> updateprovisioning(map<string, file> artifacts, provisioner provisionservice) throws exception { resourceinstaller resourceinstaller = provisionservice.getresourceinstaller(); map<resourceidentity, resource> installedresources = getinstalledresources(provisionservice); map<requirement, resource> requirements = new hashmap<requirement, resource>(); set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\"); set<resourcehandle> resourcehandles = new linkedhashset<>(); resourceinstaller.context context = new defaultinstallercontext(resourcestoinstall, requirements); for (resource resource : resourcestoinstall) { resourcehandles.add(resourceinstaller.installresource(context, resource)); } logger.info(\"got \" + resourcehandles.size() + \" resource handle(s)\"); for (resourcehandle resourcehandle : resourcehandles) { resourcehandlemap.put(resourcehandle.getresource().getidentity(), resourcehandle); } } return resourceurisinstalled; }","classification":"DESIGN","isFinished":true,"code_context_2":"if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else {","code_context_10":"\/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) {","code_context_20":"coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource);","repo":"WillemJiang\/fabric8"}
{"id":3400,"comment_id":3,"comment":"\/\/ todo should not really happen when we can ask about the installed resources","code":"protected list<string> updateprovisioning(map<string, file> artifacts, provisioner provisionservice) throws exception { resourceinstaller resourceinstaller = provisionservice.getresourceinstaller(); map<resourceidentity, resource> installedresources = getinstalledresources(provisionservice); map<requirement, resource> requirements = new hashmap<requirement, resource>(); set<map.entry<string, file>> entries = artifacts.entryset(); list<resource> resourcestoinstall = new arraylist<resource>(); list<string> resourceurisinstalled = new arraylist<string>(); updatestatus(\"installing\", null, null); for (map.entry<string, file> entry : entries) { string name = entry.getkey(); file file = entry.getvalue(); string coords = name; int idx = coords.lastindexof(':'); if (idx > 0) { coords = name.substring(idx + 1); } \/\/ lets switch to gravia's mvn coordinates coords = coords.replace('\/', ':'); mavencoordinates mvncoords = parse(coords); url url = file.touri().tourl(); if (url == null) { logger.warn(\"could not find url for file \" + file); continue; } \/\/ todo lets just detect wars for now for servlet engines - how do we decide on wildfly? boolean isshared = !iswar(name, file); resource resource = findmavenresource(mvncoords, url, isshared); if (resource == null) { logger.warn(\"could not find resource for \" + mvncoords + \" and \" + url); } else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\"); set<resourcehandle> resourcehandles = new linkedhashset<>(); resourceinstaller.context context = new defaultinstallercontext(resourcestoinstall, requirements); for (resource resource : resourcestoinstall) { resourcehandles.add(resourceinstaller.installresource(context, resource)); } logger.info(\"got \" + resourcehandles.size() + \" resource handle(s)\"); for (resourcehandle resourcehandle : resourcehandles) { resourcehandlemap.put(resourcehandle.getresource().getidentity(), resourcehandle); } } return resourceurisinstalled; }","classification":"DESIGN","isFinished":true,"code_context_2":"resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else {","code_context_10":"resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\");","code_context_20":"} else { resourceidentity identity = resource.getidentity(); resource oldresource = installedresources.remove(identity); if (oldresource == null && !resourcehandlemap.containskey(identity)) { if (isshared) { \/\/ todo lest not deploy shared stuff for now since bundles throw an exception when trying to stop them \/\/ which breaks the tests ;) logger.debug(\"todo not installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); } else { logger.info(\"installing \" + (isshared ? \"shared\" : \"non-shared\") + \" resource: \" + identity); resourcestoinstall.add(resource); resourceurisinstalled.add(name); } } } } for (resource installedresource : installedresources.values()) { resourceidentity identity = installedresource.getidentity(); resourcehandle resourcehandle = resourcehandlemap.get(identity); if (resourcehandle == null) { \/\/ todo should not really happen when we can ask about the installed resources logger.warn(\"todo: cannot uninstall \" + installedresource + \" as we have no handle!\"); } else { logger.info(\"uninstalling \" + installedresource); resourcehandle.uninstall(); resourcehandlemap.remove(identity); logger.info(\"uninstalled \" + installedresource); } } if (resourcestoinstall.size() > 0) { logger.info(\"installing \" + resourcestoinstall.size() + \" resource(s)\"); set<resourcehandle> resourcehandles = new linkedhashset<>(); resourceinstaller.context context = new defaultinstallercontext(resourcestoinstall, requirements); for (resource resource : resourcestoinstall) { resourcehandles.add(resourceinstaller.installresource(context, resource)); } logger.info(\"got \" + resourcehandles.size() + \" resource handle(s)\"); for (resourcehandle resourcehandle : resourcehandles) { resourcehandlemap.put(resourcehandle.getresource().getidentity(), resourcehandle); } }","repo":"WillemJiang\/fabric8"}
{"id":3401,"comment_id":0,"comment":"\/\/todo: this needs to be fixed at gravia","code":"\/\/todo: this needs to be fixed at gravia private static mavencoordinates parse(string coordinates) { mavencoordinates result; string[] parts = coordinates.split(\":\"); if (parts.length == 3) { result = mavencoordinates.create(parts[0], parts[1], parts[2], null, null); } else if (parts.length == 4) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], null); } else if (parts.length == 5) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], parts[4]); } else { throw new illegalargumentexception(\"invalid coordinates: \" + coordinates); } return result; }","classification":"DEFECT","isFinished":true,"code_context_2":"private static mavencoordinates parse(string coordinates) { mavencoordinates result; string[] parts = coordinates.split(\":\"); if (parts.length == 3) { result = mavencoordinates.create(parts[0], parts[1], parts[2], null, null); } else if (parts.length == 4) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], null); } else if (parts.length == 5) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], parts[4]); } else { throw new illegalargumentexception(\"invalid coordinates: \" + coordinates); } return result; }","code_context_10":"private static mavencoordinates parse(string coordinates) { mavencoordinates result; string[] parts = coordinates.split(\":\"); if (parts.length == 3) { result = mavencoordinates.create(parts[0], parts[1], parts[2], null, null); } else if (parts.length == 4) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], null); } else if (parts.length == 5) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], parts[4]); } else { throw new illegalargumentexception(\"invalid coordinates: \" + coordinates); } return result; }","code_context_20":"private static mavencoordinates parse(string coordinates) { mavencoordinates result; string[] parts = coordinates.split(\":\"); if (parts.length == 3) { result = mavencoordinates.create(parts[0], parts[1], parts[2], null, null); } else if (parts.length == 4) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], null); } else if (parts.length == 5) { result = mavencoordinates.create(parts[0], parts[1], parts[2], parts[3], parts[4]); } else { throw new illegalargumentexception(\"invalid coordinates: \" + coordinates); } return result; }","repo":"WillemJiang\/fabric8"}
{"id":19814,"comment_id":0,"comment":"\/** * validates the data on entering the corresponding parse tree node. * * @throws datamodelexception a violation of data model rules *\/","code":"\/** * validates the data on entering the corresponding parse tree node. * * @throws datamodelexception a violation of data model rules *\/ @override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_10":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_20":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","repo":"airlenet\/yang-maven-plugin"}
{"id":19814,"comment_id":1,"comment":"\/\/ todo auto-generated method stub, to be implemented by parser","code":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_10":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_20":"@override public void validatedataonentry() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","repo":"airlenet\/yang-maven-plugin"}
{"id":19815,"comment_id":0,"comment":"\/** * validates the data on exiting the corresponding parse tree node. * * @throws datamodelexception a violation of data model rules *\/","code":"\/** * validates the data on exiting the corresponding parse tree node. * * @throws datamodelexception a violation of data model rules *\/ @override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_10":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_20":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","repo":"airlenet\/yang-maven-plugin"}
{"id":19815,"comment_id":1,"comment":"\/\/ todo auto-generated method stub, to be implemented by parser","code":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_10":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","code_context_20":"@override public void validatedataonexit() throws datamodelexception { \/\/ todo auto-generated method stub, to be implemented by parser }","repo":"airlenet\/yang-maven-plugin"}
{"id":19923,"comment_id":0,"comment":"\/\/todo send setting level frame and change shared prefs and display","code":"@onclick(r.id.btn_meter_set_minus) void decreaselevel() { if (mleveltoset == channels.chn_min_value_of_everything) { return; } mleveltoset--; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"mleveltoset--; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero();","code_context_10":"@onclick(r.id.btn_meter_set_minus) void decreaselevel() { if (mleveltoset == channels.chn_min_value_of_everything) { return; } mleveltoset--; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","code_context_20":"@onclick(r.id.btn_meter_set_minus) void decreaselevel() { if (mleveltoset == channels.chn_min_value_of_everything) { return; } mleveltoset--; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","repo":"SirdarYangK\/SirdarYKCode"}
{"id":19924,"comment_id":0,"comment":"\/\/todo send setting level frame and change shared prefs and display","code":"@onclick(r.id.btn_meter_set_plus) void increaselevel() { if (mleveltoset == channels.chn_max_level) { return; } mleveltoset++; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"mleveltoset++; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero();","code_context_10":"@onclick(r.id.btn_meter_set_plus) void increaselevel() { if (mleveltoset == channels.chn_max_level) { return; } mleveltoset++; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","code_context_20":"@onclick(r.id.btn_meter_set_plus) void increaselevel() { if (mleveltoset == channels.chn_max_level) { return; } mleveltoset++; mtextviewlevel.settext(string.format(locale.us, \"%1$d\", mleveltoset)); \/\/todo send setting level frame and change shared prefs and display updatelevelforprefsandviewandsendframe(mleveltoset); islevelzero(); }","repo":"SirdarYangK\/SirdarYKCode"}
{"id":3700,"comment_id":0,"comment":"\/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\");","code":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","classification":"NONSATD","isFinished":true,"code_context_2":"public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node;","code_context_10":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","code_context_20":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","repo":"TheNunoGomes\/clava"}
{"id":3700,"comment_id":1,"comment":"\/\/ return node; \/\/ todo: consider returning newstmt instead","code":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","code_context_10":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","code_context_20":"@override public ajoinpoint insertbeginimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(node.getnode() instanceof stmt, \/\/ \"expected input of action scope.insertentry to be a stmt joinpoint\"); cxxactions.insertstmt(\"before\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); }","repo":"TheNunoGomes\/clava"}
{"id":3701,"comment_id":0,"comment":"\/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype());","code":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","classification":"NONSATD","isFinished":true,"code_context_2":"public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node;","code_context_10":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt =","code_context_20":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","repo":"TheNunoGomes\/clava"}
{"id":3701,"comment_id":1,"comment":"\/\/ return node; \/\/ todo: consider returning newstmt instead","code":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/*","code_context_10":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt);","code_context_20":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","repo":"TheNunoGomes\/clava"}
{"id":3701,"comment_id":2,"comment":"\/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/","code":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","code_context_10":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","code_context_20":"@override public ajoinpoint insertendimpl(ajoinpoint node) { stmt newstmt = clavanodes.tostmt(node.getnode()); \/\/ preconditions.checkargument(newstmt instanceof stmt, \/\/ \"expected input of action scope.insertend to be a stmt joinpoint, is a \" + \/\/ node.getjoinpointtype()); cxxactions.insertstmt(\"after\", scope, newstmt, getweaverengine()); \/\/ return node; \/\/ todo: consider returning newstmt instead return cxxjoinpoints.create(newstmt); \/* * list<? extends astatement> statements = selectstatements(); if * (statements.isempty()) { throw new * runtimeexception(\"not yet implemented when scope is empty\"); } * * stmt newstmt = * cxxactions.getvalidstatement(collectionutils.last(statements).getnode()); * * insertimpl(position, newstmt); * * \/\/ body becomes the parent of this statement return new cxxstatement(newstmt, * this); *\/ }","repo":"TheNunoGomes\/clava"}
{"id":12023,"comment_id":0,"comment":"\/\/ this update method will be called from update in breakoutview \/\/ it determines if the paddle needs to move and changes the coordinates \/\/ contained in rect if necessary","code":"\/\/ this update method will be called from update in breakoutview \/\/ it determines if the paddle needs to move and changes the coordinates \/\/ contained in rect if necessary public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"NONSATD","isFinished":true,"code_context_2":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","code_context_10":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":12023,"comment_id":1,"comment":"\/\/ to fix paddle going off the screen","code":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"DEFECT","isFinished":true,"code_context_2":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position","code_context_10":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; }","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":12023,"comment_id":2,"comment":"\/\/ decrement position","code":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; }","code_context_10":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x;","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":12023,"comment_id":3,"comment":"\/\/ to fix paddle going off the screen","code":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"DEFECT","isFinished":true,"code_context_2":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position","code_context_10":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; }","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":12023,"comment_id":4,"comment":"\/\/ increment position","code":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; }","code_context_10":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":12023,"comment_id":5,"comment":"\/\/ apply the new position","code":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","classification":"NONSATD","isFinished":true,"code_context_2":"x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length;","code_context_10":"if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","code_context_20":"public void update(long fps) { if (paddlemoving == left) { \/\/ to fix paddle going off the screen if (x >= -myscreendpi \/ 10) \/\/ decrement position x = x - paddlespeed \/ fps; } if (paddlemoving == right) { \/\/ to fix paddle going off the screen if (x <= scrx - length - myscreendpi \/ 14) \/\/ increment position x = x + paddlespeed \/ fps; } \/\/ apply the new position rect.left = x; rect.right = x + length; }","repo":"Shuffler\/Breakout-Android-Game"}
{"id":20364,"comment_id":0,"comment":"\/** getter * todo: write general description for this method *\/","code":"\/** getter * todo: write general description for this method *\/ @jsongetter(\"action\") public applicationactiontypeenum getaction ( ) { return this.action; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsongetter(\"action\") public applicationactiontypeenum getaction ( ) { return this.action; }","code_context_10":"@jsongetter(\"action\") public applicationactiontypeenum getaction ( ) { return this.action; }","code_context_20":"@jsongetter(\"action\") public applicationactiontypeenum getaction ( ) { return this.action; }","repo":"agaveplatform\/java-sdk"}
{"id":20365,"comment_id":0,"comment":"\/** setter * todo: write general description for this method *\/","code":"\/** setter * todo: write general description for this method *\/ @jsonsetter(\"action\") private void setaction (applicationactiontypeenum value) { this.action = value; }","classification":"DOCUMENTATION","isFinished":true,"code_context_2":"@jsonsetter(\"action\") private void setaction (applicationactiontypeenum value) { this.action = value; }","code_context_10":"@jsonsetter(\"action\") private void setaction (applicationactiontypeenum value) { this.action = value; }","code_context_20":"@jsonsetter(\"action\") private void setaction (applicationactiontypeenum value) { this.action = value; }","repo":"agaveplatform\/java-sdk"}
{"id":12178,"comment_id":0,"comment":"\/* todo need to find alternative for this datamapperroot rootdiagram = (datamapperroot)datamapperdiagrameditor.getinstance().getdiagram().getelement(); treenode inputtreenode = rootdiagram.getinput().gettreenode().get(0); treenode outputtreenode = rootdiagram.getoutput().gettreenode().get(0); string input = inputtreenode.getname(); string output = outputtreenode.getname(); string functionstart = \"function map_s_\"+input+\"_s_\"+output+\"(\" + input + \", \" + output + \"){\\n\"; string functionreturn = \"return \" + output + \";\\n\"; jsfunction mainfunction = new jsfunction(0); mainfunction.setfunctionstart(functionstart); mainfunction.setfunctionreturn(functionreturn); dmcfunctions.add(mainfunction); list<jsfunction> innerfunctions = getfunctionforthetreenode(rootdiagram.getinput().gettreenode(), dmcfunctions, 0, null); mainfunction.getfunctions().addall(innerfunctions); *\/","code":"public static string generatefunction(){ list<jsfunction> dmcfunctions = new arraylist<jsfunction>(); \/* todo need to find alternative for this datamapperroot rootdiagram = (datamapperroot)datamapperdiagrameditor.getinstance().getdiagram().getelement(); treenode inputtreenode = rootdiagram.getinput().gettreenode().get(0); treenode outputtreenode = rootdiagram.getoutput().gettreenode().get(0); string input = inputtreenode.getname(); string output = outputtreenode.getname(); string functionstart = \"function map_s_\"+input+\"_s_\"+output+\"(\" + input + \", \" + output + \"){\\n\"; string functionreturn = \"return \" + output + \";\\n\"; jsfunction mainfunction = new jsfunction(0); mainfunction.setfunctionstart(functionstart); mainfunction.setfunctionreturn(functionreturn); dmcfunctions.add(mainfunction); list<jsfunction> innerfunctions = getfunctionforthetreenode(rootdiagram.getinput().gettreenode(), dmcfunctions, 0, null); mainfunction.getfunctions().addall(innerfunctions); *\/ string documentstring = \"\"; for (jsfunction func : dmcfunctions) { documentstring += func.tostring() + \"\\n\\n\"; } return documentstring; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static string generatefunction(){ list<jsfunction> dmcfunctions = new arraylist<jsfunction>(); \/* todo need to find alternative for this datamapperroot rootdiagram = (datamapperroot)datamapperdiagrameditor.getinstance().getdiagram().getelement(); treenode inputtreenode = rootdiagram.getinput().gettreenode().get(0); treenode outputtreenode = rootdiagram.getoutput().gettreenode().get(0); string input = inputtreenode.getname(); string output = outputtreenode.getname(); string functionstart = \"function map_s_\"+input+\"_s_\"+output+\"(\" + input + \", \" + output + \"){\\n\"; string functionreturn = \"return \" + output + \";\\n\"; jsfunction mainfunction = new jsfunction(0); mainfunction.setfunctionstart(functionstart); mainfunction.setfunctionreturn(functionreturn); dmcfunctions.add(mainfunction); list<jsfunction> innerfunctions = getfunctionforthetreenode(rootdiagram.getinput().gettreenode(), dmcfunctions, 0, null); mainfunction.getfunctions().addall(innerfunctions); *\/ string documentstring = \"\"; for (jsfunction func : dmcfunctions) {","code_context_10":"public static string generatefunction(){ list<jsfunction> dmcfunctions = new arraylist<jsfunction>(); \/* todo need to find alternative for this datamapperroot rootdiagram = (datamapperroot)datamapperdiagrameditor.getinstance().getdiagram().getelement(); treenode inputtreenode = rootdiagram.getinput().gettreenode().get(0); treenode outputtreenode = rootdiagram.getoutput().gettreenode().get(0); string input = inputtreenode.getname(); string output = outputtreenode.getname(); string functionstart = \"function map_s_\"+input+\"_s_\"+output+\"(\" + input + \", \" + output + \"){\\n\"; string functionreturn = \"return \" + output + \";\\n\"; jsfunction mainfunction = new jsfunction(0); mainfunction.setfunctionstart(functionstart); mainfunction.setfunctionreturn(functionreturn); dmcfunctions.add(mainfunction); list<jsfunction> innerfunctions = getfunctionforthetreenode(rootdiagram.getinput().gettreenode(), dmcfunctions, 0, null); mainfunction.getfunctions().addall(innerfunctions); *\/ string documentstring = \"\"; for (jsfunction func : dmcfunctions) { documentstring += func.tostring() + \"\\n\\n\"; } return documentstring; }","code_context_20":"public static string generatefunction(){ list<jsfunction> dmcfunctions = new arraylist<jsfunction>(); \/* todo need to find alternative for this datamapperroot rootdiagram = (datamapperroot)datamapperdiagrameditor.getinstance().getdiagram().getelement(); treenode inputtreenode = rootdiagram.getinput().gettreenode().get(0); treenode outputtreenode = rootdiagram.getoutput().gettreenode().get(0); string input = inputtreenode.getname(); string output = outputtreenode.getname(); string functionstart = \"function map_s_\"+input+\"_s_\"+output+\"(\" + input + \", \" + output + \"){\\n\"; string functionreturn = \"return \" + output + \";\\n\"; jsfunction mainfunction = new jsfunction(0); mainfunction.setfunctionstart(functionstart); mainfunction.setfunctionreturn(functionreturn); dmcfunctions.add(mainfunction); list<jsfunction> innerfunctions = getfunctionforthetreenode(rootdiagram.getinput().gettreenode(), dmcfunctions, 0, null); mainfunction.getfunctions().addall(innerfunctions); *\/ string documentstring = \"\"; for (jsfunction func : dmcfunctions) { documentstring += func.tostring() + \"\\n\\n\"; } return documentstring; }","repo":"SanojPunchihewa\/devstudio-tooling-esb"}
{"id":12258,"comment_id":0,"comment":"\/** * @see internaldataview#postputall(distributedputalloperation, * versionedobjectlist, localregion) *\/","code":"\/** * @see internaldataview#postputall(distributedputalloperation, * versionedobjectlist, localregion) *\/ public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","code_context_10":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","code_context_20":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","repo":"SnappyDataInc\/snappy-store"}
{"id":12258,"comment_id":1,"comment":"\/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions?","code":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) {","code_context_10":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); }","code_context_20":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/);","repo":"SnappyDataInc\/snappy-store"}
{"id":12258,"comment_id":2,"comment":"\/\/ use putallprmessage that already handles transactions","code":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); }","code_context_10":"\/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) {","code_context_20":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe);","repo":"SnappyDataInc\/snappy-store"}
{"id":12258,"comment_id":3,"comment":"\/\/ process on self first","code":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs,","code_context_10":"if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) {","code_context_20":"final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","repo":"SnappyDataInc\/snappy-store"}
{"id":12258,"comment_id":4,"comment":"\/* sendreply *\/","code":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region);","code_context_10":"} else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } }","code_context_20":"\/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","repo":"SnappyDataInc\/snappy-store"}
{"id":12258,"comment_id":5,"comment":"\/\/ distribute if required","code":"public void postputall(final distributedputalloperation putallop, final versionedobjectlist successfulputs, final localregion region) { \/\/ todo: tx: add support for batching using performop as for other \/\/ update operations; add cachewrite flag support for proper writer \/\/ invocation like in other ops; also support for normal\/preloaded regions? markdirty(); if (issnapshot()) { addaffectedregion(region); region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); }","code_context_10":"final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","code_context_20":"region.getshareddataview().postputall(putallop, successfulputs, region); return; } if (region.getpartitionattributes() != null) { \/\/ use putallprmessage that already handles transactions region.postputallsend(putallop, this, successfulputs); } else { try { final putallentrydata[] data = putallop.putalldata; final entryeventimpl event = putallop.getbaseevent(); final remoteputallmessage msg = new remoteputallmessage(event, null, data, data.length, event.ispossibleduplicate(), null, this); \/\/ process on self first if (region.getdatapolicy().withstorage()) { msg.dolocalputall(region, event, putallop, successfulputs, region.getmyid(), false \/* sendreply *\/); } addaffectedregion(region); if (region.getscope().isdistributed()) { \/\/ distribute if required msg.distribute(event); } } catch (remoteoperationexception roe) { throw new transactiondatanodehasdepartedexception(roe); } } }","repo":"SnappyDataInc\/snappy-store"}
{"id":12419,"comment_id":0,"comment":"\/\/todo remove after testing","code":"public static void layoutinit() { dimension dimension = new dimension(560, 320); if (operatingsystem.getcurrent() == operatingsystem.macos) { dimension.setsize(dimension.getwidth() * popupbase.macos_width_scale, dimension.getheight()); } frame.setpreferredsize(dimension); log_btn.addactionlistener((e) -> { if (!popupbase.isalive(logframe.class)) { new logframe(); } else { popupbase.getalive(logframe.class).reopen(); } }); js_btn.addactionlistener((e) -> { mainjdec.is_enabled.setselected(false); mainjdec.is_enabled.setenabled(false); if (!popupbase.isalive(joystickframe.class)) { new joystickframe(); } else { popupbase.getalive(joystickframe.class).reopen(); } }); stats_btn.addactionlistener((e) -> { if (!popupbase.isalive(statsframe.class)) { new statsframe(); } else { popupbase.getalive(statsframe.class).reopen(); } }); nt_btn.addactionlistener((e) -> { if (!popupbase.isalive(ntframe.class)) { nt_frame = new ntframe(); } else { popupbase.getalive(ntframe.class).reopen(); } }); usb_connect.addactionlistener((e) -> { thread reload = new thread() { @override public void run() { networkreloader.reloadrio(protocol.udp); networkreloader.reloadrio(protocol.tcp); super.run(); interrupt(); } }; reload.start(); }); restart_code_btn.addactionlistener(e -> is_enabled.setselected(false)); \/\/todo remove after testing team_number.settext(\"localhost\"); team_number.getdocument().adddocumentlistener(new teamnumlistener()); is_enabled.setenabled(false); globalscreen.addnativekeylistener(globalkeylistener.instance .addkeyevent(nativekeyevent.vc_enter, () -> mainjdec.is_enabled.setselected(false)) .addkeyevent(nativekeyevent.vc_space, mainjdec.estop_btn::doclick)); gbcpanelbuilder endr = base.clone().setanchor(gridbagconstraints.line_end).setfill(gridbagconstraints.none); base.clone().setpos(0, 0, 6, 1).setfill(gridbagconstraints.none).build(title); base.clone().setpos(0, 1, 6, 1).setfill(gridbagconstraints.none).build(link); base.clone().setpos(5, 0, 1, 2).setfill(gridbagconstraints.none).build(new jlabel(new imageicon(mainframe.icon_min))); base.clone().setpos(0, 2, 1, 1).build(is_enabled); base.clone().setpos(1, 2, 1, 1).build(robot_drive_mode); base.clone().setpos(0, 3, 2, 1).setfill(gridbagconstraints.none).build(new jlabel(\"alliance station\")); base.clone().setpos(0, 4, 1, 1).build(alliance_num); base.clone().setpos(1, 4, 1, 1).build(alliance_color); endr.clone().setpos(0, 5, 1, 1).build(new jlabel(\"team number:\")); base.clone().setpos(1, 5, 1, 1).setanchor(gridbagconstraints.line_start).build(team_number); endr.clone().setpos(0, 6, 1, 1).build(new jlabel(\"game data:\")); base.clone().setpos(1, 6, 1, 1).setanchor(gridbagconstraints.line_start).build(game_data); endr.clone().setpos(0, 7, 1, 1).build(new jlabel(\"protocol year:\")); base.clone().setpos(1, 7, 1, 1).setanchor(gridbagconstraints.line_start).build(protocol_year); base.clone().setpos(2, 2, 2, 1).build(restart_code_btn); base.clone().setpos(2, 3, 2, 1).build(restart_robo_rio_btn); base.clone().setpos(2, 4, 2, 1).build(estop_btn); base.clone().setpos(2, 5, 1, 1).build(js_btn); base.clone().setpos(3, 5, 1, 1).build(stats_btn); base.clone().setpos(2, 6, 1, 1).build(nt_btn); base.clone().setpos(3, 6, 1, 1).build(log_btn); base.clone().setpos(2, 7, 1, 1).build(fms_connect); base.clone().setpos(3, 7, 1, 1).build(usb_connect); base.clone().setpos(4, 2, 2, 1).setfill(gridbagconstraints.none).build(bat_voltage); endr.clone().setpos(4, 3, 1, 1).build(new jlabel(\"robot:\")); base.clone().setpos(5, 3, 1, 1).setanchor(gridbagconstraints.line_start).build(robot_connection_status); endr.clone().setpos(4, 4, 1, 1).build(new jlabel(\"code: \")); base.clone().setpos(5, 4, 1, 1).setanchor(gridbagconstraints.line_start).build(robot_code_status); endr.clone().setpos(4, 5, 1, 1).build(new jlabel(\"estop: \")); base.clone().setpos(5, 5, 1, 1).setanchor(gridbagconstraints.line_start).build(estop_status); endr.clone().setpos(4, 6, 1, 1).build(new jlabel(\"fms: \")); base.clone().setpos(5, 6, 1, 1).setanchor(gridbagconstraints.line_start).build(fms_connection_status); endr.clone().setpos(4, 7, 1, 1).build(new jlabel(\"time: \")); base.clone().setpos(5, 7, 1, 1).setanchor(gridbagconstraints.line_start).build(match_time); }","classification":"DESIGN","isFinished":true,"code_context_2":"}); restart_code_btn.addactionlistener(e -> is_enabled.setselected(false)); \/\/todo remove after testing team_number.settext(\"localhost\"); team_number.getdocument().adddocumentlistener(new teamnumlistener());","code_context_10":"public void run() { networkreloader.reloadrio(protocol.udp); networkreloader.reloadrio(protocol.tcp); super.run(); interrupt(); } }; reload.start(); }); restart_code_btn.addactionlistener(e -> is_enabled.setselected(false)); \/\/todo remove after testing team_number.settext(\"localhost\"); team_number.getdocument().adddocumentlistener(new teamnumlistener()); is_enabled.setenabled(false); globalscreen.addnativekeylistener(globalkeylistener.instance .addkeyevent(nativekeyevent.vc_enter, () -> mainjdec.is_enabled.setselected(false)) .addkeyevent(nativekeyevent.vc_space, mainjdec.estop_btn::doclick)); gbcpanelbuilder endr = base.clone().setanchor(gridbagconstraints.line_end).setfill(gridbagconstraints.none); base.clone().setpos(0, 0, 6, 1).setfill(gridbagconstraints.none).build(title); base.clone().setpos(0, 1, 6, 1).setfill(gridbagconstraints.none).build(link); base.clone().setpos(5, 0, 1, 2).setfill(gridbagconstraints.none).build(new jlabel(new imageicon(mainframe.icon_min)));","code_context_20":"nt_btn.addactionlistener((e) -> { if (!popupbase.isalive(ntframe.class)) { nt_frame = new ntframe(); } else { popupbase.getalive(ntframe.class).reopen(); } }); usb_connect.addactionlistener((e) -> { thread reload = new thread() { @override public void run() { networkreloader.reloadrio(protocol.udp); networkreloader.reloadrio(protocol.tcp); super.run(); interrupt(); } }; reload.start(); }); restart_code_btn.addactionlistener(e -> is_enabled.setselected(false)); \/\/todo remove after testing team_number.settext(\"localhost\"); team_number.getdocument().adddocumentlistener(new teamnumlistener()); is_enabled.setenabled(false); globalscreen.addnativekeylistener(globalkeylistener.instance .addkeyevent(nativekeyevent.vc_enter, () -> mainjdec.is_enabled.setselected(false)) .addkeyevent(nativekeyevent.vc_space, mainjdec.estop_btn::doclick)); gbcpanelbuilder endr = base.clone().setanchor(gridbagconstraints.line_end).setfill(gridbagconstraints.none); base.clone().setpos(0, 0, 6, 1).setfill(gridbagconstraints.none).build(title); base.clone().setpos(0, 1, 6, 1).setfill(gridbagconstraints.none).build(link); base.clone().setpos(5, 0, 1, 2).setfill(gridbagconstraints.none).build(new jlabel(new imageicon(mainframe.icon_min))); base.clone().setpos(0, 2, 1, 1).build(is_enabled); base.clone().setpos(1, 2, 1, 1).build(robot_drive_mode); base.clone().setpos(0, 3, 2, 1).setfill(gridbagconstraints.none).build(new jlabel(\"alliance station\")); base.clone().setpos(0, 4, 1, 1).build(alliance_num); base.clone().setpos(1, 4, 1, 1).build(alliance_color); endr.clone().setpos(0, 5, 1, 1).build(new jlabel(\"team number:\")); base.clone().setpos(1, 5, 1, 1).setanchor(gridbagconstraints.line_start).build(team_number); endr.clone().setpos(0, 6, 1, 1).build(new jlabel(\"game data:\")); base.clone().setpos(1, 6, 1, 1).setanchor(gridbagconstraints.line_start).build(game_data); endr.clone().setpos(0, 7, 1, 1).build(new jlabel(\"protocol year:\"));","repo":"Tecbot3158\/open-ds"}
{"id":20824,"comment_id":0,"comment":"\/** * returns all available sd-cards in the system (include emulated) * * warning: hack! based on android source code of version 4.3 (api 18) * because there is no standart way to get it. * todo: test on future android versions 4.4+ * * @return paths to all available sd-cards in the system (include emulated) *\/","code":"\/** * returns all available sd-cards in the system (include emulated) * * warning: hack! based on android source code of version 4.3 (api 18) * because there is no standart way to get it. * todo: test on future android versions 4.4+ * * @return paths to all available sd-cards in the system (include emulated) *\/ public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"TEST","isFinished":true,"code_context_2":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","code_context_10":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":1,"comment":"\/\/ final set of paths","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"{ final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated)","code_context_10":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths.","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid;","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":2,"comment":"\/\/ primary physical sd-card (not emulated)","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\"","code_context_10":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default.","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\";","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":3,"comment":"\/\/ all secondary sd-cards (all exclude primary) separated by \":\"","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card","code_context_10":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else {","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath();","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":4,"comment":"\/\/ primary emulated sd-card","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) {","code_context_10":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); }","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1];","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":5,"comment":"\/\/ device has physical external storage; use plain paths.","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default.","code_context_10":"\/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid;","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true;","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":6,"comment":"\/\/ external_storage undefined; falling back to default.","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else {","code_context_10":"\/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\";","code_context_20":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { }","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":7,"comment":"\/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them.","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) {","code_context_10":"if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder);","code_context_20":"{ final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid);","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":8,"comment":"\/\/ \/storage\/emulated\/0[1,2,...]","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget);","code_context_10":"final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) {","code_context_20":"rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":9,"comment":"\/\/ add all secondary storages","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) {","code_context_10":"rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","code_context_20":"} else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","repo":"acestream\/acestream-android-sdk"}
{"id":20824,"comment_id":10,"comment":"\/\/ all secondary sd-cards splited into array","code":"public static string[] getstoragedirectories(boolean includeprimary) { final pattern dir_separator = pattern.compile(\"\/\"); \/\/ final set of paths final set<string> rv = new hashset<string>(); \/\/ primary physical sd-card (not emulated) final string rawexternalstorage = system.getenv(\"external_storage\"); \/\/ all secondary sd-cards (all exclude primary) separated by \":\" final string rawsecondarystoragesstr = system.getenv(\"secondary_storage\"); \/\/ primary emulated sd-card final string rawemulatedstoragetarget = system.getenv(\"emulated_storage_target\"); if(includeprimary) { if (textutils.isempty(rawemulatedstoragetarget)) { \/\/ device has physical external storage; use plain paths. if (textutils.isempty(rawexternalstorage)) { \/\/ external_storage undefined; falling back to default. rv.add(\"\/storage\/sdcard0\"); } else { rv.add(rawexternalstorage); } } else { \/\/ device has emulated storage; external storage paths should have \/\/ userid burned into them. final string rawuserid; if (build.version.sdk_int < build.version_codes.jelly_bean_mr1) { rawuserid = \"\"; } else { final string path = android.os.environment.getexternalstoragedirectory().getabsolutepath(); final string[] folders = dir_separator.split(path); final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","classification":"NONSATD","isFinished":true,"code_context_2":"if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages);","code_context_10":"if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","code_context_20":"final string lastfolder = folders[folders.length - 1]; boolean isdigit = false; try { integer.valueof(lastfolder); isdigit = true; } catch (numberformatexception ignored) { } rawuserid = isdigit ? lastfolder : \"\"; } \/\/ \/storage\/emulated\/0[1,2,...] if (textutils.isempty(rawuserid)) { rv.add(rawemulatedstoragetarget); } else { rv.add(rawemulatedstoragetarget + file.separator + rawuserid); } } } \/\/ add all secondary storages if(!textutils.isempty(rawsecondarystoragesstr)) { \/\/ all secondary sd-cards splited into array final string[] rawsecondarystorages = rawsecondarystoragesstr.split(file.pathseparator); collections.addall(rv, rawsecondarystorages); } return rv.toarray(new string[0]); }","repo":"acestream\/acestream-android-sdk"}
{"id":20869,"comment_id":0,"comment":"\/\/ todo error handling, 429 handling","code":"\/\/ todo error handling, 429 handling private void execute(object args, string url, httpheaders headers, httpmethod method) { httpentity<object> entity = new httpentity<>(args, headers); responseentity<object> response = resttemplate.exchange(url, method, entity, object.class); if (response.getstatuscode().is2xxsuccessful()) { system.out.println(response.getbody()); } else { system.out.println(\"error! \" + response.getstatuscode().name() + \": \" + response.getbody()); } }","classification":"DEFECT","isFinished":true,"code_context_2":"private void execute(object args, string url, httpheaders headers, httpmethod method) { httpentity<object> entity = new httpentity<>(args, headers); responseentity<object> response = resttemplate.exchange(url, method, entity, object.class); if (response.getstatuscode().is2xxsuccessful()) { system.out.println(response.getbody()); } else { system.out.println(\"error! \" + response.getstatuscode().name() + \": \" + response.getbody()); } }","code_context_10":"private void execute(object args, string url, httpheaders headers, httpmethod method) { httpentity<object> entity = new httpentity<>(args, headers); responseentity<object> response = resttemplate.exchange(url, method, entity, object.class); if (response.getstatuscode().is2xxsuccessful()) { system.out.println(response.getbody()); } else { system.out.println(\"error! \" + response.getstatuscode().name() + \": \" + response.getbody()); } }","code_context_20":"private void execute(object args, string url, httpheaders headers, httpmethod method) { httpentity<object> entity = new httpentity<>(args, headers); responseentity<object> response = resttemplate.exchange(url, method, entity, object.class); if (response.getstatuscode().is2xxsuccessful()) { system.out.println(response.getbody()); } else { system.out.println(\"error! \" + response.getstatuscode().name() + \": \" + response.getbody()); } }","repo":"TONY-All\/Hangar"}
{"id":20888,"comment_id":0,"comment":"\/\/private static boolean _use_dos_palette = false;","code":"\/\/private static boolean _use_dos_palette = false; private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","code_context_10":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":1,"comment":"\/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win;","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index;","code_context_10":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1?","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":2,"comment":"\/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0);","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium","code_context_10":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); }","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++);","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":3,"comment":"\/\/ non-breaking space medium","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large","code_context_10":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed(","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++);","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":4,"comment":"\/\/ non-breaking space tiny","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793;","code_context_10":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1],","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++);","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":5,"comment":"\/\/ non-breaking space large","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1?","code_context_10":"{ \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename,","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base;","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":6,"comment":"\/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) {","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"DESIGN","isFinished":true,"code_context_2":"spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i);","code_context_10":"\/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ );","code_context_20":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++);","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":7,"comment":"\/\/files.landscape[_sprite_page_to_load - 1].filename,","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++","code_context_10":"spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base;","code_context_20":"{ \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info));","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":8,"comment":"\/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++);","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base;","code_context_10":"loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info));","code_context_20":"spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0,","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":9,"comment":"\/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info )","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"DESIGN","isFinished":true,"code_context_2":"loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0,","code_context_10":"assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy(","code_context_20":"load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames();","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":10,"comment":"\/\/ unload sprite group data","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites();","code_context_10":"system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","code_context_20":"\/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":11,"comment":"\/\/ reset price base data","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"NONSATD","isFinished":true,"code_context_2":"engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf","code_context_10":"enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","code_context_20":"system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","repo":"alexey-lukyanenko\/jdrive"}
{"id":20888,"comment_id":12,"comment":"\/\/ todo was called from loadnewgrf","code":"private static void loadspritetables() { \/\/final filelist files = _use_dos_palette ? files_dos : files_win; \/\/final filelist files = files_win; final string[] files = files_win; int load_index; int i; \/\/loadgrfindexed(files.basic[0].filename, trg1idx, 0); loadgrfindexed(files[0], trg1idx, 0); spritecache.dupsprite( 2, 130); \/\/ non-breaking space medium spritecache.dupsprite(226, 354); \/\/ non-breaking space tiny spritecache.dupsprite(450, 578); \/\/ non-breaking space large load_index = 4793; \/\/ todo why start from 1? \/\/for (i = 1; files.basic[i].filename != null; i++) { for (i = 1; files[i] != null; i++) { load_index += loadgrffile(files[i], load_index, i); } if (_sprite_page_to_load != 0) { loadgrfindexed( files_landscape[_sprite_page_to_load - 1], \/\/files.landscape[_sprite_page_to_load - 1].filename, _landscape_spriteindexes[_sprite_page_to_load - 1], i++ ); } assert(load_index == sprites.spr_canals_base); load_index += loadgrffile(\"canalsw.grf\", load_index, i++); assert(load_index == sprites.spr_slopes_base); \/\/ todo loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_opt.landscape], i++); loadgrfindexed(\"trkfoundw.grf\", _slopes_spriteindexes[_sprite_page_to_load], i++); load_index = sprites.spr_autorail_base; load_index += loadgrffile(\"autorail.grf\", load_index, i++); assert(load_index == sprites.spr_openttd_base); loadgrfindexed(\"openttd.grf\", _openttd_grf_indexes, i++); load_index = sprites.spr_openttd_base + openttd_sprites_count; \/\/ [dz] wrong place, but it was in loadnewgrf for some reason. \/\/memcpy(&_engine_info, &orig_engine_info, sizeof(orig_engine_info)); \/\/memcpy(&_rail_vehicle_info, &orig_rail_vehicle_info, sizeof(orig_rail_vehicle_info)); \/\/memcpy(&_ship_vehicle_info, &orig_ship_vehicle_info, sizeof(orig_ship_vehicle_info)); \/\/memcpy(&_aircraft_vehicle_info, &orig_aircraft_vehicle_info, sizeof(orig_aircraft_vehicle_info)); \/\/memcpy(&_road_vehicle_info, &orig_road_vehicle_info, sizeof(orig_road_vehicle_info)); \/\/ todo make deep copy?? \/\/global._engine_info = enginetables2.orig_engine_info; \/\/for( engineinfo ei : enginetables2.orig_engine_info ) system.arraycopy( enginetables2.orig_engine_info, 0, global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i);","code_context_10":"system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","code_context_20":"global._engine_info, 0, global._engine_info.length ); system.arraycopy( enginetables2.orig_rail_vehicle_info , 0, global._rail_vehicle_info, 0, global._rail_vehicle_info.length ); system.arraycopy( enginetables2.orig_ship_vehicle_info, 0, global._ship_vehicle_info, 0, global._ship_vehicle_info.length ); system.arraycopy( enginetables2.orig_aircraft_vehicle_info, 0, global._aircraft_vehicle_info, 0, global._aircraft_vehicle_info.length ); system.arraycopy( enginetables2.orig_road_vehicle_info, 0, global._road_vehicle_info, 0, global._road_vehicle_info.length ); bridge.loadorigbridges(); \/\/ unload sprite group data engine.unloadwagonoverrides(); engine.unloadcustomenginesprites(); engine.unloadcustomenginenames(); \/\/ reset price base data economy.resetpricebasemultipliers(); \/\/ todo was called from loadnewgrf grffile.resetnewgrfdata(); grffile.loadnewgrf(load_index, i); }","repo":"alexey-lukyanenko\/jdrive"}
{"id":13084,"comment_id":0,"comment":"\/\/todo add you childview to rootview , usually not youself layout the view!","code":"@override public void addcontentview(view view) { \/\/todo add you childview to rootview , usually not youself layout the view! addview(view); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@override public void addcontentview(view view) { \/\/todo add you childview to rootview , usually not youself layout the view! addview(view); }","code_context_10":"@override public void addcontentview(view view) { \/\/todo add you childview to rootview , usually not youself layout the view! addview(view); }","code_context_20":"@override public void addcontentview(view view) { \/\/todo add you childview to rootview , usually not youself layout the view! addview(view); }","repo":"Tamicer\/FilterBar"}
{"id":13100,"comment_id":0,"comment":"\/\/ todo change the file location\/name according to your needs","code":"private boolean writeresponsebodytodisk(responsebody body) { try { \/\/ todo change the file location\/name according to your needs file futurestudioiconfile = new file(getexternalfilesdir(null) + file.separator + nombreeditar + \".jpg\"); inputstream inputstream = null; outputstream outputstream = null; try { byte[] filereader = new byte[4096]; long filesize = body.contentlength(); long filesizedownloaded = 0; inputstream = body.bytestream(); outputstream = new fileoutputstream(futurestudioiconfile); while (true) { int read = inputstream.read(filereader); if (read == -1) { log.d(\"writeresponsebodytodisk\", \"file download: \" + filesizedownloaded + \" of \" + filesize); break; } outputstream.write(filereader, 0, read); filesizedownloaded += read; } outputstream.flush(); return true; } catch (ioexception e) { return false; } finally { if (inputstream != null) { inputstream.close(); } if (outputstream != null) { outputstream.close(); } } } catch (ioexception e) { return false; } }","classification":"DESIGN","isFinished":true,"code_context_2":"private boolean writeresponsebodytodisk(responsebody body) { try { \/\/ todo change the file location\/name according to your needs file futurestudioiconfile = new file(getexternalfilesdir(null) + file.separator + nombreeditar + \".jpg\"); inputstream inputstream = null;","code_context_10":"private boolean writeresponsebodytodisk(responsebody body) { try { \/\/ todo change the file location\/name according to your needs file futurestudioiconfile = new file(getexternalfilesdir(null) + file.separator + nombreeditar + \".jpg\"); inputstream inputstream = null; outputstream outputstream = null; try { byte[] filereader = new byte[4096]; long filesize = body.contentlength(); long filesizedownloaded = 0; inputstream = body.bytestream(); outputstream = new fileoutputstream(futurestudioiconfile); while (true) {","code_context_20":"private boolean writeresponsebodytodisk(responsebody body) { try { \/\/ todo change the file location\/name according to your needs file futurestudioiconfile = new file(getexternalfilesdir(null) + file.separator + nombreeditar + \".jpg\"); inputstream inputstream = null; outputstream outputstream = null; try { byte[] filereader = new byte[4096]; long filesize = body.contentlength(); long filesizedownloaded = 0; inputstream = body.bytestream(); outputstream = new fileoutputstream(futurestudioiconfile); while (true) { int read = inputstream.read(filereader); if (read == -1) { log.d(\"writeresponsebodytodisk\", \"file download: \" + filesizedownloaded + \" of \" + filesize); break; } outputstream.write(filereader, 0, read); filesizedownloaded += read; } outputstream.flush(); return true;","repo":"UNIZAR-30226-2021-14\/Front-end"}
{"id":13511,"comment_id":0,"comment":"\/\/ todo either pr bytebuffer support into actson, or sneaky-access the underlying byte array fields here","code":"@override public graphstagelogic createlogic(attributes attr) throws exception { jsonparser parser = new jsonparser(); return new graphstagelogic(shape) { { sethandler(out, new abstractouthandler() { @override public void onpull() throws exception { list<jsonevent> events = new arraylist<>(); parseinto(events); if (events.isempty()) { pull(in); } else { emitmultiple(out, events.iterator()); } } }); sethandler(in, new abstractinhandler() { @override public void onpush() throws exception { list<jsonevent> events = new arraylist<>(); bytestring bytes = grab(in); \/\/ todo either pr bytebuffer support into actson, or sneaky-access the underlying byte array fields here for (bytebuffer b: bytes.getbytebuffers()) { byte[] buf= new byte[b.remaining()]; b.get(buf, 0, b.remaining()); int i = 0; while (i < buf.length) { i += parser.getfeeder().feed(buf, i, buf.length - i); parseinto(events); } } if (events.isempty()) { pull(in); } else { emitmultiple(out, events.iterator()); } } public void onupstreamfinish() throws exception { parser.getfeeder().done(); list<jsonevent> events = new arraylist<>(); parseinto(events); emitmultiple(out, events.iterator()); complete(out); } }); } private void parseinto(list<jsonevent> events) { option<jsonevent> evt = next(); while (evt.isdefined()) { events.add(evt.get()); evt = next(); } }; private option<jsonevent> next() { switch(parser.nextevent()) { case jsonevent.end_array: return some(jsonevent.end_array); case jsonevent.end_object: return some(jsonevent.end_object); case jsonevent.error: throw new illegalargumentexception(\"there was a parse error at around character \" + parser.getparsedcharactercount()); case jsonevent.eof: return none(); case jsonevent.field_name: return some(new jsonevent.fieldname(parser.getcurrentstring())); case jsonevent.need_more_input: return none(); case jsonevent.start_array: return some(jsonevent.start_array); case jsonevent.start_object: return some(jsonevent.start_object); case jsonevent.value_double: return some(new jsonevent.numericvalue(string.valueof(parser.getcurrentdouble()))); case jsonevent.value_false: return some(jsonevent.false); case jsonevent.value_int: return some(new jsonevent.numericvalue(parser.getcurrentstring())); case jsonevent.value_null: return some(jsonevent.null); case jsonevent.value_string: return some(new jsonevent.stringvalue(parser.getcurrentstring())); case jsonevent.value_true: return some(jsonevent.true); default: throw new unsupportedoperationexception(\"unexpected event in json parser\"); } } }; }","classification":"DESIGN","isFinished":true,"code_context_2":"list<jsonevent> events = new arraylist<>(); bytestring bytes = grab(in); \/\/ todo either pr bytebuffer support into actson, or sneaky-access the underlying byte array fields here for (bytebuffer b: bytes.getbytebuffers()) { byte[] buf= new byte[b.remaining()];","code_context_10":"} else { emitmultiple(out, events.iterator()); } } }); sethandler(in, new abstractinhandler() { @override public void onpush() throws exception { list<jsonevent> events = new arraylist<>(); bytestring bytes = grab(in); \/\/ todo either pr bytebuffer support into actson, or sneaky-access the underlying byte array fields here for (bytebuffer b: bytes.getbytebuffers()) { byte[] buf= new byte[b.remaining()]; b.get(buf, 0, b.remaining()); int i = 0; while (i < buf.length) { i += parser.getfeeder().feed(buf, i, buf.length - i); parseinto(events); } } if (events.isempty()) {","code_context_20":"jsonparser parser = new jsonparser(); return new graphstagelogic(shape) { { sethandler(out, new abstractouthandler() { @override public void onpull() throws exception { list<jsonevent> events = new arraylist<>(); parseinto(events); if (events.isempty()) { pull(in); } else { emitmultiple(out, events.iterator()); } } }); sethandler(in, new abstractinhandler() { @override public void onpush() throws exception { list<jsonevent> events = new arraylist<>(); bytestring bytes = grab(in); \/\/ todo either pr bytebuffer support into actson, or sneaky-access the underlying byte array fields here for (bytebuffer b: bytes.getbytebuffers()) { byte[] buf= new byte[b.remaining()]; b.get(buf, 0, b.remaining()); int i = 0; while (i < buf.length) { i += parser.getfeeder().feed(buf, i, buf.length - i); parseinto(events); } } if (events.isempty()) { pull(in); } else { emitmultiple(out, events.iterator()); } } public void onupstreamfinish() throws exception { parser.getfeeder().done(); list<jsonevent> events = new arraylist<>(); parseinto(events); emitmultiple(out, events.iterator());","repo":"alar17\/ts-reaktive"}
{"id":13714,"comment_id":0,"comment":"\/\/ system.out.println(\"warn: be supported in sflowvisitor\");","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt();","code_context_10":"annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) {","code_context_20":"inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":1,"comment":"\/\/ like x = y.m(z);","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) {","code_context_10":"if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations();","code_context_20":"while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type);","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":2,"comment":"\/\/ do viewpoint adaptation","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations());","code_context_10":"} else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break;","code_context_20":"inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt);","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":3,"comment":"\/\/ todo: consider using viewpoint adaptation","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"DESIGN","isFinished":true,"code_context_2":"break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type);","code_context_10":"rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype);","code_context_20":"annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree);","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":4,"comment":"\/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree();","code_context_10":"type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations();","code_context_20":"rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":5,"comment":"\/\/ we don't want to annotate class type","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type);","code_context_10":"set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations());","code_context_20":"variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } }","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":6,"comment":"\/\/ may need viewpoint adaptation if it is a field","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this","code_context_10":"type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set);","code_context_20":"\/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2.","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":7,"comment":"\/\/ we need to adapt it from pov of this","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) {","code_context_10":"} } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else {","code_context_20":"classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression();","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":8,"comment":"\/\/ this happen in the static initializer \/\/ ignore","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"} } else { \/\/ this happen in the static initializer \/\/ ignore } }","code_context_10":"executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array;","code_context_20":"} break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select:","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":9,"comment":"\/\/ wei: move from reimannotatedtypefactory on aug 2.","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression();","code_context_10":"type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations();","code_context_20":"\/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) {","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":10,"comment":"\/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree);","code_context_10":"set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt);","code_context_20":"} } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":11,"comment":"\/\/ if it is like body.this \/\/ fixme:","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"DEFECT","isFinished":true,"code_context_2":"element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) {","code_context_10":"type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt));","code_context_20":"arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt)","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13714,"comment_id":12,"comment":"\/\/ do viewpoint adaptation","code":"private void annotateinferredtype(tree tree, annotatedtypemirror type) { switch (tree.getkind()) { case new_array: case new_class: inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(tree), type); break; case method: executableelement methodelt = treeutils.elementfromdeclaration( (methodtree) tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(methodelt), type); break; case type_cast: if (!checker.isannotated(type)) { tree t = tree; while (t.getkind() == kind.type_cast) { t = ((typecasttree) t).getexpression(); if (t instanceof expressiontree) t = treeutils.skipparens((expressiontree) t); } annotatedtypemirror casttype = getannotatedtype(t); inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt); inferencemain.getinstance().getcurrentextractor() .annotateinferredtype(getidentifier(classelt), defconstructortype); set<annotationmirror> set = checker.adaptfieldset(defconstructortype .getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } break; case identifier: element idelt = treeutils.elementfromuse((identifiertree) tree); \/\/ we don't want to annotate class type if (idelt.getkind() != elementkind.class && idelt.getkind() != elementkind.interface) { inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(idelt), type); \/\/ may need viewpoint adaptation if it is a field if (idelt.getkind() == elementkind.field) { \/\/ we need to adapt it from pov of this executableelement currentmethod = getcurrentmethodelt(); if (currentmethod != null) { annotatedexecutabletype methodtype = getannotatedtype(currentmethod); set<annotationmirror> set = checker.adaptfieldset(methodtype .getreceivertype().getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else { \/\/ this happen in the static initializer \/\/ ignore } } } break; case array_access: \/\/ wei: move from reimannotatedtypefactory on aug 2. arrayaccesstree atree = (arrayaccesstree) tree; expressiontree aexpr = atree.getexpression(); annotatedtypemirror aexprtype = getannotatedtype(aexpr); assert aexprtype.getkind() == typekind.array; set<annotationmirror> componentannos = ((annotatedarraytype) aexprtype) .getcomponenttype().getannotations(); set<annotationmirror> adaptedannos = checker.adaptfieldset( aexprtype.getannotations(), componentannos); if (!adaptedannos.isempty()) { type.clearannotations(); type.addannotations(adaptedannos); } break; case member_select: \/\/ wei: added on aug 2 \/\/ wei: remove the above line, also considering remove the \/\/ tree.getkind() == kind.member_select in the \"default\" case memberselecttree mtree = (memberselecttree) tree; element fieldelt = treeutils.elementfromuse(mtree); if (checker.isaccessouterthis(mtree)) { \/\/ if it is like body.this \/\/ fixme: methodtree methodtree = this.getvisitorstate().getmethodtree(); if (methodtree != null) { executableelement currentmethodelt = treeutils .elementfromdeclaration(methodtree); element outerelt = checker.getouterthiselement(mtree, currentmethodelt); reference inferredref = null; if (outerelt != null && outerelt.getkind() == elementkind.method) { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(outerelt)); } else { inferredref = inferencemain.getinstance().getcurrentextractor().getinferredreference(getidentifier(currentmethodelt)); } if (inferredref != null) inferenceutils.annotatereferencetype(type, ((executablereference) inferredref).getreceiverref()); else system.err.println(\"warn: cannot annotate \" + mtree); } } else if (!fieldelt.getsimplename().contentequals(\"super\") && fieldelt.getkind() == elementkind.field && !elementutils.isstatic(fieldelt) && checker.isannotated(type) ) { \/\/ do viewpoint adaptation expressiontree expr = mtree.getexpression(); annotatedtypemirror exprtype = getannotatedtype(expr); annotatedtypemirror fieldtype = getannotatedtype(fieldelt); set<annotationmirror> set = checker.adaptfieldset( exprtype.getannotations(), fieldtype.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } else if (!checker.isannotated(type) && fieldelt.getsimplename().contentequals(\"class\")) type.addannotation(checker.bottom); break; default: if(!checker.isannotated(type)) { if (tree instanceof unarytree) { annotatedtypemirror atype = getannotatedtype( ((unarytree) tree).getexpression()); inferenceutils.assignannotations(type, atype); } else if (tree instanceof binarytree && !checker.isannotated(type)) { expressiontree left = ((binarytree)tree).getleftoperand(); expressiontree right = ((binarytree)tree).getrightoperand(); annotatedtypemirror lefttype = getannotatedtype(left); annotatedtypemirror righttype = getannotatedtype(right); set<annotationmirror> leftset = lefttype.getannotations(); set<annotationmirror> rightset = righttype.getannotations(); set<annotationmirror> set = qualhierarchy.leastupperbound(leftset, rightset); type.addannotations(set); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"} if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations());","code_context_10":"} else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break;","code_context_20":"inferenceutils.assignannotations(type, casttype); } break; case method_invocation: if (type.getkind() != typekind.void) { methodinvocationtree mitree = (methodinvocationtree) tree; executableelement imethodelt = treeutils.elementfromuse(mitree); expressiontree rcvtree = inferenceutils.getreceivertree(mitree); if (elementutils.isstatic(imethodelt)) { \/\/ system.out.println(\"warn: be supported in sflowvisitor\"); } else { executableelement currentmethod = getcurrentmethodelt(); annotatedtypemirror rcvtype = null; if (rcvtree != null) { \/\/ like x = y.m(z); rcvtype = getannotatedtype(rcvtree); } else if (currentmethod != null) { rcvtype = getannotatedtype(currentmethod).getreceivertype(); } if (rcvtype != null) { \/\/ do viewpoint adaptation set<annotationmirror> set = checker.adaptfieldset( rcvtype.getannotations(), type.getannotations()); if (!set.isempty()) { type.clearannotations(); type.addannotations(set); } } } } break; case variable: \/\/ todo: consider using viewpoint adaptation variableelement varelt = treeutils.elementfromdeclaration((variabletree)tree); inferencemain.getinstance().getcurrentextractor().annotateinferredtype(getidentifier(varelt), type); \/\/ if there is an initialization for field, we need adapt it from \/\/ classtree type if (varelt.getkind().isfield() && !elementutils.isstatic(varelt)) { classtree classtree = this.getvisitorstate().getclasstree(); typeelement classelt = treeutils.elementfromdeclaration(classtree); annotateddeclaredtype defconstructortype = getannotatedtype(classelt);","repo":"SoftwareEngineeringToolDemos\/type-inference"}
{"id":13884,"comment_id":0,"comment":"\/\/todo: replace this with your own logic","code":"private boolean ispasswordvalid(string password) { \/\/todo: replace this with your own logic return password.length() > 5; }","classification":"DESIGN","isFinished":true,"code_context_2":"private boolean ispasswordvalid(string password) { \/\/todo: replace this with your own logic return password.length() > 5; }","code_context_10":"private boolean ispasswordvalid(string password) { \/\/todo: replace this with your own logic return password.length() > 5; }","code_context_20":"private boolean ispasswordvalid(string password) { \/\/todo: replace this with your own logic return password.length() > 5; }","repo":"ShivamPokhriyal\/Custom-UI-Sample"}
{"id":30271,"comment_id":0,"comment":"\/** * returns a list of clang flags used for all link and compile actions executed through clang. *\/","code":"\/** * returns a list of clang flags used for all link and compile actions executed through clang. *\/ private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","classification":"NONSATD","isFinished":true,"code_context_2":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","code_context_10":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","code_context_20":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","repo":"Tingbopku\/tingbo1"}
{"id":30271,"comment_id":1,"comment":"\/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version.","code":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","classification":"DESIGN","isFinished":true,"code_context_2":"break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform));","code_context_10":"switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator:","code_context_20":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); }","repo":"Tingbopku\/tingbo1"}
{"id":30271,"comment_id":2,"comment":"\/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version.","code":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","classification":"DESIGN","isFinished":true,"code_context_2":"break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform));","code_context_10":"switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator:","code_context_20":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); }","repo":"Tingbopku\/tingbo1"}
{"id":30271,"comment_id":3,"comment":"\/\/ todo(bazel-team): pass framework search paths to xcodegen.","code":"private list<string> commonlinkandcompileflagsforclang( objcprovider provider, objcconfiguration objcconfiguration, appleconfiguration appleconfiguration) { immutablelist.builder<string> builder = new immutablelist.builder<>(); platform platform = appleconfiguration.getsinglearchplatform(); switch (platform) { case ios_simulator: builder.add(\"-mios-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case ios_device: builder.add(\"-miphoneos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case watchos_simulator: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-simulator-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case watchos_device: \/\/ todo(bazel-team): use the value from --watchos-minimum-os instead of tying to the sdk \/\/ version. builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":".add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build();","code_context_10":"break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","code_context_20":"builder.add(\"-mwatchos-version-min=\" + appleconfiguration.getsdkversionforplatform(platform)); break; case tvos_simulator: builder.add(\"-mtvos-simulator-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; case tvos_device: builder.add(\"-mtvos-version-min=\" + appleconfiguration.getminimumosforplatformtype(platform.gettype())); break; default: throw new illegalargumentexception(\"unhandled platform \" + platform); } if (objcconfiguration.generatedsym()) { builder.add(\"-g\"); } return builder .add(\"-arch\", appleconfiguration.getsinglearchitecture()) .add(\"-isysroot\", appletoolchain.sdkdir()) \/\/ todo(bazel-team): pass framework search paths to xcodegen. .addall(commonframeworkflags(provider, appleconfiguration)) .build(); }","repo":"Tingbopku\/tingbo1"}
{"id":22098,"comment_id":0,"comment":"\/\/ user clicked ok button","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer","code_context_10":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) {","code_context_20":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) {","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":1,"comment":"\/\/starts at startingplayer, since input list starts at startingplayer","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i);","code_context_10":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show();","code_context_20":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show();","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":2,"comment":"\/\/verify input","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try {","code_context_10":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; }","code_context_20":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; }","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":3,"comment":"\/\/validate results","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) {","code_context_10":"int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) {","code_context_20":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); }","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":4,"comment":"\/\/save results \/\/todo: save playerid with input field for better code quality","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) {","code_context_10":"toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores();","code_context_20":"toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); }","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":5,"comment":"\/\/if this entry is score, update views && activate next round","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap);","code_context_10":"toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else {","code_context_20":"int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","repo":"ThaChillera\/CardScore"}
{"id":22098,"comment_id":6,"comment":"\/\/change buttons","code":"@override public void onclick(dialoginterface dialog, int which) { \/\/ user clicked ok button int[] inputs = new int[playermanager.getselectedplayercount()]; \/\/starts at startingplayer, since input list starts at startingplayer for (int i = startingplayer; i < playermanager.getselectedplayercount() + startingplayer; i++) { int index = getplayerindex(i); edittext edittext = (edittext) ((linearlayout) linearlayout.getchildat(i - startingplayer)).getchildat(3); \/\/verify input int input; try { input = integer.parseint(edittext.gettext().tostring()); } catch (numberformatexception nfe) { toast toast = toast.maketext(context, \"invalid input\", toast.length_short); toast.show(); return; } inputs[index] = input; } \/\/validate results int totalvalue = 0; for (int value : inputs) { if (value < 0) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_number), toast.length_short); toast.show(); return; } totalvalue += value; } if (gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score && totalvalue != gamescoremanager.getcardcount(gamescoremanager.getround())) { toast toast = toast.maketext(context, context.getresources().getstring(r.string.invalid_score), toast.length_long); toast.show(); return; } \/\/save results \/\/todo: save playerid with input field for better code quality map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","classification":"NONSATD","isFinished":true,"code_context_2":"changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","code_context_10":"changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","code_context_20":"map<long, integer> inputmap = new hashmap<>(); for (int i = 0; i < playermanager.getselectedplayercount(); i++) { inputmap.put(playermanager.getselectedplayers()[i], inputs[i]); } \/\/if this entry is score, update views && activate next round if (gamescoremanager.getnextentrytype() == gamescoremanager.entrytype.score) { gamescoremanager.enterscores(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); headermanager.updatescores(); rowmanager.updatescores(); changebuttonvisibility(buttonvisible.none); if (gamescoremanager.getround() != gamescoremanager.getamountofrounds()) { nextround.changebuttonvisibility(buttonvisible.predict); } } else { gamescoremanager.enterpredictions(inputmap); persistencemanager.getinstance().savegame(gamescoremanager); rowmanager.updatepredictions(); changebuttonvisibility(buttonvisible.score); } \/\/change buttons changebuttonvisibility(gamescoremanager.getnextentrytype() == readonlygamescoremanager.entrytype.score ? buttonvisible.score : buttonvisible.none); }","repo":"ThaChillera\/CardScore"}
{"id":22436,"comment_id":0,"comment":"\/\/ todo auto-generated method stub \/\/ first populate, then call super","code":"@override public void prepareforsave(kualidocumentevent event) { \/\/ todo auto-generated method stub \/\/ first populate, then call super if (event instanceof attributedcontinuepurapevent) { springcontext.getbean(oleinvoiceservice.class).populateinvoice(this); } if(this.getvendorpaymenttermscode() != null && this.getvendorpaymenttermscode().isempty()) { this.setvendorpaymenttermscode(null); } super.prepareforsave(event); try { if (this.proformaindicator && !this.immediatepaymentindicator) { this.setimmediatepaymentindicator(true); } log.debug(\"###########inside oleinvoicedocument \" + \"repareforsave###########\"); list<oleinvoiceitem> items = new arraylist<oleinvoiceitem>(); items = this.getitems(); iterator iterator = items.iterator(); hashmap datamap = new hashmap(); string titleid; while (iterator.hasnext()) { log.debug(\"###########inside prepareforsave item loop###########\"); object object = iterator.next(); if (object instanceof oleinvoiceitem) { log.debug(\"###########inside prepareforsave ole payment request item###########\"); oleinvoiceitem singleitem = (oleinvoiceitem) object; if (stringutils.isnotblank(this.invoicecurrencytype)) { this.setinvoicecurrencytypeid(new long(this.getinvoicecurrencytype())); string currencytype = springcontext.getbean(oleinvoiceservice.class).getcurrencytype(this.getinvoicecurrencytype()); if (stringutils.isnotblank(currencytype)) { if(!currencytype.equalsignorecase(oleselectconstant.currency_type_name)) { if (stringutils.isnotblank(this.getinvoicecurrencyexchangerate())) { try { double.parsedouble(this.getinvoicecurrencyexchangerate()); singleitem.setitemexchangerate(new kualidecimal(this.getinvoicecurrencyexchangerate())); singleitem.setexchangerate(this.getinvoicecurrencyexchangerate()); } catch (numberformatexception nfe) { throw new runtimeexception(\"invalid exchange rate\", nfe); } } else { bigdecimal exchangerate = springcontext.getbean(oleinvoiceservice.class).getexchangerate(this.getinvoicecurrencytype()).getexchangerate(); this.setinvoicecurrencyexchangerate(exchangerate.tostring()); singleitem.setitemexchangerate(new kualidecimal(exchangerate)); singleitem.setexchangerate(exchangerate.tostring()); } this.setvendorinvoiceamount(this.getforeignvendorinvoiceamount() != null ? new kualidecimal(this.getforeignvendorinvoiceamount().divide(new bigdecimal(singleitem.getexchangerate()), 4, roundingmode.half_up)) : null); } } } setitemdescription(singleitem); map<string, string> copycriteria = new hashmap<string, string>(); if (singleitem.getpaidcopies().size() <= 0 && singleitem.getpoitemidentifier() != null && (this.getpurapdocumentidentifier() != null && singleitem.getitemidentifier() != null)) { copycriteria.put(\"poitemid\", singleitem.getpoitemidentifier().tostring()); list<olecopy> copies = (list<olecopy>) getbusinessobjectservice().findmatching(olecopy.class, copycriteria); if (copies.size() > 0) { list<olepaidcopy> paidcopies = new arraylist<olepaidcopy>(); for (olecopy copy : copies) { olepaidcopy paidcopy = new olepaidcopy(); paidcopy.setcopyid(copy.getcopyid()); paidcopy.setinvoiceitemid(this.getpurapdocumentidentifier()); paidcopy.setinvoiceidentifier(singleitem.getitemidentifier()); \/\/copy.getolepaidcopies().add(paidcopy); paidcopies.add(paidcopy); } getbusinessobjectservice().save(paidcopies); singleitem.setpaidcopies(paidcopies); } } } } } catch (exception e) { log.error(\"exception during prepareforsave() in oleinvoicedocument\", e); throw new runtimeexception(e); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"@override public void prepareforsave(kualidocumentevent event) { \/\/ todo auto-generated method stub \/\/ first populate, then call super if (event instanceof attributedcontinuepurapevent) { springcontext.getbean(oleinvoiceservice.class).populateinvoice(this);","code_context_10":"@override public void prepareforsave(kualidocumentevent event) { \/\/ todo auto-generated method stub \/\/ first populate, then call super if (event instanceof attributedcontinuepurapevent) { springcontext.getbean(oleinvoiceservice.class).populateinvoice(this); } if(this.getvendorpaymenttermscode() != null && this.getvendorpaymenttermscode().isempty()) { this.setvendorpaymenttermscode(null); } super.prepareforsave(event); try { if (this.proformaindicator && !this.immediatepaymentindicator) { this.setimmediatepaymentindicator(true);","code_context_20":"@override public void prepareforsave(kualidocumentevent event) { \/\/ todo auto-generated method stub \/\/ first populate, then call super if (event instanceof attributedcontinuepurapevent) { springcontext.getbean(oleinvoiceservice.class).populateinvoice(this); } if(this.getvendorpaymenttermscode() != null && this.getvendorpaymenttermscode().isempty()) { this.setvendorpaymenttermscode(null); } super.prepareforsave(event); try { if (this.proformaindicator && !this.immediatepaymentindicator) { this.setimmediatepaymentindicator(true); } log.debug(\"###########inside oleinvoicedocument \" + \"repareforsave###########\"); list<oleinvoiceitem> items = new arraylist<oleinvoiceitem>(); items = this.getitems(); iterator iterator = items.iterator(); hashmap datamap = new hashmap(); string titleid; while (iterator.hasnext()) { log.debug(\"###########inside prepareforsave item loop###########\"); object object = iterator.next();","repo":"VU-libtech\/OLE-INST"}
{"id":22436,"comment_id":1,"comment":"\/\/copy.getolepaidcopies().add(paidcopy);","code":"@override public void prepareforsave(kualidocumentevent event) { \/\/ todo auto-generated method stub \/\/ first populate, then call super if (event instanceof attributedcontinuepurapevent) { springcontext.getbean(oleinvoiceservice.class).populateinvoice(this); } if(this.getvendorpaymenttermscode() != null && this.getvendorpaymenttermscode().isempty()) { this.setvendorpaymenttermscode(null); } super.prepareforsave(event); try { if (this.proformaindicator && !this.immediatepaymentindicator) { this.setimmediatepaymentindicator(true); } log.debug(\"###########inside oleinvoicedocument \" + \"repareforsave###########\"); list<oleinvoiceitem> items = new arraylist<oleinvoiceitem>(); items = this.getitems(); iterator iterator = items.iterator(); hashmap datamap = new hashmap(); string titleid; while (iterator.hasnext()) { log.debug(\"###########inside prepareforsave item loop###########\"); object object = iterator.next(); if (object instanceof oleinvoiceitem) { log.debug(\"###########inside prepareforsave ole payment request item###########\"); oleinvoiceitem singleitem = (oleinvoiceitem) object; if (stringutils.isnotblank(this.invoicecurrencytype)) { this.setinvoicecurrencytypeid(new long(this.getinvoicecurrencytype())); string currencytype = springcontext.getbean(oleinvoiceservice.class).getcurrencytype(this.getinvoicecurrencytype()); if (stringutils.isnotblank(currencytype)) { if(!currencytype.equalsignorecase(oleselectconstant.currency_type_name)) { if (stringutils.isnotblank(this.getinvoicecurrencyexchangerate())) { try { double.parsedouble(this.getinvoicecurrencyexchangerate()); singleitem.setitemexchangerate(new kualidecimal(this.getinvoicecurrencyexchangerate())); singleitem.setexchangerate(this.getinvoicecurrencyexchangerate()); } catch (numberformatexception nfe) { throw new runtimeexception(\"invalid exchange rate\", nfe); } } else { bigdecimal exchangerate = springcontext.getbean(oleinvoiceservice.class).getexchangerate(this.getinvoicecurrencytype()).getexchangerate(); this.setinvoicecurrencyexchangerate(exchangerate.tostring()); singleitem.setitemexchangerate(new kualidecimal(exchangerate)); singleitem.setexchangerate(exchangerate.tostring()); } this.setvendorinvoiceamount(this.getforeignvendorinvoiceamount() != null ? new kualidecimal(this.getforeignvendorinvoiceamount().divide(new bigdecimal(singleitem.getexchangerate()), 4, roundingmode.half_up)) : null); } } } setitemdescription(singleitem); map<string, string> copycriteria = new hashmap<string, string>(); if (singleitem.getpaidcopies().size() <= 0 && singleitem.getpoitemidentifier() != null && (this.getpurapdocumentidentifier() != null && singleitem.getitemidentifier() != null)) { copycriteria.put(\"poitemid\", singleitem.getpoitemidentifier().tostring()); list<olecopy> copies = (list<olecopy>) getbusinessobjectservice().findmatching(olecopy.class, copycriteria); if (copies.size() > 0) { list<olepaidcopy> paidcopies = new arraylist<olepaidcopy>(); for (olecopy copy : copies) { olepaidcopy paidcopy = new olepaidcopy(); paidcopy.setcopyid(copy.getcopyid()); paidcopy.setinvoiceitemid(this.getpurapdocumentidentifier()); paidcopy.setinvoiceidentifier(singleitem.getitemidentifier()); \/\/copy.getolepaidcopies().add(paidcopy); paidcopies.add(paidcopy); } getbusinessobjectservice().save(paidcopies); singleitem.setpaidcopies(paidcopies); } } } } } catch (exception e) { log.error(\"exception during prepareforsave() in oleinvoicedocument\", e); throw new runtimeexception(e); } }","classification":"NONSATD","isFinished":true,"code_context_2":"paidcopy.setinvoiceitemid(this.getpurapdocumentidentifier()); paidcopy.setinvoiceidentifier(singleitem.getitemidentifier()); \/\/copy.getolepaidcopies().add(paidcopy); paidcopies.add(paidcopy); }","code_context_10":"if (singleitem.getpaidcopies().size() <= 0 && singleitem.getpoitemidentifier() != null && (this.getpurapdocumentidentifier() != null && singleitem.getitemidentifier() != null)) { copycriteria.put(\"poitemid\", singleitem.getpoitemidentifier().tostring()); list<olecopy> copies = (list<olecopy>) getbusinessobjectservice().findmatching(olecopy.class, copycriteria); if (copies.size() > 0) { list<olepaidcopy> paidcopies = new arraylist<olepaidcopy>(); for (olecopy copy : copies) { olepaidcopy paidcopy = new olepaidcopy(); paidcopy.setcopyid(copy.getcopyid()); paidcopy.setinvoiceitemid(this.getpurapdocumentidentifier()); paidcopy.setinvoiceidentifier(singleitem.getitemidentifier()); \/\/copy.getolepaidcopies().add(paidcopy); paidcopies.add(paidcopy); } getbusinessobjectservice().save(paidcopies); singleitem.setpaidcopies(paidcopies); } } } } } catch (exception e) { log.error(\"exception during prepareforsave() in oleinvoicedocument\", e);","code_context_20":"singleitem.setitemexchangerate(new kualidecimal(exchangerate)); singleitem.setexchangerate(exchangerate.tostring()); } this.setvendorinvoiceamount(this.getforeignvendorinvoiceamount() != null ? new kualidecimal(this.getforeignvendorinvoiceamount().divide(new bigdecimal(singleitem.getexchangerate()), 4, roundingmode.half_up)) : null); } } } setitemdescription(singleitem); map<string, string> copycriteria = new hashmap<string, string>(); if (singleitem.getpaidcopies().size() <= 0 && singleitem.getpoitemidentifier() != null && (this.getpurapdocumentidentifier() != null && singleitem.getitemidentifier() != null)) { copycriteria.put(\"poitemid\", singleitem.getpoitemidentifier().tostring()); list<olecopy> copies = (list<olecopy>) getbusinessobjectservice().findmatching(olecopy.class, copycriteria); if (copies.size() > 0) { list<olepaidcopy> paidcopies = new arraylist<olepaidcopy>(); for (olecopy copy : copies) { olepaidcopy paidcopy = new olepaidcopy(); paidcopy.setcopyid(copy.getcopyid()); paidcopy.setinvoiceitemid(this.getpurapdocumentidentifier()); paidcopy.setinvoiceidentifier(singleitem.getitemidentifier()); \/\/copy.getolepaidcopies().add(paidcopy); paidcopies.add(paidcopy); } getbusinessobjectservice().save(paidcopies); singleitem.setpaidcopies(paidcopies); } } } } } catch (exception e) { log.error(\"exception during prepareforsave() in oleinvoicedocument\", e); throw new runtimeexception(e); } }","repo":"VU-libtech\/OLE-INST"}
{"id":14444,"comment_id":0,"comment":"\/** * set a new strategies how to load options. * * @param filterablepagingprovider the paging provider that gives the actual * options in pages * @param filterablecountprovider the count provider to give the total about * of options with current filter * @param pagelength the length of the pages that component should use to * access providers *\/","code":"\/** * set a new strategies how to load options. * * @param filterablepagingprovider the paging provider that gives the actual * options in pages * @param filterablecountprovider the count provider to give the total about * of options with current filter * @param pagelength the length of the pages that component should use to * access providers *\/ public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","classification":"NONSATD","isFinished":true,"code_context_2":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","code_context_10":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","code_context_20":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","repo":"andreika63\/viritin"}
{"id":14444,"comment_id":1,"comment":"\/\/ need to re-create the piggybacklist & set container, some refactoring should be done here","code":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","classification":"DESIGN","isFinished":true,"code_context_2":"this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l;","code_context_10":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l;","code_context_20":"public void loadfrom(filterablepagingprovider<t> filterablepagingprovider, filterablecountprovider filterablecountprovider, int pagelength) { this.fpp = filterablepagingprovider; this.fcp = filterablecountprovider; \/\/ need to re-create the piggybacklist & set container, some refactoring should be done here piggybacklazylist = new lazylist<>(new lazylist.pagingprovider<t>() { private static final long serialversionuid = 1027614132444478021l; @override public list<t> findentities(int firstrow) { return fpp.findentities(firstrow, getcurrentfilter()); } }, new lazylist.countprovider() { private static final long serialversionuid = -7339189124024626177l; @override public int size() { return fcp.size(getcurrentfilter()); } }, pagelength); setbic(new dummyfilterablelistcontainer<t>(gettype(), piggybacklazylist)); getselect().setcontainerdatasource(getbic()); }","repo":"andreika63\/viritin"}
{"id":22702,"comment_id":0,"comment":"\/** * metodo para buscar una compra (read) * @param compraid, id de la compra a buscar * @return la compra con el id ingresado por parametro *\/","code":"\/** * metodo para buscar una compra (read) * @param compraid, id de la compra a buscar * @return la compra con el id ingresado por parametro *\/ public compraentity find(long compraid) { logger.log(level.info, \"buscando compra con el id={0}\", compraid); return em.find(compraentity.class, compraid); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public compraentity find(long compraid) { logger.log(level.info, \"buscando compra con el id={0}\", compraid); return em.find(compraentity.class, compraid); }","code_context_10":"public compraentity find(long compraid) { logger.log(level.info, \"buscando compra con el id={0}\", compraid); return em.find(compraentity.class, compraid); }","code_context_20":"public compraentity find(long compraid) { logger.log(level.info, \"buscando compra con el id={0}\", compraid); return em.find(compraentity.class, compraid); }","repo":"Uniandes-isis2603\/s2_Boletas"}
{"id":22714,"comment_id":0,"comment":"\/\/ todo: !! delete key should also delete this attachment.","code":"\/\/ todo: !! delete key should also delete this attachment. public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"DESIGN","isFinished":true,"code_context_2":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","code_context_10":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","code_context_20":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":1,"comment":"\/\/log.v(tag, \"oncreatedialog() called\");","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"NONSATD","isFinished":true,"code_context_2":"dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>();","code_context_10":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener.","code_context_20":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore.","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":2,"comment":"\/\/ todo: !!! make handler implement the dialoginterface.onclicklistener.","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":".seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{","code_context_10":"\/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore.","code_context_20":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break;","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":3,"comment":"\/\/ error already handled, so just notify user.","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"NONSATD","isFinished":true,"code_context_2":"if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing","code_context_10":"case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } }","code_context_20":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity);","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":4,"comment":"\/\/ notify the listadapter that it's cursor needs refreshing","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"NONSATD","isFinished":true,"code_context_2":"errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. }","code_context_10":".settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null)","code_context_20":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog;","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":5,"comment":"\/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record.","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"DESIGN","isFinished":true,"code_context_2":"} \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore.","code_context_10":".seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create();","code_context_20":"dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":6,"comment":"\/\/ ignore.","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"NONSATD","isFinished":true,"code_context_2":"notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp);","code_context_10":".setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break;","code_context_20":"\/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","repo":"SpencerRiddering\/flingtap-done"}
{"id":22714,"comment_id":7,"comment":"\/\/ ignore.","code":"public dialog oncreatedialog(int dialogid){ dialog dialog = null; try{ \/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","classification":"NONSATD","isFinished":true,"code_context_2":"notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp);","code_context_10":".setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break;","code_context_20":"\/\/log.v(tag, \"oncreatedialog() called\"); if (mmanageddialogs == null) { mmanageddialogs = new sparsearray<dialog>(); } switch(dialogid){ case dialog_delete_attachment_id: dialog = new alertdialog.builder(mactivity) .settitle(r.string.dialog_confirmdelete) .seticon(android.r.drawable.ic_dialog_alert) .setmessage(r.string.dialog_areyousure) .setpositivebutton(r.string.button_yes, new android.content.dialoginterface.onclicklistener(){ \/\/ todo: !!! make handler implement the dialoginterface.onclicklistener. public void onclick(dialoginterface dialog, int whichbutton){ try{ if( whichbutton == android.content.dialoginterface.button_positive){ if( !completableutil.delete(mactivity, mattachmenturi) ){ errorutil.notifyuser(mactivity); \/\/ error already handled, so just notify user. } \/\/ notify the listadapter that it's cursor needs refreshing notifydatasetchanged(); \/\/ todo: !! isn't this a hack to get around the normal observer thing? no, not always. sometimes data changes in the db record that the uri refers to and it isn't really a change to the attachment record. } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fd\", exp); errorutil.handleexceptionnotifyuser(\"err000fd\", exp, mactivity); } } }) .setnegativebutton(r.string.button_no, null) .create(); mmanageddialogs.put(dialogid, dialog); break; } }catch(handledexception h){ \/\/ ignore. }catch(exception exp){ log.e(tag, \"err000fc\", exp); errorutil.handleexceptionnotifyuser(\"err000fc\", exp, mactivity); } return dialog; }","repo":"SpencerRiddering\/flingtap-done"}
{"id":30955,"comment_id":0,"comment":"\/** * metodo para compartir el anuncio a traves del email * * @param email * @param model * @param authentication * @param req * @param flash * @return *\/","code":"\/** * metodo para compartir el anuncio a traves del email * * @param email * @param model * @param authentication * @param req * @param flash * @return *\/ @requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","classification":"NONSATD","isFinished":true,"code_context_2":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","code_context_10":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","code_context_20":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","repo":"adriancice\/adrian-pfm"}
{"id":30955,"comment_id":1,"comment":"\/\/ email message","code":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","classification":"NONSATD","isFinished":true,"code_context_2":"vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email);","code_context_10":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) {","code_context_20":"@requestmapping(value = \"\/shareanuncio\", method = requestmethod.post) public string shareanuncio(@requestparam(\"email\") string email, model model, authentication authentication, httpservletrequest req, redirectattributes flash) { logger.info(\"contactar-anunciante\"); integer id = integer.parseint(req.getparameter(\"id\")); try { vehiculo veh = vehiculoservice.findbyid(id); string appurl = req.getscheme() + \":\/\/\" + req.getservername() + \":\" + req.getserverport(); \/\/ email message simplemailmessage shareemail = new simplemailmessage(); shareemail.setto(email); shareemail.setsubject(\"coches: un amigo te recomienda este anuncio\"); shareemail.settext(\"\u00a1hola!\\n\" + \"un amigo se ha acordado de ti al ver este anuncio \" + veh.getmarca() + \" y cree que te puede interesar.\" + \"\\n\u00bftienes curiosidad?\\n\" + appurl + \"\/anuncio\/detalle\/\" + id); emailservice.sendemail(shareemail); model.addattribute(\"emailsend\", \"el correo se envio correctamente\"); logger.info(\"email enviado correctamente\"); } catch (exception e) { e.printstacktrace(); } return \"redirect:\/anuncio\/detalle\/\" + id; }","repo":"adriancice\/adrian-pfm"}
{"id":14663,"comment_id":0,"comment":"\/\/ todo: these could be optimised","code":"private void initshape() { \/\/ todo: these could be optimised float cx = dim * 0.5f; float cy = dim * 0.5f + 1; float r = (dim - 3) * 0.5f; float rh = r * 0.4f; for (int i = 0; i < 10; i++) { double ang = math.pi\/180 * (i * 36 - 90); float ri = i % 2 == 0 ? r : rh; float x = (float) math.cos(ang) * ri + cx; float y = (float) math.sin(ang) * ri + cy; if (i == 0) { gp.moveto(x, y); } else { gp.lineto(x, y); } } gp.closepath(); }","classification":"DESIGN","isFinished":true,"code_context_2":"private void initshape() { \/\/ todo: these could be optimised float cx = dim * 0.5f; float cy = dim * 0.5f + 1;","code_context_10":"private void initshape() { \/\/ todo: these could be optimised float cx = dim * 0.5f; float cy = dim * 0.5f + 1; float r = (dim - 3) * 0.5f; float rh = r * 0.4f; for (int i = 0; i < 10; i++) { double ang = math.pi\/180 * (i * 36 - 90); float ri = i % 2 == 0 ? r : rh; float x = (float) math.cos(ang) * ri + cx; float y = (float) math.sin(ang) * ri + cy; if (i == 0) {","code_context_20":"private void initshape() { \/\/ todo: these could be optimised float cx = dim * 0.5f; float cy = dim * 0.5f + 1; float r = (dim - 3) * 0.5f; float rh = r * 0.4f; for (int i = 0; i < 10; i++) { double ang = math.pi\/180 * (i * 36 - 90); float ri = i % 2 == 0 ? r : rh; float x = (float) math.cos(ang) * ri + cx; float y = (float) math.sin(ang) * ri + cy; if (i == 0) { gp.moveto(x, y); } else { gp.lineto(x, y); } } gp.closepath(); }","repo":"Sciss\/Rating"}
{"id":22873,"comment_id":0,"comment":"\/** * fill this collision map with a set of rectangles. a rectangle is added to a * cell if it overlaps with it (that includes just touching it). afterwards, * each cell of the collision map should contain all rectangles that cover the * cell. * * @param rectangles is a set of rectangles to insert, it must be != null * @throws collisionmapoutofboundsexception if a rectangle is out of the bounds * of this rectangle *\/","code":"\/** * fill this collision map with a set of rectangles. a rectangle is added to a * cell if it overlaps with it (that includes just touching it). afterwards, * each cell of the collision map should contain all rectangles that cover the * cell. * * @param rectangles is a set of rectangles to insert, it must be != null * @throws collisionmapoutofboundsexception if a rectangle is out of the bounds * of this rectangle *\/ private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ map[j][i].add(rectangle); } } } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ map[j][i].add(rectangle); } } } }","code_context_10":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ map[j][i].add(rectangle); } } } }","code_context_20":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ map[j][i].add(rectangle); } } } }","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":22873,"comment_id":1,"comment":"\/\/ todo insert code for assignment 5.2.a","code":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ map[j][i].add(rectangle); } } } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() ||","code_context_10":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety());","code_context_20":"private void fillcollisionmap(set<rectangle> rectangles) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.a for(rectangle rectangle:rectangles){ if(rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()); if(endx == this.grid_resolution_x){ endx = this.grid_resolution_x - 1; } int endy = (int)transformy(rectangle.gety() + rectangle.getheight()); if(endy == this.grid_resolution_y){ endy = this.grid_resolution_y - 1; } for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":22874,"comment_id":0,"comment":"\/** * given a rectangle, this method returns a set of potential colliding * rectangles (rectangles in the same cells). * * @param rectangle the rectangle to test overlap with must be != null * @return a set with all rectangles that possibly overlap with rectangle * @throws collisionmapoutofboundsexception if the rectangle is out of the * bounding box for this collisionmap *\/","code":"\/** * given a rectangle, this method returns a set of potential colliding * rectangles (rectangles in the same cells). * * @param rectangle the rectangle to test overlap with must be != null * @return a set with all rectangles that possibly overlap with rectangle * @throws collisionmapoutofboundsexception if the rectangle is out of the * bounding box for this collisionmap *\/ private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } } return rectangleset; }","classification":"NONSATD","isFinished":true,"code_context_2":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } } return rectangleset; }","code_context_10":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } } return rectangleset; }","code_context_20":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } } return rectangleset; }","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":22874,"comment_id":1,"comment":"\/\/ todo insert code for assignment 5.2.b","code":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } } return rectangleset; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() ||","code_context_10":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx());","code_context_20":"private set<rectangle> getcollisioncandidates(final rectangle rectangle) throws collisionmapoutofboundsexception { \/\/ todo insert code for assignment 5.2.b if( rectangle.getx() < this.gridrectangle.getx() || rectangle.getx() + rectangle.getwidth() > this.gridrectangle.getx() + this.gridrectangle.getwidth() || rectangle.gety() < this.gridrectangle.gety() || rectangle.gety() + rectangle.getheight() > this.gridrectangle.gety() + this.gridrectangle.getheight() ){ throw new collisionmapoutofboundsexception(\"a rectangle is out of the bounds of this rectangle\"); } set<rectangle> rectangleset = new hashset<>(); int startx = (int)transformx(rectangle.getx()); int starty = (int)transformy(rectangle.gety()); int endx = (int)transformx(rectangle.getx() + rectangle.getwidth()) + 1; int endy = (int)transformy(rectangle.gety() + rectangle.getheight()) + 1; for(int i = startx; i <= endx; i++){ for(int j = starty; j<=endy; j++){ for(rectangle re :map[j][i]){ rectangleset.add(re); } } }","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":22875,"comment_id":0,"comment":"\/** * check if the given rectangle collides with rectangles in the * {@link collisionmap}. * * @param rectangle the rectangle to check for collision * @return true if the given rectangle intersects one of the rectangles in the * collision map. * @throws illegalargumentexception if rectangle is null *\/","code":"\/** * check if the given rectangle collides with rectangles in the * {@link collisionmap}. * * @param rectangle the rectangle to check for collision * @return true if the given rectangle intersects one of the rectangles in the * collision map. * @throws illegalargumentexception if rectangle is null *\/ public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","classification":"NONSATD","isFinished":true,"code_context_2":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","code_context_10":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","code_context_20":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":22875,"comment_id":1,"comment":"\/\/ todo insert code for assignment 5.2.c","code":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\");","code_context_10":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; }","code_context_20":"public boolean collide(final rectangle rectangle) { \/\/ todo insert code for assignment 5.2.c if(rectangle == null){ throw new illegalargumentexception(\"rectangle is null\"); } boolean flag = false; try{ set<rectangle> rectangleset = this.getcollisioncandidates(rectangle); for(rectangle re:rectangleset){ if(re.intersects(rectangle)){ flag = true; } } }catch (exception e){ system.out.println(e.getmessage()); }finally { return flag; } }","repo":"SiyuChen1\/Datenstrukturen-und-Algorithmen-SS21"}
{"id":14690,"comment_id":0,"comment":"\/\/ todo: 8\/11\/20 defensively copy all collections and check for nulls?","code":"\/\/ todo: 8\/11\/20 defensively copy all collections and check for nulls? public mapperbuilder withinputnames(iterable<string> inputnames) { objects.requirenonnull(inputnames); this.inputnames = inputnames; return this; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public mapperbuilder withinputnames(iterable<string> inputnames) { objects.requirenonnull(inputnames); this.inputnames = inputnames; return this; }","code_context_10":"public mapperbuilder withinputnames(iterable<string> inputnames) { objects.requirenonnull(inputnames); this.inputnames = inputnames; return this; }","code_context_20":"public mapperbuilder withinputnames(iterable<string> inputnames) { objects.requirenonnull(inputnames); this.inputnames = inputnames; return this; }","repo":"andbi-redpill\/datasonnet-mapper"}
{"id":14723,"comment_id":0,"comment":"\/\/ id de usuario","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes","code_context_10":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution);","code_context_20":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":1,"comment":"\/\/ usuarios concurrentes","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes);","code_context_10":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\");","code_context_20":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\");","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":2,"comment":"\/\/ tiempo","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo);","code_context_10":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){","code_context_20":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue();","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":3,"comment":"\/\/ resoluci\u00f3n","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution);","code_context_10":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even);","code_context_20":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\");","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":4,"comment":"\/\/ disponibilidad","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0);","code_context_10":"integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){","code_context_20":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue();","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":5,"comment":"\/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"} } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\");","code_context_10":"bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair","code_context_20":"float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else {","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":6,"comment":"\/\/ hacemos llamada a paypal para comprobar el estado del acuerdo","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created","code_context_10":"bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null","code_context_20":"}else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":7,"comment":"\/\/ nvpdecoder object is created","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the","code_context_10":"} } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) {","code_context_20":"float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":8,"comment":"\/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display","code_context_10":"\/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else {","code_context_20":"bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":9,"comment":"\/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null","code_context_10":"string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){","code_context_20":"float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":10,"comment":"\/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"&& !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else {","code_context_10":"nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo","code_context_20":"} \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\");","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":11,"comment":"\/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){","code_context_10":"resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\";","code_context_20":"try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":12,"comment":"\/\/ comprobaci\u00f3n del resultado del check del acuerdo","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){","code_context_10":"\/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\");","code_context_20":"nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"),","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":13,"comment":"\/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\");","code_context_10":"string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"),","code_context_20":"\/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\");","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":14,"comment":"\/\/ acuerdo activo","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\");","code_context_10":"} } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error","code_context_20":"&& !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) {","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":15,"comment":"\/\/ mostrar alert informando al usuario del problema","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito","code_context_10":"string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\");","code_context_20":"resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) {","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":16,"comment":"\/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\");","code_context_10":"string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"),","code_context_20":"\/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\");","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":17,"comment":"\/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\");","code_context_10":"}else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block","code_context_20":"} } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":18,"comment":"\/\/ cerramos la ventana de confirmaci\u00f3n","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios","code_context_10":"\/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) {","code_context_20":"\/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":19,"comment":"\/\/ cerramos el di\u00e1logo de precios","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) {","code_context_10":"getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace();","code_context_20":"handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":20,"comment":"\/\/ todo auto-generated catch block","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) {","code_context_10":"\/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); }","code_context_20":"icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":21,"comment":"\/\/ todo auto-generated catch block","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) {","code_context_10":"\/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); }","code_context_20":"icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","repo":"adele-robots\/fiona"}
{"id":14723,"comment_id":22,"comment":"\/\/ todo auto-generated catch block","code":"public void procesarajaxchangelistener(gestorestadocomponentes gestorestados, gestordatoscomponentes gestordatos) { \/\/ id de usuario integer intcodusuario = contextutils.getuseridasinteger(); \/\/ usuarios concurrentes string strnumusersconcurrentes = (string)gestordatos.getvalue(\"numusuariosconcu\"); integer intnumuserconcurrentes = integer.valueof(strnumusersconcurrentes); \/\/ tiempo string stridunidadtiempo = (string)gestordatos.getvalue(\"idunidadtiempo\"); integer intidunidadtiempo = integer.valueof(stridunidadtiempo); \/\/ resoluci\u00f3n string stridresolution = (string)gestordatos.getvalue(\"resolution\"); integer intidresolution = integer.valueof(stridresolution); \/\/ disponibilidad boolean highavailability = (boolean)gestordatos.getvalue(\"checkavailability\"); integer inthighavailability = highavailability?new integer(1):new integer(0); float preciototal = null; if(gestordatos.getvalue(\"preciototal\") != null && !\"\".equals(gestordatos.getvalue(\"preciototal\")) && !\"0.0\".equals(gestordatos.getvalue(\"preciototal\"))){ preciototal = (float)gestordatos.getvalue(\"preciototal\"); bigdecimal bidpreciototal = new bigdecimal(preciototal); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ if(gestordatos.getvalue(\"preciototaltiempo\") != null && !\"\".equals(gestordatos.getvalue(\"preciototaltiempo\")) & !\"0.0\".equals(gestordatos.getvalue(\"preciototaltiempo\"))){ float preciototaltiempo = (float)gestordatos.getvalue(\"preciototaltiempo\"); bigdecimal bidpreciototal = new bigdecimal(preciototaltiempo); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); }else{ float preciototaluso = (float)gestordatos.getvalue(\"preciototaluso\"); float preciohosting = (float)gestordatos.getvalue(\"preciototalhosting\"); bigdecimal bidpreciototal = new bigdecimal(preciototaluso+preciohosting); bidpreciototal = bidpreciototal.setscale(2, roundingmode.half_even); preciototal = bidpreciototal.floatvalue(); } } \/\/ todo cambiar el segundo par\u00e1metro cuando podamos distinguir \/\/ entre ficheros de varias configuraciones try { string billingagreementid = helpercontext.getinstance().getvaluecontext(\"secure_user_billing_agreement_id\"); string resultadoacuerdo = \"noagreement\"; if(billingagreementid != null && !\"\".equals(billingagreementid)){ \/\/ hacemos llamada a paypal para comprobar el estado del acuerdo string ppresponse = paypalutilities.getinstance().baupdate(billingagreementid); \/\/ nvpdecoder object is created nvpdecoder resultvalues = new nvpdecoder(); \/\/ decode method of nvpdecoder will parse the request and decode the \/\/ name and value pair resultvalues.decode(ppresponse); \/\/ checks for acknowledgement and redirects accordingly to display \/\/ error messages string strack = resultvalues.get(\"ack\"); if (strack != null && !(strack.equals(\"success\") || strack .equals(\"successwithwarning\"))) { \/\/ todo: indicar al usuario que el acuerdo previo ha sido cancelado y ser\u00e1 necesaria la creaci\u00f3n de uno nuevo resultadoacuerdo = \"noagreement\"; } else { \/\/ en este punto todo ha ido bien as\u00ed que obtenemos el status string status = resultvalues.get(\"billingagreementstatus\"); if(status.comparetoignorecase(\"active\")==0){ resultadoacuerdo = \"agreement\"; } } } \/\/ comprobaci\u00f3n del resultado del check del acuerdo string idalert = \"alertinfouploadproduction\"; if(resultadoacuerdo.comparetoignorecase(\"noagreement\")==0){ idalert = \"alertinfobillingagreement\"; \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertbillagreement.cabecerapanel.valor\", \"billing agreement needed!\"), getmessage(\"fiona.alertbillagreement.mensajeok.valor\", \"you need to sign a new billing agreement!!\"), \"\", \"\"); }else if(resultadoacuerdo.comparetoignorecase(\"agreement\")==0){\/\/ acuerdo activo icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","classification":"DESIGN","isFinished":true,"code_context_2":"gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) {","code_context_10":"\/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); }","code_context_20":"icontexto[] salida = invokeuploadtoproduction(intcodusuario, null,intnumuserconcurrentes,intidunidadtiempo, intidresolution,inthighavailability, preciototal); string mensaje = salida[0].getstring(\"fioneg003010\"); \/\/ mostrar alert informando al usuario del problema if(mensaje.comparetoignorecase(\"ok\")==0){ \/\/ mostrar mensaje \u00e9xito \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"info\", getmessage(\"fiona.alertuploadprodok.cabecerapanel.valor\", \"success!\"), getmessage(\"fiona.alertuploadprodok.mensajeok.valor\", \"request completed!!\"), \"\", \"\"); }else{ \/\/ mostrar mensaje error \/\/ asignar t\u00edtulo y contenido adecuado handlemodalalert(gestordatos, gestorestados, idalert, \"error\", getmessage(\"fiona.alertuploadprodok.cabecerapanelerror.valor\", \"error!\"), getmessage(\"fiona.alertuploadprodok.mensajeerror.valor\", \"something went wrong...\"), \"\", \"\"); } } \/\/ cerramos la ventana de confirmaci\u00f3n gestorestados.closemodalalert(\"alertuploadconfirm\"); \/\/ cerramos el di\u00e1logo de precios gestorestados.closemodalalert(\"dialogoprecios\"); } catch (factoriadatosexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (persistenciaexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); } catch (fawnainvokerexception e) { \/\/ todo auto-generated catch block e.printstacktrace(); }catch(paypalexception ppex){ ppex.printstacktrace(); } }","repo":"adele-robots\/fiona"}
{"id":14725,"comment_id":0,"comment":"\/\/ todo: fix this so the label is a child of the lane or pool. \/\/ there's a problem with resize feature if the label is a direct child of lane\/pool.","code":"protected containershape gettargetcontainer(pictogramelement ownerpe) { \/\/ todo: fix this so the label is a child of the lane or pool. \/\/ there's a problem with resize feature if the label is a direct child of lane\/pool. return (containershape) ownerpe.econtainer(); }","classification":"DESIGN","isFinished":true,"code_context_2":"protected containershape gettargetcontainer(pictogramelement ownerpe) { \/\/ todo: fix this so the label is a child of the lane or pool. \/\/ there's a problem with resize feature if the label is a direct child of lane\/pool. return (containershape) ownerpe.econtainer(); }","code_context_10":"protected containershape gettargetcontainer(pictogramelement ownerpe) { \/\/ todo: fix this so the label is a child of the lane or pool. \/\/ there's a problem with resize feature if the label is a direct child of lane\/pool. return (containershape) ownerpe.econtainer(); }","code_context_20":"protected containershape gettargetcontainer(pictogramelement ownerpe) { \/\/ todo: fix this so the label is a child of the lane or pool. \/\/ there's a problem with resize feature if the label is a direct child of lane\/pool. return (containershape) ownerpe.econtainer(); }","repo":"alfa-ryano\/org.eclipse.bpmn2-modeler"}
{"id":31226,"comment_id":0,"comment":"\/\/ todo: alternatively we can just take a json string here and pass that directly to the ffi for librgb","code":"@reactmethod public void issue( \/\/ todo: alternatively we can just take a json string here and pass that directly to the ffi for librgb int alloc_coins, string alloc_outpoint, string network, string ticker, string name, string description, int precision, promise promise) { try { final runtime runtime = ((mainapplication) getcurrentactivity().getapplication()).getruntime(); final outpointcoins allocation = new outpointcoins((long) alloc_coins, alloc_outpoint); runtime.issue(network, ticker, name, description, precision, arrays.aslist(allocation), new hashset<outpointcoins>(), null, null); writablemap map = arguments.createmap(); promise.resolve(map); } catch (exception e) { promise.reject(e); } }","classification":"DESIGN","isFinished":true,"code_context_2":"@reactmethod public void issue( \/\/ todo: alternatively we can just take a json string here and pass that directly to the ffi for librgb int alloc_coins, string alloc_outpoint,","code_context_10":"@reactmethod public void issue( \/\/ todo: alternatively we can just take a json string here and pass that directly to the ffi for librgb int alloc_coins, string alloc_outpoint, string network, string ticker, string name, string description, int precision, promise promise) { try { final runtime runtime = ((mainapplication) getcurrentactivity().getapplication()).getruntime();","code_context_20":"@reactmethod public void issue( \/\/ todo: alternatively we can just take a json string here and pass that directly to the ffi for librgb int alloc_coins, string alloc_outpoint, string network, string ticker, string name, string description, int precision, promise promise) { try { final runtime runtime = ((mainapplication) getcurrentactivity().getapplication()).getruntime(); final outpointcoins allocation = new outpointcoins((long) alloc_coins, alloc_outpoint); runtime.issue(network, ticker, name, description, precision, arrays.aslist(allocation), new hashset<outpointcoins>(), null, null); writablemap map = arguments.createmap(); promise.resolve(map); } catch (exception e) { promise.reject(e); } }","repo":"alexeyneu\/rgb-sdk"}
{"id":31251,"comment_id":0,"comment":"\/* write a program to add a score of 100 to the the array scores. *\/","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"NONSATD","isFinished":true,"code_context_2":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores));","code_context_10":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line","code_context_20":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores);","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":1,"comment":"\/\/todo 1: write code to make a new array that can hold a new score","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){","code_context_10":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1];","code_context_20":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":2,"comment":"\/\/ ... code to add should stay above this line","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"NONSATD","isFinished":true,"code_context_2":"temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores","code_context_10":"*\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores);","code_context_20":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":3,"comment":"\/\/todo 2: next, write code to remove the first value from the scores","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){","code_context_10":"system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","code_context_20":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":4,"comment":"\/\/ ... code to remove should stay above this line","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"NONSATD","isFinished":true,"code_context_2":"temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below","code_context_10":"} temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","code_context_20":"\/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":5,"comment":"\/\/todo 3: implement the methods below","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"\/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores);","code_context_10":"scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","code_context_20":"the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":31251,"comment_id":6,"comment":"\/\/system.out.println(\"copy of scores looks like: \" + scores);","code":"public static void main(string[] args){ \/* write a program to add a score of 100 to the the array scores. *\/ int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","code_context_10":"system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","code_context_20":"int[] scores = {88,91,80,78,95}; system.out.println(\"current scores are: \" + arrays.tostring(scores)); \/\/todo 1: write code to make a new array that can hold a new score int[] temp = new int[scores.length + 1]; for(int i = 0; i<scores.length; i++){ temp[i] = scores[i]; } temp[temp.length -1] = 100; scores = temp; \/\/ ... code to add should stay above this line system.out.println(\"after 'adding' score: \" + arrays.tostring(scores)); \/\/todo 2: next, write code to remove the first value from the scores int[] temp2 = new int[scores.length -1]; for(int i = 1; i < scores.length; i++){ temp2[i-1] = scores[i]; } \/\/ ... code to remove should stay above this line system.out.println(\"after 'remove' scores are: \" + arrays.tostring(scores)); \/\/todo 3: implement the methods below int[] arr2 = makecopyof(scores); \/\/system.out.println(\"copy of scores looks like: \" + scores); }","repo":"SwettSoquelHS\/think-java-notswett"}
{"id":23212,"comment_id":0,"comment":"\/\/ system.out.println(\"pausing poll request\");","code":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","classification":"NONSATD","isFinished":true,"code_context_2":"@override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it","code_context_10":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } });","code_context_20":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","repo":"allanim\/vaadin"}
{"id":23212,"comment_id":1,"comment":"\/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment.","code":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) {","code_context_10":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } });","code_context_20":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","repo":"allanim\/vaadin"}
{"id":23212,"comment_id":2,"comment":"\/\/ system.out.println(\"continuing poll request\");","code":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","classification":"NONSATD","isFinished":true,"code_context_2":"e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } });","code_context_10":"@override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\")));","code_context_20":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","repo":"allanim\/vaadin"}
{"id":23212,"comment_id":3,"comment":"\/\/ hacky urls that are might not work in all deployment scenarios","code":"@override protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","classification":"DEFECT","isFinished":true,"code_context_2":"} }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\")));","code_context_10":"thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","code_context_20":"protected void setup(vaadinrequest request) { addcomponent(new progressindicator() { { registerrpc(new progressindicatorserverrpc() { @override public void poll() { \/\/ system.out.println(\"pausing poll request\"); try { \/\/ make the xhr request last longer to make it \/\/ easier to click the link at the right moment. thread.sleep(1000); } catch (interruptedexception e) { e.printstacktrace(); } \/\/ system.out.println(\"continuing poll request\"); } }); setpollinginterval(3000); } }); \/\/ hacky urls that are might not work in all deployment scenarios addcomponent(new link(\"navigate away\", new externalresource( \"slowrequesthandler\"))); addcomponent(new link(\"start download\", new externalresource( \"slowrequesthandler?download\"))); }","repo":"allanim\/vaadin"}
{"id":23397,"comment_id":0,"comment":"\/\/only reassign if not -1 as messes up code further down","code":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","classification":"NONSATD","isFinished":true,"code_context_2":"final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf","code_context_10":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue);","code_context_20":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","repo":"UprootStaging\/maven-OpenViewerFX-src"}
{"id":23397,"comment_id":1,"comment":"\/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue","code":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","classification":"DEFECT","isFinished":true,"code_context_2":"glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph);","code_context_10":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } }","code_context_20":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","repo":"UprootStaging\/maven-OpenViewerFX-src"}
{"id":23397,"comment_id":2,"comment":"\/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value","code":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","classification":"NONSATD","isFinished":true,"code_context_2":"}else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue);","code_context_10":"if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","code_context_20":"static boolean remapglyph(pdffont currentfontdata, glyphdata glyphdata){ boolean alreadyremaped=false; final string charglyph= currentfontdata.getmappedchar(glyphdata.getrawint(), false); if(charglyph!=null){ final int newrawint=currentfontdata.getdiffchar(charglyph); if(newrawint!=-1){ glyphdata.setrawint(newrawint); \/\/only reassign if not -1 as messes up code further down glyphdata.setdisplayvalue(string.valueof((char)newrawint)); \/\/fix for pdfdata\/sample_pdfs_html\/general-july2012\/klar--men-aldri-ferdig_dacecc.pdf \/\/in some examples the unicode table is wrong and maps the character into this odd range, but the glyph is always correct \/\/this is a sanity check to fix this mapping issue }else if(!glyphdata.getdisplayvalue().isempty() && glyphdata.getdisplayvalue().charat(0)<32){ final int altvalue=standardfonts.getadobemap(charglyph); \/\/this test can return -1 for invalid value as in sample_pdfs_html\/general-may2014\/18147.pdf \/\/which breaks code further down so we reject this value if(altvalue>-1) { glyphdata.setrawint(altvalue); glyphdata.set(string.valueof((char) altvalue)); alreadyremaped = true; } } } return alreadyremaped; }","repo":"UprootStaging\/maven-OpenViewerFX-src"}
{"id":31695,"comment_id":0,"comment":"\/\/tore: [by ys] should be storing repo once interfaces refactoring is done","code":"@override @nonnull public mutablevfsitem getmutableitem(repopath repopath) { \/\/tore: [by ys] should be storing repo once interfaces refactoring is done localrepo localrepo = localorcachedrepositorybykey(repopath.getrepokey()); if (localrepo != null) { mutablevfsitem mutablefsitem = localrepo.getmutablefsitem(repopath); if (mutablefsitem != null) { return mutablefsitem; } } throw new itemnotfoundruntimeexception(repopath); }","classification":"DESIGN","isFinished":true,"code_context_2":"@nonnull public mutablevfsitem getmutableitem(repopath repopath) { \/\/tore: [by ys] should be storing repo once interfaces refactoring is done localrepo localrepo = localorcachedrepositorybykey(repopath.getrepokey()); if (localrepo != null) {","code_context_10":"@override @nonnull public mutablevfsitem getmutableitem(repopath repopath) { \/\/tore: [by ys] should be storing repo once interfaces refactoring is done localrepo localrepo = localorcachedrepositorybykey(repopath.getrepokey()); if (localrepo != null) { mutablevfsitem mutablefsitem = localrepo.getmutablefsitem(repopath); if (mutablefsitem != null) { return mutablefsitem; } } throw new itemnotfoundruntimeexception(repopath); }","code_context_20":"@override @nonnull public mutablevfsitem getmutableitem(repopath repopath) { \/\/tore: [by ys] should be storing repo once interfaces refactoring is done localrepo localrepo = localorcachedrepositorybykey(repopath.getrepokey()); if (localrepo != null) { mutablevfsitem mutablefsitem = localrepo.getmutablefsitem(repopath); if (mutablefsitem != null) { return mutablefsitem; } } throw new itemnotfoundruntimeexception(repopath); }","repo":"alancnet\/artifactory"}
{"id":15371,"comment_id":0,"comment":"\/** returns the target for the given specialinvokeexpr. *\/","code":"\/** returns the target for the given specialinvokeexpr. *\/ public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","classification":"NONSATD","isFinished":true,"code_context_2":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","code_context_10":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","code_context_20":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","repo":"UCLA-SEAL\/JShrink"}
{"id":15371,"comment_id":1,"comment":"\/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/","code":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","classification":"DESIGN","isFinished":true,"code_context_2":"sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target;","code_context_10":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","code_context_20":"public sootmethod resolvespecialdispatch(specialinvokeexpr ie, sootmethod container) { container.getdeclaringclass().checklevel(sootclass.hierarchy); sootmethod target = ie.getmethod(); target.getdeclaringclass().checklevel(sootclass.hierarchy); \/* * this is a bizarre condition! hopefully the implementation is correct. see vm spec, 2nd edition, chapter 6, in the * definition of invokespecial. *\/ if (\"<init>\".equals(target.getname()) || target.isprivate()) { return target; } else if (isclasssubclassof(target.getdeclaringclass(), container.getdeclaringclass())) { return resolveconcretedispatch(container.getdeclaringclass(), target); } else { return target; } }","repo":"UCLA-SEAL\/JShrink"}
{"id":15595,"comment_id":0,"comment":"\/\/ todo: how to identify the correct device if there are several devices in the \/\/ list?","code":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","classification":"DESIGN","isFinished":true,"code_context_2":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject????","code_context_10":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","code_context_20":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","repo":"Thewbi\/knx_meister"}
{"id":15595,"comment_id":1,"comment":"\/\/ todo: maybe create a map from datapoint id to comobject????","code":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist());","code_context_10":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","code_context_20":"public static list<knxcomobject> retrievecomobjectlistbydatapointid(final knxproject knxproject, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(0); \/\/ todo: maybe create a map from datapoint id to comobject???? final list<knxcomobject> knxcomobjects = knxdeviceinstance.getcomobjects().values().stream() .filter(c -> c.getnumber() == datapointid).filter(c -> c.isgroupobject()).collect(collectors.tolist()); return knxcomobjects; }","repo":"Thewbi\/knx_meister"}
{"id":15596,"comment_id":0,"comment":"\/\/ todo: how to identify the correct device if there are several devices in the \/\/ list?","code":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","classification":"DESIGN","isFinished":true,"code_context_2":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject????","code_context_10":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst();","code_context_20":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","repo":"Thewbi\/knx_meister"}
{"id":15596,"comment_id":1,"comment":"\/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off","code":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","classification":"DESIGN","isFinished":true,"code_context_2":"\/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects()","code_context_10":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","code_context_20":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","repo":"Thewbi\/knx_meister"}
{"id":15596,"comment_id":2,"comment":"\/\/ @formatter:on","code":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","classification":"NONSATD","isFinished":true,"code_context_2":".filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","code_context_10":"final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","code_context_20":"public static optional<knxcomobject> retrievecomobjectbydatapointid(final knxproject knxproject, final int deviceindex, final int datapointid) { \/\/ todo: how to identify the correct device if there are several devices in the \/\/ list? final knxdeviceinstance knxdeviceinstance = knxproject.getdeviceinstances().get(deviceindex); \/\/ todo: maybe create a map from datapoint id to comobject???? \/\/ @formatter:off return knxdeviceinstance .getcomobjects() .values() .stream() .filter(c -> c.getnumber() == datapointid) .filter(c -> c.isgroupobject()) .findfirst(); \/\/ @formatter:on }","repo":"Thewbi\/knx_meister"}
{"id":23864,"comment_id":0,"comment":"\/** * a method to build an exp4j expression for a formula object, * given that a valid formula equation was input by the configuration file. * @throws an exception if _formulaequation cannot be parsed. * @return ? *\/ \/\/todo: add exceptions for nulls, bad ins, w.e.","code":"\/** * a method to build an exp4j expression for a formula object, * given that a valid formula equation was input by the configuration file. * @throws an exception if _formulaequation cannot be parsed. * @return ? *\/ \/\/todo: add exceptions for nulls, bad ins, w.e. private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":1,"comment":"\/\/ make base exp4j expressionbuilder using _formulaequation string as input","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) {","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":2,"comment":"\/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); }","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":3,"comment":"\/\/ make a matcher to get the variables out of the formula equation string given, using above pattern","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression.","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":4,"comment":"\/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0)","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression;","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":5,"comment":"\/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0)","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder","code_context_10":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":6,"comment":"\/\/ set ith match from regex as a variable in the formula expression builder","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"\/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); }","code_context_10":"expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":23864,"comment_id":7,"comment":"\/\/ once regex stuff is done and variables are set, properly build the expression.","code":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","classification":"NONSATD","isFinished":true,"code_context_2":"} } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression;","code_context_10":"\/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","code_context_20":"private expression _buildexpression() { \/\/ make base exp4j expressionbuilder using _formulaequation string as input expressionbuilder _formulaexpressionbuilder = new expressionbuilder(this._formulaequation); \/\/ setup regex pattern we want to use to isolate formula variables from _formulaequation string \/\/ ==in terms of modularity, should we keep the regex string we use as a field for formulas that can be changed by config? dunno, probably not, would be interesting though pattern _formularegex = new pattern.compile(\"\\s?_[a-za-z0-9_]*_\\s?\"); \/\/ make a matcher to get the variables out of the formula equation string given, using above pattern matcher _formulavarmatcher = new _formularegex.matcher(this._formulaequation); \/\/ while regex matcher can find matching values, set them as variables in exp4j expressionbuilder while (_formulavarmatcher.find()) { \/\/ while index i, starting at 1, is less than matcher.groupcount(), which inherently does not include groupcount(0) for (int i=1; i<=_formulavarmatcher.groupcount(); i++) { \/\/ set ith match from regex as a variable in the formula expression builder _formulaexpressionbuilder.variable(_formulavarmatcher.group(i)); } } \/\/ once regex stuff is done and variables are set, properly build the expression. expression _formulaexpression = _formulaexpressionbuilder.build(); return _formulaexpression; }","repo":"ambedrake\/UniversalAuthenticatedReportGenerator"}
{"id":32072,"comment_id":0,"comment":"\/\/ todo: what happens if final count is 63 and we smelt double?","code":"private void craftrecipe( recipe<?> currentrecipe) { if (currentrecipe != null && this.canacceptrecipeoutput(currentrecipe)) { itemstack inputstack = this.inventory.get(0); itemstack outputstack = this.inventory.get(2); itemstack reciperesultstack = currentrecipe.getoutput(); int resultcount = world.random.nextint(100) < dupechance100 ? 2 : 1; if (outputstack.isempty()) { itemstack newresultstack = reciperesultstack.copy(); newresultstack.setamount(resultcount); this.inventory.set(2, newresultstack); } else if (outputstack.getitem() == reciperesultstack.getitem()) { \/\/ todo: what happens if final count is 63 and we smelt double? outputstack.addamount(resultcount); } if (!this.world.isclient) this.setlastrecipe(currentrecipe); if (inputstack.getitem() == blocks.wet_sponge.getitem() && !((itemstack) this.inventory.get(1)).isempty() && ((itemstack) this.inventory.get(1)).getitem() == items.bucket) { this.inventory.set(1, new itemstack(items.water_bucket)); } inputstack.subtractamount(1); } }","classification":"DESIGN","isFinished":true,"code_context_2":"else if (outputstack.getitem() == reciperesultstack.getitem()) { \/\/ todo: what happens if final count is 63 and we smelt double? outputstack.addamount(resultcount); }","code_context_10":"itemstack reciperesultstack = currentrecipe.getoutput(); int resultcount = world.random.nextint(100) < dupechance100 ? 2 : 1; if (outputstack.isempty()) { itemstack newresultstack = reciperesultstack.copy(); newresultstack.setamount(resultcount); this.inventory.set(2, newresultstack); } else if (outputstack.getitem() == reciperesultstack.getitem()) { \/\/ todo: what happens if final count is 63 and we smelt double? outputstack.addamount(resultcount); } if (!this.world.isclient) this.setlastrecipe(currentrecipe); if (inputstack.getitem() == blocks.wet_sponge.getitem() && !((itemstack) this.inventory.get(1)).isempty() && ((itemstack) this.inventory.get(1)).getitem() == items.bucket) { this.inventory.set(1, new itemstack(items.water_bucket)); } inputstack.subtractamount(1); }","code_context_20":"private void craftrecipe( recipe<?> currentrecipe) { if (currentrecipe != null && this.canacceptrecipeoutput(currentrecipe)) { itemstack inputstack = this.inventory.get(0); itemstack outputstack = this.inventory.get(2); itemstack reciperesultstack = currentrecipe.getoutput(); int resultcount = world.random.nextint(100) < dupechance100 ? 2 : 1; if (outputstack.isempty()) { itemstack newresultstack = reciperesultstack.copy(); newresultstack.setamount(resultcount); this.inventory.set(2, newresultstack); } else if (outputstack.getitem() == reciperesultstack.getitem()) { \/\/ todo: what happens if final count is 63 and we smelt double? outputstack.addamount(resultcount); } if (!this.world.isclient) this.setlastrecipe(currentrecipe); if (inputstack.getitem() == blocks.wet_sponge.getitem() && !((itemstack) this.inventory.get(1)).isempty() && ((itemstack) this.inventory.get(1)).getitem() == items.bucket) { this.inventory.set(1, new itemstack(items.water_bucket)); } inputstack.subtractamount(1); } }","repo":"XuyuEre\/fabric-furnaces"}
{"id":7716,"comment_id":0,"comment":"\/\/ merge sort","code":"\/\/ merge sort public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","classification":"NONSATD","isFinished":true,"code_context_2":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","code_context_10":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","code_context_20":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","repo":"Sailia\/data_structures"}
{"id":7716,"comment_id":1,"comment":"\/\/ todo: implement this method (in an iterative way)","code":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","code_context_10":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","code_context_20":"public void mergesort(card[] cardarray) { \/\/ todo: implement this method (in an iterative way) }","repo":"Sailia\/data_structures"}
{"id":7891,"comment_id":0,"comment":"\/\/todo @test if findcommentsbypostid_returns_postid_not_found","code":"\/\/todo @test if findcommentsbypostid_returns_postid_not_found @test public void findallsubcomments_for_comment_returns_collection_status_isfound() throws exception{ when(commentservice.findcommentsbycommentparentid(anyint())).thenreturn(arrays.aslist(comments)); when(userservice.finduserbyid(anyint())).thenreturn(optional.of(user)); when(commentlikeservice.checkifcommentisliked(any(comment.class), any(user.class))).thenreturn(true); resultactions results = mockmvc .perform( get(\"\/microblogging\/v1\/comment\/2?requesteduserid=1\")) .anddo(print()); results .andexpect(status().isok()) .andexpect(content().contenttype(mediatype.application_json)) .andexpect(jsonpath(\"$.*\").isarray()) .andexpect(jsonpath(\"$.*\",hassize(4))) .andreturn(); }","classification":"TEST","isFinished":true,"code_context_2":"@test public void findallsubcomments_for_comment_returns_collection_status_isfound() throws exception{ when(commentservice.findcommentsbycommentparentid(anyint())).thenreturn(arrays.aslist(comments)); when(userservice.finduserbyid(anyint())).thenreturn(optional.of(user)); when(commentlikeservice.checkifcommentisliked(any(comment.class), any(user.class))).thenreturn(true); resultactions results = mockmvc .perform( get(\"\/microblogging\/v1\/comment\/2?requesteduserid=1\")) .anddo(print()); results .andexpect(status().isok()) .andexpect(content().contenttype(mediatype.application_json)) .andexpect(jsonpath(\"$.*\").isarray()) .andexpect(jsonpath(\"$.*\",hassize(4))) .andreturn(); }","code_context_10":"@test public void findallsubcomments_for_comment_returns_collection_status_isfound() throws exception{ when(commentservice.findcommentsbycommentparentid(anyint())).thenreturn(arrays.aslist(comments)); when(userservice.finduserbyid(anyint())).thenreturn(optional.of(user)); when(commentlikeservice.checkifcommentisliked(any(comment.class), any(user.class))).thenreturn(true); resultactions results = mockmvc .perform( get(\"\/microblogging\/v1\/comment\/2?requesteduserid=1\")) .anddo(print()); results .andexpect(status().isok()) .andexpect(content().contenttype(mediatype.application_json)) .andexpect(jsonpath(\"$.*\").isarray()) .andexpect(jsonpath(\"$.*\",hassize(4))) .andreturn(); }","code_context_20":"@test public void findallsubcomments_for_comment_returns_collection_status_isfound() throws exception{ when(commentservice.findcommentsbycommentparentid(anyint())).thenreturn(arrays.aslist(comments)); when(userservice.finduserbyid(anyint())).thenreturn(optional.of(user)); when(commentlikeservice.checkifcommentisliked(any(comment.class), any(user.class))).thenreturn(true); resultactions results = mockmvc .perform( get(\"\/microblogging\/v1\/comment\/2?requesteduserid=1\")) .anddo(print()); results .andexpect(status().isok()) .andexpect(content().contenttype(mediatype.application_json)) .andexpect(jsonpath(\"$.*\").isarray()) .andexpect(jsonpath(\"$.*\",hassize(4))) .andreturn(); }","repo":"Yarulika\/Microblogging"}
{"id":16097,"comment_id":0,"comment":"\/* returns a list of filenames (just the filename, not the path) in working directory. todo: currently this skips over subdirs. this will throw an ioexception exception if the working directory is deleted (or possibly if a file is removed) while this method is executing. *\/","code":"\/* returns a list of filenames (just the filename, not the path) in working directory. todo: currently this skips over subdirs. this will throw an ioexception exception if the working directory is deleted (or possibly if a file is removed) while this method is executing. *\/ public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","classification":"DESIGN","isFinished":true,"code_context_2":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","code_context_10":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","code_context_20":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","repo":"SciGaP\/DEPRECATED-Cipres-Airavata-POC"}
{"id":16097,"comment_id":1,"comment":"\/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/","code":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","classification":"NONSATD","isFinished":true,"code_context_2":"string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; }","code_context_10":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","code_context_20":"public list<filehandler.fileattributes> listworkingdirectory() throws ioexception, exception { filehandler filehandler = null; try { tool tool = gettool(); filehandler = tool.gettoolresource().getfilehandler(); string workingdirectory = tool.gettoolresource().getworkingdirectory(task.getjobhandle()); list<filehandler.fileattributes> list = filehandler.list(workingdirectory); \/* log.debug(\"in listworkingdirectory, directory is \" + workingdirectory + \" and there are \" + list.size() + \" files.\"); *\/ return list; } finally { if (filehandler != null) { filehandler.close(); } } }","repo":"SciGaP\/DEPRECATED-Cipres-Airavata-POC"}
{"id":8012,"comment_id":0,"comment":"\/** * codegen iflexmodulefactory.callincontext(); * * public final override function callincontext(fn:function, thisarg:object, argarray:array, returns:boolean=true) : * * { * var ret : * = fn.apply(thisarg, argarray); * if (returns) return ret; * return; * } * * @param classgen * @param isoverride true if the generated method overrides a base class * method, false otherwise. *\/","code":"\/** * codegen iflexmodulefactory.callincontext(); * * public final override function callincontext(fn:function, thisarg:object, argarray:array, returns:boolean=true) : * * { * var ret : * = fn.apply(thisarg, argarray); * if (returns) return ret; * return; * } * * @param classgen * @param isoverride true if the generated method overrides a base class * method, false otherwise. *\/ protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","classification":"NONSATD","isFinished":true,"code_context_2":"protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","code_context_10":"protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","code_context_20":"protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","repo":"alinakazi\/apache-royale-0.9.8-bin-js-swf"}
{"id":8012,"comment_id":1,"comment":"\/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed.","code":"protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","classification":"DESIGN","isFinished":true,"code_context_2":"callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>()","code_context_10":"instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","code_context_20":"protected final void codegencallincontextmethod(classgeneratorhelper classgen, boolean isoverride) { iresolvedqualifiersreference applyreference = referencefactory.resolvedqualifierqualifiedreference(royaleproject.getworkspace(), namespacedefinition.getas3namespacedefinition(), \"apply\"); instructionlist callincontext = new instructionlist(); callincontext.addinstruction(abcconstants.op_getlocal1); callincontext.addinstruction(abcconstants.op_getlocal2); callincontext.addinstruction(abcconstants.op_getlocal3); callincontext.addinstruction(abcconstants.op_callproperty, new object[] {applyreference.getmname(), 2}); callincontext.addinstruction(abcconstants.op_getlocal, 4); label callincontextreturnvoid = new label(); callincontext.addinstruction(abcconstants.op_iffalse, callincontextreturnvoid); callincontext.addinstruction(abcconstants.op_returnvalue); callincontext.labelnext(callincontextreturnvoid); \/\/ todo this should be op_returnvoid, but the boolean default value \/\/ for the 'returns' parameter isn't defaulting to true. \/\/ fix this after cmp-936 is fixed. callincontext.addinstruction(abcconstants.op_returnvalue); immutablelist<name> callincontextparams = new immutablelist.builder<name>() .add(new name(iaslanguageconstants.function)) .add(new name(iaslanguageconstants.object)) .add(new name(iaslanguageconstants.array)) .add(new name(iaslanguageconstants.boolean)) .build(); classgen.additraitsmethod(new name(\"callincontext\"), callincontextparams, null, collections.<object> singletonlist(boolean.true), false, true, isoverride, callincontext); }","repo":"alinakazi\/apache-royale-0.9.8-bin-js-swf"}
{"id":16242,"comment_id":0,"comment":"\/\/gen-first:event_rhkeyreleased","code":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","classification":"NONSATD","isFinished":true,"code_context_2":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","code_context_10":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","code_context_20":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","repo":"ajpro-byte\/ClinicMGMT"}
{"id":16242,"comment_id":1,"comment":"\/\/ calc_total(); \/\/ todo add your handling code here:","code":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","code_context_10":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","code_context_20":"private void rhkeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rhkeyreleased \/\/ calc_total(); \/\/ todo add your handling code here: }","repo":"ajpro-byte\/ClinicMGMT"}
{"id":16243,"comment_id":0,"comment":"\/\/gen-first:event_rikeyreleased","code":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","classification":"NONSATD","isFinished":true,"code_context_2":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){","code_context_10":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","code_context_20":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","repo":"ajpro-byte\/ClinicMGMT"}
{"id":16243,"comment_id":1,"comment":"\/\/calc_total(); \/\/ todo add your handling code here:","code":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","classification":"IMPLEMENTATION","isFinished":true,"code_context_2":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total();","code_context_10":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","code_context_20":"private void rikeyreleased(java.awt.event.keyevent evt) {\/\/gen-first:event_rikeyreleased \/\/calc_total(); \/\/ todo add your handling code here: if (ri.isenabled()==true){ calc_total(); }else{ } }","repo":"ajpro-byte\/ClinicMGMT"}
