{"id":24672,"original_code":"public String getJavaName() {\n        return service.getName(); \/\/TODO Capitalize first char??\n    }","code":"public String getJavaName() {\n        return service.getName();\n    }","cleancode":"public string getjavaname() { return service.getname(); }","comment":"\/\/todo capitalize first char??","repo":"timfel\/netbeans","code_context_2":"public String getJavaName() {\nreturn service.getName(); \/\/TODO Capitalize first char??\n}","code_context_10":"public String getJavaName() {\nreturn service.getName(); \/\/TODO Capitalize first char??\n}","code_context_20":"public String getJavaName() {\nreturn service.getName(); \/\/TODO Capitalize first char??\n}","label":[0,1,0,0]}
{"id":32867,"original_code":"@Override\n   public boolean defineLock(String name, ClusteredLockConfiguration configuration) {\n      \/\/ TODO: Configuration is not used because we don't support any other mode for now. For that : ISPN-8413\n      CacheHolder cacheHolder = extractCacheHolder(cacheHolderFuture);\n      cache = cacheHolder.getClusteredLockCache();\n      ClusteredLockKey key = new ClusteredLockKey(ByteString.fromString(name));\n      ClusteredLockValue clusteredLockValue = cache.putIfAbsent(key, ClusteredLockValue.INITIAL_STATE);\n      locks.putIfAbsent(name, new ClusteredLockImpl(name, key, cache, this));\n      return clusteredLockValue == null;\n   }","code":"@Override\n   public boolean defineLock(String name, ClusteredLockConfiguration configuration) {\n     \n      CacheHolder cacheHolder = extractCacheHolder(cacheHolderFuture);\n      cache = cacheHolder.getClusteredLockCache();\n      ClusteredLockKey key = new ClusteredLockKey(ByteString.fromString(name));\n      ClusteredLockValue clusteredLockValue = cache.putIfAbsent(key, ClusteredLockValue.INITIAL_STATE);\n      locks.putIfAbsent(name, new ClusteredLockImpl(name, key, cache, this));\n      return clusteredLockValue == null;\n   }","cleancode":"@override public boolean definelock(string name, clusteredlockconfiguration configuration) { cacheholder cacheholder = extractcacheholder(cacheholderfuture); cache = cacheholder.getclusteredlockcache(); clusteredlockkey key = new clusteredlockkey(bytestring.fromstring(name)); clusteredlockvalue clusteredlockvalue = cache.putifabsent(key, clusteredlockvalue.initial_state); locks.putifabsent(name, new clusteredlockimpl(name, key, cache, this)); return clusteredlockvalue == null; }","comment":"\/\/ todo: configuration is not used because we don't support any other mode for now. for that : ispn-8413","repo":"tqrg-bot\/infinispan","code_context_2":"@Override\npublic boolean defineLock(String name, ClusteredLockConfiguration configuration) {\n\/\/ TODO: Configuration is not used because we don't support any other mode for now. For that : ISPN-8413\nCacheHolder cacheHolder = extractCacheHolder(cacheHolderFuture);\ncache = cacheHolder.getClusteredLockCache();","code_context_10":"@Override\npublic boolean defineLock(String name, ClusteredLockConfiguration configuration) {\n\/\/ TODO: Configuration is not used because we don't support any other mode for now. For that : ISPN-8413\nCacheHolder cacheHolder = extractCacheHolder(cacheHolderFuture);\ncache = cacheHolder.getClusteredLockCache();\nClusteredLockKey key = new ClusteredLockKey(ByteString.fromString(name));\nClusteredLockValue clusteredLockValue = cache.putIfAbsent(key, ClusteredLockValue.INITIAL_STATE);\nlocks.putIfAbsent(name, new ClusteredLockImpl(name, key, cache, this));\nreturn clusteredLockValue == null;\n}","code_context_20":"@Override\npublic boolean defineLock(String name, ClusteredLockConfiguration configuration) {\n\/\/ TODO: Configuration is not used because we don't support any other mode for now. For that : ISPN-8413\nCacheHolder cacheHolder = extractCacheHolder(cacheHolderFuture);\ncache = cacheHolder.getClusteredLockCache();\nClusteredLockKey key = new ClusteredLockKey(ByteString.fromString(name));\nClusteredLockValue clusteredLockValue = cache.putIfAbsent(key, ClusteredLockValue.INITIAL_STATE);\nlocks.putIfAbsent(name, new ClusteredLockImpl(name, key, cache, this));\nreturn clusteredLockValue == null;\n}","label":[1,0,0,0]}
{"id":8369,"original_code":"public static void attachEndpointToSession(Channel channel, Endpoint endpoint) {\n    \/\/ TODO\n    \/\/ Netty allow to set\/get attachment on Channel in the near feature, e.g.\n    \/\/ channel.getAttribute(new AttributeKey<Endpoint>(TRANSPORT_SENDER))\n    endpoints.set(channel, endpoint);\n  }","code":"public static void attachEndpointToSession(Channel channel, Endpoint endpoint) {\n   \n   \n   \n    endpoints.set(channel, endpoint);\n  }","cleancode":"public static void attachendpointtosession(channel channel, endpoint endpoint) { endpoints.set(channel, endpoint); }","comment":"\/\/ todo \/\/ netty allow to set\/get attachment on channel in the near feature, e.g. \/\/ channel.getattribute(new attributekey<endpoint>(transport_sender))","repo":"tianshaojie\/common-framework","code_context_2":"public static void attachEndpointToSession(Channel channel, Endpoint endpoint) {\n\/\/ TODO\n\/\/ Netty allow to set\/get attachment on Channel in the near feature, e.g.\n\/\/ channel.getAttribute(new AttributeKey<Endpoint>(TRANSPORT_SENDER))\nendpoints.set(channel, endpoint);\n}","code_context_10":"public static void attachEndpointToSession(Channel channel, Endpoint endpoint) {\n\/\/ TODO\n\/\/ Netty allow to set\/get attachment on Channel in the near feature, e.g.\n\/\/ channel.getAttribute(new AttributeKey<Endpoint>(TRANSPORT_SENDER))\nendpoints.set(channel, endpoint);\n}","code_context_20":"public static void attachEndpointToSession(Channel channel, Endpoint endpoint) {\n\/\/ TODO\n\/\/ Netty allow to set\/get attachment on Channel in the near feature, e.g.\n\/\/ channel.getAttribute(new AttributeKey<Endpoint>(TRANSPORT_SENDER))\nendpoints.set(channel, endpoint);\n}","label":[0,1,0,0]}
{"id":24782,"original_code":"private void searchTweets(final String keyword) {\n        safelyUnsubscribe(subDelayedSearch, subLoadMoreTweets, subSearchTweets);\n        lastKeyword = keyword;\n        if (!networkApi.isConnectedToInternet(this)) {\n            showSnackBar(msgNoInternetConnection);\n            return;\n        }\n        if (!twitterApi.canSearchTweets(keyword)) {\n            return;\n        }\n        subSearchTweets = twitterApi.searchTweets(keyword)\n                .subscribeOn(Schedulers.io())\n                .observeOn(AndroidSchedulers.mainThread())\n                .subscribe(new Subscriber<List<Status>>() {\n                    @Override\n                    public void onStart() {\n                    }\n                    @Override\n                    public void onCompleted() {\n                        \/\/ we don't have to implement this method\n                    }\n                    @Override\n                    public void onError(final Throwable e) {\n                        final String message = getErrorMessage((TwitterException) e);\n                        showSnackBar(message);\n                        showErrorMessageContainer(message, R.drawable.no_tweets);\n                    }\n                    @Override\n                    public void onNext(final List<Status> tweets) {\n                        handleSearchResults(tweets, keyword);\n                    }\n                });\n    }","code":"private void searchTweets(final String keyword) {\n        safelyUnsubscribe(subDelayedSearch, subLoadMoreTweets, subSearchTweets);\n        lastKeyword = keyword;\n        if (!networkApi.isConnectedToInternet(this)) {\n            showSnackBar(msgNoInternetConnection);\n            return;\n        }\n        if (!twitterApi.canSearchTweets(keyword)) {\n            return;\n        }\n        subSearchTweets = twitterApi.searchTweets(keyword)\n                .subscribeOn(Schedulers.io())\n                .observeOn(AndroidSchedulers.mainThread())\n                .subscribe(new Subscriber<List<Status>>() {\n                    @Override\n                    public void onStart() {\n                    }\n                    @Override\n                    public void onCompleted() {\n                       \n                    }\n                    @Override\n                    public void onError(final Throwable e) {\n                        final String message = getErrorMessage((TwitterException) e);\n                        showSnackBar(message);\n                        showErrorMessageContainer(message, R.drawable.no_tweets);\n                    }\n                    @Override\n                    public void onNext(final List<Status> tweets) {\n                        handleSearchResults(tweets, keyword);\n                    }\n                });\n    }","cleancode":"private void searchtweets(final string keyword) { safelyunsubscribe(subdelayedsearch, subloadmoretweets, subsearchtweets); lastkeyword = keyword; if (!networkapi.isconnectedtointernet(this)) { showsnackbar(msgnointernetconnection); return; } if (!twitterapi.cansearchtweets(keyword)) { return; } subsearchtweets = twitterapi.searchtweets(keyword) .subscribeon(schedulers.io()) .observeon(androidschedulers.mainthread()) .subscribe(new subscriber<list<status>>() { @override public void onstart() { } @override public void oncompleted() { } @override public void onerror(final throwable e) { final string message = geterrormessage((twitterexception) e); showsnackbar(message); showerrormessagecontainer(message, r.drawable.no_tweets); } @override public void onnext(final list<status> tweets) { handlesearchresults(tweets, keyword); } }); }","comment":"\/\/ we don't have to implement this method","repo":"umeshbsa\/android-twitter-search-api","code_context_2":"@Override\npublic void onCompleted() {\n\/\/ we don't have to implement this method\n}\n@Override","code_context_10":"}\nsubSearchTweets = twitterApi.searchTweets(keyword)\n.subscribeOn(Schedulers.io())\n.observeOn(AndroidSchedulers.mainThread())\n.subscribe(new Subscriber<List<Status>>() {\n@Override\npublic void onStart() {\n}\n@Override\npublic void onCompleted() {\n\/\/ we don't have to implement this method\n}\n@Override\npublic void onError(final Throwable e) {\nfinal String message = getErrorMessage((TwitterException) e);\nshowSnackBar(message);\nshowErrorMessageContainer(message, R.drawable.no_tweets);\n}\n@Override\npublic void onNext(final List<Status> tweets) {\nhandleSearchResults(tweets, keyword);","code_context_20":"private void searchTweets(final String keyword) {\nsafelyUnsubscribe(subDelayedSearch, subLoadMoreTweets, subSearchTweets);\nlastKeyword = keyword;\nif (!networkApi.isConnectedToInternet(this)) {\nshowSnackBar(msgNoInternetConnection);\nreturn;\n}\nif (!twitterApi.canSearchTweets(keyword)) {\nreturn;\n}\nsubSearchTweets = twitterApi.searchTweets(keyword)\n.subscribeOn(Schedulers.io())\n.observeOn(AndroidSchedulers.mainThread())\n.subscribe(new Subscriber<List<Status>>() {\n@Override\npublic void onStart() {\n}\n@Override\npublic void onCompleted() {\n\/\/ we don't have to implement this method\n}\n@Override\npublic void onError(final Throwable e) {\nfinal String message = getErrorMessage((TwitterException) e);\nshowSnackBar(message);\nshowErrorMessageContainer(message, R.drawable.no_tweets);\n}\n@Override\npublic void onNext(final List<Status> tweets) {\nhandleSearchResults(tweets, keyword);\n}\n});\n}","label":[0,0,0,0]}
{"id":24804,"original_code":"@SuppressWarnings(\"restriction\")\n\tprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\n\t\t\tMap<String, Object> code) {\n\t\tlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\tObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\n\t\tlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\n\t\tCacheUtils.remove(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\n\t\tObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\n\t\tlogger.info(\"signObj-->\" + (signObj == null));\n\t\tCacheUtils.remove(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\n\t\tif (signObj == null) {\n\t\t\tsignObj = signObjVaccid;\n\t\t}\n\t\tlogger.info(\"signObjFinal-->\" + (signObj == null));\n\t\tif (signObj != null) {\n\t\t\tString signStr = (String) signObj;\n\t\t\t\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\n\t\t\tchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\n\t\t\tif (childVaccinaterecord != null) {\n\t\t\t\t\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\t\t\t\t\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\n\t\t\t\tcode.put(\"sign\", signStr);\n\t\t\t\t\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\n\t\t\t\tBASE64Decoder decoder = new BASE64Decoder();\n\t\t\t\ttry {\n\t\t\t\t\tbyte[] sign = decoder.decodeBuffer(signStr);\n\t\t\t\t\tif (null != sign && sign.length > 0) {\n\t\t\t\t\t\tchildVaccinaterecord.setSignatureData(sign);\n\t\t\t\t\t\tchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\t\t\t\t\t\t\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\t\t\t\t\t\tint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\n\t\t\t\t\t\tif (count == 0) {\n\t\t\t\t\t\t\t\/\/ \u65b0\u589e\u7b7e\u5b57\n\t\t\t\t\t\t\tchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n\t\t\t\t\t\t}\n\t\t\t\t\t\t\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\n\t\t\t\t\t\tchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\n\t\t\t\t\t\tchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n\t\t\t\t}\n\t\t\t\t\/\/ \u7b7e\u5b57\u72b6\u6001\n\t\t\t}\n\t\t\tmaplist.put(\"success\", true);\n\t\t\tlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\t} else {\n\t\t\tlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\t}\n\t}","code":"@SuppressWarnings(\"restriction\")\n\tprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\n\t\t\tMap<String, Object> code) {\n\t\tlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\tObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\n\t\tlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\n\t\tCacheUtils.remove(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\n\t\tObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\n\t\tlogger.info(\"signObj-->\" + (signObj == null));\n\t\tCacheUtils.remove(CacheUtils.SIGN_CACHE,\n\t\t\t\tchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\n\t\tif (signObj == null) {\n\t\t\tsignObj = signObjVaccid;\n\t\t}\n\t\tlogger.info(\"signObjFinal-->\" + (signObj == null));\n\t\tif (signObj != null) {\n\t\t\tString signStr = (String) signObj;\n\t\tnaterecord = childVaccinaterecordService.get(childVaccinaterecord);\n\t\t\tif (childVaccinaterecord != null) {\n\t\t\tt(\"sign\", signStr);\n\t\t\tE64Decoder decoder = new BASE64Decoder();\n\t\t\t\ttry {\n\t\t\t\t\tbyte[] sign = decoder.decodeBuffer(signStr);\n\t\t\t\t\tif (null != sign && sign.length > 0) {\n\t\t\t\t\t\tchildVaccinaterecord.setSignatureData(sign);\n\t\t\t\t\t\tchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\t\t\t\t\tldVaccinaterecordService.querySignature(childVaccinaterecord);\n\t\t\t\t\t\tif (count == 0) {\n\t\t\t\t\t\tchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n\t\t\t\t\t\t}\n\t\t\t\t\tVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\n\t\t\t\t\t\tchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n\t\t\t\t}\n\t\t\t\tmaplist.put(\"success\", true);\n\t\t\tlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\t} else {\n\t\t\tlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\t\t\t\t\t+ childVaccinaterecord.getVaccineid());\n\t\t}\n\t}","cleancode":"@suppresswarnings(\"restriction\") private void updatedjtsign(childvaccinaterecord childvaccinaterecord, map<string, object> maplist, map<string, object> code) { logger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childvaccinaterecord.getnid().substring(0, 2) + \"||\" + childvaccinaterecord.getvaccineid()); object signobjvaccid = cacheutils.get(cacheutils.sign_cache, childvaccinaterecord.getchildid() + \"_\" + childvaccinaterecord.getnid().substring(0, 2)); logger.info(\"signobjvaccid-->\" + (signobjvaccid == null)); cacheutils.remove(cacheutils.sign_cache, childvaccinaterecord.getchildid() + \"_\" + childvaccinaterecord.getnid().substring(0, 2)); object signobj = cacheutils.get(cacheutils.sign_cache, childvaccinaterecord.getchildid() + \"_\" + childvaccinaterecord.getvaccineid()); logger.info(\"signobj-->\" + (signobj == null)); cacheutils.remove(cacheutils.sign_cache, childvaccinaterecord.getchildid() + \"_\" + childvaccinaterecord.getvaccineid()); if (signobj == null) { signobj = signobjvaccid; } logger.info(\"signobjfinal-->\" + (signobj == null)); if (signobj != null) { string signstr = (string) signobj; naterecord = childvaccinaterecordservice.get(childvaccinaterecord); if (childvaccinaterecord != null) { t(\"sign\", signstr); e64decoder decoder = new base64decoder(); try { byte[] sign = decoder.decodebuffer(signstr); if (null != sign && sign.length > 0) { childvaccinaterecord.setsignaturedata(sign); childvaccinaterecord.setstype(childvaccinaterecord.signature_source_djt); ldvaccinaterecordservice.querysignature(childvaccinaterecord); if (count == 0) { childvaccinaterecordservice.insertsignatures(childvaccinaterecord); } vaccinaterecord.setsignature(childvaccinaterecord.signature_yes); childvaccinaterecordservice.updatesignatures(childvaccinaterecord); } } catch (exception e) { logger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getmessage()); } maplist.put(\"success\", true); logger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childvaccinaterecord.getnid().substring(0, 2) + \"||\" + childvaccinaterecord.getvaccineid()); } else { logger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childvaccinaterecord.getnid().substring(0, 2) + \"||\" + childvaccinaterecord.getvaccineid()); } }","comment":"\/** * \u83b7\u53d6\u767b\u8bb0\u53f0\u7b7e\u5b57 * * @author fuxin * @date 2017\u5e7412\u670828\u65e5 \u4e0a\u534812:20:22 * @description todo * @param childvaccinaterecord * @param maplist * @param code * *\/\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728 \/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u65b0\u589e\u7b7e\u5b57\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\n\/\/ \u7b7e\u5b57\u72b6\u6001","repo":"wufang742987117\/vaccinate","code_context_2":"@SuppressWarnings(\"restriction\")\nprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\nMap<String, Object> code) {\nlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\nObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}\n\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\n\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\n\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);","code_context_10":"@SuppressWarnings(\"restriction\")\nprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\nMap<String, Object> code) {\nlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\nObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}\n\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\n\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\n\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\n\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\n\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}","code_context_20":"@SuppressWarnings(\"restriction\")\nprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\nMap<String, Object> code) {\nlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\nObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}\n\nprivate void updateDJTSign(ChildVaccinaterecord childVaccinaterecord, Map<String, Object> maplist,\nMap<String, Object> code) {\nlogger.info(\"\u83b7\u53d6\u6392\u53f7\u7b7e\u5b57\u6570\u636e\u5f00\u59cb\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\nObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\n\n+ childVaccinaterecord.getVaccineid());\nObject signObjVaccid = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n\nlogger.info(\"signObjVaccid-->\" + (signObjVaccid == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getNid().substring(0, 2));\nObject signObj = CacheUtils.get(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nlogger.info(\"signObj-->\" + (signObj == null));\nCacheUtils.remove(CacheUtils.SIGN_CACHE,\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n\nchildVaccinaterecord.getChildid() + \"_\" + childVaccinaterecord.getVaccineid());\nif (signObj == null) {\nsignObj = signObjVaccid;\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n\n}\nlogger.info(\"signObjFinal-->\" + (signObj == null));\nif (signObj != null) {\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}\n\nString signStr = (String) signObj;\n\/\/ \u521d\u59cb\u5316\u8bb0\u5f55\u6570\u636e\nchildVaccinaterecord = childVaccinaterecordService.get(childVaccinaterecord);\nif (childVaccinaterecord != null) {\n\/\/ \u5224\u65ad\u7b7e\u5b57\u662f\u5426\u5b58\u5728\n\/\/ \u6253\u5370\u7b7e\u5b57\u4fe1\u606f\ncode.put(\"sign\", signStr);\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}\n\n\/\/ base64 \u8f6c\u6362\u7b7e\u5b57\nBASE64Decoder decoder = new BASE64Decoder();\ntry {\nbyte[] sign = decoder.decodeBuffer(signStr);\nif (null != sign && sign.length > 0) {\nchildVaccinaterecord.setSignatureData(sign);\nchildVaccinaterecord.setStype(ChildVaccinaterecord.SIGNATURE_SOURCE_DJT);\n\/\/ \u67e5\u8be2\u8be5\u8bb0\u5f55\u7b7e\u5b57\u662f\u5426\u5b58\u5728\nint count = childVaccinaterecordService.querySignature(childVaccinaterecord);\nif (count == 0) {\n\/\/ \u65b0\u589e\u7b7e\u5b57\nchildVaccinaterecordService.insertSignatures(childVaccinaterecord);\n}\n\/\/ \u4fee\u6539\u7b7e\u5b57\u72b6\u6001\nchildVaccinaterecord.setSignature(ChildVaccinaterecord.SIGNATURE_YES);\nchildVaccinaterecordService.updateSignatures(childVaccinaterecord);\n}\n} catch (Exception e) {\nlogger.error(\"\u5fae\u4fe1\u7b7e\u5b57base64\u8f6cbytes\u5931\u8d25\", e.getMessage());\n}\n\/\/ \u7b7e\u5b57\u72b6\u6001\n}\nmaplist.put(\"success\", true);\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u6210\u529f\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n} else {\nlogger.error(\"\u6253\u5370\u6392\u53f7\u83b7\u53d6\u7b7e\u5b57\u5931\u8d25\" + childVaccinaterecord.getNid().substring(0, 2) + \"||\"\n+ childVaccinaterecord.getVaccineid());\n}\n}","label":[0,1,0,0]}
{"id":24825,"original_code":"public synchronized void draw_World(){\n       \/\/for each cells \n       ant1nbCells=0;\n       ant2nbCells=0;\n       ant3nbCells=0;\n       ant4nbCells=0;\n        for (int x=0;x<WIDTH;x++){\n            for (int y=0;y<HEIGHT;y++){\n                \/\/test is colorized\n                if (world.getLocation().get((WIDTH*y)+x).isColorized()){\n                    \/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n                    \/\/yes draw a point with this color\n                    wimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n                }\n                else \n                {\n                    \/\/no draw a black point\n                     wimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n                }\n            }\n        }\n        imgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n        \/\/refresh counters\n        lbTotalCellsNb.setText(nbTotalCells+\" cells\");\n        lbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n    }","code":"public synchronized void draw_World(){\n      \n       ant1nbCells=0;\n       ant2nbCells=0;\n       ant3nbCells=0;\n       ant4nbCells=0;\n        for (int x=0;x<WIDTH;x++){\n            for (int y=0;y<HEIGHT;y++){\n               \n                if (world.getLocation().get((WIDTH*y)+x).isColorized()){\n                   \n                   \n                    wimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\n                    if (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n                }\n                else \n                {\n                   \n                     wimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n                }\n            }\n        }\n        imgWorld.setImage(wimgWorld);\n       \n        lbTotalCellsNb.setText(nbTotalCells+\" cells\");\n        lbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\n        lbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n    }","cleancode":"public synchronized void draw_world(){ ant1nbcells=0; ant2nbcells=0; ant3nbcells=0; ant4nbcells=0; for (int x=0;x<width;x++){ for (int y=0;y<height;y++){ if (world.getlocation().get((width*y)+x).iscolorized()){ wimgworld.getpixelwriter().setcolor(x, y, world.getlocation().get((width*y)+x).getcolors()); if (world.getlocation().get((width*y)+x).getname().compareto(ant1)==0){ant1nbcells++;} if (world.getlocation().get((width*y)+x).getname().compareto(ant2)==0){ant2nbcells++;} if (world.getlocation().get((width*y)+x).getname().compareto(ant3)==0){ant3nbcells++;} if (world.getlocation().get((width*y)+x).getname().compareto(ant4)==0){ant4nbcells++;} } else { wimgworld.getpixelwriter().setcolor(x, y, javafx.scene.paint.color.black); } } } imgworld.setimage(wimgworld); lbtotalcellsnb.settext(nbtotalcells+\" cells\"); lbant1cellsnb.settext(ant1nbcells+\" cells (\"+formatter.format(((double)ant1nbcells\/nbtotalcells)*100)+\"%)\"); lbant2cellsnb.settext(ant2nbcells+\" cells (\"+formatter.format(((double)ant2nbcells\/nbtotalcells)*100)+\"%)\"); lbant3cellsnb.settext(ant3nbcells+\" cells (\"+formatter.format(((double)ant3nbcells\/nbtotalcells)*100)+\"%)\"); lbant4cellsnb.settext(ant4nbcells+\" cells (\"+formatter.format(((double)ant4nbcells\/nbtotalcells)*100)+\"%)\"); }","comment":"\/************************************************************************** * drawing the image of the world and assign on the imageviewer in the gui * not very fast, can be improved... **************************************************************************\/\n\/\/for each cells\n\/\/test is colorized\n\/\/system.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\"); \/\/yes draw a point with this color\n\/\/no draw a black point\n\/\/show me the result on scsreen\n\/\/refresh counters","repo":"tondeur-h\/LangTonAnt","code_context_2":"public synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\n\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\n\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\n\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");","code_context_10":"public synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\n\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}","code_context_20":"public synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n\npublic synchronized void draw_World(){\n\/\/for each cells\nant1nbCells=0;\nant2nbCells=0;\nant3nbCells=0;\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\nant4nbCells=0;\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}\n\nfor (int x=0;x<WIDTH;x++){\nfor (int y=0;y<HEIGHT;y++){\n\/\/test is colorized\nif (world.getLocation().get((WIDTH*y)+x).isColorized()){\n\/\/System.out.print(\"(x,y)=(\"+x+\",\"+y+\")&\");\n\/\/yes draw a point with this color\nwimgWorld.getPixelWriter().setColor(x, y, world.getLocation().get((WIDTH*y)+x).getColorS());\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT1)==0){ant1nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT2)==0){ant2nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT3)==0){ant3nbCells++;}\nif (world.getLocation().get((WIDTH*y)+x).getName().compareTo(ANT4)==0){ant4nbCells++;}\n}\nelse\n{\n\/\/no draw a black point\nwimgWorld.getPixelWriter().setColor(x, y, javafx.scene.paint.Color.BLACK);\n}\n}\n}\nimgWorld.setImage(wimgWorld); \/\/show me the result on scsreen\n\/\/refresh counters\nlbTotalCellsNb.setText(nbTotalCells+\" cells\");\nlbAnt1CellsNb.setText(ant1nbCells+\" cells (\"+formatter.format(((double)ant1nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt2CellsNb.setText(ant2nbCells+\" cells (\"+formatter.format(((double)ant2nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt3CellsNb.setText(ant3nbCells+\" cells (\"+formatter.format(((double)ant3nbCells\/nbTotalCells)*100)+\"%)\");\nlbAnt4CellsNb.setText(ant4nbCells+\" cells (\"+formatter.format(((double)ant4nbCells\/nbTotalCells)*100)+\"%)\");\n}","label":[1,0,0,0]}
{"id":16665,"original_code":"public void clearNzSessions() throws IOException, InterruptedException {\n    String pathToNzSession = System.getProperty(\n        NZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n    \/\/ Run nzsession and capture a list of open transactions.\n    ArrayList<String> args = new ArrayList<String>();\n    args.add(pathToNzSession);\n    args.add(\"-host\");\n    args.add(NETEZZA_HOST);\n    args.add(\"-u\");\n    args.add(ADMIN_USER);\n    args.add(\"-pw\");\n    args.add(ADMIN_PASS);\n    Process p = Runtime.getRuntime().exec(args.toArray(new String[0]));\n    InputStream is = p.getInputStream();\n    LineBufferingAsyncSink sink = new LineBufferingAsyncSink();\n    sink.processStream(is);\n    \/\/ Wait for the process to end.\n    int result = p.waitFor();\n    if (0 != result) {\n      throw new IOException(\"Session list command terminated with \" + result);\n    }\n    \/\/ Collect all the stdout, and parse the output.\n    \/\/ If the third whitespace-delimited token is the sqooptest user,\n    \/\/ the the first token is the nzsession id. We should kill that id.\n    sink.join();\n    List<String> processList = sink.getLines();\n    for (String processLine : processList) {\n      if (null == processLine || processLine.length() == 0) {\n        continue; \/\/ Ignore empty lines.\n      }\n      String [] tokens = processLine.split(\" +\");\n      if (tokens.length < 3) {\n        continue; \/\/ Not enough tokens on this line.\n      }\n      if (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n        \/\/ Found a match.\n        killSession(tokens[0]);\n      }\n    }\n  }","code":"public void clearNzSessions() throws IOException, InterruptedException {\n    String pathToNzSession = System.getProperty(\n        NZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n   \n    ArrayList<String> args = new ArrayList<String>();\n    args.add(pathToNzSession);\n    args.add(\"-host\");\n    args.add(NETEZZA_HOST);\n    args.add(\"-u\");\n    args.add(ADMIN_USER);\n    args.add(\"-pw\");\n    args.add(ADMIN_PASS);\n    Process p = Runtime.getRuntime().exec(args.toArray(new String[0]));\n    InputStream is = p.getInputStream();\n    LineBufferingAsyncSink sink = new LineBufferingAsyncSink();\n    sink.processStream(is);\n   \n    int result = p.waitFor();\n    if (0 != result) {\n      throw new IOException(\"Session list command terminated with \" + result);\n    }\n   \n   \n   \n    sink.join();\n    List<String> processList = sink.getLines();\n    for (String processLine : processList) {\n      if (null == processLine || processLine.length() == 0) {\n        continue;\n      }\n      String [] tokens = processLine.split(\" +\");\n      if (tokens.length < 3) {\n        continue;\n      }\n      if (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n       \n        killSession(tokens[0]);\n      }\n    }\n  }","cleancode":"public void clearnzsessions() throws ioexception, interruptedexception { string pathtonzsession = system.getproperty( nz_session_path_key, default_nz_session_path); arraylist<string> args = new arraylist<string>(); args.add(pathtonzsession); args.add(\"-host\"); args.add(netezza_host); args.add(\"-u\"); args.add(admin_user); args.add(\"-pw\"); args.add(admin_pass); process p = runtime.getruntime().exec(args.toarray(new string[0])); inputstream is = p.getinputstream(); linebufferingasyncsink sink = new linebufferingasyncsink(); sink.processstream(is); int result = p.waitfor(); if (0 != result) { throw new ioexception(\"session list command terminated with \" + result); } sink.join(); list<string> processlist = sink.getlines(); for (string processline : processlist) { if (null == processline || processline.length() == 0) { continue; } string [] tokens = processline.split(\" +\"); if (tokens.length < 3) { continue; } if (tokens[2].equalsignorecase(netezza_user)) { killsession(tokens[0]); } } }","comment":"\/** * use the 'nzsession' program to clear out any persistent sessions. * this is a hack; somehow, the connection.close() call occurring in * teardown() is not actually closing the open netezza sessions. after * 32 connections open like this, subsequent tests will deadlock. * this method terminates the sessions forcefully. *\/\n\/\/ run nzsession and capture a list of open transactions.\n\/\/ wait for the process to end.\n\/\/ collect all the stdout, and parse the output. \/\/ if the third whitespace-delimited token is the sqooptest user, \/\/ the the first token is the nzsession id. we should kill that id.\n\/\/ ignore empty lines.\n\/\/ not enough tokens on this line.\n\/\/ found a match.","repo":"viveshs\/sqoop-netezza-connector","code_context_2":"public void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\n\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\n\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\n\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\n\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}","code_context_10":"public void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\npublic void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\n\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\n\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\n\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}","code_context_20":"public void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\npublic void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\n\npublic void clearNzSessions() throws IOException, InterruptedException {\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n\nString pathToNzSession = System.getProperty(\nNZ_SESSION_PATH_KEY, DEFAULT_NZ_SESSION_PATH);\n\/\/ Run nzsession and capture a list of open transactions.\nArrayList<String> args = new ArrayList<String>();\nargs.add(pathToNzSession);\nargs.add(\"-host\");\nargs.add(NETEZZA_HOST);\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\nargs.add(\"-u\");\nargs.add(ADMIN_USER);\nargs.add(\"-pw\");\nargs.add(ADMIN_PASS);\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\nProcess p = Runtime.getRuntime().exec(args.toArray(new String[0]));\nInputStream is = p.getInputStream();\nLineBufferingAsyncSink sink = new LineBufferingAsyncSink();\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}\n\nsink.processStream(is);\n\/\/ Wait for the process to end.\nint result = p.waitFor();\nif (0 != result) {\nthrow new IOException(\"Session list command terminated with \" + result);\n}\n\/\/ Collect all the stdout, and parse the output.\n\/\/ If the third whitespace-delimited token is the sqooptest user,\n\/\/ the the first token is the nzsession id. We should kill that id.\nsink.join();\nList<String> processList = sink.getLines();\nfor (String processLine : processList) {\nif (null == processLine || processLine.length() == 0) {\ncontinue; \/\/ Ignore empty lines.\n}\nString [] tokens = processLine.split(\" +\");\nif (tokens.length < 3) {\ncontinue; \/\/ Not enough tokens on this line.\n}\nif (tokens[2].equalsIgnoreCase(NETEZZA_USER)) {\n\/\/ Found a match.\nkillSession(tokens[0]);\n}\n}\n}","label":[1,0,0,0]}
{"id":16761,"original_code":"@CalledByNative\n    protected void releaseOutputBuffer(int index, boolean render) {\n        try {\n            mMediaCodec.releaseOutputBuffer(index, render);\n        } catch (IllegalStateException e) {\n            \/\/ TODO(qinmin): May need to report the error to the caller. crbug.com\/356498.\n            Log.e(TAG, \"Failed to release output buffer\", e);\n        }\n    }","code":"@CalledByNative\n    protected void releaseOutputBuffer(int index, boolean render) {\n        try {\n            mMediaCodec.releaseOutputBuffer(index, render);\n        } catch (IllegalStateException e) {\n           \n            Log.e(TAG, \"Failed to release output buffer\", e);\n        }\n    }","cleancode":"@calledbynative protected void releaseoutputbuffer(int index, boolean render) { try { mmediacodec.releaseoutputbuffer(index, render); } catch (illegalstateexception e) { log.e(tag, \"failed to release output buffer\", e); } }","comment":"\/\/ todo(qinmin): may need to report the error to the caller. crbug.com\/356498.","repo":"zealoussnow\/chromium","code_context_2":"mMediaCodec.releaseOutputBuffer(index, render);\n} catch (IllegalStateException e) {\n\/\/ TODO(qinmin): May need to report the error to the caller. crbug.com\/356498.\nLog.e(TAG, \"Failed to release output buffer\", e);\n}","code_context_10":"@CalledByNative\nprotected void releaseOutputBuffer(int index, boolean render) {\ntry {\nmMediaCodec.releaseOutputBuffer(index, render);\n} catch (IllegalStateException e) {\n\/\/ TODO(qinmin): May need to report the error to the caller. crbug.com\/356498.\nLog.e(TAG, \"Failed to release output buffer\", e);\n}\n}","code_context_20":"@CalledByNative\nprotected void releaseOutputBuffer(int index, boolean render) {\ntry {\nmMediaCodec.releaseOutputBuffer(index, render);\n} catch (IllegalStateException e) {\n\/\/ TODO(qinmin): May need to report the error to the caller. crbug.com\/356498.\nLog.e(TAG, \"Failed to release output buffer\", e);\n}\n}","label":[0,1,0,0]}
{"id":16764,"original_code":"@Override\n        public void onError(MediaCodec codec, MediaCodec.CodecException e) {\n            \/\/ TODO(dalecurtis): We may want to drop transient errors here.\n            Log.e(TAG, \"MediaCodec.onError: %s\", e.getDiagnosticInfo());\n            mMediaCodecBridge.onError(e);\n        }","code":"@Override\n        public void onError(MediaCodec codec, MediaCodec.CodecException e) {\n           \n            Log.e(TAG, \"MediaCodec.onError: %s\", e.getDiagnosticInfo());\n            mMediaCodecBridge.onError(e);\n        }","cleancode":"@override public void onerror(mediacodec codec, mediacodec.codecexception e) { log.e(tag, \"mediacodec.onerror: %s\", e.getdiagnosticinfo()); mmediacodecbridge.onerror(e); }","comment":"\/\/ todo(dalecurtis): we may want to drop transient errors here.","repo":"zealoussnow\/chromium","code_context_2":"@Override\npublic void onError(MediaCodec codec, MediaCodec.CodecException e) {\n\/\/ TODO(dalecurtis): We may want to drop transient errors here.\nLog.e(TAG, \"MediaCodec.onError: %s\", e.getDiagnosticInfo());\nmMediaCodecBridge.onError(e);","code_context_10":"@Override\npublic void onError(MediaCodec codec, MediaCodec.CodecException e) {\n\/\/ TODO(dalecurtis): We may want to drop transient errors here.\nLog.e(TAG, \"MediaCodec.onError: %s\", e.getDiagnosticInfo());\nmMediaCodecBridge.onError(e);\n}","code_context_20":"@Override\npublic void onError(MediaCodec codec, MediaCodec.CodecException e) {\n\/\/ TODO(dalecurtis): We may want to drop transient errors here.\nLog.e(TAG, \"MediaCodec.onError: %s\", e.getDiagnosticInfo());\nmMediaCodecBridge.onError(e);\n}","label":[0,1,0,0]}
{"id":25136,"original_code":"@VisibleForTesting\n  static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\n    RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\n    rateLimiter.setRate(permitsPerSecond);\n    return rateLimiter;\n  }","code":"@VisibleForTesting\n  static RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\n    RateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0);\n    rateLimiter.setRate(permitsPerSecond);\n    return rateLimiter;\n  }","cleancode":"@visiblefortesting static ratelimiter create(sleepingstopwatch stopwatch, double permitspersecond) { ratelimiter ratelimiter = new smoothbursty(stopwatch, 1.0); ratelimiter.setrate(permitspersecond); return ratelimiter; }","comment":"\/* * todo(cpovirk): make sleepingstopwatch the last parameter throughout the class so that the * overloads follow the usual convention: foo(int), foo(int, sleepingstopwatch) *\/\n\/* maxburstseconds *\/","repo":"xushjie1987\/common-utils","code_context_2":"@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;\n}\n\n@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;","code_context_10":"@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;\n}\n\n@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;\n}","code_context_20":"@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;\n}\n\n@VisibleForTesting\nstatic RateLimiter create(SleepingStopwatch stopwatch, double permitsPerSecond) {\nRateLimiter rateLimiter = new SmoothBursty(stopwatch, 1.0 \/* maxBurstSeconds *\/);\nrateLimiter.setRate(permitsPerSecond);\nreturn rateLimiter;\n}","label":[0,1,0,0]}
{"id":571,"original_code":"public static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\n        String sequenceName = tableName + \"_seq\";\n        String triggerName = tableName + \"_id\";\n        connection.prepareStatement(\n                \"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n        ).executeUpdate();\n        \/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n        \/\/ when we execute this as a prepared statement. Might be a config issue on our side.\n        connection\n                .createStatement()\n                .execute(\n                        \"create or replace trigger \" + triggerName +\n                        \"        before insert on \" + tableName +\n                        \"        for each row \" +\n                        \"        begin \" +\n                        \"                :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n                        \"        end;\"\n                );\n    }","code":"public static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\n        String sequenceName = tableName + \"_seq\";\n        String triggerName = tableName + \"_id\";\n        connection.prepareStatement(\n                \"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n        ).executeUpdate();\n       \n       \n        connection\n                .createStatement()\n                .execute(\n                        \"create or replace trigger \" + triggerName +\n                        \"        before insert on \" + tableName +\n                        \"        for each row \" +\n                        \"        begin \" +\n                        \"                :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n                        \"        end;\"\n                );\n    }","cleancode":"public static void simulateautoincrement(connection connection, string tablename, string columnname) throws sqlexception { string sequencename = tablename + \"_seq\"; string triggername = tablename + \"_id\"; connection.preparestatement( \"create sequence \" + sequencename + \" start with 1 increment by 1 nocycle\" ).executeupdate(); connection .createstatement() .execute( \"create or replace trigger \" + triggername + \" before insert on \" + tablename + \" for each row \" + \" begin \" + \" :new.\" + columnname + \" := \" + sequencename + \".nextval; \" + \" end;\" ); }","comment":"\/** * oracle11 does not have auto incremented values. this method uses a sequence and a trigger to create the same * behavior. * * @param connection the connection to the database that will be used to execute the queries * @param tablename the name of the table that contains the column that should be automatically incremented * @param columnname the name of the column that should be automatically incremented * @throws sqlexception if the auto increment statement cannot be created or executed *\/\n\/\/ the oracle driver is getting confused by this statement, claiming we have to declare some in out parameter, \/\/ when we execute this as a prepared statement. might be a config issue on our side.","repo":"szymek22\/AxonFramework","code_context_2":"public static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\nString sequenceName = tableName + \"_seq\";\nString triggerName = tableName + \"_id\";\nconnection.prepareStatement(\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()\n.execute(\n\"create or replace trigger \" + triggerName +\n\" before insert on \" + tableName +\n\" for each row \" +\n\" begin \" +\n\" :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n\" end;\"\n);\n}\n\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()","code_context_10":"public static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\nString sequenceName = tableName + \"_seq\";\nString triggerName = tableName + \"_id\";\nconnection.prepareStatement(\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()\n.execute(\n\"create or replace trigger \" + triggerName +\n\" before insert on \" + tableName +\n\" for each row \" +\n\" begin \" +\n\" :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n\" end;\"\n);\n}\n\npublic static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\nString sequenceName = tableName + \"_seq\";\nString triggerName = tableName + \"_id\";\nconnection.prepareStatement(\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()\n.execute(\n\"create or replace trigger \" + triggerName +\n\" before insert on \" + tableName +\n\" for each row \" +\n\" begin \" +\n\" :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n\" end;\"\n);","code_context_20":"public static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\nString sequenceName = tableName + \"_seq\";\nString triggerName = tableName + \"_id\";\nconnection.prepareStatement(\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()\n.execute(\n\"create or replace trigger \" + triggerName +\n\" before insert on \" + tableName +\n\" for each row \" +\n\" begin \" +\n\" :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n\" end;\"\n);\n}\n\npublic static void simulateAutoIncrement(Connection connection, String tableName, String columnName) throws SQLException {\nString sequenceName = tableName + \"_seq\";\nString triggerName = tableName + \"_id\";\nconnection.prepareStatement(\n\"CREATE sequence \" + sequenceName + \" start with 1 increment by 1 nocycle\"\n).executeUpdate();\n\/\/ The oracle driver is getting confused by this statement, claiming we have to declare some in out parameter,\n\/\/ when we execute this as a prepared statement. Might be a config issue on our side.\nconnection\n.createStatement()\n.execute(\n\"create or replace trigger \" + triggerName +\n\" before insert on \" + tableName +\n\" for each row \" +\n\" begin \" +\n\" :new.\" + columnName + \" := \" + sequenceName + \".nextval; \" +\n\" end;\"\n);\n}","label":[0,0,1,0]}
{"id":8804,"original_code":"public void handle(ExtendedBlock block, IOException e) {\n      FsVolumeSpi volume = scanner.volume;\n      if (e == null) {\n        LOG.trace(\"Successfully scanned {} on {}\", block, volume);\n        return;\n      }\n      \/\/ If the block does not exist anymore, then it's not an error.\n      if (!volume.getDataset().contains(block)) {\n        LOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\n            volume, block);\n        return;\n      }\n      \/\/ If the block exists, the exception may due to a race with write:\n      \/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n      \/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n      \/\/ file before BlockReceiver updated the VolumeMap. The state of the\n      \/\/ block can be changed again now, so ignore this error here. If there\n      \/\/ is a block really deleted by mistake, DirectoryScan should catch it.\n      if (e instanceof FileNotFoundException ) {\n        LOG.info(\"Volume {}: verification failed for {} because of \" +\n                \"FileNotFoundException.  This may be due to a race with write.\",\n            volume, block);\n        return;\n      }\n      LOG.warn(\"Reporting bad {} on {}\", block, volume);\n      try {\n        scanner.datanode.reportBadBlocks(block, volume);\n      } catch (IOException ie) {\n        \/\/ This is bad, but not bad enough to shut down the scanner.\n        LOG.warn(\"Cannot report bad block \" + block, ie);\n      }\n    }","code":"public void handle(ExtendedBlock block, IOException e) {\n      FsVolumeSpi volume = scanner.volume;\n      if (e == null) {\n        LOG.trace(\"Successfully scanned {} on {}\", block, volume);\n        return;\n      }\n     \n      if (!volume.getDataset().contains(block)) {\n        LOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\n            volume, block);\n        return;\n      }\n     \n     \n     \n     \n     \n     \n      if (e instanceof FileNotFoundException ) {\n        LOG.info(\"Volume {}: verification failed for {} because of \" +\n                \"FileNotFoundException.  This may be due to a race with write.\",\n            volume, block);\n        return;\n      }\n      LOG.warn(\"Reporting bad {} on {}\", block, volume);\n      try {\n        scanner.datanode.reportBadBlocks(block, volume);\n      } catch (IOException ie) {\n       \n        LOG.warn(\"Cannot report bad block \" + block, ie);\n      }\n    }","cleancode":"public void handle(extendedblock block, ioexception e) { fsvolumespi volume = scanner.volume; if (e == null) { log.trace(\"successfully scanned {} on {}\", block, volume); return; } if (!volume.getdataset().contains(block)) { log.debug(\"volume {}: block {} is no longer in the dataset.\", volume, block); return; } if (e instanceof filenotfoundexception ) { log.info(\"volume {}: verification failed for {} because of \" + \"filenotfoundexception. this may be due to a race with write.\", volume, block); return; } log.warn(\"reporting bad {} on {}\", block, volume); try { scanner.datanode.reportbadblocks(block, volume); } catch (ioexception ie) { log.warn(\"cannot report bad block \" + block, ie); } }","comment":"\/\/ if the block does not exist anymore, then it's not an error.\n\/\/ if the block exists, the exception may due to a race with write: \/\/ the blocksender got an old block path in rbw. blockreceiver removed \/\/ the rbw block from rbw to finalized but blocksender tried to open the \/\/ file before blockreceiver updated the volumemap. the state of the \/\/ block can be changed again now, so ignore this error here. if there \/\/ is a block really deleted by mistake, directoryscan should catch it.\n\/\/ this is bad, but not bad enough to shut down the scanner.","repo":"xiaojimi\/hadoop","code_context_2":"return;\n}\n\/\/ If the block does not exist anymore, then it's not an error.\nif (!volume.getDataset().contains(block)) {\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\n\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\/\/ is a block really deleted by mistake, DirectoryScan should catch it.\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\nscanner.datanode.reportBadBlocks(block, volume);\n} catch (IOException ie) {\n\/\/ This is bad, but not bad enough to shut down the scanner.\nLOG.warn(\"Cannot report bad block \" + block, ie);\n}","code_context_10":"public void handle(ExtendedBlock block, IOException e) {\nFsVolumeSpi volume = scanner.volume;\nif (e == null) {\nLOG.trace(\"Successfully scanned {} on {}\", block, volume);\nreturn;\n}\n\/\/ If the block does not exist anymore, then it's not an error.\nif (!volume.getDataset().contains(block)) {\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\nvolume, block);\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\nif (e == null) {\nLOG.trace(\"Successfully scanned {} on {}\", block, volume);\nreturn;\n}\n\/\/ If the block does not exist anymore, then it's not an error.\nif (!volume.getDataset().contains(block)) {\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\nvolume, block);\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\/\/ is a block really deleted by mistake, DirectoryScan should catch it.\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\"FileNotFoundException. This may be due to a race with write.\",\nvolume, block);\nreturn;\n}\nLOG.warn(\"Reporting bad {} on {}\", block, volume);\ntry {\nscanner.datanode.reportBadBlocks(block, volume);\n} catch (IOException ie) {\n\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\"FileNotFoundException. This may be due to a race with write.\",\nvolume, block);\nreturn;\n}\nLOG.warn(\"Reporting bad {} on {}\", block, volume);\ntry {\nscanner.datanode.reportBadBlocks(block, volume);\n} catch (IOException ie) {\n\/\/ This is bad, but not bad enough to shut down the scanner.\nLOG.warn(\"Cannot report bad block \" + block, ie);\n}\n}","code_context_20":"public void handle(ExtendedBlock block, IOException e) {\nFsVolumeSpi volume = scanner.volume;\nif (e == null) {\nLOG.trace(\"Successfully scanned {} on {}\", block, volume);\nreturn;\n}\n\/\/ If the block does not exist anymore, then it's not an error.\nif (!volume.getDataset().contains(block)) {\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\nvolume, block);\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\/\/ is a block really deleted by mistake, DirectoryScan should catch it.\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\"FileNotFoundException. This may be due to a race with write.\",\nvolume, block);\nreturn;\n}\nLOG.warn(\"Reporting bad {} on {}\", block, volume);\ntry {\nscanner.datanode.reportBadBlocks(block, volume);\n\npublic void handle(ExtendedBlock block, IOException e) {\nFsVolumeSpi volume = scanner.volume;\nif (e == null) {\nLOG.trace(\"Successfully scanned {} on {}\", block, volume);\nreturn;\n}\n\/\/ If the block does not exist anymore, then it's not an error.\nif (!volume.getDataset().contains(block)) {\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\nvolume, block);\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\/\/ is a block really deleted by mistake, DirectoryScan should catch it.\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\"FileNotFoundException. This may be due to a race with write.\",\nvolume, block);\nreturn;\n}\nLOG.warn(\"Reporting bad {} on {}\", block, volume);\ntry {\nscanner.datanode.reportBadBlocks(block, volume);\n} catch (IOException ie) {\n\/\/ This is bad, but not bad enough to shut down the scanner.\nLOG.warn(\"Cannot report bad block \" + block, ie);\n}\n}\n\nLOG.debug(\"Volume {}: block {} is no longer in the dataset.\",\nvolume, block);\nreturn;\n}\n\/\/ If the block exists, the exception may due to a race with write:\n\/\/ The BlockSender got an old block path in rbw. BlockReceiver removed\n\/\/ the rbw block from rbw to finalized but BlockSender tried to open the\n\/\/ file before BlockReceiver updated the VolumeMap. The state of the\n\/\/ block can be changed again now, so ignore this error here. If there\n\/\/ is a block really deleted by mistake, DirectoryScan should catch it.\nif (e instanceof FileNotFoundException ) {\nLOG.info(\"Volume {}: verification failed for {} because of \" +\n\"FileNotFoundException. This may be due to a race with write.\",\nvolume, block);\nreturn;\n}\nLOG.warn(\"Reporting bad {} on {}\", block, volume);\ntry {\nscanner.datanode.reportBadBlocks(block, volume);\n} catch (IOException ie) {\n\/\/ This is bad, but not bad enough to shut down the scanner.\nLOG.warn(\"Cannot report bad block \" + block, ie);\n}\n}","label":[1,0,0,0]}
{"id":17001,"original_code":"@Override\n    @SuppressWarnings(\"unchecked\")\n    public Set keySet(Predicate predicate) {\n        checkTransactionState();\n        checkNotNull(predicate, \"Predicate should not be null!\");\n        checkNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries!\");\n        MapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\n        SerializationService serializationService = getNodeEngine().getSerializationService();\n        QueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\n        Set<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n        \/\/ TODO: Can't we just use the original set?\n        Set<Object> keySet = new HashSet<Object>(queryResult);\n        Extractors extractors = mapServiceContext.getExtractors(name);\n        for (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\n            Data keyData = entry.getKey();\n            if (!Type.REMOVED.equals(entry.getValue().type)) {\n                Object value = (entry.getValue().value instanceof Data)\n                        ? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\n                QueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\n                        keyData, value, extractors);\n                \/\/ apply predicate on txMap\n                if (predicate.apply(queryEntry)) {\n                    Object keyObject = serializationService.toObject(keyData);\n                    keySet.add(keyObject);\n                }\n            } else {\n                \/\/ meanwhile remove keys which are not in txMap\n                Object keyObject = serializationService.toObject(keyData);\n                keySet.remove(keyObject);\n            }\n        }\n        return keySet;\n    }","code":"@Override\n    @SuppressWarnings(\"unchecked\")\n    public Set keySet(Predicate predicate) {\n        checkTransactionState();\n        checkNotNull(predicate, \"Predicate should not be null!\");\n        checkNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries!\");\n        MapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\n        SerializationService serializationService = getNodeEngine().getSerializationService();\n        QueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\n        Set<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n       \n        Set<Object> keySet = new HashSet<Object>(queryResult);\n        Extractors extractors = mapServiceContext.getExtractors(name);\n        for (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\n            Data keyData = entry.getKey();\n            if (!Type.REMOVED.equals(entry.getValue().type)) {\n                Object value = (entry.getValue().value instanceof Data)\n                        ? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\n                QueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\n                        keyData, value, extractors);\n               \n                if (predicate.apply(queryEntry)) {\n                    Object keyObject = serializationService.toObject(keyData);\n                    keySet.add(keyObject);\n                }\n            } else {\n               \n                Object keyObject = serializationService.toObject(keyData);\n                keySet.remove(keyObject);\n            }\n        }\n        return keySet;\n    }","cleancode":"@override @suppresswarnings(\"unchecked\") public set keyset(predicate predicate) { checktransactionstate(); checknotnull(predicate, \"predicate should not be null!\"); checknotinstanceof(pagingpredicate.class, predicate, \"paging is not supported for transactional queries!\"); mapqueryengine queryengine = mapservicecontext.getmapqueryengine(name); serializationservice serializationservice = getnodeengine().getserializationservice(); queryresult result = queryengine.invokequeryallpartitions(name, predicate, iterationtype.key); set<object> queryresult = new queryresultcollection(serializationservice, iterationtype.key, false, true, result); set<object> keyset = new hashset<object>(queryresult); extractors extractors = mapservicecontext.getextractors(name); for (map.entry<data, txnvaluewrapper> entry : txmap.entryset()) { data keydata = entry.getkey(); if (!type.removed.equals(entry.getvalue().type)) { object value = (entry.getvalue().value instanceof data) ? toobjectifneeded(entry.getvalue().value) : entry.getvalue().value; queryableentry queryentry = new cachedqueryentry((internalserializationservice) serializationservice, keydata, value, extractors); if (predicate.apply(queryentry)) { object keyobject = serializationservice.toobject(keydata); keyset.add(keyobject); } } else { object keyobject = serializationservice.toobject(keydata); keyset.remove(keyobject); } } return keyset; }","comment":"\/\/ todo: can't we just use the original set?\n\/\/ apply predicate on txmap\n\/\/ meanwhile remove keys which are not in txmap","repo":"tsasaki609\/hazelcast","code_context_2":"QueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\nSet<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\n\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\n\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);","code_context_10":"@Override\n@SuppressWarnings(\"unchecked\")\npublic Set keySet(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate should not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries!\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\nSet<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nData keyData = entry.getKey();\nif (!Type.REMOVED.equals(entry.getValue().type)) {\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\n\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nData keyData = entry.getKey();\nif (!Type.REMOVED.equals(entry.getValue().type)) {\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\nkeySet.add(keyObject);\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);\n}\n}\n\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\nkeySet.add(keyObject);\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);\n}\n}\nreturn keySet;\n}","code_context_20":"@Override\n@SuppressWarnings(\"unchecked\")\npublic Set keySet(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate should not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries!\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\nSet<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nData keyData = entry.getKey();\nif (!Type.REMOVED.equals(entry.getValue().type)) {\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\nkeySet.add(keyObject);\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);\n}\n}\n\n@Override\n@SuppressWarnings(\"unchecked\")\npublic Set keySet(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate should not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries!\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\nSet<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nData keyData = entry.getKey();\nif (!Type.REMOVED.equals(entry.getValue().type)) {\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\nkeySet.add(keyObject);\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);\n}\n}\nreturn keySet;\n}\n\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.KEY);\nSet<Object> queryResult = new QueryResultCollection(serializationService, IterationType.KEY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nSet<Object> keySet = new HashSet<Object>(queryResult);\nExtractors extractors = mapServiceContext.getExtractors(name);\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nData keyData = entry.getKey();\nif (!Type.REMOVED.equals(entry.getValue().type)) {\nObject value = (entry.getValue().value instanceof Data)\n? toObjectIfNeeded(entry.getValue().value) : entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nkeyData, value, extractors);\n\/\/ apply predicate on txMap\nif (predicate.apply(queryEntry)) {\nObject keyObject = serializationService.toObject(keyData);\nkeySet.add(keyObject);\n}\n} else {\n\/\/ meanwhile remove keys which are not in txMap\nObject keyObject = serializationService.toObject(keyData);\nkeySet.remove(keyObject);\n}\n}\nreturn keySet;\n}","label":[1,0,0,0]}
{"id":17002,"original_code":"@Override\n    @SuppressWarnings(\"unchecked\")\n    public Collection values(Predicate predicate) {\n        checkTransactionState();\n        checkNotNull(predicate, \"Predicate can not be null!\");\n        checkNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\n        MapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\n        SerializationService serializationService = getNodeEngine().getSerializationService();\n        QueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\n        QueryResultCollection<Map.Entry> queryResult\n                = new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n        \/\/ TODO: Can't we just use the original set?\n        List<Object> valueSet = new ArrayList<Object>();\n        Set<Object> keyWontBeIncluded = new HashSet<Object>();\n        Extractors extractors = mapServiceContext.getExtractors(name);\n        \/\/ iterate over the txMap and see if the values are updated or removed\n        for (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\n            boolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\n            boolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\n            Object keyObject = serializationService.toObject(entry.getKey());\n            if (isRemoved) {\n                keyWontBeIncluded.add(keyObject);\n            } else {\n                if (isUpdated) {\n                    keyWontBeIncluded.add(keyObject);\n                }\n                Object entryValue = entry.getValue().value;\n                QueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\n                        entry.getKey(), entryValue, extractors);\n                if (predicate.apply(queryEntry)) {\n                    valueSet.add(queryEntry.getValue());\n                }\n            }\n        }\n        removeFromResultSet(queryResult, valueSet, keyWontBeIncluded);\n        return valueSet;\n    }","code":"@Override\n    @SuppressWarnings(\"unchecked\")\n    public Collection values(Predicate predicate) {\n        checkTransactionState();\n        checkNotNull(predicate, \"Predicate can not be null!\");\n        checkNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\n        MapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\n        SerializationService serializationService = getNodeEngine().getSerializationService();\n        QueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\n        QueryResultCollection<Map.Entry> queryResult\n                = new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n       \n        List<Object> valueSet = new ArrayList<Object>();\n        Set<Object> keyWontBeIncluded = new HashSet<Object>();\n        Extractors extractors = mapServiceContext.getExtractors(name);\n       \n        for (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\n            boolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\n            boolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\n            Object keyObject = serializationService.toObject(entry.getKey());\n            if (isRemoved) {\n                keyWontBeIncluded.add(keyObject);\n            } else {\n                if (isUpdated) {\n                    keyWontBeIncluded.add(keyObject);\n                }\n                Object entryValue = entry.getValue().value;\n                QueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\n                        entry.getKey(), entryValue, extractors);\n                if (predicate.apply(queryEntry)) {\n                    valueSet.add(queryEntry.getValue());\n                }\n            }\n        }\n        removeFromResultSet(queryResult, valueSet, keyWontBeIncluded);\n        return valueSet;\n    }","cleancode":"@override @suppresswarnings(\"unchecked\") public collection values(predicate predicate) { checktransactionstate(); checknotnull(predicate, \"predicate can not be null!\"); checknotinstanceof(pagingpredicate.class, predicate, \"paging is not supported for transactional queries\"); mapqueryengine queryengine = mapservicecontext.getmapqueryengine(name); serializationservice serializationservice = getnodeengine().getserializationservice(); queryresult result = queryengine.invokequeryallpartitions(name, predicate, iterationtype.entry); queryresultcollection<map.entry> queryresult = new queryresultcollection<map.entry>(serializationservice, iterationtype.entry, false, true, result); list<object> valueset = new arraylist<object>(); set<object> keywontbeincluded = new hashset<object>(); extractors extractors = mapservicecontext.getextractors(name); for (map.entry<data, txnvaluewrapper> entry : txmap.entryset()) { boolean isremoved = type.removed.equals(entry.getvalue().type); boolean isupdated = type.updated.equals(entry.getvalue().type); object keyobject = serializationservice.toobject(entry.getkey()); if (isremoved) { keywontbeincluded.add(keyobject); } else { if (isupdated) { keywontbeincluded.add(keyobject); } object entryvalue = entry.getvalue().value; queryableentry queryentry = new cachedqueryentry((internalserializationservice) serializationservice, entry.getkey(), entryvalue, extractors); if (predicate.apply(queryentry)) { valueset.add(queryentry.getvalue()); } } } removefromresultset(queryresult, valueset, keywontbeincluded); return valueset; }","comment":"\/\/ todo: can't we just use the original set?\n\/\/ iterate over the txmap and see if the values are updated or removed","repo":"tsasaki609\/hazelcast","code_context_2":"QueryResultCollection<Map.Entry> queryResult\n= new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nList<Object> valueSet = new ArrayList<Object>();\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\n\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\nExtractors extractors = mapServiceContext.getExtractors(name);\n\/\/ iterate over the txMap and see if the values are updated or removed\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nboolean isRemoved = Type.REMOVED.equals(entry.getValue().type);","code_context_10":"@SuppressWarnings(\"unchecked\")\npublic Collection values(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate can not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\nQueryResultCollection<Map.Entry> queryResult\n= new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nList<Object> valueSet = new ArrayList<Object>();\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\nExtractors extractors = mapServiceContext.getExtractors(name);\n\/\/ iterate over the txMap and see if the values are updated or removed\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nboolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\nboolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\nObject keyObject = serializationService.toObject(entry.getKey());\nif (isRemoved) {\nkeyWontBeIncluded.add(keyObject);\n\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\nQueryResultCollection<Map.Entry> queryResult\n= new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nList<Object> valueSet = new ArrayList<Object>();\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\nExtractors extractors = mapServiceContext.getExtractors(name);\n\/\/ iterate over the txMap and see if the values are updated or removed\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nboolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\nboolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\nObject keyObject = serializationService.toObject(entry.getKey());\nif (isRemoved) {\nkeyWontBeIncluded.add(keyObject);\n} else {\nif (isUpdated) {\nkeyWontBeIncluded.add(keyObject);\n}","code_context_20":"@Override\n@SuppressWarnings(\"unchecked\")\npublic Collection values(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate can not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\nQueryResultCollection<Map.Entry> queryResult\n= new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nList<Object> valueSet = new ArrayList<Object>();\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\nExtractors extractors = mapServiceContext.getExtractors(name);\n\/\/ iterate over the txMap and see if the values are updated or removed\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nboolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\nboolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\nObject keyObject = serializationService.toObject(entry.getKey());\nif (isRemoved) {\nkeyWontBeIncluded.add(keyObject);\n} else {\nif (isUpdated) {\nkeyWontBeIncluded.add(keyObject);\n}\nObject entryValue = entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nentry.getKey(), entryValue, extractors);\nif (predicate.apply(queryEntry)) {\nvalueSet.add(queryEntry.getValue());\n}\n\n@Override\n@SuppressWarnings(\"unchecked\")\npublic Collection values(Predicate predicate) {\ncheckTransactionState();\ncheckNotNull(predicate, \"Predicate can not be null!\");\ncheckNotInstanceOf(PagingPredicate.class, predicate, \"Paging is not supported for Transactional queries\");\nMapQueryEngine queryEngine = mapServiceContext.getMapQueryEngine(name);\nSerializationService serializationService = getNodeEngine().getSerializationService();\nQueryResult result = queryEngine.invokeQueryAllPartitions(name, predicate, IterationType.ENTRY);\nQueryResultCollection<Map.Entry> queryResult\n= new QueryResultCollection<Map.Entry>(serializationService, IterationType.ENTRY, false, true, result);\n\/\/ TODO: Can't we just use the original set?\nList<Object> valueSet = new ArrayList<Object>();\nSet<Object> keyWontBeIncluded = new HashSet<Object>();\nExtractors extractors = mapServiceContext.getExtractors(name);\n\/\/ iterate over the txMap and see if the values are updated or removed\nfor (Map.Entry<Data, TxnValueWrapper> entry : txMap.entrySet()) {\nboolean isRemoved = Type.REMOVED.equals(entry.getValue().type);\nboolean isUpdated = Type.UPDATED.equals(entry.getValue().type);\nObject keyObject = serializationService.toObject(entry.getKey());\nif (isRemoved) {\nkeyWontBeIncluded.add(keyObject);\n} else {\nif (isUpdated) {\nkeyWontBeIncluded.add(keyObject);\n}\nObject entryValue = entry.getValue().value;\nQueryableEntry queryEntry = new CachedQueryEntry((InternalSerializationService) serializationService,\nentry.getKey(), entryValue, extractors);\nif (predicate.apply(queryEntry)) {\nvalueSet.add(queryEntry.getValue());\n}\n}\n}\nremoveFromResultSet(queryResult, valueSet, keyWontBeIncluded);\nreturn valueSet;","label":[1,0,0,0]}
{"id":25228,"original_code":"private static void resetStatSpecs(String testId, List testContainers,\n                                     String statSpecFileOverride) {\n    if (testContainers.size() == 1) { \/\/ special case\n      TestContainer testContainer = (TestContainer)testContainers.get(0);\n      \/\/ determine which statspec file to use\n      String statSpecFile = statSpecFileOverride;\n      if (statSpecFileOverride == null) {\n        statSpecFile = getLastStatSpecFile(testContainer);\n      } \/\/ @todo lises support option to use union of all statspecs\n      \/\/ reset the statspec file for each test in the container\n      List tests = testContainer.getTests();\n      for (Iterator i = tests.iterator(); i.hasNext();) {\n        Test test = (Test)i.next();\n        test.resetStatSpecs(statSpecFile);\n      }\n    } else {\n      \/\/ determine which statspec file to use for this test id\n      String statSpecFile = statSpecFileOverride;\n      if (statSpecFileOverride == null) {\n        statSpecFile = getLastStatSpecFile(testId, testContainers);\n      } \/\/ @todo lises support option to use union of all statspecs\n      \/\/ reset the statspec file for each test with the given test id\n      for (Iterator i = testContainers.iterator(); i.hasNext();) {\n        TestContainer testContainer = (TestContainer)i.next();\n        List tests = testContainer.getTestsWithId(testId);\n        for (Iterator j = tests.iterator(); j.hasNext();) {\n          Test test = (Test)j.next();\n          test.resetStatSpecs(statSpecFile);\n        }\n      }\n    }\n  }","code":"private static void resetStatSpecs(String testId, List testContainers,\n                                     String statSpecFileOverride) {\n    if (testContainers.size() == 1) {\n      TestContainer testContainer = (TestContainer)testContainers.get(0);\n     \n      String statSpecFile = statSpecFileOverride;\n      if (statSpecFileOverride == null) {\n        statSpecFile = getLastStatSpecFile(testContainer);\n      }\n     \n      List tests = testContainer.getTests();\n      for (Iterator i = tests.iterator(); i.hasNext();) {\n        Test test = (Test)i.next();\n        test.resetStatSpecs(statSpecFile);\n      }\n    } else {\n     \n      String statSpecFile = statSpecFileOverride;\n      if (statSpecFileOverride == null) {\n        statSpecFile = getLastStatSpecFile(testId, testContainers);\n      }\n     \n      for (Iterator i = testContainers.iterator(); i.hasNext();) {\n        TestContainer testContainer = (TestContainer)i.next();\n        List tests = testContainer.getTestsWithId(testId);\n        for (Iterator j = tests.iterator(); j.hasNext();) {\n          Test test = (Test)j.next();\n          test.resetStatSpecs(statSpecFile);\n        }\n      }\n    }\n  }","cleancode":"private static void resetstatspecs(string testid, list testcontainers, string statspecfileoverride) { if (testcontainers.size() == 1) { testcontainer testcontainer = (testcontainer)testcontainers.get(0); string statspecfile = statspecfileoverride; if (statspecfileoverride == null) { statspecfile = getlaststatspecfile(testcontainer); } list tests = testcontainer.gettests(); for (iterator i = tests.iterator(); i.hasnext();) { test test = (test)i.next(); test.resetstatspecs(statspecfile); } } else { string statspecfile = statspecfileoverride; if (statspecfileoverride == null) { statspecfile = getlaststatspecfile(testid, testcontainers); } for (iterator i = testcontainers.iterator(); i.hasnext();) { testcontainer testcontainer = (testcontainer)i.next(); list tests = testcontainer.gettestswithid(testid); for (iterator j = tests.iterator(); j.hasnext();) { test test = (test)j.next(); test.resetstatspecs(statspecfile); } } } }","comment":"\/** * resets the statspecs to make them consistent for all tests in all * containers with the given test id. uses a global override, if provided. *\/\n\/\/ special case\n\/\/ determine which statspec file to use\n\/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\n\/\/ determine which statspec file to use for this test id\n\/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id","repo":"xyxiaoyou\/snappy-store","code_context_2":"private static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\n\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\n\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\n\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\n\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\n\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\n\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();","code_context_10":"private static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\n\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}","code_context_20":"private static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}\n\nprivate static void resetStatSpecs(String testId, List testContainers,\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n\nString statSpecFileOverride) {\nif (testContainers.size() == 1) { \/\/ special case\nTestContainer testContainer = (TestContainer)testContainers.get(0);\n\/\/ determine which statspec file to use\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testContainer);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test in the container\nList tests = testContainer.getTests();\nfor (Iterator i = tests.iterator(); i.hasNext();) {\nTest test = (Test)i.next();\ntest.resetStatSpecs(statSpecFile);\n}\n} else {\n\/\/ determine which statspec file to use for this test id\nString statSpecFile = statSpecFileOverride;\nif (statSpecFileOverride == null) {\nstatSpecFile = getLastStatSpecFile(testId, testContainers);\n} \/\/ @todo lises support option to use union of all statspecs\n\/\/ reset the statspec file for each test with the given test id\nfor (Iterator i = testContainers.iterator(); i.hasNext();) {\nTestContainer testContainer = (TestContainer)i.next();\nList tests = testContainer.getTestsWithId(testId);\nfor (Iterator j = tests.iterator(); j.hasNext();) {\nTest test = (Test)j.next();\ntest.resetStatSpecs(statSpecFile);\n}\n}\n}\n}","label":[0,1,0,0]}
{"id":25229,"original_code":"private static List buildValueComparators(String testId,\n                                            List testContainers) {\n    List comparators = new ArrayList();\n    for (int i = 0; i < testContainers.size(); i++) {\n      TestContainer testContainer = (TestContainer)testContainers.get(i);\n      List tests = testContainer.getTestsWithId(testId);\n      if (tests.size() == 0) { \/\/ test is missing from this container\n        comparators.add(null);\n      } else if (tests.size() == 1) {\n        Test test = (Test)tests.get(0);\n        ValueComparator comparator = new ValueComparator(i, test);\n        comparators.add(comparator);\n      } else { \/\/ multiple runs of this test are present\n        \/\/ @todo lises move this check into ValueComparator, for future\n        \/\/             averaging, make ValueComparator accept a list of tests\n        String s = \"Not implemented yet: multiple tests in \"\n                 + testContainer.getTestContainerDir() + \" with id=\" + testId;\n        throw new UnsupportedOperationException(s);\n      }\n    }\n    \/\/ make each instance read its archives\n    for (Iterator i = comparators.iterator(); i.hasNext();) {\n      ValueComparator comparator = (ValueComparator)i.next();\n      if (comparator != null) {\n        comparator.readArchives();\n      }\n    }\n    return comparators;\n  }","code":"private static List buildValueComparators(String testId,\n                                            List testContainers) {\n    List comparators = new ArrayList();\n    for (int i = 0; i < testContainers.size(); i++) {\n      TestContainer testContainer = (TestContainer)testContainers.get(i);\n      List tests = testContainer.getTestsWithId(testId);\n      if (tests.size() == 0) {\n        comparators.add(null);\n      } else if (tests.size() == 1) {\n        Test test = (Test)tests.get(0);\n        ValueComparator comparator = new ValueComparator(i, test);\n        comparators.add(comparator);\n      } else {\n       \n       \n        String s = \"Not implemented yet: multiple tests in \"\n                 + testContainer.getTestContainerDir() + \" with id=\" + testId;\n        throw new UnsupportedOperationException(s);\n      }\n    }\n   \n    for (Iterator i = comparators.iterator(); i.hasNext();) {\n      ValueComparator comparator = (ValueComparator)i.next();\n      if (comparator != null) {\n        comparator.readArchives();\n      }\n    }\n    return comparators;\n  }","cleancode":"private static list buildvaluecomparators(string testid, list testcontainers) { list comparators = new arraylist(); for (int i = 0; i < testcontainers.size(); i++) { testcontainer testcontainer = (testcontainer)testcontainers.get(i); list tests = testcontainer.gettestswithid(testid); if (tests.size() == 0) { comparators.add(null); } else if (tests.size() == 1) { test test = (test)tests.get(0); valuecomparator comparator = new valuecomparator(i, test); comparators.add(comparator); } else { string s = \"not implemented yet: multiple tests in \" + testcontainer.gettestcontainerdir() + \" with id=\" + testid; throw new unsupportedoperationexception(s); } } for (iterator i = comparators.iterator(); i.hasnext();) { valuecomparator comparator = (valuecomparator)i.next(); if (comparator != null) { comparator.readarchives(); } } return comparators; }","comment":"\/** * returns a list of {@link valuecomparator}s for the given test and test * containers with values for relevant statistics. *\/\n\/\/ test is missing from this container\n\/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into valuecomparator, for future \/\/ averaging, make valuecomparator accept a list of tests\n\/\/ make each instance read its archives","repo":"xyxiaoyou\/snappy-store","code_context_2":"private static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}\n\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\n\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\n\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\n\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();","code_context_10":"private static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}\n\nprivate static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\n\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\n\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}","code_context_20":"private static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}\n\nprivate static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\n\nprivate static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}\n\nprivate static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}\n\nprivate static List buildValueComparators(String testId,\nList testContainers) {\nList comparators = new ArrayList();\nfor (int i = 0; i < testContainers.size(); i++) {\nTestContainer testContainer = (TestContainer)testContainers.get(i);\nList tests = testContainer.getTestsWithId(testId);\nif (tests.size() == 0) { \/\/ test is missing from this container\ncomparators.add(null);\n} else if (tests.size() == 1) {\nTest test = (Test)tests.get(0);\nValueComparator comparator = new ValueComparator(i, test);\ncomparators.add(comparator);\n} else { \/\/ multiple runs of this test are present\n\/\/ @todo lises move this check into ValueComparator, for future\n\/\/ averaging, make ValueComparator accept a list of tests\nString s = \"Not implemented yet: multiple tests in \"\n+ testContainer.getTestContainerDir() + \" with id=\" + testId;\nthrow new UnsupportedOperationException(s);\n}\n}\n\/\/ make each instance read its archives\nfor (Iterator i = comparators.iterator(); i.hasNext();) {\nValueComparator comparator = (ValueComparator)i.next();\nif (comparator != null) {\ncomparator.readArchives();\n}\n}\nreturn comparators;\n}","label":[0,1,0,0]}
{"id":8858,"original_code":"private static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\n            throws IOException\n    {\n        try (PDPageContentStream cs\n                = new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n        {\n            float fontHeight = 100; \/\/ arbitrary for short text\n            float width = page.getMediaBox().getWidth();\n            float height = page.getMediaBox().getHeight();\n            float stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\n            float diagonalLength = (float) Math.sqrt(width * width + height * height);\n            float angle = (float) Math.atan2(height, width);\n            float x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\n            float y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\n            cs.transform(Matrix.getRotateInstance(angle, 0, 0));\n            cs.setFont(font, fontHeight);\n            \/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\n            PDExtendedGraphicsState gs = new PDExtendedGraphicsState();\n            gs.setNonStrokingAlphaConstant(0.2f);\n            gs.setStrokingAlphaConstant(0.2f);\n            gs.setBlendMode(BlendMode.MULTIPLY);\n            gs.setLineWidth(3f);\n            cs.setGraphicsStateParameters(gs);\n            \/\/ some API weirdness here. When int, range is 0..255.\n            \/\/ when float, this would be 0..1f\n            cs.setNonStrokingColor(255, 0, 0);\n            cs.setStrokingColor(255, 0, 0);\n            cs.beginText();\n            cs.newLineAtOffset(x, y);\n            cs.showText(text);\n            cs.endText();\n        }\n    }","code":"private static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\n            throws IOException\n    {\n        try (PDPageContentStream cs\n                = new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n        {\n            float fontHeight = 100;\n            float width = page.getMediaBox().getWidth();\n            float height = page.getMediaBox().getHeight();\n            float stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\n            float diagonalLength = (float) Math.sqrt(width * width + height * height);\n            float angle = (float) Math.atan2(height, width);\n            float x = (diagonalLength - stringWidth) \/ 2;\n            float y = -fontHeight \/ 4;\n            cs.transform(Matrix.getRotateInstance(angle, 0, 0));\n            cs.setFont(font, fontHeight);\n           \n            PDExtendedGraphicsState gs = new PDExtendedGraphicsState();\n            gs.setNonStrokingAlphaConstant(0.2f);\n            gs.setStrokingAlphaConstant(0.2f);\n            gs.setBlendMode(BlendMode.MULTIPLY);\n            gs.setLineWidth(3f);\n            cs.setGraphicsStateParameters(gs);\n           \n           \n            cs.setNonStrokingColor(255, 0, 0);\n            cs.setStrokingColor(255, 0, 0);\n            cs.beginText();\n            cs.newLineAtOffset(x, y);\n            cs.showText(text);\n            cs.endText();\n        }\n    }","cleancode":"private static void addwatermarktext(pddocument doc, pdpage page, pdfont font, string text) throws ioexception { try (pdpagecontentstream cs = new pdpagecontentstream(doc, page, pdpagecontentstream.appendmode.append, true, true)) { float fontheight = 100; float width = page.getmediabox().getwidth(); float height = page.getmediabox().getheight(); float stringwidth = font.getstringwidth(text) \/ 1000 * fontheight; float diagonallength = (float) math.sqrt(width * width + height * height); float angle = (float) math.atan2(height, width); float x = (diagonallength - stringwidth) \/ 2; float y = -fontheight \/ 4; cs.transform(matrix.getrotateinstance(angle, 0, 0)); cs.setfont(font, fontheight); pdextendedgraphicsstate gs = new pdextendedgraphicsstate(); gs.setnonstrokingalphaconstant(0.2f); gs.setstrokingalphaconstant(0.2f); gs.setblendmode(blendmode.multiply); gs.setlinewidth(3f); cs.setgraphicsstateparameters(gs); cs.setnonstrokingcolor(255, 0, 0); cs.setstrokingcolor(255, 0, 0); cs.begintext(); cs.newlineatoffset(x, y); cs.showtext(text); cs.endtext(); } }","comment":"\/\/ arbitrary for short text\n\/\/ \"horizontal\" position in rotated world\n\/\/ 4 is a trial-and-error thing, this lowers the text a bit\n\/\/ cs.setrenderingmode(renderingmode.stroke) \/\/ for \"hollow\" effect\n\/\/ some api weirdness here. when int, range is 0..255. \/\/ when float, this would be 0..1f","repo":"vijji432\/pdfbox","code_context_2":"= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\n\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\n\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\n\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);","code_context_10":"private static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\nthrows IOException\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\n\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\n\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\ncs.beginText();\ncs.newLineAtOffset(x, y);\ncs.showText(text);\ncs.endText();\n}\n}","code_context_20":"private static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\nthrows IOException\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\n\nprivate static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\nthrows IOException\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\ncs.beginText();\ncs.newLineAtOffset(x, y);\ncs.showText(text);\ncs.endText();\n}\n}\n\nprivate static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\nthrows IOException\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\ncs.beginText();\ncs.newLineAtOffset(x, y);\ncs.showText(text);\ncs.endText();\n}\n}\n\nprivate static void addWatermarkText(PDDocument doc, PDPage page, PDFont font, String text)\nthrows IOException\n{\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\ncs.beginText();\ncs.newLineAtOffset(x, y);\ncs.showText(text);\ncs.endText();\n}\n}\n\ntry (PDPageContentStream cs\n= new PDPageContentStream(doc, page, PDPageContentStream.AppendMode.APPEND, true, true))\n{\nfloat fontHeight = 100; \/\/ arbitrary for short text\nfloat width = page.getMediaBox().getWidth();\nfloat height = page.getMediaBox().getHeight();\nfloat stringWidth = font.getStringWidth(text) \/ 1000 * fontHeight;\nfloat diagonalLength = (float) Math.sqrt(width * width + height * height);\nfloat angle = (float) Math.atan2(height, width);\nfloat x = (diagonalLength - stringWidth) \/ 2; \/\/ \"horizontal\" position in rotated world\nfloat y = -fontHeight \/ 4; \/\/ 4 is a trial-and-error thing, this lowers the text a bit\ncs.transform(Matrix.getRotateInstance(angle, 0, 0));\ncs.setFont(font, fontHeight);\n\/\/ cs.setRenderingMode(RenderingMode.STROKE) \/\/ for \"hollow\" effect\nPDExtendedGraphicsState gs = new PDExtendedGraphicsState();\ngs.setNonStrokingAlphaConstant(0.2f);\ngs.setStrokingAlphaConstant(0.2f);\ngs.setBlendMode(BlendMode.MULTIPLY);\ngs.setLineWidth(3f);\ncs.setGraphicsStateParameters(gs);\n\/\/ some API weirdness here. When int, range is 0..255.\n\/\/ when float, this would be 0..1f\ncs.setNonStrokingColor(255, 0, 0);\ncs.setStrokingColor(255, 0, 0);\ncs.beginText();\ncs.newLineAtOffset(x, y);\ncs.showText(text);\ncs.endText();\n}\n}","label":[0,0,1,0]}
{"id":17057,"original_code":"private void deflateData(boolean force) throws IOException {\n        \/\/we don't need to flush here, as this should have been called already by the time we get to\n        \/\/this point\n        boolean nextCreated = false;\n        try {\n            PooledByteBuffer pooled = this.currentBuffer;\n            final ByteBuffer outputBuffer = pooled.getBuffer();\n            final boolean shutdown = anyAreSet(state, SHUTDOWN);\n            byte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\n            while (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\n                int count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\n                Connectors.updateResponseBytesSent(exchange, count);\n                if (count != 0) {\n                    int remaining = outputBuffer.remaining();\n                    if (remaining > count) {\n                        outputBuffer.put(buffer, 0, count);\n                    } else {\n                        if (remaining == count) {\n                            outputBuffer.put(buffer, 0, count);\n                        } else {\n                            outputBuffer.put(buffer, 0, remaining);\n                            additionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n                        }\n                        outputBuffer.flip();\n                        this.state |= FLUSHING_BUFFER;\n                        if (next == null) {\n                            nextCreated = true;\n                            this.next = createNextChannel();\n                        }\n                        if (!performFlushIfRequired()) {\n                            return;\n                        }\n                    }\n                } else {\n                    force = false;\n                }\n            }\n        } finally {\n            if (nextCreated) {\n                if (anyAreSet(state, WRITES_RESUMED)) {\n                    next.resumeWrites();\n                }\n            }\n        }\n    }","code":"private void deflateData(boolean force) throws IOException {\n       \n       \n        boolean nextCreated = false;\n        try {\n            PooledByteBuffer pooled = this.currentBuffer;\n            final ByteBuffer outputBuffer = pooled.getBuffer();\n            final boolean shutdown = anyAreSet(state, SHUTDOWN);\n            byte[] buffer = new byte[1024];\n            while (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\n                int count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\n                Connectors.updateResponseBytesSent(exchange, count);\n                if (count != 0) {\n                    int remaining = outputBuffer.remaining();\n                    if (remaining > count) {\n                        outputBuffer.put(buffer, 0, count);\n                    } else {\n                        if (remaining == count) {\n                            outputBuffer.put(buffer, 0, count);\n                        } else {\n                            outputBuffer.put(buffer, 0, remaining);\n                            additionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n                        }\n                        outputBuffer.flip();\n                        this.state |= FLUSHING_BUFFER;\n                        if (next == null) {\n                            nextCreated = true;\n                            this.next = createNextChannel();\n                        }\n                        if (!performFlushIfRequired()) {\n                            return;\n                        }\n                    }\n                } else {\n                    force = false;\n                }\n            }\n        } finally {\n            if (nextCreated) {\n                if (anyAreSet(state, WRITES_RESUMED)) {\n                    next.resumeWrites();\n                }\n            }\n        }\n    }","cleancode":"private void deflatedata(boolean force) throws ioexception { boolean nextcreated = false; try { pooledbytebuffer pooled = this.currentbuffer; final bytebuffer outputbuffer = pooled.getbuffer(); final boolean shutdown = anyareset(state, shutdown); byte[] buffer = new byte[1024]; while (force || !deflater.needsinput() || (shutdown && !deflater.finished())) { int count = deflater.deflate(buffer, 0, buffer.length, force ? deflater.sync_flush: deflater.no_flush); connectors.updateresponsebytessent(exchange, count); if (count != 0) { int remaining = outputbuffer.remaining(); if (remaining > count) { outputbuffer.put(buffer, 0, count); } else { if (remaining == count) { outputbuffer.put(buffer, 0, count); } else { outputbuffer.put(buffer, 0, remaining); additionalbuffer = bytebuffer.wrap(buffer, remaining, count - remaining); } outputbuffer.flip(); this.state |= flushing_buffer; if (next == null) { nextcreated = true; this.next = createnextchannel(); } if (!performflushifrequired()) { return; } } } else { force = false; } } } finally { if (nextcreated) { if (anyareset(state, writes_resumed)) { next.resumewrites(); } } } }","comment":"\/** * runs the current data through the deflater. as much as possible this will be buffered in the current output * stream. * * @throws ioexception *\/\n\/\/we don't need to flush here, as this should have been called already by the time we get to \/\/this point\n\/\/todo: we should pool this and make it configurable or something","repo":"yzy830\/undertow-analyze","code_context_2":"private void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);\n} else {\noutputBuffer.put(buffer, 0, remaining);\nadditionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n}\noutputBuffer.flip();\nthis.state |= FLUSHING_BUFFER;\nif (next == null) {\nnextCreated = true;\nthis.next = createNextChannel();\n}\nif (!performFlushIfRequired()) {\nreturn;\n}\n}\n} else {\nforce = false;\n}\n}\n} finally {\nif (nextCreated) {\nif (anyAreSet(state, WRITES_RESUMED)) {\nnext.resumeWrites();\n}\n}\n}\n}\n\nprivate void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\n\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);","code_context_10":"private void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);\n} else {\noutputBuffer.put(buffer, 0, remaining);\nadditionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n}\noutputBuffer.flip();\nthis.state |= FLUSHING_BUFFER;\nif (next == null) {\nnextCreated = true;\nthis.next = createNextChannel();\n}\nif (!performFlushIfRequired()) {\nreturn;\n}\n}\n} else {\nforce = false;\n}\n}\n} finally {\nif (nextCreated) {\nif (anyAreSet(state, WRITES_RESUMED)) {\nnext.resumeWrites();\n}\n}\n}\n}\n\nprivate void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\n\nprivate void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);","code_context_20":"private void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);\n} else {\noutputBuffer.put(buffer, 0, remaining);\nadditionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n}\noutputBuffer.flip();\nthis.state |= FLUSHING_BUFFER;\nif (next == null) {\nnextCreated = true;\nthis.next = createNextChannel();\n}\nif (!performFlushIfRequired()) {\nreturn;\n}\n}\n} else {\nforce = false;\n}\n}\n} finally {\nif (nextCreated) {\nif (anyAreSet(state, WRITES_RESUMED)) {\nnext.resumeWrites();\n}\n}\n}\n}\n\nprivate void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);\n} else {\noutputBuffer.put(buffer, 0, remaining);\nadditionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n}\n\nprivate void deflateData(boolean force) throws IOException {\n\/\/we don't need to flush here, as this should have been called already by the time we get to\n\/\/this point\nboolean nextCreated = false;\ntry {\nPooledByteBuffer pooled = this.currentBuffer;\nfinal ByteBuffer outputBuffer = pooled.getBuffer();\nfinal boolean shutdown = anyAreSet(state, SHUTDOWN);\nbyte[] buffer = new byte[1024]; \/\/TODO: we should pool this and make it configurable or something\nwhile (force || !deflater.needsInput() || (shutdown && !deflater.finished())) {\nint count = deflater.deflate(buffer, 0, buffer.length, force ? Deflater.SYNC_FLUSH: Deflater.NO_FLUSH);\nConnectors.updateResponseBytesSent(exchange, count);\nif (count != 0) {\nint remaining = outputBuffer.remaining();\nif (remaining > count) {\noutputBuffer.put(buffer, 0, count);\n} else {\nif (remaining == count) {\noutputBuffer.put(buffer, 0, count);\n} else {\noutputBuffer.put(buffer, 0, remaining);\nadditionalBuffer = ByteBuffer.wrap(buffer, remaining, count - remaining);\n}\noutputBuffer.flip();\nthis.state |= FLUSHING_BUFFER;\nif (next == null) {\nnextCreated = true;\nthis.next = createNextChannel();\n}","label":[1,0,0,0]}
{"id":33483,"original_code":"public void copyData(DataWrapper body, byte[] data, int offset) {\n\t\tfor(int i = 0; i < body.getReadableSize(); i++) {\n\t\t\t\/\/TODO: Think about using System.arrayCopy here(what is faster?)\n\t\t\tdata[offset + i] = body.readByteAt(i);\n\t\t}\n\t}","code":"public void copyData(DataWrapper body, byte[] data, int offset) {\n\t\tfor(int i = 0; i < body.getReadableSize(); i++) {\n\t\t\n\t\t\tdata[offset + i] = body.readByteAt(i);\n\t\t}\n\t}","cleancode":"public void copydata(datawrapper body, byte[] data, int offset) { for(int i = 0; i < body.getreadablesize(); i++) { data[offset + i] = body.readbyteat(i); } }","comment":"\/\/todo: think about using system.arraycopy here(what is faster?)","repo":"zreed\/webpieces","code_context_2":"public void copyData(DataWrapper body, byte[] data, int offset) {\nfor(int i = 0; i < body.getReadableSize(); i++) {\n\/\/TODO: Think about using System.arrayCopy here(what is faster?)\ndata[offset + i] = body.readByteAt(i);\n}","code_context_10":"public void copyData(DataWrapper body, byte[] data, int offset) {\nfor(int i = 0; i < body.getReadableSize(); i++) {\n\/\/TODO: Think about using System.arrayCopy here(what is faster?)\ndata[offset + i] = body.readByteAt(i);\n}\n}","code_context_20":"public void copyData(DataWrapper body, byte[] data, int offset) {\nfor(int i = 0; i < body.getReadableSize(); i++) {\n\/\/TODO: Think about using System.arrayCopy here(what is faster?)\ndata[offset + i] = body.readByteAt(i);\n}\n}","label":[1,0,0,0]}
{"id":33494,"original_code":"public boolean expire(Table table) {\n    if (expirationPeriod <= 0) {\n      return false;\n    }\n    long current = System.currentTimeMillis();\n    Long last = expirationStatus.putIfAbsent(table.location(), current);\n    if (last != null && current - last >= expirationPeriod) {\n      expirationStatus.put(table.location(), current);\n      ExecutorService executorService = executorService();\n      executorService.submit(() -> {\n        logger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\n        table.expireSnapshots()\n          .expireOlderThan(current)\n          .commit();\n        \/\/ TODO: Replace with table metadata expiration through Iceberg API\n        \/\/       when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n        \/\/       table.expireTableMetadata().expireOlderThan(current).commit();\n        expireTableMetadata(table);\n      });\n      return true;\n    }\n    return false;\n  }","code":"public boolean expire(Table table) {\n    if (expirationPeriod <= 0) {\n      return false;\n    }\n    long current = System.currentTimeMillis();\n    Long last = expirationStatus.putIfAbsent(table.location(), current);\n    if (last != null && current - last >= expirationPeriod) {\n      expirationStatus.put(table.location(), current);\n      ExecutorService executorService = executorService();\n      executorService.submit(() -> {\n        logger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\n        table.expireSnapshots()\n          .expireOlderThan(current)\n          .commit();\n       \n       \n       \n        expireTableMetadata(table);\n      });\n      return true;\n    }\n    return false;\n  }","cleancode":"public boolean expire(table table) { if (expirationperiod <= 0) { return false; } long current = system.currenttimemillis(); long last = expirationstatus.putifabsent(table.location(), current); if (last != null && current - last >= expirationperiod) { expirationstatus.put(table.location(), current); executorservice executorservice = executorservice(); executorservice.submit(() -> { logger.debug(\"expiring iceberg table [{}] metadata\", table.location()); table.expiresnapshots() .expireolderthan(current) .commit(); expiretablemetadata(table); }); return true; } return false; }","comment":"\/** * checks if expiration process needs to be performed for the given iceberg table * by comparing stored last expiration time. * if difference between last expiration time and current time is more or equal to * expiration period, launches expiration process. * if expiration period is zero or negative, no expiration process will be launched. * * @param table iceberg table instance * @return true if expiration process was launched, false otherwise *\/\n\/\/ todo: replace with table metadata expiration through iceberg api \/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved \/\/ table.expiretablemetadata().expireolderthan(current).commit();","repo":"yanlin-Lynn\/drill","code_context_2":"public boolean expire(Table table) {\nif (expirationPeriod <= 0) {\nreturn false;\n}\nlong current = System.currentTimeMillis();\nLong last = expirationStatus.putIfAbsent(table.location(), current);\nif (last != null && current - last >= expirationPeriod) {\nexpirationStatus.put(table.location(), current);\nExecutorService executorService = executorService();\nexecutorService.submit(() -> {\nlogger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\ntable.expireSnapshots()\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});\nreturn true;\n}\nreturn false;\n}\n\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});","code_context_10":"public boolean expire(Table table) {\nif (expirationPeriod <= 0) {\nreturn false;\n}\nlong current = System.currentTimeMillis();\nLong last = expirationStatus.putIfAbsent(table.location(), current);\nif (last != null && current - last >= expirationPeriod) {\nexpirationStatus.put(table.location(), current);\nExecutorService executorService = executorService();\nexecutorService.submit(() -> {\nlogger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\ntable.expireSnapshots()\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});\nreturn true;\n}\nreturn false;\n}\n\nlong current = System.currentTimeMillis();\nLong last = expirationStatus.putIfAbsent(table.location(), current);\nif (last != null && current - last >= expirationPeriod) {\nexpirationStatus.put(table.location(), current);\nExecutorService executorService = executorService();\nexecutorService.submit(() -> {\nlogger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\ntable.expireSnapshots()\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});\nreturn true;\n}\nreturn false;\n}","code_context_20":"public boolean expire(Table table) {\nif (expirationPeriod <= 0) {\nreturn false;\n}\nlong current = System.currentTimeMillis();\nLong last = expirationStatus.putIfAbsent(table.location(), current);\nif (last != null && current - last >= expirationPeriod) {\nexpirationStatus.put(table.location(), current);\nExecutorService executorService = executorService();\nexecutorService.submit(() -> {\nlogger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\ntable.expireSnapshots()\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});\nreturn true;\n}\nreturn false;\n}\n\npublic boolean expire(Table table) {\nif (expirationPeriod <= 0) {\nreturn false;\n}\nlong current = System.currentTimeMillis();\nLong last = expirationStatus.putIfAbsent(table.location(), current);\nif (last != null && current - last >= expirationPeriod) {\nexpirationStatus.put(table.location(), current);\nExecutorService executorService = executorService();\nexecutorService.submit(() -> {\nlogger.debug(\"Expiring Iceberg table [{}] metadata\", table.location());\ntable.expireSnapshots()\n.expireOlderThan(current)\n.commit();\n\/\/ TODO: Replace with table metadata expiration through Iceberg API\n\/\/ when https:\/\/github.com\/apache\/incubator-iceberg\/issues\/181 is resolved\n\/\/ table.expireTableMetadata().expireOlderThan(current).commit();\nexpireTableMetadata(table);\n});\nreturn true;\n}\nreturn false;\n}","label":[1,0,0,0]}
{"id":728,"original_code":"protected boolean shouldNotifyObserversOnSetIndex() {\n        return true;\n    }","code":"protected boolean shouldNotifyObserversOnSetIndex() {\n        return true;\n    }","cleancode":"protected boolean shouldnotifyobserversonsetindex() { return true; }","comment":"\/\/ todo(crbug.com\/948518): this is a band-aid fix for not crashing when undo the last closed \/\/ tab, should remove later. \/** * @return whether filter should notify observers about the setindex call. *\/","repo":"zealoussnow\/chromium","code_context_2":"protected boolean shouldNotifyObserversOnSetIndex() {\nreturn true;\n}","code_context_10":"protected boolean shouldNotifyObserversOnSetIndex() {\nreturn true;\n}","code_context_20":"protected boolean shouldNotifyObserversOnSetIndex() {\nreturn true;\n}","label":[0,0,1,0]}
{"id":8942,"original_code":"private void configureEditableItem() {\n        String editText = item.getText();\n        etEditItem = (EditText) findViewById(R.id.etEditItem);\n        etEditItem.setText(editText);\n        etEditItem.setSelection(editText.length());\n        \/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\n        etDueDate = (EditText) findViewById(R.id.etDueDate);\n        String dueDate = item.getDueDate();\n        etDueDate.setText(dueDate);\n        \/*if (dueDate != null) {\n            SimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\n            Date date = new Date();\n            try {\n                date = sdf.parse(dueDate);\n            } catch (ParseException e) {\n                Log.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n            }\n            Calendar cal = Calendar.getInstance();\n            cal.setTime(date);\n            datePicker.updateDate(cal.get(Calendar.YEAR), cal.get(Calendar.MONTH), cal.get(Calendar.DAY_OF_MONTH));\n        }*\/\n        spPriority = (Spinner) findViewById(R.id.spinnerPriority);\n        ArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(\n                this, android.R.layout.simple_list_item_1, TodoItem.Priority.values());\n        spPriority.setAdapter(priorityAdapter);\n        int priorityIndex = item.getPriority().ordinal();\n        spPriority.setSelection(priorityIndex);\n    }","code":"private void configureEditableItem() {\n        String editText = item.getText();\n        etEditItem = (EditText) findViewById(R.id.etEditItem);\n        etEditItem.setText(editText);\n        etEditItem.setSelection(editText.length());\n       \n        etDueDate = (EditText) findViewById(R.id.etDueDate);\n        String dueDate = item.getDueDate();\n        etDueDate.setText(dueDate);\n       \n        spPriority = (Spinner) findViewById(R.id.spinnerPriority);\n        ArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(\n                this, android.R.layout.simple_list_item_1, TodoItem.Priority.values());\n        spPriority.setAdapter(priorityAdapter);\n        int priorityIndex = item.getPriority().ordinal();\n        spPriority.setSelection(priorityIndex);\n    }","cleancode":"private void configureeditableitem() { string edittext = item.gettext(); etedititem = (edittext) findviewbyid(r.id.etedititem); etedititem.settext(edittext); etedititem.setselection(edittext.length()); etduedate = (edittext) findviewbyid(r.id.etduedate); string duedate = item.getduedate(); etduedate.settext(duedate); sppriority = (spinner) findviewbyid(r.id.spinnerpriority); arrayadapter<todoitem.priority> priorityadapter = new arrayadapter<todoitem.priority>( this, android.r.layout.simple_list_item_1, todoitem.priority.values()); sppriority.setadapter(priorityadapter); int priorityindex = item.getpriority().ordinal(); sppriority.setselection(priorityindex); }","comment":"\/\/ todo: allow user to not choose a date (and make the datepicker look a lot better)\n\/*if (duedate != null) { simpledateformat sdf = new simpledateformat(todoitem.due_date_format); date date = new date(); try { date = sdf.parse(duedate); } catch (parseexception e) { log.w(getclass().getsimplename(), \"failed to parse due date, '\" + duedate + \"' using format \" + todoitem.due_date_format); } calendar cal = calendar.getinstance(); cal.settime(date); datepicker.updatedate(cal.get(calendar.year), cal.get(calendar.month), cal.get(calendar.day_of_month)); }*\/","repo":"willieowens\/simpletodo","code_context_2":"etEditItem.setText(editText);\netEditItem.setSelection(editText.length());\n\/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\netDueDate = (EditText) findViewById(R.id.etDueDate);\nString dueDate = item.getDueDate();\n\nString dueDate = item.getDueDate();\netDueDate.setText(dueDate);\n\/*if (dueDate != null) {\nSimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\nDate date = new Date();\ntry {\ndate = sdf.parse(dueDate);\n} catch (ParseException e) {\nLog.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n}\nCalendar cal = Calendar.getInstance();\ncal.setTime(date);\ndatePicker.updateDate(cal.get(Calendar.YEAR), cal.get(Calendar.MONTH), cal.get(Calendar.DAY_OF_MONTH));\n}*\/\nspPriority = (Spinner) findViewById(R.id.spinnerPriority);\nArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(","code_context_10":"private void configureEditableItem() {\nString editText = item.getText();\netEditItem = (EditText) findViewById(R.id.etEditItem);\netEditItem.setText(editText);\netEditItem.setSelection(editText.length());\n\/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\netDueDate = (EditText) findViewById(R.id.etDueDate);\nString dueDate = item.getDueDate();\netDueDate.setText(dueDate);\n\/*if (dueDate != null) {\nSimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\nDate date = new Date();\ntry {\ndate = sdf.parse(dueDate);\n} catch (ParseException e) {\nLog.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n\nprivate void configureEditableItem() {\nString editText = item.getText();\netEditItem = (EditText) findViewById(R.id.etEditItem);\netEditItem.setText(editText);\netEditItem.setSelection(editText.length());\n\/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\netDueDate = (EditText) findViewById(R.id.etDueDate);\nString dueDate = item.getDueDate();\netDueDate.setText(dueDate);\n\/*if (dueDate != null) {\nSimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\nDate date = new Date();\ntry {\ndate = sdf.parse(dueDate);\n} catch (ParseException e) {\nLog.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n}\nCalendar cal = Calendar.getInstance();\ncal.setTime(date);\ndatePicker.updateDate(cal.get(Calendar.YEAR), cal.get(Calendar.MONTH), cal.get(Calendar.DAY_OF_MONTH));\n}*\/\nspPriority = (Spinner) findViewById(R.id.spinnerPriority);\nArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(\nthis, android.R.layout.simple_list_item_1, TodoItem.Priority.values());\nspPriority.setAdapter(priorityAdapter);\nint priorityIndex = item.getPriority().ordinal();\nspPriority.setSelection(priorityIndex);\n}","code_context_20":"private void configureEditableItem() {\nString editText = item.getText();\netEditItem = (EditText) findViewById(R.id.etEditItem);\netEditItem.setText(editText);\netEditItem.setSelection(editText.length());\n\/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\netDueDate = (EditText) findViewById(R.id.etDueDate);\nString dueDate = item.getDueDate();\netDueDate.setText(dueDate);\n\/*if (dueDate != null) {\nSimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\nDate date = new Date();\ntry {\ndate = sdf.parse(dueDate);\n} catch (ParseException e) {\nLog.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n}\nCalendar cal = Calendar.getInstance();\ncal.setTime(date);\ndatePicker.updateDate(cal.get(Calendar.YEAR), cal.get(Calendar.MONTH), cal.get(Calendar.DAY_OF_MONTH));\n}*\/\nspPriority = (Spinner) findViewById(R.id.spinnerPriority);\nArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(\nthis, android.R.layout.simple_list_item_1, TodoItem.Priority.values());\nspPriority.setAdapter(priorityAdapter);\nint priorityIndex = item.getPriority().ordinal();\n\nprivate void configureEditableItem() {\nString editText = item.getText();\netEditItem = (EditText) findViewById(R.id.etEditItem);\netEditItem.setText(editText);\netEditItem.setSelection(editText.length());\n\/\/ TODO: allow user to not choose a date (and make the datepicker look a lot better)\netDueDate = (EditText) findViewById(R.id.etDueDate);\nString dueDate = item.getDueDate();\netDueDate.setText(dueDate);\n\/*if (dueDate != null) {\nSimpleDateFormat sdf = new SimpleDateFormat(TodoItem.DUE_DATE_FORMAT);\nDate date = new Date();\ntry {\ndate = sdf.parse(dueDate);\n} catch (ParseException e) {\nLog.w(getClass().getSimpleName(), \"Failed to parse due date, '\" + dueDate + \"' using format \" + TodoItem.DUE_DATE_FORMAT);\n}\nCalendar cal = Calendar.getInstance();\ncal.setTime(date);\ndatePicker.updateDate(cal.get(Calendar.YEAR), cal.get(Calendar.MONTH), cal.get(Calendar.DAY_OF_MONTH));\n}*\/\nspPriority = (Spinner) findViewById(R.id.spinnerPriority);\nArrayAdapter<TodoItem.Priority> priorityAdapter = new ArrayAdapter<TodoItem.Priority>(\nthis, android.R.layout.simple_list_item_1, TodoItem.Priority.values());\nspPriority.setAdapter(priorityAdapter);\nint priorityIndex = item.getPriority().ordinal();\nspPriority.setSelection(priorityIndex);\n}","label":[1,0,0,0]}
{"id":776,"original_code":"@Override\n    public int write(ChannelBuffer cb) {\n        \/\/ TODO This will be implemented in the next version\n        return 0;\n    }","code":"@Override\n    public int write(ChannelBuffer cb) {\n       \n        return 0;\n    }","cleancode":"@override public int write(channelbuffer cb) { return 0; }","comment":"\/\/ todo this will be implemented in the next version","repo":"ustc-fhq\/onos","code_context_2":"@Override\npublic int write(ChannelBuffer cb) {\n\/\/ TODO This will be implemented in the next version\nreturn 0;\n}","code_context_10":"@Override\npublic int write(ChannelBuffer cb) {\n\/\/ TODO This will be implemented in the next version\nreturn 0;\n}","code_context_20":"@Override\npublic int write(ChannelBuffer cb) {\n\/\/ TODO This will be implemented in the next version\nreturn 0;\n}","label":[0,1,0,0]}
{"id":17189,"original_code":"@Override\n  public void allocateMultiple(MemoryBuffer[] dest, int size)\n      throws AllocatorOutOfMemoryException {\n    assert size > 0 : \"size is \" + size;\n    if (size > maxAllocation) {\n      throw new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n    }\n    int freeListIx = 31 - Integer.numberOfLeadingZeros(size);\n    if (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\n    freeListIx = Math.max(freeListIx - minAllocLog2, 0);\n    int allocLog2 = freeListIx + minAllocLog2;\n    int allocationSize = 1 << allocLog2;\n    \/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\n    memoryManager.reserveMemory(dest.length << allocLog2, true);\n    int ix = 0;\n    for (int i = 0; i < dest.length; ++i) {\n      if (dest[i] != null) continue;\n      dest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n    }\n    \/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\n    int arenaCount = allocatedArenas.get();\n    if (arenaCount < 0) {\n      arenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n    }\n    long threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n    {\n      int startIndex = (int)(threadId % arenaCount), index = startIndex;\n      do {\n        int newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\n        if (newIx == dest.length) return;\n        if (newIx != -1) {  \/\/ TODO: check if it can still happen; count should take care of this.\n          ix = newIx;\n        }\n        ix = newIx;\n        if ((++index) == arenaCount) {\n          index = 0;\n        }\n      } while (index != startIndex);\n    }\n    \/\/ TODO: this is very hacky.\n    \/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n    \/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n    \/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n    \/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n    \/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n    \/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n    \/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n    \/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n    \/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n    \/\/ block and the time it returns the remaining 768Kb.\n    \/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n    \/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n    \/\/ allocator thread (or threads per arena).\n    \/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n    \/\/ But for now we will just retry 5 times 0_o\n    for (int attempt = 0; attempt < 5; ++attempt) {\n      \/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\n      for (int i = 0; i < arenaCount; ++i) {\n        int newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\n        if (newIx == -1) break; \/\/ Shouldn't happen.\n        if (newIx == dest.length) return;\n        ix = newIx;\n      }\n      if (attempt == 0) {\n        \/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\n        for (int i = arenaCount; i < arenas.length; ++i) {\n          ix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\n          if (ix == dest.length) return;\n        }\n      }\n      LlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n    }\n    String msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\n    LlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n        + \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\n    throw new AllocatorOutOfMemoryException(msg);\n  }","code":"@Override\n  public void allocateMultiple(MemoryBuffer[] dest, int size)\n      throws AllocatorOutOfMemoryException {\n    assert size > 0 : \"size is \" + size;\n    if (size > maxAllocation) {\n      throw new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n    }\n    int freeListIx = 31 - Integer.numberOfLeadingZeros(size);\n    if (size != (1 << freeListIx)) ++freeListIx;\n    freeListIx = Math.max(freeListIx - minAllocLog2, 0);\n    int allocLog2 = freeListIx + minAllocLog2;\n    int allocationSize = 1 << allocLog2;\n   \n    memoryManager.reserveMemory(dest.length << allocLog2, true);\n    int ix = 0;\n    for (int i = 0; i < dest.length; ++i) {\n      if (dest[i] != null) continue;\n      dest[i] = createUnallocated();\n    }\n   \n    int arenaCount = allocatedArenas.get();\n    if (arenaCount < 0) {\n      arenaCount = -arenaCount - 1;\n    }\n    long threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n    {\n      int startIndex = (int)(threadId % arenaCount), index = startIndex;\n      do {\n        int newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\n        if (newIx == dest.length) return;\n        if (newIx != -1) { \n          ix = newIx;\n        }\n        ix = newIx;\n        if ((++index) == arenaCount) {\n          index = 0;\n        }\n      } while (index != startIndex);\n    }\n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n   \n    for (int attempt = 0; attempt < 5; ++attempt) {\n     \n      for (int i = 0; i < arenaCount; ++i) {\n        int newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\n        if (newIx == -1) break;\n        if (newIx == dest.length) return;\n        ix = newIx;\n      }\n      if (attempt == 0) {\n       \n        for (int i = arenaCount; i < arenas.length; ++i) {\n          ix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\n          if (ix == dest.length) return;\n        }\n      }\n      LlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n    }\n    String msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\n    LlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n        + \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\n    throw new AllocatorOutOfMemoryException(msg);\n  }","cleancode":"@override public void allocatemultiple(memorybuffer[] dest, int size) throws allocatoroutofmemoryexception { assert size > 0 : \"size is \" + size; if (size > maxallocation) { throw new runtimeexception(\"trying to allocate \" + size + \"; max is \" + maxallocation); } int freelistix = 31 - integer.numberofleadingzeros(size); if (size != (1 << freelistix)) ++freelistix; freelistix = math.max(freelistix - minalloclog2, 0); int alloclog2 = freelistix + minalloclog2; int allocationsize = 1 << alloclog2; memorymanager.reservememory(dest.length << alloclog2, true); int ix = 0; for (int i = 0; i < dest.length; ++i) { if (dest[i] != null) continue; dest[i] = createunallocated(); } int arenacount = allocatedarenas.get(); if (arenacount < 0) { arenacount = -arenacount - 1; } long threadid = arenacount > 1 ? thread.currentthread().getid() : 0; { int startindex = (int)(threadid % arenacount), index = startindex; do { int newix = arenas[index].allocatefast(index, freelistix, dest, ix, allocationsize); if (newix == dest.length) return; if (newix != -1) { ix = newix; } ix = newix; if ((++index) == arenacount) { index = 0; } } while (index != startindex); } for (int attempt = 0; attempt < 5; ++attempt) { for (int i = 0; i < arenacount; ++i) { int newix = arenas[i].allocatewithsplit(i, freelistix, dest, ix, allocationsize); if (newix == -1) break; if (newix == dest.length) return; ix = newix; } if (attempt == 0) { for (int i = arenacount; i < arenas.length; ++i) { ix = arenas[i].allocatewithexpand(i, freelistix, dest, ix, allocationsize); if (ix == dest.length) return; } } llapioimpl.log.warn(\"failed to allocate despite reserved memory; will retry \" + attempt); } string msg = \"failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length; llapioimpl.log.error(msg + \"\\nallocator state:\\n\" + debugdump() + \"\\nparent state:\\n\" + memorymanager.debugdumpforoom()); throw new allocatoroutofmemoryexception(msg); }","comment":"\/\/ todo: would it make sense to return buffers asynchronously?\n\/\/ not a power of two, add one more\n\/\/ todo: reserving the entire thing is not ideal before we alloc anything. interleave?\n\/\/ todo: pool of objects?\n\/\/ first try to quickly lock some of the correct-sized free lists and allocate from them.\n\/\/ next arena is being allocated.\n\/\/ todo: check if it can still happen; count should take care of this.\n\/\/ todo: this is very hacky. \/\/ we called reservememory so we know that somewhere in there, there's memory waiting for us. \/\/ however, we have a class of rare race conditions related to the order of locking\/checking of \/\/ different allocation areas. simple case - say we have 2 arenas, 256kb available in arena 2. \/\/ we look at arena 1; someone deallocs 256kb from arena 1 and allocs the same from arena 2; \/\/ we look at arena 2 and find no memory. or, for single arena, 2 threads reserve 256k each, \/\/ and a single 1mb block is available. when the 1st thread locks the 1mb freelist, the 2nd one \/\/ might have already examined the 256k and 512k lists, finding nothing. blocks placed by (1) \/\/ into smaller lists after its split is done will not be found by (2); given that freelist \/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1mb \/\/ block and the time it returns the remaining 768kb. \/\/ two solutions to this are some form of cross-thread helping (threads putting \"demand\" \/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\" \/\/ allocator thread (or threads per arena). \/\/ the 2nd one is probably much simpler and will allow us to get rid of a lot of sync code. \/\/ but for now we will just retry 5 times 0_o\n\/\/ try to split bigger blocks. todo: again, ideally we would trylock at least once\n\/\/ shouldn't happen.\n\/\/ try to allocate memory if we haven't allocated all the way to maxsize yet; very rare.","repo":"woowahan\/hive","code_context_2":"@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}\n\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\n\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\n\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\n\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\n\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\n\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\n\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\n\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);","code_context_10":"@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}\n\n@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\n\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\n\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\n\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\n\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\n\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\n\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());","code_context_20":"@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}\n\n@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\n\n@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\n\n@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n\n@Override\npublic void allocateMultiple(MemoryBuffer[] dest, int size)\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\nthrows AllocatorOutOfMemoryException {\nassert size > 0 : \"size is \" + size;\nif (size > maxAllocation) {\nthrow new RuntimeException(\"Trying to allocate \" + size + \"; max is \" + maxAllocation);\n}\nint freeListIx = 31 - Integer.numberOfLeadingZeros(size);\nif (size != (1 << freeListIx)) ++freeListIx; \/\/ not a power of two, add one more\nfreeListIx = Math.max(freeListIx - minAllocLog2, 0);\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\nint allocLog2 = freeListIx + minAllocLog2;\nint allocationSize = 1 << allocLog2;\n\/\/ TODO: reserving the entire thing is not ideal before we alloc anything. Interleave?\nmemoryManager.reserveMemory(dest.length << allocLog2, true);\nint ix = 0;\nfor (int i = 0; i < dest.length; ++i) {\nif (dest[i] != null) continue;\ndest[i] = createUnallocated(); \/\/ TODO: pool of objects?\n}\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\n\/\/ First try to quickly lock some of the correct-sized free lists and allocate from them.\nint arenaCount = allocatedArenas.get();\nif (arenaCount < 0) {\narenaCount = -arenaCount - 1; \/\/ Next arena is being allocated.\n}\nlong threadId = arenaCount > 1 ? Thread.currentThread().getId() : 0;\n{\nint startIndex = (int)(threadId % arenaCount), index = startIndex;\ndo {\nint newIx = arenas[index].allocateFast(index, freeListIx, dest, ix, allocationSize);\nif (newIx == dest.length) return;\nif (newIx != -1) { \/\/ TODO: check if it can still happen; count should take care of this.\nix = newIx;\n}\nix = newIx;\nif ((++index) == arenaCount) {\nindex = 0;\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\n\n}\n} while (index != startIndex);\n}\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}\n\n\/\/ TODO: this is very hacky.\n\/\/ We called reserveMemory so we know that somewhere in there, there's memory waiting for us.\n\/\/ However, we have a class of rare race conditions related to the order of locking\/checking of\n\/\/ different allocation areas. Simple case - say we have 2 arenas, 256Kb available in arena 2.\n\/\/ We look at arena 1; someone deallocs 256Kb from arena 1 and allocs the same from arena 2;\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}\n\n\/\/ we look at arena 2 and find no memory. Or, for single arena, 2 threads reserve 256k each,\n\/\/ and a single 1Mb block is available. When the 1st thread locks the 1Mb freelist, the 2nd one\n\/\/ might have already examined the 256k and 512k lists, finding nothing. Blocks placed by (1)\n\/\/ into smaller lists after its split is done will not be found by (2); given that freelist\n\/\/ locks don't overlap, (2) may even run completely between the time (1) takes out the 1Mb\n\/\/ block and the time it returns the remaining 768Kb.\n\/\/ Two solutions to this are some form of cross-thread helping (threads putting \"demand\"\n\/\/ into some sort of queues that deallocate and split will examine), or having and \"actor\"\n\/\/ allocator thread (or threads per arena).\n\/\/ The 2nd one is probably much simpler and will allow us to get rid of a lot of sync code.\n\/\/ But for now we will just retry 5 times 0_o\nfor (int attempt = 0; attempt < 5; ++attempt) {\n\/\/ Try to split bigger blocks. TODO: again, ideally we would tryLock at least once\nfor (int i = 0; i < arenaCount; ++i) {\nint newIx = arenas[i].allocateWithSplit(i, freeListIx, dest, ix, allocationSize);\nif (newIx == -1) break; \/\/ Shouldn't happen.\nif (newIx == dest.length) return;\nix = newIx;\n}\nif (attempt == 0) {\n\/\/ Try to allocate memory if we haven't allocated all the way to maxSize yet; very rare.\nfor (int i = arenaCount; i < arenas.length; ++i) {\nix = arenas[i].allocateWithExpand(i, freeListIx, dest, ix, allocationSize);\nif (ix == dest.length) return;\n}\n}\nLlapIoImpl.LOG.warn(\"Failed to allocate despite reserved memory; will retry \" + attempt);\n}\nString msg = \"Failed to allocate \" + size + \"; at \" + ix + \" out of \" + dest.length;\nLlapIoImpl.LOG.error(msg + \"\\nALLOCATOR STATE:\\n\" + debugDump()\n+ \"\\nPARENT STATE:\\n\" + memoryManager.debugDumpForOom());\nthrow new AllocatorOutOfMemoryException(msg);\n}","label":[1,1,0,0]}
{"id":17191,"original_code":"private int allocateWithSplit(int arenaIx, int freeListIx,\n        MemoryBuffer[] dest, int ix, int allocationSize) {\n      if (data == null) return -1; \/\/ not allocated yet\n      FreeList freeList = freeLists[freeListIx];\n      int remaining = -1;\n      freeList.lock.lock();\n      try {\n        \/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\n        ix = allocateFromFreeListUnderLock(\n            arenaIx, freeList, freeListIx, dest, ix, allocationSize);\n        remaining = dest.length - ix;\n        if (remaining == 0) return ix;\n      } finally {\n        freeList.lock.unlock();\n      }\n      byte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\n      int headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\n      int splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n      \/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n      \/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n      \/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\n      while (remaining > 0 && splitListIx < freeLists.length) {\n        int splitWaysLog2 = (splitListIx - freeListIx);\n        assert splitWaysLog2 > 0;\n        int splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\n        int lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\n        int lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\n        FreeList splitList = freeLists[splitListIx];\n        splitList.lock.lock();\n        try {\n          int headerIx = splitList.listHead; \/\/ Index of the next free block to split.\n          while (headerIx >= 0 && remaining > 0) {\n            int origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n            \/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n            \/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\n            int toTake = Math.min(splitWays, remaining);\n            remaining -= toTake;\n            lastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n            \/\/ Take toTake blocks by splitting the block at offset.\n            for (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\n              headers[headerIx] = headerData;\n              \/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n              ((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n            }\n            lastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\n            headerIx = getNextFreeListItem(origOffset);\n          }\n          replaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n        } finally {\n          splitList.lock.unlock();\n        }\n        if (remaining == 0) {\n          \/\/ We have just obtained all we needed by splitting some block; now we need\n          \/\/ to put the space remaining from that block into lower free lists.\n          \/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n          \/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n          \/\/ is one block in a list offset from target-sized list by bit index.\n          int newListIndex = freeListIx;\n          while (lastSplitBlocksRemaining > 0) {\n            if ((lastSplitBlocksRemaining & 1) == 1) {\n              FreeList newFreeList = freeLists[newListIndex];\n              newFreeList.lock.lock();\n              headers[lastSplitNextHeader] = makeHeader(newListIndex, false);\n              try {\n                addBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n              } finally {\n                newFreeList.lock.unlock();\n              }\n              lastSplitNextHeader += (1 << newListIndex);\n            }\n            lastSplitBlocksRemaining >>>= 1;\n            ++newListIndex;\n            continue;\n          }\n        }\n        ++splitListIx;\n      }\n      return ix;\n    }","code":"private int allocateWithSplit(int arenaIx, int freeListIx,\n        MemoryBuffer[] dest, int ix, int allocationSize) {\n      if (data == null) return -1;\n      FreeList freeList = freeLists[freeListIx];\n      int remaining = -1;\n      freeList.lock.lock();\n      try {\n       \n        ix = allocateFromFreeListUnderLock(\n            arenaIx, freeList, freeListIx, dest, ix, allocationSize);\n        remaining = dest.length - ix;\n        if (remaining == 0) return ix;\n      } finally {\n        freeList.lock.unlock();\n      }\n      byte headerData = makeHeader(freeListIx, true);\n      int headerStep = 1 << freeListIx;\n      int splitListIx = freeListIx + 1;\n     \n     \n     \n      while (remaining > 0 && splitListIx < freeLists.length) {\n        int splitWaysLog2 = (splitListIx - freeListIx);\n        assert splitWaysLog2 > 0;\n        int splitWays = 1 << splitWaysLog2;\n        int lastSplitBlocksRemaining = -1;\n        int lastSplitNextHeader = -1;\n        FreeList splitList = freeLists[splitListIx];\n        splitList.lock.lock();\n        try {\n          int headerIx = splitList.listHead;\n          while (headerIx >= 0 && remaining > 0) {\n            int origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n           \n           \n            int toTake = Math.min(splitWays, remaining);\n            remaining -= toTake;\n            lastSplitBlocksRemaining = splitWays - toTake;\n           \n            for (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\n              headers[headerIx] = headerData;\n             \n              ((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n            }\n            lastSplitNextHeader = headerIx;\n            headerIx = getNextFreeListItem(origOffset);\n          }\n          replaceListHeadUnderLock(splitList, headerIx);\n        } finally {\n          splitList.lock.unlock();\n        }\n        if (remaining == 0) {\n         \n         \n         \n         \n         \n          int newListIndex = freeListIx;\n          while (lastSplitBlocksRemaining > 0) {\n            if ((lastSplitBlocksRemaining & 1) == 1) {\n              FreeList newFreeList = freeLists[newListIndex];\n              newFreeList.lock.lock();\n              headers[lastSplitNextHeader] = makeHeader(newListIndex, false);\n              try {\n                addBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n              } finally {\n                newFreeList.lock.unlock();\n              }\n              lastSplitNextHeader += (1 << newListIndex);\n            }\n            lastSplitBlocksRemaining >>>= 1;\n            ++newListIndex;\n            continue;\n          }\n        }\n        ++splitListIx;\n      }\n      return ix;\n    }","cleancode":"private int allocatewithsplit(int arenaix, int freelistix, memorybuffer[] dest, int ix, int allocationsize) { if (data == null) return -1; freelist freelist = freelists[freelistix]; int remaining = -1; freelist.lock.lock(); try { ix = allocatefromfreelistunderlock( arenaix, freelist, freelistix, dest, ix, allocationsize); remaining = dest.length - ix; if (remaining == 0) return ix; } finally { freelist.lock.unlock(); } byte headerdata = makeheader(freelistix, true); int headerstep = 1 << freelistix; int splitlistix = freelistix + 1; while (remaining > 0 && splitlistix < freelists.length) { int splitwayslog2 = (splitlistix - freelistix); assert splitwayslog2 > 0; int splitways = 1 << splitwayslog2; int lastsplitblocksremaining = -1; int lastsplitnextheader = -1; freelist splitlist = freelists[splitlistix]; splitlist.lock.lock(); try { int headerix = splitlist.listhead; while (headerix >= 0 && remaining > 0) { int origoffset = offsetfromheaderindex(headerix), offset = origoffset; int totake = math.min(splitways, remaining); remaining -= totake; lastsplitblocksremaining = splitways - totake; for (; totake > 0; ++ix, --totake, headerix += headerstep, offset += allocationsize) { headers[headerix] = headerdata; ((llapdatabuffer)dest[ix]).initialize(arenaix, data, offset, allocationsize); } lastsplitnextheader = headerix; headerix = getnextfreelistitem(origoffset); } replacelistheadunderlock(splitlist, headerix); } finally { splitlist.lock.unlock(); } if (remaining == 0) { int newlistindex = freelistix; while (lastsplitblocksremaining > 0) { if ((lastsplitblocksremaining & 1) == 1) { freelist newfreelist = freelists[newlistindex]; newfreelist.lock.lock(); headers[lastsplitnextheader] = makeheader(newlistindex, false); try { addblocktofreelistunderlock(newfreelist, lastsplitnextheader); } finally { newfreelist.lock.unlock(); } lastsplitnextheader += (1 << newlistindex); } lastsplitblocksremaining >>>= 1; ++newlistindex; continue; } } ++splitlistix; } return ix; }","comment":"\/\/ not allocated yet\n\/\/ try to allocate from target-sized free list, maybe we'll get lucky.\n\/\/ header for newly allocated used blocks.\n\/\/ number of headers (smallest blocks) per target block.\n\/\/ next free list from which we will be splitting.\n\/\/ each iteration of this loop tries to split blocks from one level of the free list into \/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the \/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\n\/\/ how many ways each block splits into target size.\n\/\/ how many target-sized blocks remain from last split.\n\/\/ the header index for the beginning of the remainder.\n\/\/ index of the next free block to split.\n\/\/ we will split the block at headerix [splitways] ways, and take [totake] blocks, \/\/ which will leave [lastsplitblocksremaining] free blocks of target size.\n\/\/ whatever remains.\n\/\/ take totake blocks by splitting the block at offset.\n\/\/ todo: this could be done out of the lock, we only need to take the blocks out.\n\/\/ if anything remains, this is where it starts.\n\/\/ in the end, update free list head.\n\/\/ we have just obtained all we needed by splitting some block; now we need \/\/ to put the space remaining from that block into lower free lists. \/\/ we'll put at most one block into each list, since 2 blocks can always be combined \/\/ to make a larger-level block. each bit in the remaining target-sized blocks count \/\/ is one block in a list offset from target-sized list by bit index.","repo":"woowahan\/hive","code_context_2":"private int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\n\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\n\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\n\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\n\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\n\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\n\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\n\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\n\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\n\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\n\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {","code_context_10":"private int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\n\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\n\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\n\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\n\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\n\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\n\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\n\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\n\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\n\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\n\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\nif ((lastSplitBlocksRemaining & 1) == 1) {\nFreeList newFreeList = freeLists[newListIndex];\nnewFreeList.lock.lock();\nheaders[lastSplitNextHeader] = makeHeader(newListIndex, false);\ntry {\naddBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n} finally {\nnewFreeList.lock.unlock();","code_context_20":"private int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\nprivate int allocateWithSplit(int arenaIx, int freeListIx,\nMemoryBuffer[] dest, int ix, int allocationSize) {\nif (data == null) return -1; \/\/ not allocated yet\nFreeList freeList = freeLists[freeListIx];\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\nint remaining = -1;\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\n\nfreeList.lock.lock();\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n\ntry {\n\/\/ Try to allocate from target-sized free list, maybe we'll get lucky.\nix = allocateFromFreeListUnderLock(\narenaIx, freeList, freeListIx, dest, ix, allocationSize);\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\n\nremaining = dest.length - ix;\nif (remaining == 0) return ix;\n} finally {\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\n\nfreeList.lock.unlock();\n}\nbyte headerData = makeHeader(freeListIx, true); \/\/ Header for newly allocated used blocks.\nint headerStep = 1 << freeListIx; \/\/ Number of headers (smallest blocks) per target block.\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\nint splitListIx = freeListIx + 1; \/\/ Next free list from which we will be splitting.\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\n\n\/\/ Each iteration of this loop tries to split blocks from one level of the free list into\n\/\/ target size blocks; if we cannot satisfy the allocation from the free list containing the\n\/\/ blocks of a particular size, we'll try to split yet larger blocks, until we run out.\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\n\nwhile (remaining > 0 && splitListIx < freeLists.length) {\nint splitWaysLog2 = (splitListIx - freeListIx);\nassert splitWaysLog2 > 0;\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\nif ((lastSplitBlocksRemaining & 1) == 1) {\nFreeList newFreeList = freeLists[newListIndex];\nnewFreeList.lock.lock();\n\nint splitWays = 1 << splitWaysLog2; \/\/ How many ways each block splits into target size.\nint lastSplitBlocksRemaining = -1; \/\/ How many target-sized blocks remain from last split.\nint lastSplitNextHeader = -1; \/\/ The header index for the beginning of the remainder.\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\nif ((lastSplitBlocksRemaining & 1) == 1) {\nFreeList newFreeList = freeLists[newListIndex];\nnewFreeList.lock.lock();\nheaders[lastSplitNextHeader] = makeHeader(newListIndex, false);\ntry {\naddBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n\nFreeList splitList = freeLists[splitListIx];\nsplitList.lock.lock();\ntry {\nint headerIx = splitList.listHead; \/\/ Index of the next free block to split.\nwhile (headerIx >= 0 && remaining > 0) {\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\nif ((lastSplitBlocksRemaining & 1) == 1) {\nFreeList newFreeList = freeLists[newListIndex];\nnewFreeList.lock.lock();\nheaders[lastSplitNextHeader] = makeHeader(newListIndex, false);\ntry {\naddBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n} finally {\nnewFreeList.lock.unlock();\n}\n\nint origOffset = offsetFromHeaderIndex(headerIx), offset = origOffset;\n\/\/ We will split the block at headerIx [splitWays] ways, and take [toTake] blocks,\n\/\/ which will leave [lastSplitBlocksRemaining] free blocks of target size.\nint toTake = Math.min(splitWays, remaining);\nremaining -= toTake;\nlastSplitBlocksRemaining = splitWays - toTake; \/\/ Whatever remains.\n\/\/ Take toTake blocks by splitting the block at offset.\nfor (; toTake > 0; ++ix, --toTake, headerIx += headerStep, offset += allocationSize) {\nheaders[headerIx] = headerData;\n\/\/ TODO: this could be done out of the lock, we only need to take the blocks out.\n((LlapDataBuffer)dest[ix]).initialize(arenaIx, data, offset, allocationSize);\n}\nlastSplitNextHeader = headerIx; \/\/ If anything remains, this is where it starts.\nheaderIx = getNextFreeListItem(origOffset);\n}\nreplaceListHeadUnderLock(splitList, headerIx); \/\/ In the end, update free list head.\n} finally {\nsplitList.lock.unlock();\n}\nif (remaining == 0) {\n\/\/ We have just obtained all we needed by splitting some block; now we need\n\/\/ to put the space remaining from that block into lower free lists.\n\/\/ We'll put at most one block into each list, since 2 blocks can always be combined\n\/\/ to make a larger-level block. Each bit in the remaining target-sized blocks count\n\/\/ is one block in a list offset from target-sized list by bit index.\nint newListIndex = freeListIx;\nwhile (lastSplitBlocksRemaining > 0) {\nif ((lastSplitBlocksRemaining & 1) == 1) {\nFreeList newFreeList = freeLists[newListIndex];\nnewFreeList.lock.lock();\nheaders[lastSplitNextHeader] = makeHeader(newListIndex, false);\ntry {\naddBlockToFreeListUnderLock(newFreeList, lastSplitNextHeader);\n} finally {\nnewFreeList.lock.unlock();\n}\nlastSplitNextHeader += (1 << newListIndex);\n}\nlastSplitBlocksRemaining >>>= 1;\n++newListIndex;\ncontinue;\n}\n}\n++splitListIx;\n}","label":[1,0,0,0]}
{"id":17246,"original_code":"private boolean checkAccessPermission() throws IOException {\n      final JobConf jobConf = new JobConf(hiveConf);\n      Preconditions.checkArgument(updateKey.getCachedEntitiesCount() > 0, \"hive partition update key should contain at least one path\");\n      for (FileSystemCachedEntity cachedEntity : updateKey.getCachedEntitiesList()) {\n        final Path cachedEntityPath;\n        if (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\n          cachedEntityPath = new Path(updateKey.getPartitionRootDir());\n        } else {\n          cachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n        }\n        \/\/ Create filesystem for the given user and given path\n        \/\/ TODO: DX-16001 - make async configurable for Hive.\n        final HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\n        try {\n          if (cachedEntity.getIsDir()) {\n            \/\/DX-7850 : remove once solution for maprfs is found\n            if (userFS.isMapRfs()) {\n              userFS.access(cachedEntityPath, FsAction.READ);\n            } else {\n              userFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n            }\n          } else {\n            userFS.access(cachedEntityPath, FsAction.READ);\n          }\n        } catch (AccessControlException ace) {\n          return false;\n        }\n      }\n      return true;\n    }","code":"private boolean checkAccessPermission() throws IOException {\n      final JobConf jobConf = new JobConf(hiveConf);\n      Preconditions.checkArgument(updateKey.getCachedEntitiesCount() > 0, \"hive partition update key should contain at least one path\");\n      for (FileSystemCachedEntity cachedEntity : updateKey.getCachedEntitiesList()) {\n        final Path cachedEntityPath;\n        if (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\n          cachedEntityPath = new Path(updateKey.getPartitionRootDir());\n        } else {\n          cachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n        }\n       \n       \n        final HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\n        try {\n          if (cachedEntity.getIsDir()) {\n           \n            if (userFS.isMapRfs()) {\n              userFS.access(cachedEntityPath, FsAction.READ);\n            } else {\n              userFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n            }\n          } else {\n            userFS.access(cachedEntityPath, FsAction.READ);\n          }\n        } catch (AccessControlException ace) {\n          return false;\n        }\n      }\n      return true;\n    }","cleancode":"private boolean checkaccesspermission() throws ioexception { final jobconf jobconf = new jobconf(hiveconf); preconditions.checkargument(updatekey.getcachedentitiescount() > 0, \"hive partition update key should contain at least one path\"); for (filesystemcachedentity cachedentity : updatekey.getcachedentitieslist()) { final path cachedentitypath; if (cachedentity.getpath() == null || cachedentity.getpath().isempty()) { cachedentitypath = new path(updatekey.getpartitionrootdir()); } else { cachedentitypath = new path(updatekey.getpartitionrootdir(), cachedentity.getpath()); } final hadoopfilesystemwrapper userfs = hiveimpersonationutil.createfilesystem(user, jobconf, cachedentitypath); try { if (cachedentity.getisdir()) { if (userfs.ismaprfs()) { userfs.access(cachedentitypath, fsaction.read); } else { userfs.access(cachedentitypath, fsaction.read_execute); } } else { userfs.access(cachedentitypath, fsaction.read); } } catch (accesscontrolexception ace) { return false; } } return true; }","comment":"\/\/ create filesystem for the given user and given path \/\/ todo: dx-16001 - make async configurable for hive.\n\/\/dx-7850 : remove once solution for maprfs is found","repo":"wangchong6808\/dremio-oss","code_context_2":"cachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n}\n\/\/ Create filesystem for the given user and given path\n\/\/ TODO: DX-16001 - make async configurable for Hive.\nfinal HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\ntry {\n\ntry {\nif (cachedEntity.getIsDir()) {\n\/\/DX-7850 : remove once solution for maprfs is found\nif (userFS.isMapRfs()) {\nuserFS.access(cachedEntityPath, FsAction.READ);","code_context_10":"private boolean checkAccessPermission() throws IOException {\nfinal JobConf jobConf = new JobConf(hiveConf);\nPreconditions.checkArgument(updateKey.getCachedEntitiesCount() > 0, \"hive partition update key should contain at least one path\");\nfor (FileSystemCachedEntity cachedEntity : updateKey.getCachedEntitiesList()) {\nfinal Path cachedEntityPath;\nif (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir());\n} else {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n}\n\/\/ Create filesystem for the given user and given path\n\/\/ TODO: DX-16001 - make async configurable for Hive.\nfinal HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\ntry {\nif (cachedEntity.getIsDir()) {\n\/\/DX-7850 : remove once solution for maprfs is found\nif (userFS.isMapRfs()) {\nuserFS.access(cachedEntityPath, FsAction.READ);\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n}\n} else {\n\nif (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir());\n} else {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n}\n\/\/ Create filesystem for the given user and given path\n\/\/ TODO: DX-16001 - make async configurable for Hive.\nfinal HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\ntry {\nif (cachedEntity.getIsDir()) {\n\/\/DX-7850 : remove once solution for maprfs is found\nif (userFS.isMapRfs()) {\nuserFS.access(cachedEntityPath, FsAction.READ);\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n}\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ);\n}\n} catch (AccessControlException ace) {\nreturn false;","code_context_20":"private boolean checkAccessPermission() throws IOException {\nfinal JobConf jobConf = new JobConf(hiveConf);\nPreconditions.checkArgument(updateKey.getCachedEntitiesCount() > 0, \"hive partition update key should contain at least one path\");\nfor (FileSystemCachedEntity cachedEntity : updateKey.getCachedEntitiesList()) {\nfinal Path cachedEntityPath;\nif (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir());\n} else {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n}\n\/\/ Create filesystem for the given user and given path\n\/\/ TODO: DX-16001 - make async configurable for Hive.\nfinal HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\ntry {\nif (cachedEntity.getIsDir()) {\n\/\/DX-7850 : remove once solution for maprfs is found\nif (userFS.isMapRfs()) {\nuserFS.access(cachedEntityPath, FsAction.READ);\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n}\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ);\n}\n} catch (AccessControlException ace) {\nreturn false;\n}\n}\nreturn true;\n}\n\nprivate boolean checkAccessPermission() throws IOException {\nfinal JobConf jobConf = new JobConf(hiveConf);\nPreconditions.checkArgument(updateKey.getCachedEntitiesCount() > 0, \"hive partition update key should contain at least one path\");\nfor (FileSystemCachedEntity cachedEntity : updateKey.getCachedEntitiesList()) {\nfinal Path cachedEntityPath;\nif (cachedEntity.getPath() == null || cachedEntity.getPath().isEmpty()) {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir());\n} else {\ncachedEntityPath = new Path(updateKey.getPartitionRootDir(), cachedEntity.getPath());\n}\n\/\/ Create filesystem for the given user and given path\n\/\/ TODO: DX-16001 - make async configurable for Hive.\nfinal HadoopFileSystemWrapper userFS = HiveImpersonationUtil.createFileSystem(user, jobConf, cachedEntityPath);\ntry {\nif (cachedEntity.getIsDir()) {\n\/\/DX-7850 : remove once solution for maprfs is found\nif (userFS.isMapRfs()) {\nuserFS.access(cachedEntityPath, FsAction.READ);\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ_EXECUTE);\n}\n} else {\nuserFS.access(cachedEntityPath, FsAction.READ);\n}\n} catch (AccessControlException ace) {\nreturn false;\n}\n}\nreturn true;\n}","label":[1,1,0,0]}
{"id":17282,"original_code":"private void ntlmProxyChallenge(String authenticateHeader,\/\/\n            Request request,\/\/\n            HttpHeaders requestHeaders,\/\/\n            Realm proxyRealm,\/\/\n            NettyResponseFuture<?> future) {\n        if (authenticateHeader.equals(\"NTLM\")) {\n            \/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\n            String challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n            \/\/ FIXME we might want to filter current NTLM and add (leave other\n            \/\/ Authorization headers untouched)\n            requestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n            future.getInProxyAuth().set(false);\n        } else {\n            String serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\n            String challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\n                    proxyRealm.getNtlmHost(), serverChallenge);\n            \/\/ FIXME we might want to filter current NTLM and add (leave other\n            \/\/ Authorization headers untouched)\n            requestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n        }\n    }","code":"private void ntlmProxyChallenge(String authenticateHeader,            Request request\n            HttpHeaders requestHeaders\n            Realm proxyRealm\n            NettyResponseFuture<?> future) {\n        if (authenticateHeader.equals(\"NTLM\")) {\n           \n            String challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n           \n           \n            requestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n            future.getInProxyAuth().set(false);\n        } else {\n            String serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\n            String challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\n                    proxyRealm.getNtlmHost(), serverChallenge);\n           \n           \n            requestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n        }\n    }","cleancode":"private void ntlmproxychallenge(string authenticateheader, request request httpheaders requestheaders realm proxyrealm nettyresponsefuture<?> future) { if (authenticateheader.equals(\"ntlm\")) { string challengeheader = ntlmengine.instance.generatetype1msg(); requestheaders.set(httpheaders.names.proxy_authorization, \"ntlm \" + challengeheader); future.getinproxyauth().set(false); } else { string serverchallenge = authenticateheader.substring(\"ntlm \".length()).trim(); string challengeheader = ntlmengine.instance.generatetype3msg(proxyrealm.getprincipal(), proxyrealm.getpassword(), proxyrealm.getntlmdomain(), proxyrealm.getntlmhost(), serverchallenge); requestheaders.set(httpheaders.names.proxy_authorization, \"ntlm \" + challengeheader); } }","comment":"\/\/\n\/\/\n\/\/\n\/\/\n\/\/ server replied bare ntlm => we didn't preemptively sent type1msg\n\/\/ fixme we might want to filter current ntlm and add (leave other \/\/ authorization headers untouched)\n\/\/ fixme we might want to filter current ntlm and add (leave other \/\/ authorization headers untouched)","repo":"wsargent\/async-http-client","code_context_2":"private void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\n\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);","code_context_10":"private void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}","code_context_20":"private void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}\n\nprivate void ntlmProxyChallenge(String authenticateHeader,\/\/\nRequest request,\/\/\nHttpHeaders requestHeaders,\/\/\nRealm proxyRealm,\/\/\nNettyResponseFuture<?> future) {\nif (authenticateHeader.equals(\"NTLM\")) {\n\/\/ server replied bare NTLM => we didn't preemptively sent Type1Msg\nString challengeHeader = NtlmEngine.INSTANCE.generateType1Msg();\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\nfuture.getInProxyAuth().set(false);\n} else {\nString serverChallenge = authenticateHeader.substring(\"NTLM \".length()).trim();\nString challengeHeader = NtlmEngine.INSTANCE.generateType3Msg(proxyRealm.getPrincipal(), proxyRealm.getPassword(), proxyRealm.getNtlmDomain(),\nproxyRealm.getNtlmHost(), serverChallenge);\n\/\/ FIXME we might want to filter current NTLM and add (leave other\n\/\/ Authorization headers untouched)\nrequestHeaders.set(HttpHeaders.Names.PROXY_AUTHORIZATION, \"NTLM \" + challengeHeader);\n}\n}","label":[0,0,1,0]}
{"id":974,"original_code":"private void trackWatchForAttempt(WatchedPathInfo watchedPathInfo, WatchKey watchKey) {\n    assert watchedPathInfo.pathIdentifier != null;\n    \/\/ TODO May be possible to do finer-grained locks.\n    synchronized (watchesPerAttempt) {\n      List<WatchKey> list = watchesPerAttempt.get(watchedPathInfo.pathIdentifier);\n      if (list == null) {\n        list = new LinkedList<>();\n        watchesPerAttempt.put(watchedPathInfo.pathIdentifier, list);\n      }\n      list.add(watchKey);\n    }\n  }","code":"private void trackWatchForAttempt(WatchedPathInfo watchedPathInfo, WatchKey watchKey) {\n    assert watchedPathInfo.pathIdentifier != null;\n   \n    synchronized (watchesPerAttempt) {\n      List<WatchKey> list = watchesPerAttempt.get(watchedPathInfo.pathIdentifier);\n      if (list == null) {\n        list = new LinkedList<>();\n        watchesPerAttempt.put(watchedPathInfo.pathIdentifier, list);\n      }\n      list.add(watchKey);\n    }\n  }","cleancode":"private void trackwatchforattempt(watchedpathinfo watchedpathinfo, watchkey watchkey) { assert watchedpathinfo.pathidentifier != null; synchronized (watchesperattempt) { list<watchkey> list = watchesperattempt.get(watchedpathinfo.pathidentifier); if (list == null) { list = new linkedlist<>(); watchesperattempt.put(watchedpathinfo.pathidentifier, list); } list.add(watchkey); } }","comment":"\/\/ todo may be possible to do finer-grained locks.","repo":"zem13579\/hive","code_context_2":"private void trackWatchForAttempt(WatchedPathInfo watchedPathInfo, WatchKey watchKey) {\nassert watchedPathInfo.pathIdentifier != null;\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized (watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.get(watchedPathInfo.pathIdentifier);","code_context_10":"private void trackWatchForAttempt(WatchedPathInfo watchedPathInfo, WatchKey watchKey) {\nassert watchedPathInfo.pathIdentifier != null;\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized (watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.get(watchedPathInfo.pathIdentifier);\nif (list == null) {\nlist = new LinkedList<>();\nwatchesPerAttempt.put(watchedPathInfo.pathIdentifier, list);\n}\nlist.add(watchKey);\n}\n}","code_context_20":"private void trackWatchForAttempt(WatchedPathInfo watchedPathInfo, WatchKey watchKey) {\nassert watchedPathInfo.pathIdentifier != null;\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized (watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.get(watchedPathInfo.pathIdentifier);\nif (list == null) {\nlist = new LinkedList<>();\nwatchesPerAttempt.put(watchedPathInfo.pathIdentifier, list);\n}\nlist.add(watchKey);\n}\n}","label":[1,0,0,0]}
{"id":975,"original_code":"private void cancelWatchesForAttempt(AttemptPathIdentifier pathIdentifier) {\n    \/\/ TODO May be possible to do finer-grained locks.\n    synchronized(watchesPerAttempt) {\n      List<WatchKey> list = watchesPerAttempt.remove(pathIdentifier);\n      if (list != null) {\n        for (WatchKey watchKey : list) {\n          watchKey.cancel();\n        }\n      }\n    }\n  }","code":"private void cancelWatchesForAttempt(AttemptPathIdentifier pathIdentifier) {\n   \n    synchronized(watchesPerAttempt) {\n      List<WatchKey> list = watchesPerAttempt.remove(pathIdentifier);\n      if (list != null) {\n        for (WatchKey watchKey : list) {\n          watchKey.cancel();\n        }\n      }\n    }\n  }","cleancode":"private void cancelwatchesforattempt(attemptpathidentifier pathidentifier) { synchronized(watchesperattempt) { list<watchkey> list = watchesperattempt.remove(pathidentifier); if (list != null) { for (watchkey watchkey : list) { watchkey.cancel(); } } } }","comment":"\/\/ todo may be possible to do finer-grained locks.","repo":"zem13579\/hive","code_context_2":"private void cancelWatchesForAttempt(AttemptPathIdentifier pathIdentifier) {\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized(watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.remove(pathIdentifier);","code_context_10":"private void cancelWatchesForAttempt(AttemptPathIdentifier pathIdentifier) {\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized(watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.remove(pathIdentifier);\nif (list != null) {\nfor (WatchKey watchKey : list) {\nwatchKey.cancel();\n}\n}\n}\n}","code_context_20":"private void cancelWatchesForAttempt(AttemptPathIdentifier pathIdentifier) {\n\/\/ TODO May be possible to do finer-grained locks.\nsynchronized(watchesPerAttempt) {\nList<WatchKey> list = watchesPerAttempt.remove(pathIdentifier);\nif (list != null) {\nfor (WatchKey watchKey : list) {\nwatchKey.cancel();\n}\n}\n}\n}","label":[1,0,0,0]}
{"id":1017,"original_code":"public static String[] textToWords(String text) {\n        \/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n        \/\/ Currently assuming hyphenated expressions split into two Asr words.\n        return text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n    }","code":"public static String[] textToWords(String text) {\n       \n       \n        return text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n    }","cleancode":"public static string[] texttowords(string text) { return text.replace('-', ' ').replaceall(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").touppercase(locale.us).trim().split(\"\\\\s+\"); }","comment":"\/** * utility function to convert text string into canonical-format word array * * @param text -- text string including punctuation *\/\n\/\/ todo: strip word-final or -initial apostrophes as in james' or 'cause. \/\/ currently assuming hyphenated expressions split into two asr words.","repo":"yejingjie0209\/robotutor_china","code_context_2":"public static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}\n\npublic static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}","code_context_10":"public static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}\n\npublic static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}","code_context_20":"public static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}\n\npublic static String[] textToWords(String text) {\n\/\/ TODO: strip word-final or -initial apostrophes as in James' or 'cause.\n\/\/ Currently assuming hyphenated expressions split into two Asr words.\nreturn text.replace('-', ' ').replaceAll(\"['.!?,:;\\\"\\\\(\\\\)]\", \" \").toUpperCase(Locale.US).trim().split(\"\\\\s+\");\n}","label":[1,0,0,0]}
{"id":1034,"original_code":"public void engineSetPadding(String padding)\n        throws NoSuchPaddingException\n    {\n        String paddingName = Strings.toUpperCase(padding);\n        \/\/ TDOD: make this meaningful...\n        if (paddingName.equals(\"NOPADDING\"))\n        {\n        }\n        else if (paddingName.equals(\"PKCS5PADDING\") || paddingName.equals(\"PKCS7PADDING\"))\n        {\n        }\n        else\n        {\n            throw new NoSuchPaddingException(\"padding not available with IESCipher\");\n        }\n    }","code":"public void engineSetPadding(String padding)\n        throws NoSuchPaddingException\n    {\n        String paddingName = Strings.toUpperCase(padding);\n       \n        if (paddingName.equals(\"NOPADDING\"))\n        {\n        }\n        else if (paddingName.equals(\"PKCS5PADDING\") || paddingName.equals(\"PKCS7PADDING\"))\n        {\n        }\n        else\n        {\n            throw new NoSuchPaddingException(\"padding not available with IESCipher\");\n        }\n    }","cleancode":"public void enginesetpadding(string padding) throws nosuchpaddingexception { string paddingname = strings.touppercase(padding); if (paddingname.equals(\"nopadding\")) { } else if (paddingname.equals(\"pkcs5padding\") || paddingname.equals(\"pkcs7padding\")) { } else { throw new nosuchpaddingexception(\"padding not available with iescipher\"); } }","comment":"\/\/ tdod: make this meaningful...","repo":"tonywasher\/bc-java","code_context_2":"{\nString paddingName = Strings.toUpperCase(padding);\n\/\/ TDOD: make this meaningful...\nif (paddingName.equals(\"NOPADDING\"))\n{","code_context_10":"public void engineSetPadding(String padding)\nthrows NoSuchPaddingException\n{\nString paddingName = Strings.toUpperCase(padding);\n\/\/ TDOD: make this meaningful...\nif (paddingName.equals(\"NOPADDING\"))\n{\n}\nelse if (paddingName.equals(\"PKCS5PADDING\") || paddingName.equals(\"PKCS7PADDING\"))\n{\n}\nelse\n{\nthrow new NoSuchPaddingException(\"padding not available with IESCipher\");\n}","code_context_20":"public void engineSetPadding(String padding)\nthrows NoSuchPaddingException\n{\nString paddingName = Strings.toUpperCase(padding);\n\/\/ TDOD: make this meaningful...\nif (paddingName.equals(\"NOPADDING\"))\n{\n}\nelse if (paddingName.equals(\"PKCS5PADDING\") || paddingName.equals(\"PKCS7PADDING\"))\n{\n}\nelse\n{\nthrow new NoSuchPaddingException(\"padding not available with IESCipher\");\n}\n}","label":[1,0,0,0]}
{"id":1094,"original_code":"private void addStylesQueueRequest(int start, int length, String s) {\n    \/\/ System.err.println(start + \" ---> \" + length);\n    int startNew = backupToPossibleStyleStart(start);\n    length = length + start - startNew;\n    start = startNew;\n    \/\/ System.err.println(start + \" ---> \" + length);\n    if (syntaxBusy) {\n      \/\/ System.err.println(\"syntaxBusy, request queued\");\n      styleQueue.add(new StyleQueueItem(start, length, s));\n    } else {\n      \/\/ Todo: if syntax is not busy but a request got stuck\n      \/\/ System.err.println(\"request not queued\");\n      if (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\n      syntaxBusy = true;\n      addStylesNew(start, length, s);\n    }\n  }","code":"private void addStylesQueueRequest(int start, int length, String s) {\n   \n    int startNew = backupToPossibleStyleStart(start);\n    length = length + start - startNew;\n    start = startNew;\n   \n    if (syntaxBusy) {\n     \n      styleQueue.add(new StyleQueueItem(start, length, s));\n    } else {\n     \n     \n      if (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\n      syntaxBusy = true;\n      addStylesNew(start, length, s);\n    }\n  }","cleancode":"private void addstylesqueuerequest(int start, int length, string s) { int startnew = backuptopossiblestylestart(start); length = length + start - startnew; start = startnew; if (syntaxbusy) { stylequeue.add(new stylequeueitem(start, length, s)); } else { if (stylequeue.size() != 0) system.err.println(\"a request got stuck\"); syntaxbusy = true; addstylesnew(start, length, s); } }","comment":"\/\/ system.err.println(start + \" ---> \" + length);\n\/\/ system.err.println(start + \" ---> \" + length);\n\/\/ system.err.println(\"syntaxbusy, request queued\");\n\/\/ todo: if syntax is not busy but a request got stuck \/\/ system.err.println(\"request not queued\");","repo":"xmf-xmodeler\/MosaicFX","code_context_2":"private void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\n\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;","code_context_10":"private void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}","code_context_20":"private void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}\n\nprivate void addStylesQueueRequest(int start, int length, String s) {\n\/\/ System.err.println(start + \" ---> \" + length);\nint startNew = backupToPossibleStyleStart(start);\nlength = length + start - startNew;\nstart = startNew;\n\/\/ System.err.println(start + \" ---> \" + length);\nif (syntaxBusy) {\n\/\/ System.err.println(\"syntaxBusy, request queued\");\nstyleQueue.add(new StyleQueueItem(start, length, s));\n} else {\n\/\/ Todo: if syntax is not busy but a request got stuck\n\/\/ System.err.println(\"request not queued\");\nif (styleQueue.size() != 0) System.err.println(\"A request got stuck\");\nsyntaxBusy = true;\naddStylesNew(start, length, s);\n}\n}","label":[1,0,0,0]}
{"id":17497,"original_code":"public long getMicrosecondLength()\n  {\n    long tickLength = getTickLength();\n    if (divisionType == PPQ)\n    {\n      \/\/ FIXME\n      \/\/ How can this possible be computed?  PPQ is pulses per quarter-note,\n      \/\/ which is dependent on the tempo of the Sequencer.\n      throw new \n\t  UnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n    }\n    else\n    {\n      \/\/ This is a fixed tick per frame computation\n      return (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n    }\n  }","code":"public long getMicrosecondLength()\n  {\n    long tickLength = getTickLength();\n    if (divisionType == PPQ)\n    {\n     \n     \n     \n      throw new \n\t  UnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n    }\n    else\n    {\n     \n      return (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n    }\n  }","cleancode":"public long getmicrosecondlength() { long ticklength = getticklength(); if (divisiontype == ppq) { throw new unsupportedoperationexception(\"can't compute ppq based lengths yet\"); } else { return (long) ((ticklength * 1000000) \/ (divisiontype * resolution)); } }","comment":"\/** * the length of this sequence in microseconds. * * @return the length of this sequence in microseconds *\/\n\/\/ fixme \/\/ how can this possible be computed? ppq is pulses per quarter-note, \/\/ which is dependent on the tempo of the sequencer.\n\/\/ this is a fixed tick per frame computation","repo":"vidkidz\/crossbridge","code_context_2":"public long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}\n\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}","code_context_10":"public long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}\n\npublic long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}\n\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}","code_context_20":"public long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}\n\npublic long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}\n\npublic long getMicrosecondLength()\n{\nlong tickLength = getTickLength();\nif (divisionType == PPQ)\n{\n\/\/ FIXME\n\/\/ How can this possible be computed? PPQ is pulses per quarter-note,\n\/\/ which is dependent on the tempo of the Sequencer.\nthrow new\nUnsupportedOperationException(\"Can't compute PPQ based lengths yet\");\n}\nelse\n{\n\/\/ This is a fixed tick per frame computation\nreturn (long) ((tickLength * 1000000) \/ (divisionType * resolution));\n}\n}","label":[0,0,1,0]}
{"id":9309,"original_code":"@TargetApi(Build.VERSION_CODES.KITKAT)\n    public static File getBestAvailableCacheRoot(Context context) {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n            \/\/ In KitKat we can query multiple devices.\n            \/\/ TODO: optimize for stability instead of picking first one\n            File[] roots = context.getExternalCacheDirs();\n            if (roots != null) {\n                for (File root : roots) {\n                    if (root == null) {\n                        continue;\n                    }\n                    if (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\n                        return root;\n                    }\n                }\n            }\n        } else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n            \/\/ Pre-KitKat, only one external storage device was addressable\n            return context.getExternalCacheDir();\n        }\n        \/\/ Worst case, resort to internal storage\n        return context.getCacheDir();\n    }","code":"@TargetApi(Build.VERSION_CODES.KITKAT)\n    public static File getBestAvailableCacheRoot(Context context) {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n           \n           \n            File[] roots = context.getExternalCacheDirs();\n            if (roots != null) {\n                for (File root : roots) {\n                    if (root == null) {\n                        continue;\n                    }\n                    if (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\n                        return root;\n                    }\n                }\n            }\n        } else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n           \n            return context.getExternalCacheDir();\n        }\n       \n        return context.getCacheDir();\n    }","cleancode":"@targetapi(build.version_codes.kitkat) public static file getbestavailablecacheroot(context context) { if (build.version.sdk_int >= build.version_codes.kitkat) { file[] roots = context.getexternalcachedirs(); if (roots != null) { for (file root : roots) { if (root == null) { continue; } if (environment.media_mounted.equals(environment.getstoragestate(root))) { return root; } } } } else if (environment.media_mounted.equals(environment.getexternalstoragestate())) { return context.getexternalcachedir(); } return context.getcachedir(); }","comment":"\/\/ in kitkat we can query multiple devices. \/\/ todo: optimize for stability instead of picking first one\n\/\/ pre-kitkat, only one external storage device was addressable\n\/\/ worst case, resort to internal storage","repo":"xxwar\/muzei","code_context_2":"public static File getBestAvailableCacheRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalCacheDirs();\nif (roots != null) {\n\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}","code_context_10":"@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableCacheRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalCacheDirs();\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}\n\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}","code_context_20":"@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableCacheRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalCacheDirs();\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}\n\n@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableCacheRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalCacheDirs();\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}\n\n@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableCacheRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalCacheDirs();\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalCacheDir();\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getCacheDir();\n}","label":[1,0,0,0]}
{"id":9310,"original_code":"@TargetApi(Build.VERSION_CODES.KITKAT)\n    public static File getBestAvailableFilesRoot(Context context) {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n            \/\/ In KitKat we can query multiple devices.\n            \/\/ TODO: optimize for stability instead of picking first one\n            File[] roots = context.getExternalFilesDirs(null);\n            if (roots != null) {\n                for (File root : roots) {\n                    if (root == null) {\n                        continue;\n                    }\n                    if (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\n                        return root;\n                    }\n                }\n            }\n        } else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n            \/\/ Pre-KitKat, only one external storage device was addressable\n            return context.getExternalFilesDir(null);\n        }\n        \/\/ Worst case, resort to internal storage\n        return context.getFilesDir();\n    }","code":"@TargetApi(Build.VERSION_CODES.KITKAT)\n    public static File getBestAvailableFilesRoot(Context context) {\n        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n           \n           \n            File[] roots = context.getExternalFilesDirs(null);\n            if (roots != null) {\n                for (File root : roots) {\n                    if (root == null) {\n                        continue;\n                    }\n                    if (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\n                        return root;\n                    }\n                }\n            }\n        } else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n           \n            return context.getExternalFilesDir(null);\n        }\n       \n        return context.getFilesDir();\n    }","cleancode":"@targetapi(build.version_codes.kitkat) public static file getbestavailablefilesroot(context context) { if (build.version.sdk_int >= build.version_codes.kitkat) { file[] roots = context.getexternalfilesdirs(null); if (roots != null) { for (file root : roots) { if (root == null) { continue; } if (environment.media_mounted.equals(environment.getstoragestate(root))) { return root; } } } } else if (environment.media_mounted.equals(environment.getexternalstoragestate())) { return context.getexternalfilesdir(null); } return context.getfilesdir(); }","comment":"\/\/ in kitkat we can query multiple devices. \/\/ todo: optimize for stability instead of picking first one\n\/\/ pre-kitkat, only one external storage device was addressable\n\/\/ worst case, resort to internal storage","repo":"xxwar\/muzei","code_context_2":"public static File getBestAvailableFilesRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalFilesDirs(null);\nif (roots != null) {\n\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}","code_context_10":"@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableFilesRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalFilesDirs(null);\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}\n\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}","code_context_20":"@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableFilesRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalFilesDirs(null);\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}\n\n@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableFilesRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalFilesDirs(null);\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}\n\n@TargetApi(Build.VERSION_CODES.KITKAT)\npublic static File getBestAvailableFilesRoot(Context context) {\nif (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\n\/\/ In KitKat we can query multiple devices.\n\/\/ TODO: optimize for stability instead of picking first one\nFile[] roots = context.getExternalFilesDirs(null);\nif (roots != null) {\nfor (File root : roots) {\nif (root == null) {\ncontinue;\n}\nif (Environment.MEDIA_MOUNTED.equals(Environment.getStorageState(root))) {\nreturn root;\n}\n}\n}\n} else if (Environment.MEDIA_MOUNTED.equals(Environment.getExternalStorageState())) {\n\/\/ Pre-KitKat, only one external storage device was addressable\nreturn context.getExternalFilesDir(null);\n}\n\/\/ Worst case, resort to internal storage\nreturn context.getFilesDir();\n}","label":[1,0,0,0]}
{"id":1129,"original_code":"@Test\n  public void testMultiColumnPruning() throws IOException {\n    shell.setHiveSessionValue(\"hive.cbo.enable\", true);\n    Schema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\n    List<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\n    testTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\n    Schema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\n    List<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\n    testTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n    \/\/ MR is needed for the reproduction\n    shell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\n    String query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\n    List<Object[]> result = shell.executeStatement(query);\n    Assert.assertEquals(1, result.size());\n    Assert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n  }","code":"@Test\n  public void testMultiColumnPruning() throws IOException {\n    shell.setHiveSessionValue(\"hive.cbo.enable\", true);\n    Schema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\n    List<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\n    testTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\n    Schema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\n    List<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\n    testTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n   \n    shell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\n    String query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\n    List<Object[]> result = shell.executeStatement(query);\n    Assert.assertEquals(1, result.size());\n    Assert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n  }","cleancode":"@test public void testmulticolumnpruning() throws ioexception { shell.sethivesessionvalue(\"hive.cbo.enable\", true); schema schema1 = new schema(optional(1, \"fk\", types.stringtype.get())); list<record> records1 = testhelper.recordsbuilder.newinstance(schema1).add(\"fk1\").build(); testtables.createtable(shell, \"table1\", schema1, fileformat, records1); schema schema2 = new schema(optional(1, \"fk\", types.stringtype.get()), optional(2, \"val\", types.stringtype.get())); list<record> records2 = testhelper.recordsbuilder.newinstance(schema2).add(\"fk1\", \"val\").build(); testtables.createtable(shell, \"table2\", schema2, fileformat, records2); shell.sethivesessionvalue(\"hive.execution.engine\", \"mr\"); string query = \"select t2.val from table1 t1 join table2 t2 on t1.fk = t2.fk\"; list<object[]> result = shell.executestatement(query); assert.assertequals(1, result.size()); assert.assertarrayequals(new object[]{\"val\"}, result.get(0)); }","comment":"\/** * column pruning could become problematic when a single map task contains multiple tablescan operators where * different columns are pruned. this only occurs on mr, as tez initializes a single map task for every tablescan * operator. *\/\n\/\/ mr is needed for the reproduction","repo":"zem13579\/hive","code_context_2":"@Test\npublic void testMultiColumnPruning() throws IOException {\nshell.setHiveSessionValue(\"hive.cbo.enable\", true);\nSchema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\nList<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\ntestTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\nSchema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\nList<Object[]> result = shell.executeStatement(query);\nAssert.assertEquals(1, result.size());\nAssert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n}\n\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";","code_context_10":"@Test\npublic void testMultiColumnPruning() throws IOException {\nshell.setHiveSessionValue(\"hive.cbo.enable\", true);\nSchema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\nList<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\ntestTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\nSchema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\nList<Object[]> result = shell.executeStatement(query);\nAssert.assertEquals(1, result.size());\nAssert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n}\n\n@Test\npublic void testMultiColumnPruning() throws IOException {\nshell.setHiveSessionValue(\"hive.cbo.enable\", true);\nSchema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\nList<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\ntestTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\nSchema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\nList<Object[]> result = shell.executeStatement(query);\nAssert.assertEquals(1, result.size());\nAssert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n}","code_context_20":"@Test\npublic void testMultiColumnPruning() throws IOException {\nshell.setHiveSessionValue(\"hive.cbo.enable\", true);\nSchema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\nList<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\ntestTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\nSchema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\nList<Object[]> result = shell.executeStatement(query);\nAssert.assertEquals(1, result.size());\nAssert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n}\n\n@Test\npublic void testMultiColumnPruning() throws IOException {\nshell.setHiveSessionValue(\"hive.cbo.enable\", true);\nSchema schema1 = new Schema(optional(1, \"fk\", Types.StringType.get()));\nList<Record> records1 = TestHelper.RecordsBuilder.newInstance(schema1).add(\"fk1\").build();\ntestTables.createTable(shell, \"table1\", schema1, fileFormat, records1);\nSchema schema2 = new Schema(optional(1, \"fk\", Types.StringType.get()), optional(2, \"val\", Types.StringType.get()));\nList<Record> records2 = TestHelper.RecordsBuilder.newInstance(schema2).add(\"fk1\", \"val\").build();\ntestTables.createTable(shell, \"table2\", schema2, fileFormat, records2);\n\/\/ MR is needed for the reproduction\nshell.setHiveSessionValue(\"hive.execution.engine\", \"mr\");\nString query = \"SELECT t2.val FROM table1 t1 JOIN table2 t2 ON t1.fk = t2.fk\";\nList<Object[]> result = shell.executeStatement(query);\nAssert.assertEquals(1, result.size());\nAssert.assertArrayEquals(new Object[]{\"val\"}, result.get(0));\n}","label":[0,0,1,0]}
{"id":17517,"original_code":"@Override\n    protected void render(GLRootView root, GL11 gl) {\n        Rect p = mPaddings;\n        int height = getHeight() - p.top - p.bottom;\n        StringTexture title = mText;\n        \/\/TODO: cut the text if it is too long\n        title.draw(root, p.left, p.top + (height - title.getHeight()) \/ 2);\n    }","code":"@Override\n    protected void render(GLRootView root, GL11 gl) {\n        Rect p = mPaddings;\n        int height = getHeight() - p.top - p.bottom;\n        StringTexture title = mText;\n       \n        title.draw(root, p.left, p.top + (height - title.getHeight()) \/ 2);\n    }","cleancode":"@override protected void render(glrootview root, gl11 gl) { rect p = mpaddings; int height = getheight() - p.top - p.bottom; stringtexture title = mtext; title.draw(root, p.left, p.top + (height - title.getheight()) \/ 2); }","comment":"\/\/todo: cut the text if it is too long","repo":"xie-wenjie\/AndroidBaseApplicationSourse","code_context_2":"int height = getHeight() - p.top - p.bottom;\nStringTexture title = mText;\n\/\/TODO: cut the text if it is too long\ntitle.draw(root, p.left, p.top + (height - title.getHeight()) \/ 2);\n}","code_context_10":"@Override\nprotected void render(GLRootView root, GL11 gl) {\nRect p = mPaddings;\nint height = getHeight() - p.top - p.bottom;\nStringTexture title = mText;\n\/\/TODO: cut the text if it is too long\ntitle.draw(root, p.left, p.top + (height - title.getHeight()) \/ 2);\n}","code_context_20":"@Override\nprotected void render(GLRootView root, GL11 gl) {\nRect p = mPaddings;\nint height = getHeight() - p.top - p.bottom;\nStringTexture title = mText;\n\/\/TODO: cut the text if it is too long\ntitle.draw(root, p.left, p.top + (height - title.getHeight()) \/ 2);\n}","label":[0,1,0,0]}
{"id":25738,"original_code":"boolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\n    if (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\n    Set<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\n    if (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\n      if (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\n        return true;\n      } else {\n        \/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n      }\n    }\n    \/\/ full (non-inplace) atomic update\n    SolrInputDocument sdoc = cmd.getSolrInputDocument();\n    BytesRef idBytes = cmd.getIndexedId();\n    String idString = cmd.getPrintableId();\n    SolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\n    if (oldRootDocWithChildren == null) {\n      if (versionOnUpdate > 0) {\n        \/\/ could just let the optimistic locking throw the error\n        throw new SolrException(ErrorCode.CONFLICT, \"Document not found for update.  id=\" + idString);\n      } else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n        \/\/ the specified document could not be found in this shard\n        \/\/ and was explicitly routed using _route_\n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Could not find document id=\" + idString +\n                \", perhaps the wrong \\\"_route_\\\" param was supplied\");\n      }\n    } else {\n      oldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n    }\n    SolrInputDocument mergedDoc;\n    if(idField == null || oldRootDocWithChildren == null) {\n      \/\/ create a new doc by default if an old one wasn't found\n      mergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n    } else {\n      \/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\n      if (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n          && req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n          && req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n      }\n      String oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\n      if(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n          !idString.equals(oldRootDocRootFieldVal)) {\n        \/\/ this is an update where the updated doc is not the root document\n        SolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\n            idBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\n        mergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n      } else {\n        mergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n      }\n    }\n    cmd.solrDoc = mergedDoc;\n    return true;\n  }","code":"boolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\n    if (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\n    Set<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\n    if (inPlaceUpdatedFields.size() > 0) {\n      if (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\n        return true;\n      } else {\n       \n      }\n    }\n   \n    SolrInputDocument sdoc = cmd.getSolrInputDocument();\n    BytesRef idBytes = cmd.getIndexedId();\n    String idString = cmd.getPrintableId();\n    SolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\n    if (oldRootDocWithChildren == null) {\n      if (versionOnUpdate > 0) {\n       \n        throw new SolrException(ErrorCode.CONFLICT, \"Document not found for update.  id=\" + idString);\n      } else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n       \n       \n        throw new SolrException(ErrorCode.BAD_REQUEST,\n            \"Could not find document id=\" + idString +\n                \", perhaps the wrong \\\"_route_\\\" param was supplied\");\n      }\n    } else {\n      oldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n    }\n    SolrInputDocument mergedDoc;\n    if(idField == null || oldRootDocWithChildren == null) {\n     \n      mergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n    } else {\n     \n      if (req.getSchema().isUsableForChildDocs()\n          && req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n          && req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\n        throw new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n      }\n      String oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\n      if(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n          !idString.equals(oldRootDocRootFieldVal)) {\n       \n        SolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\n            idBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\n        mergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n      } else {\n        mergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n      }\n    }\n    cmd.solrDoc = mergedDoc;\n    return true;\n  }","cleancode":"boolean getupdateddocument(addupdatecommand cmd, long versiononupdate) throws ioexception { if (!atomicupdatedocumentmerger.isatomicupdate(cmd)) return false; set<string> inplaceupdatedfields = atomicupdatedocumentmerger.computeinplaceupdatablefields(cmd); if (inplaceupdatedfields.size() > 0) { if (docmerger.doinplaceupdatemerge(cmd, inplaceupdatedfields)) { return true; } else { } } solrinputdocument sdoc = cmd.getsolrinputdocument(); bytesref idbytes = cmd.getindexedid(); string idstring = cmd.getprintableid(); solrinputdocument oldrootdocwithchildren = realtimegetcomponent.getinputdocument(cmd.getreq().getcore(), idbytes, realtimegetcomponent.resolution.root_with_children); if (oldrootdocwithchildren == null) { if (versiononupdate > 0) { throw new solrexception(errorcode.conflict, \"document not found for update. id=\" + idstring); } else if (req.getparams().get(shardparams._route_) != null) { throw new solrexception(errorcode.bad_request, \"could not find document id=\" + idstring + \", perhaps the wrong \\\"_route_\\\" param was supplied\"); } } else { oldrootdocwithchildren.remove(commonparams.version_field); } solrinputdocument mergeddoc; if(idfield == null || oldrootdocwithchildren == null) { mergeddoc = docmerger.merge(sdoc, new solrinputdocument()); } else { if (req.getschema().isusableforchilddocs() && req.getschema().supportspartialupdatesofchilddocs() == false && req.getsearcher().count(new termquery(new term(indexschema.root_field_name, idbytes))) > 1) { throw new solrexception(errorcode.bad_request, \"this schema does not support partial updates to nested docs. see ref guide.\"); } string oldrootdocrootfieldval = (string) oldrootdocwithchildren.getfieldvalue(indexschema.root_field_name); if(req.getschema().saveschilddocrelations() && oldrootdocrootfieldval != null && !idstring.equals(oldrootdocrootfieldval)) { solrinputdocument sdocwithchildren = realtimegetcomponent.getinputdocument(cmd.getreq().getcore(), idbytes, realtimegetcomponent.resolution.doc_with_children); mergeddoc = docmerger.mergechilddoc(sdoc, oldrootdocwithchildren, sdocwithchildren); } else { mergeddoc = docmerger.merge(sdoc, oldrootdocwithchildren); } } cmd.solrdoc = mergeddoc; return true; }","comment":"\/\/ todo: may want to switch to using optimistic locking in the future for better concurrency \/\/ that's why this code is here... need to retry in a loop closely around\/in versionadd\n\/\/ non-empty means this is suitable for in-place updates\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n\/\/ full (non-inplace) atomic update\n\/\/ could just let the optimistic locking throw the error\n\/\/ the specified document could not be found in this shard \/\/ and was explicitly routed using _route_\n\/\/ create a new doc by default if an old one wasn't found\n\/\/ safety check: don't allow an update to an existing doc that has children, unless we actually support this.\n\/\/ however, next line we see it doesn't support child docs\n\/\/ this is an update where the updated doc is not the root document","repo":"yanivru\/lucene-solr","code_context_2":"boolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}\n\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\n\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\n\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);","code_context_10":"boolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\n\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\n\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\n\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}","code_context_20":"boolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\n\nboolean getUpdatedDocument(AddUpdateCommand cmd, long versionOnUpdate) throws IOException {\nif (!AtomicUpdateDocumentMerger.isAtomicUpdate(cmd)) return false;\nSet<String> inPlaceUpdatedFields = AtomicUpdateDocumentMerger.computeInPlaceUpdatableFields(cmd);\nif (inPlaceUpdatedFields.size() > 0) { \/\/ non-empty means this is suitable for in-place updates\nif (docMerger.doInPlaceUpdateMerge(cmd, inPlaceUpdatedFields)) {\nreturn true;\n} else {\n\/\/ in-place update failed, so fall through and re-try the same with a full atomic update\n}\n}\n\/\/ full (non-inplace) atomic update\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n\nSolrInputDocument sdoc = cmd.getSolrInputDocument();\nBytesRef idBytes = cmd.getIndexedId();\nString idString = cmd.getPrintableId();\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\n\nSolrInputDocument oldRootDocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(), idBytes, RealTimeGetComponent.Resolution.ROOT_WITH_CHILDREN);\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}\n\nif (oldRootDocWithChildren == null) {\nif (versionOnUpdate > 0) {\n\/\/ could just let the optimistic locking throw the error\nthrow new SolrException(ErrorCode.CONFLICT, \"Document not found for update. id=\" + idString);\n} else if (req.getParams().get(ShardParams._ROUTE_) != null) {\n\/\/ the specified document could not be found in this shard\n\/\/ and was explicitly routed using _route_\nthrow new SolrException(ErrorCode.BAD_REQUEST,\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}\n\n\"Could not find document id=\" + idString +\n\", perhaps the wrong \\\"_route_\\\" param was supplied\");\n}\n} else {\noldRootDocWithChildren.remove(CommonParams.VERSION_FIELD);\n}\nSolrInputDocument mergedDoc;\nif(idField == null || oldRootDocWithChildren == null) {\n\/\/ create a new doc by default if an old one wasn't found\nmergedDoc = docMerger.merge(sdoc, new SolrInputDocument());\n} else {\n\/\/ Safety check: don't allow an update to an existing doc that has children, unless we actually support this.\nif (req.getSchema().isUsableForChildDocs() \/\/ however, next line we see it doesn't support child docs\n&& req.getSchema().supportsPartialUpdatesOfChildDocs() == false\n&& req.getSearcher().count(new TermQuery(new Term(IndexSchema.ROOT_FIELD_NAME, idBytes))) > 1) {\nthrow new SolrException(ErrorCode.BAD_REQUEST, \"This schema does not support partial updates to nested docs. See ref guide.\");\n}\nString oldRootDocRootFieldVal = (String) oldRootDocWithChildren.getFieldValue(IndexSchema.ROOT_FIELD_NAME);\nif(req.getSchema().savesChildDocRelations() && oldRootDocRootFieldVal != null &&\n!idString.equals(oldRootDocRootFieldVal)) {\n\/\/ this is an update where the updated doc is not the root document\nSolrInputDocument sdocWithChildren = RealTimeGetComponent.getInputDocument(cmd.getReq().getCore(),\nidBytes, RealTimeGetComponent.Resolution.DOC_WITH_CHILDREN);\nmergedDoc = docMerger.mergeChildDoc(sdoc, oldRootDocWithChildren, sdocWithChildren);\n} else {\nmergedDoc = docMerger.merge(sdoc, oldRootDocWithChildren);\n}\n}\ncmd.solrDoc = mergedDoc;\nreturn true;\n}","label":[1,0,0,0]}
{"id":9374,"original_code":"@Override\n    public void close() {\n        logger.info(\"CLOSE ZookeeperRiver\");\n        \/\/ TODO Your code..\n    }","code":"@Override\n    public void close() {\n        logger.info(\"CLOSE ZookeeperRiver\");\n       \n    }","cleancode":"@override public void close() { logger.info(\"close zookeeperriver\"); }","comment":"\/\/ todo your code..","repo":"xingxiudong\/elasticsearch-zkdiscovery","code_context_2":"public void close() {\nlogger.info(\"CLOSE ZookeeperRiver\");\n\/\/ TODO Your code..\n}","code_context_10":"@Override\npublic void close() {\nlogger.info(\"CLOSE ZookeeperRiver\");\n\/\/ TODO Your code..\n}","code_context_20":"@Override\npublic void close() {\nlogger.info(\"CLOSE ZookeeperRiver\");\n\/\/ TODO Your code..\n}","label":[0,1,0,0]}
{"id":9375,"original_code":"@Override\n        public void run() {\n            logger.info(\"START ZookeeperRiverLogic: \" + client.toString());\n            \/\/ TODO Your code..\n        }","code":"@Override\n        public void run() {\n            logger.info(\"START ZookeeperRiverLogic: \" + client.toString());\n           \n        }","cleancode":"@override public void run() { logger.info(\"start zookeeperriverlogic: \" + client.tostring()); }","comment":"\/\/ todo your code..","repo":"xingxiudong\/elasticsearch-zkdiscovery","code_context_2":"public void run() {\nlogger.info(\"START ZookeeperRiverLogic: \" + client.toString());\n\/\/ TODO Your code..\n}","code_context_10":"@Override\npublic void run() {\nlogger.info(\"START ZookeeperRiverLogic: \" + client.toString());\n\/\/ TODO Your code..\n}","code_context_20":"@Override\npublic void run() {\nlogger.info(\"START ZookeeperRiverLogic: \" + client.toString());\n\/\/ TODO Your code..\n}","label":[0,1,0,0]}
{"id":25770,"original_code":"public void testToInternal() throws Exception {\n    assertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n    \/\/ here the input isn't in the canonical form, but we should be forgiving\n    assertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n    \/\/ kind of kludgy, but we have other tests for the actual date math\n    assertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n    \/\/ as of Solr 1.3\n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n  }","code":"public void testToInternal() throws Exception {\n    assertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n   \n    assertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\n    assertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n   \n    assertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n   \n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\n    assertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n  }","cleancode":"public void testtointernal() throws exception { assertformatparsed(\"1995-12-31t23:59:59.999\", \"1995-12-31t23:59:59.999666z\"); assertformatparsed(\"1995-12-31t23:59:59.999\", \"1995-12-31t23:59:59.999z\"); assertformatparsed(\"1995-12-31t23:59:59.99\", \"1995-12-31t23:59:59.99z\"); assertformatparsed(\"1995-12-31t23:59:59.9\", \"1995-12-31t23:59:59.9z\"); assertformatparsed(\"1995-12-31t23:59:59\", \"1995-12-31t23:59:59z\"); assertformatparsed(\"1995-12-31t23:59:59.99\", \"1995-12-31t23:59:59.990z\"); assertformatparsed(\"1995-12-31t23:59:59.9\", \"1995-12-31t23:59:59.900z\"); assertformatparsed(\"1995-12-31t23:59:59.9\", \"1995-12-31t23:59:59.90z\"); assertformatparsed(\"1995-12-31t23:59:59\", \"1995-12-31t23:59:59.000z\"); assertformatparsed(\"1995-12-31t23:59:59\", \"1995-12-31t23:59:59.00z\"); assertformatparsed(\"1995-12-31t23:59:59\", \"1995-12-31t23:59:59.0z\"); assertformatparsed(dateformatutil.formatdate(p.parsemath(\"\/day\")), \"now\/day\"); assertformatparsed(\"1995-12-31t00:00:00\", \"1995-12-31t23:59:59z\/day\"); assertformatparsed(\"1995-12-31t00:00:00\", \"1995-12-31t23:59:59.123z\/day\"); assertformatparsed(\"1995-12-31t00:00:00\", \"1995-12-31t23:59:59.123999z\/day\"); }","comment":"\/\/ here the input isn't in the canonical form, but we should be forgiving\n\/\/ kind of kludgy, but we have other tests for the actual date math\n\/\/ as of solr 1.3","repo":"yida-lxw\/solr-5.3.1","code_context_2":"assertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\n\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\n\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");","code_context_10":"public void testToInternal() throws Exception {\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\n\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n}\n\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n}","code_context_20":"public void testToInternal() throws Exception {\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n}\n\npublic void testToInternal() throws Exception {\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n}\n\npublic void testToInternal() throws Exception {\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999666Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.999\", \"1995-12-31T23:59:59.999Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.99Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.9Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59Z\");\n\/\/ here the input isn't in the canonical form, but we should be forgiving\nassertFormatParsed(\"1995-12-31T23:59:59.99\", \"1995-12-31T23:59:59.990Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.900Z\");\nassertFormatParsed(\"1995-12-31T23:59:59.9\", \"1995-12-31T23:59:59.90Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.000Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.00Z\");\nassertFormatParsed(\"1995-12-31T23:59:59\", \"1995-12-31T23:59:59.0Z\");\n\/\/ kind of kludgy, but we have other tests for the actual date math\nassertFormatParsed(DateFormatUtil.formatDate(p.parseMath(\"\/DAY\")), \"NOW\/DAY\");\n\/\/ as of Solr 1.3\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123Z\/DAY\");\nassertFormatParsed(\"1995-12-31T00:00:00\", \"1995-12-31T23:59:59.123999Z\/DAY\");\n}","label":[0,0,0,1]}
{"id":33993,"original_code":"private static void checkTypeCompatibility(\n            @NotNull ExpressionTypingContext context,\n            @Nullable JetType type,\n            @NotNull JetType subjectType,\n            @NotNull JetElement reportErrorOn\n    ) {\n        \/\/ TODO : Take smart casts into account?\n        if (type == null) {\n            return;\n        }\n        if (isIntersectionEmpty(type, subjectType)) {\n            context.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\n            return;\n        }\n        \/\/ check if the pattern is essentially a 'null' expression\n        if (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\n            context.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n        }\n    }","code":"private static void checkTypeCompatibility(\n            @NotNull ExpressionTypingContext context,\n            @Nullable JetType type,\n            @NotNull JetType subjectType,\n            @NotNull JetElement reportErrorOn\n    ) {\n       \n        if (type == null) {\n            return;\n        }\n        if (isIntersectionEmpty(type, subjectType)) {\n            context.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\n            return;\n        }\n       \n        if (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\n            context.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n        }\n    }","cleancode":"private static void checktypecompatibility( @notnull expressiontypingcontext context, @nullable jettype type, @notnull jettype subjecttype, @notnull jetelement reporterroron ) { if (type == null) { return; } if (isintersectionempty(type, subjecttype)) { context.trace.report(incompatible_types.on(reporterroron, type, subjecttype)); return; } if (kotlinbuiltins.isnullablenothing(type) && !typeutils.isnullabletype(subjecttype)) { context.trace.report(senseless_null_in_when.on(reporterroron)); } }","comment":"\/* * (a: subjecttype) is type *\/\n\/\/ todo : take smart casts into account?\n\/\/ check if the pattern is essentially a 'null' expression","repo":"zarechenskiy\/kotlin","code_context_2":"private static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}\n\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));","code_context_10":"private static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}\n\nprivate static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}","code_context_20":"private static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}\n\nprivate static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}\n\nprivate static void checkTypeCompatibility(\n@NotNull ExpressionTypingContext context,\n@Nullable JetType type,\n@NotNull JetType subjectType,\n@NotNull JetElement reportErrorOn\n) {\n\/\/ TODO : Take smart casts into account?\nif (type == null) {\nreturn;\n}\nif (isIntersectionEmpty(type, subjectType)) {\ncontext.trace.report(INCOMPATIBLE_TYPES.on(reportErrorOn, type, subjectType));\nreturn;\n}\n\/\/ check if the pattern is essentially a 'null' expression\nif (KotlinBuiltIns.isNullableNothing(type) && !TypeUtils.isNullableType(subjectType)) {\ncontext.trace.report(SENSELESS_NULL_IN_WHEN.on(reportErrorOn));\n}\n}","label":[1,0,0,0]}
{"id":17632,"original_code":"private void readPreference(String file, AndroidView root, Integer preferenceId) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    Element rootElement = doc.getDocumentElement();\n    String rootTagName = rootElement.getTagName();\n    if (!(rootTagName.equals(\"PreferenceScreen\")\n            || rootTagName.equals(\"preference-headers\")\n            || rootTagName.equals(\"android.support.v7.preference.PreferenceScreen\")\n            || rootTagName.equals(\"android.support.v7.preference.preference-headers\"))) {\n      return;\n    }\n    LinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\n    work.add(new Pair<>(rootElement, root));\n    while (!work.isEmpty()) {\n      Pair<Node, AndroidView> p = work.removeFirst();\n      Node node = p.getO1();\n      AndroidView view = p.getO2();\n      view.setOrigin(file);\n      NamedNodeMap attrMap = node.getAttributes();\n      if (attrMap == null) {\n        System.out.println(file + \"!!!\" + node.getClass() + \"!!!\"\n                + node.toString() + \"!!!\" + node.getTextContent());\n      }\n      Node keyNode = attrMap.getNamedItem(KEY_ATTR);\n      if (keyNode != null) {\n        String key = keyNode.getTextContent();\n        view.addAttr(KEY_ATTR, key);\n        HashMap<Integer, String> maps = preferencesMap.get(\"preference-screen\");\n        if (maps == null) {\n          maps = Maps.newHashMap();\n        }\n        maps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\n        preferencesMap.put(\"preference-screen\", maps);\n        Set<String> preferenceKeys = preferenceKeyMaps.get(preferenceId);\n        if (preferenceKeys == null) {\n          preferenceKeys = new HashSet<>();\n          preferenceKeyMaps.put(preferenceId, preferenceKeys);\n        }\n        preferenceKeys.add(key);\n      }\n      Node fragmentNode = attrMap.getNamedItem(FRAGMENT_ATTR);\n      if (fragmentNode != null) {\n        view.addAttr(FRAGMENT_ATTR, fragmentNode.getTextContent());\n        HashMap<Integer, String> maps = preferencesMap.get(\"preference-header\");\n        if (maps == null) {\n          maps = Maps.newHashMap();\n        }\n        maps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\n        preferencesMap.put(\"preference-header\", maps);\n      }\n      int guiId = -1;\n      \/\/ Retrieve view type\n      String guiName = node.getNodeName();\n      String title = readAndroidTextOrTitle(attrMap, \"title\");\n      String summary = readAndroidTextOrTitle(attrMap, \"summary\");\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n      \/\/view.save(guiId, title, \"\", guiName);\n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n          \/\/ possible for XML files created on a different operating system\n          \/\/ than the one our analysis is run on\n          continue;\n        }\n        AndroidView newView = new AndroidView();\n        \/\/ FIXME: we assume that every node has attributes, may be wrong\n        if (!newNode.hasAttributes()) {\n          Logger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n          \/\/ Fixed: this is wrong for the case group item -> menu -> item\n          \/\/continue;\n        } else {\n          NamedNodeMap attrs = newNode.getAttributes();\n          for (int idx = 0; idx < attrs.getLength(); idx += 1) {\n            Node attr = attrs.item(idx);\n            String name = attr.getNodeName();\n            String value = attr.getNodeValue();\n            newView.addAttr(name, value);\n          }\n        }\n        newView.setParent(view);\n        work.add(new Pair<>(newNode, newView));\n      }\n    }\n  }","code":"private void readPreference(String file, AndroidView root, Integer preferenceId) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    Element rootElement = doc.getDocumentElement();\n    String rootTagName = rootElement.getTagName();\n    if (!(rootTagName.equals(\"PreferenceScreen\")\n            || rootTagName.equals(\"preference-headers\")\n            || rootTagName.equals(\"android.support.v7.preference.PreferenceScreen\")\n            || rootTagName.equals(\"android.support.v7.preference.preference-headers\"))) {\n      return;\n    }\n    LinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\n    work.add(new Pair<>(rootElement, root));\n    while (!work.isEmpty()) {\n      Pair<Node, AndroidView> p = work.removeFirst();\n      Node node = p.getO1();\n      AndroidView view = p.getO2();\n      view.setOrigin(file);\n      NamedNodeMap attrMap = node.getAttributes();\n      if (attrMap == null) {\n        System.out.println(file + \"!!!\" + node.getClass() + \"!!!\"\n                + node.toString() + \"!!!\" + node.getTextContent());\n      }\n      Node keyNode = attrMap.getNamedItem(KEY_ATTR);\n      if (keyNode != null) {\n        String key = keyNode.getTextContent();\n        view.addAttr(KEY_ATTR, key);\n        HashMap<Integer, String> maps = preferencesMap.get(\"preference-screen\");\n        if (maps == null) {\n          maps = Maps.newHashMap();\n        }\n        maps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\n        preferencesMap.put(\"preference-screen\", maps);\n        Set<String> preferenceKeys = preferenceKeyMaps.get(preferenceId);\n        if (preferenceKeys == null) {\n          preferenceKeys = new HashSet<>();\n          preferenceKeyMaps.put(preferenceId, preferenceKeys);\n        }\n        preferenceKeys.add(key);\n      }\n      Node fragmentNode = attrMap.getNamedItem(FRAGMENT_ATTR);\n      if (fragmentNode != null) {\n        view.addAttr(FRAGMENT_ATTR, fragmentNode.getTextContent());\n        HashMap<Integer, String> maps = preferencesMap.get(\"preference-header\");\n        if (maps == null) {\n          maps = Maps.newHashMap();\n        }\n        maps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\n        preferencesMap.put(\"preference-header\", maps);\n      }\n      int guiId = -1;\n     \n      String guiName = node.getNodeName();\n      String title = readAndroidTextOrTitle(attrMap, \"title\");\n      String summary = readAndroidTextOrTitle(attrMap, \"summary\");\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n     \n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n         \n         \n          continue;\n        }\n        AndroidView newView = new AndroidView();\n       \n        if (!newNode.hasAttributes()) {\n          Logger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n         \n         \n        } else {\n          NamedNodeMap attrs = newNode.getAttributes();\n          for (int idx = 0; idx < attrs.getLength(); idx += 1) {\n            Node attr = attrs.item(idx);\n            String name = attr.getNodeName();\n            String value = attr.getNodeValue();\n            newView.addAttr(name, value);\n          }\n        }\n        newView.setParent(view);\n        work.add(new Pair<>(newNode, newView));\n      }\n    }\n  }","cleancode":"private void readpreference(string file, androidview root, integer preferenceid) { document doc; try { documentbuilderfactory dbfactory = documentbuilderfactory.newinstance(); documentbuilder dbuilder = dbfactory.newdocumentbuilder(); doc = dbuilder.parse(file); } catch (exception ex) { throw new runtimeexception(ex); } element rootelement = doc.getdocumentelement(); string roottagname = rootelement.gettagname(); if (!(roottagname.equals(\"preferencescreen\") || roottagname.equals(\"preference-headers\") || roottagname.equals(\"android.support.v7.preference.preferencescreen\") || roottagname.equals(\"android.support.v7.preference.preference-headers\"))) { return; } linkedlist<pair<node, androidview>> work = lists.newlinkedlist(); work.add(new pair<>(rootelement, root)); while (!work.isempty()) { pair<node, androidview> p = work.removefirst(); node node = p.geto1(); androidview view = p.geto2(); view.setorigin(file); namednodemap attrmap = node.getattributes(); if (attrmap == null) { system.out.println(file + \"!!!\" + node.getclass() + \"!!!\" + node.tostring() + \"!!!\" + node.gettextcontent()); } node keynode = attrmap.getnameditem(key_attr); if (keynode != null) { string key = keynode.gettextcontent(); view.addattr(key_attr, key); hashmap<integer, string> maps = preferencesmap.get(\"preference-screen\"); if (maps == null) { maps = maps.newhashmap(); } maps.put(preferenceid, filenameutils.removeextension(new file(file).getname())); preferencesmap.put(\"preference-screen\", maps); set<string> preferencekeys = preferencekeymaps.get(preferenceid); if (preferencekeys == null) { preferencekeys = new hashset<>(); preferencekeymaps.put(preferenceid, preferencekeys); } preferencekeys.add(key); } node fragmentnode = attrmap.getnameditem(fragment_attr); if (fragmentnode != null) { view.addattr(fragment_attr, fragmentnode.gettextcontent()); hashmap<integer, string> maps = preferencesmap.get(\"preference-header\"); if (maps == null) { maps = maps.newhashmap(); } maps.put(preferenceid, filenameutils.removeextension(new file(file).getname())); preferencesmap.put(\"preference-header\", maps); } int guiid = -1; string guiname = node.getnodename(); string title = readandroidtextortitle(attrmap, \"title\"); string summary = readandroidtextortitle(attrmap, \"summary\"); string tooltip = readandroidtextortitle(attrmap, \"tooltiptext\"); string contentdescription = readandroidtextortitle(attrmap, \"contentdescription\"); string images = readandroidimageresource(attrmap); view.save(guiid, title, summary, tooltip, contentdescription, images, guiname); nodelist children = node.getchildnodes(); for (int i = 0; i < children.getlength(); i++) { node newnode = children.item(i); string nodename = newnode.getnodename(); if (\"#comment\".equals(nodename)) { continue; } if (\"#text\".equals(nodename)) { continue; } androidview newview = new androidview(); if (!newnode.hasattributes()) { logger.verb(\"warning\", \"xml node \" + newnode + \" has no attributes\"); } else { namednodemap attrs = newnode.getattributes(); for (int idx = 0; idx < attrs.getlength(); idx += 1) { node attr = attrs.item(idx); string name = attr.getnodename(); string value = attr.getnodevalue(); newview.addattr(name, value); } } newview.setparent(view); work.add(new pair<>(newnode, newview)); } } }","comment":"\/\/ retrieve view type\n\/\/view.save(guiid, title, \"\", guiname);\n\/\/ possible for xml files created on a different operating system \/\/ than the one our analysis is run on\n\/\/ fixme: we assume that every node has attributes, may be wrong\n\/\/ fixed: this is wrong for the case group item -> menu -> item \/\/continue;","repo":"ttincs\/guibat","code_context_2":"}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\n\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\n\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\n\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();","code_context_10":"if (fragmentNode != null) {\nview.addAttr(FRAGMENT_ATTR, fragmentNode.getTextContent());\nHashMap<Integer, String> maps = preferencesMap.get(\"preference-header\");\nif (maps == null) {\nmaps = Maps.newHashMap();\n}\nmaps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\npreferencesMap.put(\"preference-header\", maps);\n}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\n\n}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\n\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\n\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\n\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);","code_context_20":"maps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\npreferencesMap.put(\"preference-screen\", maps);\nSet<String> preferenceKeys = preferenceKeyMaps.get(preferenceId);\nif (preferenceKeys == null) {\npreferenceKeys = new HashSet<>();\npreferenceKeyMaps.put(preferenceId, preferenceKeys);\n}\npreferenceKeys.add(key);\n}\nNode fragmentNode = attrMap.getNamedItem(FRAGMENT_ATTR);\nif (fragmentNode != null) {\nview.addAttr(FRAGMENT_ATTR, fragmentNode.getTextContent());\nHashMap<Integer, String> maps = preferencesMap.get(\"preference-header\");\nif (maps == null) {\nmaps = Maps.newHashMap();\n}\nmaps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\npreferencesMap.put(\"preference-header\", maps);\n}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\n\n}\nNode fragmentNode = attrMap.getNamedItem(FRAGMENT_ATTR);\nif (fragmentNode != null) {\nview.addAttr(FRAGMENT_ATTR, fragmentNode.getTextContent());\nHashMap<Integer, String> maps = preferencesMap.get(\"preference-header\");\nif (maps == null) {\nmaps = Maps.newHashMap();\n}\nmaps.put(preferenceId, FilenameUtils.removeExtension(new File(file).getName()));\npreferencesMap.put(\"preference-header\", maps);\n}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\n\npreferencesMap.put(\"preference-header\", maps);\n}\nint guiId = -1;\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nwork.add(new Pair<>(newNode, newView));\n}\n\nString title = readAndroidTextOrTitle(attrMap, \"title\");\nString summary = readAndroidTextOrTitle(attrMap, \"summary\");\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nwork.add(new Pair<>(newNode, newView));\n}\n}\n}\n\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, title, summary, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, title, \"\", guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ Fixed: this is wrong for the case group item -> menu -> item\n\/\/continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nwork.add(new Pair<>(newNode, newView));\n}\n}\n}","label":[0,0,1,0]}
{"id":17634,"original_code":"private void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\n                               HashMap<Integer, AndroidView> viewMap, boolean isSys) {\n    HashMap<String, AndroidView> name2View = Maps.newHashMap();\n    for (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\n      String name = entry.getValue();\n      AndroidView view = viewMap.get(entry.getKey());\n      name2View.put(name, view);\n    }\n\/\/    boolean isSys = (viewMap == sysId2View);\n    LinkedList<AndroidView> work = Lists.newLinkedList();\n    work.addAll(viewMap.values());\n    while (!work.isEmpty()) {\n      AndroidView view = work.remove();\n      for (int i = 0; i < view.getNumberOfChildren(); i++) {\n        IAndroidView child = view.getChildInternal(i);\n        if (child instanceof AndroidView) {\n          work.add((AndroidView) child);\n          continue;\n        }\n        IncludeAndroidView iav = (IncludeAndroidView) child;\n        String layoutId = iav.layoutId;\n        AndroidView tgt = name2View.get(layoutId);\n        if (tgt != null) {\n          tgt = (AndroidView) tgt.deepCopy();\n          tgt.setParent(view, i);\n        } else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n          \/\/ not exist, let's get it on-demand\n          String file = getLayoutFilePath(resRoot, layoutId, isSys);\n          tgt = new AndroidView();\n          tgt.setParent(view, i);\n          tgt.setOrigin(file);\n          readLayout(file, tgt, isSys);\n          int newId = nonRId--;\n          viewMap.put(newId, tgt);\n          nameMap.put(newId, layoutId);\n        } else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n                (sysRGeneralIdMap.get(\"layout\").get(layoutId)\n                )) {\n          \/\/ <include> is used with an in built android layout id\n          tgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\n          tgt.setParent(view, i);\n        } else {\n          Logger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n                  + \" included by \" + view.getOrigin());\n          continue;\n        }\n        Integer includeeId = iav.includeeId;\n        if (includeeId != null) {\n          tgt.setId(includeeId.intValue());\n        }\n        work.add(tgt);\n      }\n    }\n  }","code":"private void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\n                               HashMap<Integer, AndroidView> viewMap, boolean isSys) {\n    HashMap<String, AndroidView> name2View = Maps.newHashMap();\n    for (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\n      String name = entry.getValue();\n      AndroidView view = viewMap.get(entry.getKey());\n      name2View.put(name, view);\n    }\n    LinkedList<AndroidView> work = Lists.newLinkedList();\n    work.addAll(viewMap.values());\n    while (!work.isEmpty()) {\n      AndroidView view = work.remove();\n      for (int i = 0; i < view.getNumberOfChildren(); i++) {\n        IAndroidView child = view.getChildInternal(i);\n        if (child instanceof AndroidView) {\n          work.add((AndroidView) child);\n          continue;\n        }\n        IncludeAndroidView iav = (IncludeAndroidView) child;\n        String layoutId = iav.layoutId;\n        AndroidView tgt = name2View.get(layoutId);\n        if (tgt != null) {\n          tgt = (AndroidView) tgt.deepCopy();\n          tgt.setParent(view, i);\n        } else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n         \n          String file = getLayoutFilePath(resRoot, layoutId, isSys);\n          tgt = new AndroidView();\n          tgt.setParent(view, i);\n          tgt.setOrigin(file);\n          readLayout(file, tgt, isSys);\n          int newId = nonRId--;\n          viewMap.put(newId, tgt);\n          nameMap.put(newId, layoutId);\n        } else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n                (sysRGeneralIdMap.get(\"layout\").get(layoutId)\n                )) {\n         \n          tgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\n          tgt.setParent(view, i);\n        } else {\n          Logger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n                  + \" included by \" + view.getOrigin());\n          continue;\n        }\n        Integer includeeId = iav.includeeId;\n        if (includeeId != null) {\n          tgt.setId(includeeId.intValue());\n        }\n        work.add(tgt);\n      }\n    }\n  }","cleancode":"private void resolveincludes(string resroot, hashmap<integer, string> namemap, hashmap<integer, androidview> viewmap, boolean issys) { hashmap<string, androidview> name2view = maps.newhashmap(); for (map.entry<integer, string> entry : namemap.entryset()) { string name = entry.getvalue(); androidview view = viewmap.get(entry.getkey()); name2view.put(name, view); } linkedlist<androidview> work = lists.newlinkedlist(); work.addall(viewmap.values()); while (!work.isempty()) { androidview view = work.remove(); for (int i = 0; i < view.getnumberofchildren(); i++) { iandroidview child = view.getchildinternal(i); if (child instanceof androidview) { work.add((androidview) child); continue; } includeandroidview iav = (includeandroidview) child; string layoutid = iav.layoutid; androidview tgt = name2view.get(layoutid); if (tgt != null) { tgt = (androidview) tgt.deepcopy(); tgt.setparent(view, i); } else if (getlayoutfilepath(resroot, layoutid, issys) != null) { string file = getlayoutfilepath(resroot, layoutid, issys); tgt = new androidview(); tgt.setparent(view, i); tgt.setorigin(file); readlayout(file, tgt, issys); int newid = nonrid--; viewmap.put(newid, tgt); namemap.put(newid, layoutid); } else if (sysrgeneralidmap.get(\"layout\").containskey(layoutid) && sysid2view.containskey (sysrgeneralidmap.get(\"layout\").get(layoutid) )) { tgt = (androidview) sysid2view.get(sysrgeneralidmap.get(\"layout\").get(layoutid)).deepcopy(); tgt.setparent(view, i); } else { logger.warn(this.getclass().getsimplename(), \"unknown layout \" + layoutid + \" included by \" + view.getorigin()); continue; } integer includeeid = iav.includeeid; if (includeeid != null) { tgt.setid(includeeid.intvalue()); } work.add(tgt); } } }","comment":"\/\/ todo: due to the way we implement resolveincludes(), now we need \/\/ to change findviewbyid.\n\/\/ boolean issys = (viewmap == sysid2view);\n\/\/ not exist, let's get it on-demand\n\/\/ <include> is used with an in built android layout id","repo":"ttincs\/guibat","code_context_2":"private void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\nHashMap<Integer, AndroidView> viewMap, boolean isSys) {\nHashMap<String, AndroidView> name2View = Maps.newHashMap();\nfor (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\nString name = entry.getValue();\nAndroidView view = viewMap.get(entry.getKey());\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\nif (includeeId != null) {\ntgt.setId(includeeId.intValue());\n}\nwork.add(tgt);\n}\n}\n}\n\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\n\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\n\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);","code_context_10":"private void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\nHashMap<Integer, AndroidView> viewMap, boolean isSys) {\nHashMap<String, AndroidView> name2View = Maps.newHashMap();\nfor (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\nString name = entry.getValue();\nAndroidView view = viewMap.get(entry.getKey());\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\nif (includeeId != null) {\ntgt.setId(includeeId.intValue());\n}\nwork.add(tgt);\n}\n}\n}\n\nprivate void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\nHashMap<Integer, AndroidView> viewMap, boolean isSys) {\nHashMap<String, AndroidView> name2View = Maps.newHashMap();\nfor (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\nString name = entry.getValue();\nAndroidView view = viewMap.get(entry.getKey());\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\n\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\nif (includeeId != null) {\ntgt.setId(includeeId.intValue());","code_context_20":"private void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\nHashMap<Integer, AndroidView> viewMap, boolean isSys) {\nHashMap<String, AndroidView> name2View = Maps.newHashMap();\nfor (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\nString name = entry.getValue();\nAndroidView view = viewMap.get(entry.getKey());\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\nif (includeeId != null) {\ntgt.setId(includeeId.intValue());\n}\nwork.add(tgt);\n}\n}\n}\n\nprivate void resolveIncludes(String resRoot, HashMap<Integer, String> nameMap,\nHashMap<Integer, AndroidView> viewMap, boolean isSys) {\nHashMap<String, AndroidView> name2View = Maps.newHashMap();\nfor (Map.Entry<Integer, String> entry : nameMap.entrySet()) {\nString name = entry.getValue();\nAndroidView view = viewMap.get(entry.getKey());\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\n\nname2View.put(name, view);\n}\n\/\/ boolean isSys = (viewMap == sysId2View);\nLinkedList<AndroidView> work = Lists.newLinkedList();\nwork.addAll(viewMap.values());\nwhile (!work.isEmpty()) {\nAndroidView view = work.remove();\nfor (int i = 0; i < view.getNumberOfChildren(); i++) {\nIAndroidView child = view.getChildInternal(i);\nif (child instanceof AndroidView) {\nwork.add((AndroidView) child);\ncontinue;\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\n\n}\nIncludeAndroidView iav = (IncludeAndroidView) child;\nString layoutId = iav.layoutId;\nAndroidView tgt = name2View.get(layoutId);\nif (tgt != null) {\ntgt = (AndroidView) tgt.deepCopy();\ntgt.setParent(view, i);\n} else if (getLayoutFilePath(resRoot, layoutId, isSys) != null) {\n\/\/ not exist, let's get it on-demand\nString file = getLayoutFilePath(resRoot, layoutId, isSys);\ntgt = new AndroidView();\ntgt.setParent(view, i);\ntgt.setOrigin(file);\nreadLayout(file, tgt, isSys);\nint newId = nonRId--;\nviewMap.put(newId, tgt);\nnameMap.put(newId, layoutId);\n} else if (sysRGeneralIdMap.get(\"layout\").containsKey(layoutId) && sysId2View.containsKey\n(sysRGeneralIdMap.get(\"layout\").get(layoutId)\n)) {\n\/\/ <include> is used with an in built android layout id\ntgt = (AndroidView) sysId2View.get(sysRGeneralIdMap.get(\"layout\").get(layoutId)).deepCopy();\ntgt.setParent(view, i);\n} else {\nLogger.warn(this.getClass().getSimpleName(), \"Unknown layout \" + layoutId\n+ \" included by \" + view.getOrigin());\ncontinue;\n}\nInteger includeeId = iav.includeeId;\nif (includeeId != null) {\ntgt.setId(includeeId.intValue());\n}\nwork.add(tgt);\n}\n}\n}","label":[1,0,0,0]}
{"id":17635,"original_code":"private void readLayout(String file, AndroidView root, boolean isSys) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      dbFactory.setNamespaceAware(true);\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    Element rootElement = doc.getDocumentElement();\n    \/\/ In older versions, Preference could be put in layout folder and we do\n    \/\/ not support Prefernce yet.\n    if (rootElement.getTagName().equals(\"PreferenceScreen\")) {\n      return;\n    }\n    LinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\n    work.add(new Pair<Node, AndroidView>(rootElement, root));\n    while (!work.isEmpty()) {\n      Pair<Node, AndroidView> p = work.removeFirst();\n      Node node = p.getO1();\n      AndroidView view = p.getO2();\n      view.setOrigin(file);\n      NamedNodeMap attrMap = node.getAttributes();\n      if (attrMap == null) {\n        Logger.verb(this.getClass().getSimpleName(), file + \"!!!\" + node.getClass() + \"!!!\"\n                + node.toString() + \"!!!\" + node.getTextContent());\n      }\n      \/\/ Retrieve view id (android:id)\n      \/\/Node idNode = attrMap.getNamedItem(ID_ATTR);\n      Node idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n      int guiId = -1;\n      String id = null;\n      if (idNode != null) {\n        String txt = idNode.getTextContent();\n        Pair<String, Integer> pair = parseAndroidId(txt, isSys);\n        id = pair.getO1();\n        Integer guiIdObj = pair.getO2();\n        if (guiIdObj == null) {\n          if (!isSys) {\n            Logger.warn(this.getClass().getSimpleName(),\n                    \"unresolved android:id \" + id + \" in \"\n                    + file);\n          }\n        } else {\n          guiId = guiIdObj.intValue();\n          if (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\n            extraId2ViewMap.put(guiIdObj, view);\n          }\n        }\n      }\n      \/\/ Retrieve view type\n      String guiName = node.getNodeName();\n      if (\"view\".equals(guiName)) {\n        \/\/ view without class attribute.\n        \/\/ It does happen.\n        if (attrMap.getNamedItem(\"class\") == null)\n          continue;\n        guiName = attrMap.getNamedItem(\"class\").getTextContent();\n      } else if (guiName.equals(\"MenuItemView\")) {\n        \/\/ FIXME(tony): this is an \"approximation\".\n        guiName = \"android.view.MenuItem\";\n      }\n      if (debug) {\n        Logger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n      }\n      \/\/Retrieve callback (android:onClick)\n      String callback = readAndroidCallback(attrMap, \"onClick\");\n      if (callback != null) {\n        view.setInlineClickHandler(callback);\n      }\n      \/\/ Retrieve text (android:text)\n      String text = readAndroidTextOrTitle(attrMap, \"text\");\n      \/\/ hailong: add hint support\n      \/\/ Retrieve hint (android:hint)\n      String hint = readAndroidTextOrTitle(attrMap, \"hint\");\n      String autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      if(attrMap.getNamedItem(\"app:menu\") != null){\n        String menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\n        if (menuName != null) {\n          Pair<String, Integer> pair = parseAndroidId(menuName, isSys);\n          Integer menuId = pair.getO2();\n          if (menuId != null) {\n            view.addAttr(AndroidView.Type.APP_MENU, String.valueOf(menuId));\n            menuId2View.put(menuId, view);\n          }\n        }\n        if (attrMap.getNamedItem(\"app:headerLayout\") != null) {\n          String headerName = attrMap.getNamedItem(\"app:headerLayout\").getTextContent();\n          if (headerName != null) {\n            Pair<String, Integer> pair = parseAndroidId(headerName, isSys);\n            Integer headerId = pair.getO2();\n            if (headerId != null) {\n              view.addAttr(AndroidView.Type.APP_HEADER_LAYOUT, String.valueOf(headerId));\n              menuHeaderId2View.put(headerId, view);\n            }\n          }\n        }\n      }\n      if (\"fragment\".equals(guiName)) {\n        Node fragmentNodeAttr = attrMap.getNamedItem(\"android:name\");\n        if (fragmentNodeAttr != null) {\n          String fragmentClass = fragmentNodeAttr.getTextContent();\n          if (fragmentClass.isEmpty()) {\n            fragmentNodeAttr = attrMap.getNamedItem(\"class\");\n            if (fragmentNodeAttr != null) {\n              fragmentClass = fragmentNodeAttr.getTextContent();\n            }\n          }\n          view.addAttr(AndroidView.Type.ANDROID_NAME, fragmentClass);\n        }\n      }\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n      \/\/view.save(guiId, text, hint, guiName);\n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n          \/\/ possible for XML files created on a different operating system\n          \/\/ than the one our analysis is run on\n          continue;\n        }\n        if (nodeName.equals(\"requestFocus\")) {\n          continue;\n        }\n        if (!newNode.hasAttributes() && !\"TableRow\".equals(nodeName)\n                && !\"View\".equals(nodeName)) {\n          Logger.warn(this.getClass().getSimpleName(),\n                  \"no attribute node \"\n                  + newNode.getNodeName());\n          continue;\n        }\n        if (newNode.getNodeName().equals(\"include\")) {\n          attrMap = newNode.getAttributes();\n          if (attrMap.getNamedItem(\"layout\") == null) {\n            Logger.warn(\"XML\", \"layout not exist in include\");\n            for (int j = 0; j < attrMap.getLength(); j++) {\n              Logger.trace(\"XML\", attrMap.item(j).getNodeName());\n            }\n            Logger.trace(\"XML\", \"filename\" + file);\n            continue;\n          }\n          String layoutTxt = attrMap.getNamedItem(\"layout\").getTextContent();\n          String layoutId = null;\n          if (layoutTxt.startsWith(\"@layout\/\")) {\n            layoutId = layoutTxt.substring(\"@layout\/\".length());\n          } else if (layoutTxt.startsWith(\"@android:layout\/\")) {\n            layoutId = layoutTxt.substring(\"@android:layout\/\".length());\n          } else if (layoutTxt.matches(\"@\\\\*android:layout\\\\\/(\\\\w)+\")) {\n            layoutId = layoutTxt.substring(\"@*android:layout\/\".length());\n          } else {\n            throw new RuntimeException(\"[WARNING] Unhandled layout id \"\n                    + layoutTxt + \",\" + file);\n          }\n          Integer includeeId = null;\n          id = null;\n          idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n          if (idNode != null) {\n            String txt = idNode.getTextContent();\n            Pair<String, Integer> pair = parseAndroidId(txt, isSys);\n            id = pair.getO1();\n            Integer guiIdObj = pair.getO2();\n            if (guiIdObj == null) {\n              if (!isSys) {\n                Logger.warn(this.getClass().getSimpleName(),\n                        \"unresolved android:id \" + id\n                        + \" in \" + file);\n              }\n            } else {\n              includeeId = guiIdObj;\n            }\n          }\n          \/\/ view.saveInclude(layoutId, includeeId);\n          IncludeAndroidView iav = new IncludeAndroidView(layoutId, includeeId);\n          iav.setParent(view);\n        } else {\n          AndroidView newView = new AndroidView();\n          newView.setParent(view);\n          work.add(new Pair<Node, AndroidView>(newNode, newView));\n        }\n      }\n    }\n  }","code":"private void readLayout(String file, AndroidView root, boolean isSys) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      dbFactory.setNamespaceAware(true);\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    Element rootElement = doc.getDocumentElement();\n   \n   \n    if (rootElement.getTagName().equals(\"PreferenceScreen\")) {\n      return;\n    }\n    LinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\n    work.add(new Pair<Node, AndroidView>(rootElement, root));\n    while (!work.isEmpty()) {\n      Pair<Node, AndroidView> p = work.removeFirst();\n      Node node = p.getO1();\n      AndroidView view = p.getO2();\n      view.setOrigin(file);\n      NamedNodeMap attrMap = node.getAttributes();\n      if (attrMap == null) {\n        Logger.verb(this.getClass().getSimpleName(), file + \"!!!\" + node.getClass() + \"!!!\"\n                + node.toString() + \"!!!\" + node.getTextContent());\n      }\n     \n     \n      Node idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n      int guiId = -1;\n      String id = null;\n      if (idNode != null) {\n        String txt = idNode.getTextContent();\n        Pair<String, Integer> pair = parseAndroidId(txt, isSys);\n        id = pair.getO1();\n        Integer guiIdObj = pair.getO2();\n        if (guiIdObj == null) {\n          if (!isSys) {\n            Logger.warn(this.getClass().getSimpleName(),\n                    \"unresolved android:id \" + id + \" in \"\n                    + file);\n          }\n        } else {\n          guiId = guiIdObj.intValue();\n          if (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\n            extraId2ViewMap.put(guiIdObj, view);\n          }\n        }\n      }\n     \n      String guiName = node.getNodeName();\n      if (\"view\".equals(guiName)) {\n       \n       \n        if (attrMap.getNamedItem(\"class\") == null)\n          continue;\n        guiName = attrMap.getNamedItem(\"class\").getTextContent();\n      } else if (guiName.equals(\"MenuItemView\")) {\n       \n        guiName = \"android.view.MenuItem\";\n      }\n      if (debug) {\n        Logger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n      }\n     \n      String callback = readAndroidCallback(attrMap, \"onClick\");\n      if (callback != null) {\n        view.setInlineClickHandler(callback);\n      }\n     \n      String text = readAndroidTextOrTitle(attrMap, \"text\");\n     \n     \n      String hint = readAndroidTextOrTitle(attrMap, \"hint\");\n      String autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      if(attrMap.getNamedItem(\"app:menu\") != null){\n        String menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\n        if (menuName != null) {\n          Pair<String, Integer> pair = parseAndroidId(menuName, isSys);\n          Integer menuId = pair.getO2();\n          if (menuId != null) {\n            view.addAttr(AndroidView.Type.APP_MENU, String.valueOf(menuId));\n            menuId2View.put(menuId, view);\n          }\n        }\n        if (attrMap.getNamedItem(\"app:headerLayout\") != null) {\n          String headerName = attrMap.getNamedItem(\"app:headerLayout\").getTextContent();\n          if (headerName != null) {\n            Pair<String, Integer> pair = parseAndroidId(headerName, isSys);\n            Integer headerId = pair.getO2();\n            if (headerId != null) {\n              view.addAttr(AndroidView.Type.APP_HEADER_LAYOUT, String.valueOf(headerId));\n              menuHeaderId2View.put(headerId, view);\n            }\n          }\n        }\n      }\n      if (\"fragment\".equals(guiName)) {\n        Node fragmentNodeAttr = attrMap.getNamedItem(\"android:name\");\n        if (fragmentNodeAttr != null) {\n          String fragmentClass = fragmentNodeAttr.getTextContent();\n          if (fragmentClass.isEmpty()) {\n            fragmentNodeAttr = attrMap.getNamedItem(\"class\");\n            if (fragmentNodeAttr != null) {\n              fragmentClass = fragmentNodeAttr.getTextContent();\n            }\n          }\n          view.addAttr(AndroidView.Type.ANDROID_NAME, fragmentClass);\n        }\n      }\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n     \n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n         \n         \n          continue;\n        }\n        if (nodeName.equals(\"requestFocus\")) {\n          continue;\n        }\n        if (!newNode.hasAttributes() && !\"TableRow\".equals(nodeName)\n                && !\"View\".equals(nodeName)) {\n          Logger.warn(this.getClass().getSimpleName(),\n                  \"no attribute node \"\n                  + newNode.getNodeName());\n          continue;\n        }\n        if (newNode.getNodeName().equals(\"include\")) {\n          attrMap = newNode.getAttributes();\n          if (attrMap.getNamedItem(\"layout\") == null) {\n            Logger.warn(\"XML\", \"layout not exist in include\");\n            for (int j = 0; j < attrMap.getLength(); j++) {\n              Logger.trace(\"XML\", attrMap.item(j).getNodeName());\n            }\n            Logger.trace(\"XML\", \"filename\" + file);\n            continue;\n          }\n          String layoutTxt = attrMap.getNamedItem(\"layout\").getTextContent();\n          String layoutId = null;\n          if (layoutTxt.startsWith(\"@layout\/\")) {\n            layoutId = layoutTxt.substring(\"@layout\/\".length());\n          } else if (layoutTxt.startsWith(\"@android:layout\/\")) {\n            layoutId = layoutTxt.substring(\"@android:layout\/\".length());\n          } else if (layoutTxt.matches(\"@\\\\*android:layout\\\\\/(\\\\w)+\")) {\n            layoutId = layoutTxt.substring(\"@*android:layout\/\".length());\n          } else {\n            throw new RuntimeException(\"[WARNING] Unhandled layout id \"\n                    + layoutTxt + \",\" + file);\n          }\n          Integer includeeId = null;\n          id = null;\n          idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n          if (idNode != null) {\n            String txt = idNode.getTextContent();\n            Pair<String, Integer> pair = parseAndroidId(txt, isSys);\n            id = pair.getO1();\n            Integer guiIdObj = pair.getO2();\n            if (guiIdObj == null) {\n              if (!isSys) {\n                Logger.warn(this.getClass().getSimpleName(),\n                        \"unresolved android:id \" + id\n                        + \" in \" + file);\n              }\n            } else {\n              includeeId = guiIdObj;\n            }\n          }\n         \n          IncludeAndroidView iav = new IncludeAndroidView(layoutId, includeeId);\n          iav.setParent(view);\n        } else {\n          AndroidView newView = new AndroidView();\n          newView.setParent(view);\n          work.add(new Pair<Node, AndroidView>(newNode, newView));\n        }\n      }\n    }\n  }","cleancode":"private void readlayout(string file, androidview root, boolean issys) { document doc; try { documentbuilderfactory dbfactory = documentbuilderfactory.newinstance(); dbfactory.setnamespaceaware(true); documentbuilder dbuilder = dbfactory.newdocumentbuilder(); doc = dbuilder.parse(file); } catch (exception ex) { throw new runtimeexception(ex); } element rootelement = doc.getdocumentelement(); if (rootelement.gettagname().equals(\"preferencescreen\")) { return; } linkedlist<pair<node, androidview>> work = lists.newlinkedlist(); work.add(new pair<node, androidview>(rootelement, root)); while (!work.isempty()) { pair<node, androidview> p = work.removefirst(); node node = p.geto1(); androidview view = p.geto2(); view.setorigin(file); namednodemap attrmap = node.getattributes(); if (attrmap == null) { logger.verb(this.getclass().getsimplename(), file + \"!!!\" + node.getclass() + \"!!!\" + node.tostring() + \"!!!\" + node.gettextcontent()); } node idnode = attrmap.getnameditemns(android_ns, \"id\"); int guiid = -1; string id = null; if (idnode != null) { string txt = idnode.gettextcontent(); pair<string, integer> pair = parseandroidid(txt, issys); id = pair.geto1(); integer guiidobj = pair.geto2(); if (guiidobj == null) { if (!issys) { logger.warn(this.getclass().getsimplename(), \"unresolved android:id \" + id + \" in \" + file); } } else { guiid = guiidobj.intvalue(); if (lookupnameingeneralmap(\"id\", guiid, issys) == null) { extraid2viewmap.put(guiidobj, view); } } } string guiname = node.getnodename(); if (\"view\".equals(guiname)) { if (attrmap.getnameditem(\"class\") == null) continue; guiname = attrmap.getnameditem(\"class\").gettextcontent(); } else if (guiname.equals(\"menuitemview\")) { guiname = \"android.view.menuitem\"; } if (debug) { logger.verb(this.getclass().getsimplename(), guiname + \" (\" + guiid + \", \" + id + \")\"); } string callback = readandroidcallback(attrmap, \"onclick\"); if (callback != null) { view.setinlineclickhandler(callback); } string text = readandroidtextortitle(attrmap, \"text\"); string hint = readandroidtextortitle(attrmap, \"hint\"); string autofillhints = readandroidtextortitle(attrmap, \"autofillhints\"); if (hint != null && autofillhints != null) hint += propertymanager.separator + autofillhints; else if (autofillhints != null) hint = autofillhints; if(attrmap.getnameditem(\"app:menu\") != null){ string menuname = attrmap.getnameditem(\"app:menu\").gettextcontent(); if (menuname != null) { pair<string, integer> pair = parseandroidid(menuname, issys); integer menuid = pair.geto2(); if (menuid != null) { view.addattr(androidview.type.app_menu, string.valueof(menuid)); menuid2view.put(menuid, view); } } if (attrmap.getnameditem(\"app:headerlayout\") != null) { string headername = attrmap.getnameditem(\"app:headerlayout\").gettextcontent(); if (headername != null) { pair<string, integer> pair = parseandroidid(headername, issys); integer headerid = pair.geto2(); if (headerid != null) { view.addattr(androidview.type.app_header_layout, string.valueof(headerid)); menuheaderid2view.put(headerid, view); } } } } if (\"fragment\".equals(guiname)) { node fragmentnodeattr = attrmap.getnameditem(\"android:name\"); if (fragmentnodeattr != null) { string fragmentclass = fragmentnodeattr.gettextcontent(); if (fragmentclass.isempty()) { fragmentnodeattr = attrmap.getnameditem(\"class\"); if (fragmentnodeattr != null) { fragmentclass = fragmentnodeattr.gettextcontent(); } } view.addattr(androidview.type.android_name, fragmentclass); } } string tooltip = readandroidtextortitle(attrmap, \"tooltiptext\"); string contentdescription = readandroidtextortitle(attrmap, \"contentdescription\"); if (hint != null && autofillhints != null) hint += propertymanager.separator + autofillhints; else if (autofillhints != null) hint = autofillhints; string images = readandroidimageresource(attrmap); view.save(guiid, text, hint, tooltip, contentdescription, images, guiname); nodelist children = node.getchildnodes(); for (int i = 0; i < children.getlength(); i++) { node newnode = children.item(i); string nodename = newnode.getnodename(); if (\"#comment\".equals(nodename)) { continue; } if (\"#text\".equals(nodename)) { continue; } if (nodename.equals(\"requestfocus\")) { continue; } if (!newnode.hasattributes() && !\"tablerow\".equals(nodename) && !\"view\".equals(nodename)) { logger.warn(this.getclass().getsimplename(), \"no attribute node \" + newnode.getnodename()); continue; } if (newnode.getnodename().equals(\"include\")) { attrmap = newnode.getattributes(); if (attrmap.getnameditem(\"layout\") == null) { logger.warn(\"xml\", \"layout not exist in include\"); for (int j = 0; j < attrmap.getlength(); j++) { logger.trace(\"xml\", attrmap.item(j).getnodename()); } logger.trace(\"xml\", \"filename\" + file); continue; } string layouttxt = attrmap.getnameditem(\"layout\").gettextcontent(); string layoutid = null; if (layouttxt.startswith(\"@layout\/\")) { layoutid = layouttxt.substring(\"@layout\/\".length()); } else if (layouttxt.startswith(\"@android:layout\/\")) { layoutid = layouttxt.substring(\"@android:layout\/\".length()); } else if (layouttxt.matches(\"@\\\\*android:layout\\\\\/(\\\\w)+\")) { layoutid = layouttxt.substring(\"@*android:layout\/\".length()); } else { throw new runtimeexception(\"[warning] unhandled layout id \" + layouttxt + \",\" + file); } integer includeeid = null; id = null; idnode = attrmap.getnameditemns(android_ns, \"id\"); if (idnode != null) { string txt = idnode.gettextcontent(); pair<string, integer> pair = parseandroidid(txt, issys); id = pair.geto1(); integer guiidobj = pair.geto2(); if (guiidobj == null) { if (!issys) { logger.warn(this.getclass().getsimplename(), \"unresolved android:id \" + id + \" in \" + file); } } else { includeeid = guiidobj; } } includeandroidview iav = new includeandroidview(layoutid, includeeid); iav.setparent(view); } else { androidview newview = new androidview(); newview.setparent(view); work.add(new pair<node, androidview>(newnode, newview)); } } } }","comment":"\/\/ in older versions, preference could be put in layout folder and we do \/\/ not support prefernce yet.\n\/\/ retrieve view id (android:id) \/\/node idnode = attrmap.getnameditem(id_attr);\n\/\/ retrieve view type\n\/\/ view without class attribute. \/\/ it does happen.\n\/\/ fixme(tony): this is an \"approximation\".\n\/\/retrieve callback (android:onclick)\n\/\/ retrieve text (android:text)\n\/\/ hailong: add hint support \/\/ retrieve hint (android:hint)\n\/\/view.save(guiid, text, hint, guiname);\n\/\/ possible for xml files created on a different operating system \/\/ than the one our analysis is run on\n\/\/ view.saveinclude(layoutid, includeeid);","repo":"ttincs\/guibat","code_context_2":"}\nElement rootElement = doc.getDocumentElement();\n\/\/ In older versions, Preference could be put in layout folder and we do\n\/\/ not support Prefernce yet.\nif (rootElement.getTagName().equals(\"PreferenceScreen\")) {\nreturn;\n\n+ node.toString() + \"!!!\" + node.getTextContent());\n}\n\/\/ Retrieve view id (android:id)\n\/\/Node idNode = attrMap.getNamedItem(ID_ATTR);\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\n\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\n\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\n\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\n\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\n\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\n\n}\n}\n\/\/ view.saveInclude(layoutId, includeeId);\nIncludeAndroidView iav = new IncludeAndroidView(layoutId, includeeId);\niav.setParent(view);","code_context_10":"Document doc;\ntry {\nDocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\ndbFactory.setNamespaceAware(true);\nDocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\ndoc = dBuilder.parse(file);\n} catch (Exception ex) {\nthrow new RuntimeException(ex);\n}\nElement rootElement = doc.getDocumentElement();\n\/\/ In older versions, Preference could be put in layout folder and we do\n\/\/ not support Prefernce yet.\nif (rootElement.getTagName().equals(\"PreferenceScreen\")) {\nreturn;\n}\nLinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\nwork.add(new Pair<Node, AndroidView>(rootElement, root));\nwhile (!work.isEmpty()) {\nPair<Node, AndroidView> p = work.removeFirst();\nNode node = p.getO1();\nAndroidView view = p.getO2();\nview.setOrigin(file);\n\nwhile (!work.isEmpty()) {\nPair<Node, AndroidView> p = work.removeFirst();\nNode node = p.getO1();\nAndroidView view = p.getO2();\nview.setOrigin(file);\nNamedNodeMap attrMap = node.getAttributes();\nif (attrMap == null) {\nLogger.verb(this.getClass().getSimpleName(), file + \"!!!\" + node.getClass() + \"!!!\"\n+ node.toString() + \"!!!\" + node.getTextContent());\n}\n\/\/ Retrieve view id (android:id)\n\/\/Node idNode = attrMap.getNamedItem(ID_ATTR);\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> pair = parseAndroidId(txt, isSys);\nid = pair.getO1();\nInteger guiIdObj = pair.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\n\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\nif (menuName != null) {\n\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\nif (menuName != null) {\nPair<String, Integer> pair = parseAndroidId(menuName, isSys);\nInteger menuId = pair.getO2();\nif (menuId != null) {\n\n}\nview.addAttr(AndroidView.Type.ANDROID_NAME, fragmentClass);\n}\n}\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\n\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nif (nodeName.equals(\"requestFocus\")) {\ncontinue;\n}\nif (!newNode.hasAttributes() && !\"TableRow\".equals(nodeName)\n&& !\"View\".equals(nodeName)) {\nLogger.warn(this.getClass().getSimpleName(),\n\"no attribute node \"\n+ newNode.getNodeName());\n\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id\n+ \" in \" + file);\n}\n} else {\nincludeeId = guiIdObj;\n}\n}\n\/\/ view.saveInclude(layoutId, includeeId);\nIncludeAndroidView iav = new IncludeAndroidView(layoutId, includeeId);\niav.setParent(view);\n} else {\nAndroidView newView = new AndroidView();\nnewView.setParent(view);\nwork.add(new Pair<Node, AndroidView>(newNode, newView));\n}\n}\n}\n}","code_context_20":"private void readLayout(String file, AndroidView root, boolean isSys) {\nDocument doc;\ntry {\nDocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\ndbFactory.setNamespaceAware(true);\nDocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\ndoc = dBuilder.parse(file);\n} catch (Exception ex) {\nthrow new RuntimeException(ex);\n}\nElement rootElement = doc.getDocumentElement();\n\/\/ In older versions, Preference could be put in layout folder and we do\n\/\/ not support Prefernce yet.\nif (rootElement.getTagName().equals(\"PreferenceScreen\")) {\nreturn;\n}\nLinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\nwork.add(new Pair<Node, AndroidView>(rootElement, root));\nwhile (!work.isEmpty()) {\nPair<Node, AndroidView> p = work.removeFirst();\nNode node = p.getO1();\nAndroidView view = p.getO2();\nview.setOrigin(file);\nNamedNodeMap attrMap = node.getAttributes();\nif (attrMap == null) {\nLogger.verb(this.getClass().getSimpleName(), file + \"!!!\" + node.getClass() + \"!!!\"\n+ node.toString() + \"!!!\" + node.getTextContent());\n}\n\/\/ Retrieve view id (android:id)\n\/\/Node idNode = attrMap.getNamedItem(ID_ATTR);\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\n\nthrow new RuntimeException(ex);\n}\nElement rootElement = doc.getDocumentElement();\n\/\/ In older versions, Preference could be put in layout folder and we do\n\/\/ not support Prefernce yet.\nif (rootElement.getTagName().equals(\"PreferenceScreen\")) {\nreturn;\n}\nLinkedList<Pair<Node, AndroidView>> work = Lists.newLinkedList();\nwork.add(new Pair<Node, AndroidView>(rootElement, root));\nwhile (!work.isEmpty()) {\nPair<Node, AndroidView> p = work.removeFirst();\nNode node = p.getO1();\nAndroidView view = p.getO2();\nview.setOrigin(file);\nNamedNodeMap attrMap = node.getAttributes();\nif (attrMap == null) {\nLogger.verb(this.getClass().getSimpleName(), file + \"!!!\" + node.getClass() + \"!!!\"\n+ node.toString() + \"!!!\" + node.getTextContent());\n}\n\/\/ Retrieve view id (android:id)\n\/\/Node idNode = attrMap.getNamedItem(ID_ATTR);\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> pair = parseAndroidId(txt, isSys);\nid = pair.getO1();\nInteger guiIdObj = pair.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> pair = parseAndroidId(txt, isSys);\nid = pair.getO1();\nInteger guiIdObj = pair.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\n\nString txt = idNode.getTextContent();\nPair<String, Integer> pair = parseAndroidId(txt, isSys);\nid = pair.getO1();\nInteger guiIdObj = pair.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\n\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\n} else {\nguiId = guiIdObj.intValue();\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\n\nif (lookupNameInGeneralMap(\"id\", guiId, isSys) == null) {\nextraId2ViewMap.put(guiIdObj, view);\n}\n}\n}\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\nif (menuName != null) {\nPair<String, Integer> pair = parseAndroidId(menuName, isSys);\nInteger menuId = pair.getO2();\nif (menuId != null) {\nview.addAttr(AndroidView.Type.APP_MENU, String.valueOf(menuId));\nmenuId2View.put(menuId, view);\n\n\/\/ Retrieve view type\nString guiName = node.getNodeName();\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\nif (menuName != null) {\nPair<String, Integer> pair = parseAndroidId(menuName, isSys);\nInteger menuId = pair.getO2();\nif (menuId != null) {\nview.addAttr(AndroidView.Type.APP_MENU, String.valueOf(menuId));\nmenuId2View.put(menuId, view);\n}\n}\nif (attrMap.getNamedItem(\"app:headerLayout\") != null) {\nString headerName = attrMap.getNamedItem(\"app:headerLayout\").getTextContent();\nif (headerName != null) {\n\nif (\"view\".equals(guiName)) {\n\/\/ view without class attribute.\n\/\/ It does happen.\nif (attrMap.getNamedItem(\"class\") == null)\ncontinue;\nguiName = attrMap.getNamedItem(\"class\").getTextContent();\n} else if (guiName.equals(\"MenuItemView\")) {\n\/\/ FIXME(tony): this is an \"approximation\".\nguiName = \"android.view.MenuItem\";\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\n\/\/Retrieve callback (android:onClick)\nString callback = readAndroidCallback(attrMap, \"onClick\");\nif (callback != null) {\nview.setInlineClickHandler(callback);\n}\n\/\/ Retrieve text (android:text)\nString text = readAndroidTextOrTitle(attrMap, \"text\");\n\/\/ hailong: add hint support\n\/\/ Retrieve hint (android:hint)\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nif(attrMap.getNamedItem(\"app:menu\") != null){\nString menuName = attrMap.getNamedItem(\"app:menu\").getTextContent();\nif (menuName != null) {\nPair<String, Integer> pair = parseAndroidId(menuName, isSys);\nInteger menuId = pair.getO2();\nif (menuId != null) {\nview.addAttr(AndroidView.Type.APP_MENU, String.valueOf(menuId));\nmenuId2View.put(menuId, view);\n}\n}\nif (attrMap.getNamedItem(\"app:headerLayout\") != null) {\nString headerName = attrMap.getNamedItem(\"app:headerLayout\").getTextContent();\nif (headerName != null) {\nPair<String, Integer> pair = parseAndroidId(headerName, isSys);\nInteger headerId = pair.getO2();\nif (headerId != null) {\n\n}\nif (\"fragment\".equals(guiName)) {\nNode fragmentNodeAttr = attrMap.getNamedItem(\"android:name\");\nif (fragmentNodeAttr != null) {\nString fragmentClass = fragmentNodeAttr.getTextContent();\nif (fragmentClass.isEmpty()) {\nfragmentNodeAttr = attrMap.getNamedItem(\"class\");\nif (fragmentNodeAttr != null) {\nfragmentClass = fragmentNodeAttr.getTextContent();\n}\n}\nview.addAttr(AndroidView.Type.ANDROID_NAME, fragmentClass);\n}\n}\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nif (nodeName.equals(\"requestFocus\")) {\ncontinue;\n}\nif (!newNode.hasAttributes() && !\"TableRow\".equals(nodeName)\n&& !\"View\".equals(nodeName)) {\nLogger.warn(this.getClass().getSimpleName(),\n\"no attribute node \"\n+ newNode.getNodeName());\n\n}\n}\nview.addAttr(AndroidView.Type.ANDROID_NAME, fragmentClass);\n}\n}\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nif (nodeName.equals(\"requestFocus\")) {\ncontinue;\n}\nif (!newNode.hasAttributes() && !\"TableRow\".equals(nodeName)\n&& !\"View\".equals(nodeName)) {\nLogger.warn(this.getClass().getSimpleName(),\n\"no attribute node \"\n+ newNode.getNodeName());\ncontinue;\n}\nif (newNode.getNodeName().equals(\"include\")) {\nattrMap = newNode.getAttributes();\nif (attrMap.getNamedItem(\"layout\") == null) {\nLogger.warn(\"XML\", \"layout not exist in include\");\nfor (int j = 0; j < attrMap.getLength(); j++) {\nLogger.trace(\"XML\", attrMap.item(j).getNodeName());\n}\nLogger.trace(\"XML\", \"filename\" + file);\n\n+ layoutTxt + \",\" + file);\n}\nInteger includeeId = null;\nid = null;\nidNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> pair = parseAndroidId(txt, isSys);\nid = pair.getO1();\nInteger guiIdObj = pair.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id\n+ \" in \" + file);\n}\n} else {\nincludeeId = guiIdObj;\n}\n}\n\/\/ view.saveInclude(layoutId, includeeId);\nIncludeAndroidView iav = new IncludeAndroidView(layoutId, includeeId);\niav.setParent(view);\n} else {\nAndroidView newView = new AndroidView();\nnewView.setParent(view);\nwork.add(new Pair<Node, AndroidView>(newNode, newView));\n}\n}\n}\n}","label":[1,0,1,0]}
{"id":17637,"original_code":"private void readMenu(String file, AndroidView root, boolean isSys) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      dbFactory.setNamespaceAware(true);\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    LinkedList<Pair<Node, AndroidView>> worklist = Lists.newLinkedList();\n    worklist.add(new Pair<Node, AndroidView>(doc.getDocumentElement(), root));\n    root = null;\n    while (!worklist.isEmpty()) {\n      Pair<Node, AndroidView> pair = worklist.remove();\n      Node node = pair.getO1();\n      AndroidView view = pair.getO2();\n      NamedNodeMap attrMap = node.getAttributes();\n      Node idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n      int guiId = -1;\n      String id = null;\n      if (idNode != null) {\n        String txt = idNode.getTextContent();\n        Pair<String, Integer> p = parseAndroidId(txt, isSys);\n        id = p.getO1();\n        Integer guiIdObj = p.getO2();\n        if (guiIdObj == null) {\n          if (!isSys) {\n            Logger.warn(this.getClass().getSimpleName(),\n                    \"unresolved android:id \" + id + \" in \"\n                    + file);\n          }\n          guiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n          \/\/ we don't know its value\n          feedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/          if (isSys) {\n\/\/            sysRIdMap.put(id, guiId);\n\/\/            invSysRIdMap.put(guiId, id);\n\/\/          } else {\n\/\/            rIdMap.put(id, guiId);\n\/\/            invRIdMap.put(guiId, id);\n\/\/          }\n        } else {\n          guiId = guiIdObj.intValue();\n        }\n      }\n      \/\/ FIXME(tony): this is an \"approximation\"\n      String guiName = node.getNodeName();\n      if (guiName.equals(\"menu\")) {\n        guiName = \"android.view.Menu\";\n      } else if (guiName.equals(\"item\")) {\n        guiName = \"android.view.MenuItem\";\n        NodeList childNodes = node.getChildNodes();\n        if(childNodes!=null) {\n          for (int i = 0; i < childNodes.getLength(); i++) {\n            Node newNode = childNodes.item(i);\n            String nodeName = newNode.getNodeName();\n            if(\"menu\".equals(nodeName)) {\n              guiName = \"android.view.ViewGroup\";\n            }\n          }\n        }\n      } else if (guiName.equals(\"group\")) {\n        \/\/ TODO(tony): we might want to create a special fake class to\n        \/\/ represent menu groups. But for now, let's simply pretend it's\n        \/\/ a ViewGroup. Also, print a warning when we do see <group>\n        Logger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\n        guiName = \"android.view.ViewGroup\";\n      } else {\n        Logger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n        \/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n      }\n      if (debug) {\n        Logger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n      }\n      String text = readAndroidTextOrTitle(attrMap, \"title\");\n      \/\/ hailong: add hint support\n      String hint = readAndroidTextOrTitle(attrMap, \"hint\");\n      String autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n      \/\/view.save(guiId, text, hint, guiName);\n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n          \/\/ possible for XML files created on a different operating system\n          \/\/ than the one our analysis is run on\n          continue;\n        }\n        AndroidView newView = new AndroidView();\n        \/\/ FIXME: we assume that every node has attributes, may be wrong\n        if (!newNode.hasAttributes()) {\n          Logger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n          \/\/ continue;\n        } else {\n          NamedNodeMap attrs = newNode.getAttributes();\n          for (int idx = 0; idx < attrs.getLength(); idx += 1) {\n            Node attr = attrs.item(idx);\n            String name = attr.getNodeName();\n            String value = attr.getNodeValue();\n            newView.addAttr(name, value);\n          }\n        }\n        newView.setParent(view);\n        worklist.add(new Pair<Node, AndroidView>(newNode, newView));\n      }\n    }\n  }","code":"private void readMenu(String file, AndroidView root, boolean isSys) {\n    Document doc;\n    try {\n      DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();\n      dbFactory.setNamespaceAware(true);\n      DocumentBuilder dBuilder = dbFactory.newDocumentBuilder();\n      doc = dBuilder.parse(file);\n    } catch (Exception ex) {\n      throw new RuntimeException(ex);\n    }\n    LinkedList<Pair<Node, AndroidView>> worklist = Lists.newLinkedList();\n    worklist.add(new Pair<Node, AndroidView>(doc.getDocumentElement(), root));\n    root = null;\n    while (!worklist.isEmpty()) {\n      Pair<Node, AndroidView> pair = worklist.remove();\n      Node node = pair.getO1();\n      AndroidView view = pair.getO2();\n      NamedNodeMap attrMap = node.getAttributes();\n      Node idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\n      int guiId = -1;\n      String id = null;\n      if (idNode != null) {\n        String txt = idNode.getTextContent();\n        Pair<String, Integer> p = parseAndroidId(txt, isSys);\n        id = p.getO1();\n        Integer guiIdObj = p.getO2();\n        if (guiIdObj == null) {\n          if (!isSys) {\n            Logger.warn(this.getClass().getSimpleName(),\n                    \"unresolved android:id \" + id + \" in \"\n                    + file);\n          }\n          guiId = nonRId--;\n         \n          feedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n        } else {\n          guiId = guiIdObj.intValue();\n        }\n      }\n     \n      String guiName = node.getNodeName();\n      if (guiName.equals(\"menu\")) {\n        guiName = \"android.view.Menu\";\n      } else if (guiName.equals(\"item\")) {\n        guiName = \"android.view.MenuItem\";\n        NodeList childNodes = node.getChildNodes();\n        if(childNodes!=null) {\n          for (int i = 0; i < childNodes.getLength(); i++) {\n            Node newNode = childNodes.item(i);\n            String nodeName = newNode.getNodeName();\n            if(\"menu\".equals(nodeName)) {\n              guiName = \"android.view.ViewGroup\";\n            }\n          }\n        }\n      } else if (guiName.equals(\"group\")) {\n       \n       \n       \n        Logger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\n        guiName = \"android.view.ViewGroup\";\n      } else {\n        Logger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n       \n      }\n      if (debug) {\n        Logger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n      }\n      String text = readAndroidTextOrTitle(attrMap, \"title\");\n     \n      String hint = readAndroidTextOrTitle(attrMap, \"hint\");\n      String autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\n      String contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\n      if (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\n      else if (autofillHints != null) hint = autofillHints;\n      String images = readAndroidImageResource(attrMap);\n      view.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n     \n      NodeList children = node.getChildNodes();\n      for (int i = 0; i < children.getLength(); i++) {\n        Node newNode = children.item(i);\n        String nodeName = newNode.getNodeName();\n        if (\"#comment\".equals(nodeName)) {\n          continue;\n        }\n        if (\"#text\".equals(nodeName)) {\n         \n         \n          continue;\n        }\n        AndroidView newView = new AndroidView();\n       \n        if (!newNode.hasAttributes()) {\n          Logger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n         \n        } else {\n          NamedNodeMap attrs = newNode.getAttributes();\n          for (int idx = 0; idx < attrs.getLength(); idx += 1) {\n            Node attr = attrs.item(idx);\n            String name = attr.getNodeName();\n            String value = attr.getNodeValue();\n            newView.addAttr(name, value);\n          }\n        }\n        newView.setParent(view);\n        worklist.add(new Pair<Node, AndroidView>(newNode, newView));\n      }\n    }\n  }","cleancode":"private void readmenu(string file, androidview root, boolean issys) { document doc; try { documentbuilderfactory dbfactory = documentbuilderfactory.newinstance(); dbfactory.setnamespaceaware(true); documentbuilder dbuilder = dbfactory.newdocumentbuilder(); doc = dbuilder.parse(file); } catch (exception ex) { throw new runtimeexception(ex); } linkedlist<pair<node, androidview>> worklist = lists.newlinkedlist(); worklist.add(new pair<node, androidview>(doc.getdocumentelement(), root)); root = null; while (!worklist.isempty()) { pair<node, androidview> pair = worklist.remove(); node node = pair.geto1(); androidview view = pair.geto2(); namednodemap attrmap = node.getattributes(); node idnode = attrmap.getnameditemns(android_ns, \"id\"); int guiid = -1; string id = null; if (idnode != null) { string txt = idnode.gettextcontent(); pair<string, integer> p = parseandroidid(txt, issys); id = p.geto1(); integer guiidobj = p.geto2(); if (guiidobj == null) { if (!issys) { logger.warn(this.getclass().getsimplename(), \"unresolved android:id \" + id + \" in \" + file); } guiid = nonrid--; feedidintogeneralmap(\"id\", id, guiid, issys); } else { guiid = guiidobj.intvalue(); } } string guiname = node.getnodename(); if (guiname.equals(\"menu\")) { guiname = \"android.view.menu\"; } else if (guiname.equals(\"item\")) { guiname = \"android.view.menuitem\"; nodelist childnodes = node.getchildnodes(); if(childnodes!=null) { for (int i = 0; i < childnodes.getlength(); i++) { node newnode = childnodes.item(i); string nodename = newnode.getnodename(); if(\"menu\".equals(nodename)) { guiname = \"android.view.viewgroup\"; } } } } else if (guiname.equals(\"group\")) { logger.trace(this.getclass().getsimplename(), \"[todo] <group> used in \" + file); guiname = \"android.view.viewgroup\"; } else { logger.trace(\"xml\", \"unhandled menu tag \" + guiname); } if (debug) { logger.verb(this.getclass().getsimplename(), guiname + \" (\" + guiid + \", \" + id + \")\"); } string text = readandroidtextortitle(attrmap, \"title\"); string hint = readandroidtextortitle(attrmap, \"hint\"); string autofillhints = readandroidtextortitle(attrmap, \"autofillhints\"); if (hint != null && autofillhints != null) hint += propertymanager.separator + autofillhints; else if (autofillhints != null) hint = autofillhints; string tooltip = readandroidtextortitle(attrmap, \"tooltiptext\"); string contentdescription = readandroidtextortitle(attrmap, \"contentdescription\"); if (hint != null && autofillhints != null) hint += propertymanager.separator + autofillhints; else if (autofillhints != null) hint = autofillhints; string images = readandroidimageresource(attrmap); view.save(guiid, text, hint, tooltip, contentdescription, images, guiname); nodelist children = node.getchildnodes(); for (int i = 0; i < children.getlength(); i++) { node newnode = children.item(i); string nodename = newnode.getnodename(); if (\"#comment\".equals(nodename)) { continue; } if (\"#text\".equals(nodename)) { continue; } androidview newview = new androidview(); if (!newnode.hasattributes()) { logger.verb(\"warning\", \"xml node \" + newnode + \" has no attributes\"); } else { namednodemap attrs = newnode.getattributes(); for (int idx = 0; idx < attrs.getlength(); idx += 1) { node attr = attrs.item(idx); string name = attr.getnodename(); string value = attr.getnodevalue(); newview.addattr(name, value); } } newview.setparent(view); worklist.add(new pair<node, androidview>(newnode, newview)); } } }","comment":"\/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\n\/\/ if (issys) { \/\/ sysridmap.put(id, guiid); \/\/ invsysridmap.put(guiid, id); \/\/ } else { \/\/ ridmap.put(id, guiid); \/\/ invridmap.put(guiid, id); \/\/ }\n\/\/ fixme(tony): this is an \"approximation\"\n\/\/ todo(tony): we might want to create a special fake class to \/\/ represent menu groups. but for now, let's simply pretend it's \/\/ a viewgroup. also, print a warning when we do see <group>\n\/\/throw new runtimeexception(\"unhandled menu tag \" + guiname);\n\/\/ hailong: add hint support\n\/\/view.save(guiid, text, hint, guiname);\n\/\/ possible for xml files created on a different operating system \/\/ than the one our analysis is run on\n\/\/ fixme: we assume that every node has attributes, may be wrong\n\/\/ continue;","repo":"ttincs\/guibat","code_context_2":"+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\n\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\n\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\n\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\n\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\n\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();","code_context_10":"String txt = idNode.getTextContent();\nPair<String, Integer> p = parseAndroidId(txt, isSys);\nid = p.getO1();\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\n\nPair<String, Integer> p = parseAndroidId(txt, isSys);\nid = p.getO1();\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\n\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\n\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\n\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\n\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\n\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);","code_context_20":"root = null;\nwhile (!worklist.isEmpty()) {\nPair<Node, AndroidView> pair = worklist.remove();\nNode node = pair.getO1();\nAndroidView view = pair.getO2();\nNamedNodeMap attrMap = node.getAttributes();\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> p = parseAndroidId(txt, isSys);\nid = p.getO1();\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\n\nwhile (!worklist.isEmpty()) {\nPair<Node, AndroidView> pair = worklist.remove();\nNode node = pair.getO1();\nAndroidView view = pair.getO2();\nNamedNodeMap attrMap = node.getAttributes();\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> p = parseAndroidId(txt, isSys);\nid = p.getO1();\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\n\nNode node = pair.getO1();\nAndroidView view = pair.getO2();\nNamedNodeMap attrMap = node.getAttributes();\nNode idNode = attrMap.getNamedItemNS(ANDROID_NS, \"id\");\nint guiId = -1;\nString id = null;\nif (idNode != null) {\nString txt = idNode.getTextContent();\nPair<String, Integer> p = parseAndroidId(txt, isSys);\nid = p.getO1();\nInteger guiIdObj = p.getO2();\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n\nif (guiIdObj == null) {\nif (!isSys) {\nLogger.warn(this.getClass().getSimpleName(),\n\"unresolved android:id \" + id + \" in \"\n+ file);\n}\nguiId = nonRId--; \/\/ negative value to indicate it is a unique id but\n\/\/ we don't know its value\nfeedIdIntoGeneralMap(\"id\", id, guiId, isSys);\n\/\/ if (isSys) {\n\/\/ sysRIdMap.put(id, guiId);\n\/\/ invSysRIdMap.put(guiId, id);\n\/\/ } else {\n\/\/ rIdMap.put(id, guiId);\n\/\/ invRIdMap.put(guiId, id);\n\/\/ }\n} else {\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\n\nguiId = guiIdObj.intValue();\n}\n}\n\/\/ FIXME(tony): this is an \"approximation\"\nString guiName = node.getNodeName();\nif (guiName.equals(\"menu\")) {\nguiName = \"android.view.Menu\";\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\n\n} else if (guiName.equals(\"item\")) {\nguiName = \"android.view.MenuItem\";\nNodeList childNodes = node.getChildNodes();\nif(childNodes!=null) {\nfor (int i = 0; i < childNodes.getLength(); i++) {\nNode newNode = childNodes.item(i);\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\n\nString nodeName = newNode.getNodeName();\nif(\"menu\".equals(nodeName)) {\nguiName = \"android.view.ViewGroup\";\n}\n}\n}\n} else if (guiName.equals(\"group\")) {\n\/\/ TODO(tony): we might want to create a special fake class to\n\/\/ represent menu groups. But for now, let's simply pretend it's\n\/\/ a ViewGroup. Also, print a warning when we do see <group>\nLogger.trace(this.getClass().getSimpleName(), \"[TODO] <group> used in \" + file);\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\nguiName = \"android.view.ViewGroup\";\n} else {\nLogger.trace(\"XML\", \"Unhandled menu tag \" + guiName);\n\/\/throw new RuntimeException(\"Unhandled menu tag \" + guiName);\n}\nif (debug) {\nLogger.verb(this.getClass().getSimpleName(), guiName + \" (\" + guiId + \", \" + id + \")\");\n}\nString text = readAndroidTextOrTitle(attrMap, \"title\");\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\n\n\/\/ hailong: add hint support\nString hint = readAndroidTextOrTitle(attrMap, \"hint\");\nString autofillHints = readAndroidTextOrTitle(attrMap, \"autofillHints\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nworklist.add(new Pair<Node, AndroidView>(newNode, newView));\n}\n}\n\nString tooltip = readAndroidTextOrTitle(attrMap, \"tooltipText\");\nString contentDescription = readAndroidTextOrTitle(attrMap, \"contentDescription\");\nif (hint != null && autofillHints != null) hint += PropertyManager.SEPARATOR + autofillHints;\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nworklist.add(new Pair<Node, AndroidView>(newNode, newView));\n}\n}\n}\n\nelse if (autofillHints != null) hint = autofillHints;\nString images = readAndroidImageResource(attrMap);\nview.save(guiId, text, hint, tooltip, contentDescription, images, guiName);\n\/\/view.save(guiId, text, hint, guiName);\nNodeList children = node.getChildNodes();\nfor (int i = 0; i < children.getLength(); i++) {\nNode newNode = children.item(i);\nString nodeName = newNode.getNodeName();\nif (\"#comment\".equals(nodeName)) {\ncontinue;\n}\nif (\"#text\".equals(nodeName)) {\n\/\/ possible for XML files created on a different operating system\n\/\/ than the one our analysis is run on\ncontinue;\n}\nAndroidView newView = new AndroidView();\n\/\/ FIXME: we assume that every node has attributes, may be wrong\nif (!newNode.hasAttributes()) {\nLogger.verb(\"WARNING\", \"xml node \" + newNode + \" has no attributes\");\n\/\/ continue;\n} else {\nNamedNodeMap attrs = newNode.getAttributes();\nfor (int idx = 0; idx < attrs.getLength(); idx += 1) {\nNode attr = attrs.item(idx);\nString name = attr.getNodeName();\nString value = attr.getNodeValue();\nnewView.addAttr(name, value);\n}\n}\nnewView.setParent(view);\nworklist.add(new Pair<Node, AndroidView>(newNode, newView));\n}\n}\n}","label":[1,0,1,0]}
{"id":34021,"original_code":"public static Color getColorByName(String colorName) {\n        switch (colorName.toLowerCase()) {\n        case COLOR_BLUE:\n            return Color.blue;\n        case COLOR_CYAN:\n            return Color.cyan;\n        case COLOR_DARKGRAY:\n        case COLOR_DARKGREY:\n            return Color.darkGray;\n        case COLOR_GRAY:\n        case COLOR_GREY:\n            return Color.gray;\n        case COLOR_LIGHTGRAY:\n        case COLOR_LIGHTGREY:\n            return Color.lightGray;\n        case COLOR_GREEN:\n            return Color.green;\n        case COLOR_MAGENTA:\n            return Color.magenta;\n        case COLOR_ORANGE:\n            return Color.orange;\n        case COLOR_PINK:\n            return Color.pink;\n        case COLOR_RED:\n            return Color.red;\n        case COLOR_WHITE:\n            return Color.white;\n        case COLOR_YELLOW:\n            return Color.yellow;\n        case COLOR_BLACK:\n        default:\n            return Color.black;\n        }\n    }","code":"public static Color getColorByName(String colorName) {\n        switch (colorName.toLowerCase()) {\n        case COLOR_BLUE:\n            return Color.blue;\n        case COLOR_CYAN:\n            return Color.cyan;\n        case COLOR_DARKGRAY:\n        case COLOR_DARKGREY:\n            return Color.darkGray;\n        case COLOR_GRAY:\n        case COLOR_GREY:\n            return Color.gray;\n        case COLOR_LIGHTGRAY:\n        case COLOR_LIGHTGREY:\n            return Color.lightGray;\n        case COLOR_GREEN:\n            return Color.green;\n        case COLOR_MAGENTA:\n            return Color.magenta;\n        case COLOR_ORANGE:\n            return Color.orange;\n        case COLOR_PINK:\n            return Color.pink;\n        case COLOR_RED:\n            return Color.red;\n        case COLOR_WHITE:\n            return Color.white;\n        case COLOR_YELLOW:\n            return Color.yellow;\n        case COLOR_BLACK:\n        default:\n            return Color.black;\n        }\n    }","cleancode":"public static color getcolorbyname(string colorname) { switch (colorname.tolowercase()) { case color_blue: return color.blue; case color_cyan: return color.cyan; case color_darkgray: case color_darkgrey: return color.darkgray; case color_gray: case color_grey: return color.gray; case color_lightgray: case color_lightgrey: return color.lightgray; case color_green: return color.green; case color_magenta: return color.magenta; case color_orange: return color.orange; case color_pink: return color.pink; case color_red: return color.red; case color_white: return color.white; case color_yellow: return color.yellow; case color_black: default: return color.black; } }","comment":"\/** * convert a color name to a color value. * @param colorname a string repr of the color. * @return the color value. * @todo refactor to use an enumeratedattribute (maybe?) *\/","repo":"yaohuizhou\/attpg","code_context_2":"public static Color getColorByName(String colorName) {\nswitch (colorName.toLowerCase()) {\ncase COLOR_BLUE:\nreturn Color.blue;\ncase COLOR_CYAN:\nreturn Color.cyan;\ncase COLOR_DARKGRAY:\ncase COLOR_DARKGREY:\nreturn Color.darkGray;\ncase COLOR_GRAY:\ncase COLOR_GREY:\nreturn Color.gray;\ncase COLOR_LIGHTGRAY:\ncase COLOR_LIGHTGREY:\nreturn Color.lightGray;\ncase COLOR_GREEN:\nreturn Color.green;\ncase COLOR_MAGENTA:\nreturn Color.magenta;\ncase COLOR_ORANGE:\nreturn Color.orange;\ncase COLOR_PINK:\nreturn Color.pink;\ncase COLOR_RED:\nreturn Color.red;\ncase COLOR_WHITE:\nreturn Color.white;\ncase COLOR_YELLOW:\nreturn Color.yellow;\ncase COLOR_BLACK:\ndefault:\nreturn Color.black;\n}\n}","code_context_10":"public static Color getColorByName(String colorName) {\nswitch (colorName.toLowerCase()) {\ncase COLOR_BLUE:\nreturn Color.blue;\ncase COLOR_CYAN:\nreturn Color.cyan;\ncase COLOR_DARKGRAY:\ncase COLOR_DARKGREY:\nreturn Color.darkGray;\ncase COLOR_GRAY:\ncase COLOR_GREY:\nreturn Color.gray;\ncase COLOR_LIGHTGRAY:\ncase COLOR_LIGHTGREY:\nreturn Color.lightGray;\ncase COLOR_GREEN:\nreturn Color.green;\ncase COLOR_MAGENTA:\nreturn Color.magenta;\ncase COLOR_ORANGE:\nreturn Color.orange;\ncase COLOR_PINK:\nreturn Color.pink;\ncase COLOR_RED:\nreturn Color.red;\ncase COLOR_WHITE:\nreturn Color.white;\ncase COLOR_YELLOW:\nreturn Color.yellow;\ncase COLOR_BLACK:\ndefault:\nreturn Color.black;\n}\n}","code_context_20":"public static Color getColorByName(String colorName) {\nswitch (colorName.toLowerCase()) {\ncase COLOR_BLUE:\nreturn Color.blue;\ncase COLOR_CYAN:\nreturn Color.cyan;\ncase COLOR_DARKGRAY:\ncase COLOR_DARKGREY:\nreturn Color.darkGray;\ncase COLOR_GRAY:\ncase COLOR_GREY:\nreturn Color.gray;\ncase COLOR_LIGHTGRAY:\ncase COLOR_LIGHTGREY:\nreturn Color.lightGray;\ncase COLOR_GREEN:\nreturn Color.green;\ncase COLOR_MAGENTA:\nreturn Color.magenta;\ncase COLOR_ORANGE:\nreturn Color.orange;\ncase COLOR_PINK:\nreturn Color.pink;\ncase COLOR_RED:\nreturn Color.red;\ncase COLOR_WHITE:\nreturn Color.white;\ncase COLOR_YELLOW:\nreturn Color.yellow;\ncase COLOR_BLACK:\ndefault:\nreturn Color.black;\n}\n}","label":[1,0,0,0]}
{"id":34026,"original_code":"public View getView(int position, View convertView, ViewGroup parent)\n    {\n        mView = convertView;\n        if (mView == null)\n        {\n            LayoutInflater viewInflator;\n            viewInflator = LayoutInflater.from(mContext);\n            mView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n        }\n        \/\/TODO add a view holder\n        mCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\n        mCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\n        mCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\n        if(mCategoryList.get(position) != null)\n        {\n            String valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\n            int resIndex = mCategoryList.get(position).mFirstField;\n            int resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\n            mCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\n            mCategoryImageView.setImageResource(resource);\n            mCategorySum.setText(valueStr);\n        }\n        return mView;\n    }","code":"public View getView(int position, View convertView, ViewGroup parent)\n    {\n        mView = convertView;\n        if (mView == null)\n        {\n            LayoutInflater viewInflator;\n            viewInflator = LayoutInflater.from(mContext);\n            mView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n        }\n       \n        mCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\n        mCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\n        mCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\n        if(mCategoryList.get(position) != null)\n        {\n            String valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\n            int resIndex = mCategoryList.get(position).mFirstField;\n            int resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\n            mCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\n            mCategoryImageView.setImageResource(resource);\n            mCategorySum.setText(valueStr);\n        }\n        return mView;\n    }","cleancode":"public view getview(int position, view convertview, viewgroup parent) { mview = convertview; if (mview == null) { layoutinflater viewinflator; viewinflator = layoutinflater.from(mcontext); mview = viewinflator.inflate(r.layout.adapter_category_tile, null); } mcaptiontextview = (textview) mview.findviewbyid(r.id.month_analytics_top_category_name); mcategoryimageview = (imageview) mview.findviewbyid(r.id.month_analytics_top_category_image); mcategorysum = (textview) mview.findviewbyid(r.id.month_analytics_top_category_sum); if(mcategorylist.get(position) != null) { string valuestr = utils.sumascurrency(mcategorylist.get(position).msecondfield); int resindex = mcategorylist.get(position).mfirstfield; int resource = images.getimagebyposition(resindex, images.getunsorted()); mcaptiontextview.settext(images.getcaptionbyimage(resource, images.getsorted())); mcategoryimageview.setimageresource(resource); mcategorysum.settext(valuestr); } return mview; }","comment":"\/** *\/\n\/\/todo add a view holder","repo":"zonnie\/Coins","code_context_2":"public View getView(int position, View convertView, ViewGroup parent)\n{\nmView = convertView;\nif (mView == null)\n{\nLayoutInflater viewInflator;\nviewInflator = LayoutInflater.from(mContext);\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\nmCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\nif(mCategoryList.get(position) != null)\n{\nString valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\nint resIndex = mCategoryList.get(position).mFirstField;\nint resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\nmCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\nmCategoryImageView.setImageResource(resource);\nmCategorySum.setText(valueStr);\n}\nreturn mView;\n}\n\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);","code_context_10":"public View getView(int position, View convertView, ViewGroup parent)\n{\nmView = convertView;\nif (mView == null)\n{\nLayoutInflater viewInflator;\nviewInflator = LayoutInflater.from(mContext);\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\nmCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\nif(mCategoryList.get(position) != null)\n{\nString valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\nint resIndex = mCategoryList.get(position).mFirstField;\nint resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\nmCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\nmCategoryImageView.setImageResource(resource);\nmCategorySum.setText(valueStr);\n}\nreturn mView;\n}\n\npublic View getView(int position, View convertView, ViewGroup parent)\n{\nmView = convertView;\nif (mView == null)\n{\nLayoutInflater viewInflator;\nviewInflator = LayoutInflater.from(mContext);\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\nmCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\nif(mCategoryList.get(position) != null)\n{\nString valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\nint resIndex = mCategoryList.get(position).mFirstField;\nint resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\nmCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\nmCategoryImageView.setImageResource(resource);","code_context_20":"public View getView(int position, View convertView, ViewGroup parent)\n{\nmView = convertView;\nif (mView == null)\n{\nLayoutInflater viewInflator;\nviewInflator = LayoutInflater.from(mContext);\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\nmCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\nif(mCategoryList.get(position) != null)\n{\nString valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\nint resIndex = mCategoryList.get(position).mFirstField;\nint resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\nmCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\nmCategoryImageView.setImageResource(resource);\nmCategorySum.setText(valueStr);\n}\nreturn mView;\n}\n\npublic View getView(int position, View convertView, ViewGroup parent)\n{\nmView = convertView;\nif (mView == null)\n{\nLayoutInflater viewInflator;\nviewInflator = LayoutInflater.from(mContext);\nmView = viewInflator.inflate(R.layout.adapter_category_tile, null);\n}\n\/\/TODO add a view holder\nmCaptionTextView = (TextView) mView.findViewById(R.id.month_analytics_top_category_name);\nmCategoryImageView = (ImageView) mView.findViewById(R.id.month_analytics_top_category_image);\nmCategorySum = (TextView) mView.findViewById(R.id.month_analytics_top_category_sum);\nif(mCategoryList.get(position) != null)\n{\nString valueStr = Utils.sumAsCurrency(mCategoryList.get(position).mSecondField);\nint resIndex = mCategoryList.get(position).mFirstField;\nint resource = Images.getImageByPosition(resIndex, Images.getUnsorted());\nmCaptionTextView.setText(Images.getCaptionByImage(resource, Images.getSorted()));\nmCategoryImageView.setImageResource(resource);\nmCategorySum.setText(valueStr);\n}\nreturn mView;\n}","label":[0,1,0,0]}
{"id":9519,"original_code":"protected static Response scoreOne(Frame frame, Model score_model) {\n    water.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\n    if (null == metrics) {\n      \/\/ have to compute\n      water.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\n      long before = System.currentTimeMillis();\n      Frame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\n      long after = System.currentTimeMillis();\n      ConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\n      AUC auc = null;\n      HitRatio hr = null;\n      if (score_model.isClassifier()) {\n        auc = new AUC();\n\/\/      hr = new HitRatio();\n        score_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\n                                      true, 20, cm, auc, hr);\n      } else {\n        score_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\n                                      true, 20, cm, null, null);\n      }\n      \/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\n      metrics = new water.ModelMetrics(score_model.getUniqueId(),\n                                       score_model.getModelCategory(),\n                                       frame.getUniqueId(),\n                                       after - before,\n                                       after,\n                                       auc,\n                                       cm);\n      \/\/ Put the metrics into the KV store\n      metrics.putInDKV();\n    } else {\n      \/\/ it's already cached in the DKV\n      water.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n    }\n    JsonObject metricsJson = metrics.toJSON();\n    JsonArray metricsArray = new JsonArray();\n    metricsArray.add(metricsJson);\n    JsonObject result = new JsonObject();\n    result.add(\"metrics\", metricsArray);\n    return Response.done(result);\n  }","code":"protected static Response scoreOne(Frame frame, Model score_model) {\n    water.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\n    if (null == metrics) {\n     \n      water.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\n      long before = System.currentTimeMillis();\n      Frame predictions = score_model.score(frame, true);\n      long after = System.currentTimeMillis();\n      ConfusionMatrix cm = new ConfusionMatrix();\n      AUC auc = null;\n      HitRatio hr = null;\n      if (score_model.isClassifier()) {\n        auc = new AUC();\n        score_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\n                                      true, 20, cm, auc, hr);\n      } else {\n        score_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\n                                      true, 20, cm, null, null);\n      }\n     \n      metrics = new water.ModelMetrics(score_model.getUniqueId(),\n                                       score_model.getModelCategory(),\n                                       frame.getUniqueId(),\n                                       after - before,\n                                       after,\n                                       auc,\n                                       cm);\n     \n      metrics.putInDKV();\n    } else {\n     \n      water.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n    }\n    JsonObject metricsJson = metrics.toJSON();\n    JsonArray metricsArray = new JsonArray();\n    metricsArray.add(metricsJson);\n    JsonObject result = new JsonObject();\n    result.add(\"metrics\", metricsArray);\n    return Response.done(result);\n  }","cleancode":"protected static response scoreone(frame frame, model score_model) { water.modelmetrics metrics = water.modelmetrics.getfromdkv(score_model, frame); if (null == metrics) { water.util.log.debug(\"cache miss: computing modelmetrics. . .\"); long before = system.currenttimemillis(); frame predictions = score_model.score(frame, true); long after = system.currenttimemillis(); confusionmatrix cm = new confusionmatrix(); auc auc = null; hitratio hr = null; if (score_model.isclassifier()) { auc = new auc(); score_model.calcerror(frame, frame.vec(score_model.responsename()), predictions, predictions, \"prediction error:\", true, 20, cm, auc, hr); } else { score_model.calcerror(frame, frame.vec(score_model.responsename()), predictions, predictions, \"prediction error:\", true, 20, cm, null, null); } metrics = new water.modelmetrics(score_model.getuniqueid(), score_model.getmodelcategory(), frame.getuniqueid(), after - before, after, auc, cm); metrics.putindkv(); } else { water.util.log.debug(\"using modelmetrics from the cache. . .\"); } jsonobject metricsjson = metrics.tojson(); jsonarray metricsarray = new jsonarray(); metricsarray.add(metricsjson); jsonobject result = new jsonobject(); result.add(\"metrics\", metricsarray); return response.done(result); }","comment":"\/** * score a frame with the given model. *\/\n\/\/ have to compute\n\/\/ todo: for now we're always calling adapt inside score\n\/\/ for regression this computes the mse\n\/\/ hr = new hitratio();\n\/\/ now call auc and confusionmatrix and maybe hitratio\n\/\/ put the metrics into the kv store\n\/\/ it's already cached in the dkv","repo":"vkuznet\/h2o","code_context_2":"protected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}\n\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\n\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\n\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\n\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\n\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}","code_context_10":"protected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\n\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\n\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}","code_context_20":"protected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\n\nprotected static Response scoreOne(Frame frame, Model score_model) {\nwater.ModelMetrics metrics = water.ModelMetrics.getFromDKV(score_model, frame);\nif (null == metrics) {\n\/\/ have to compute\nwater.util.Log.debug(\"Cache miss: computing ModelMetrics. . .\");\nlong before = System.currentTimeMillis();\nFrame predictions = score_model.score(frame, true); \/\/ TODO: for now we're always calling adapt inside score\nlong after = System.currentTimeMillis();\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}\n\nConfusionMatrix cm = new ConfusionMatrix(); \/\/ for regression this computes the MSE\nAUC auc = null;\nHitRatio hr = null;\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}\n\nif (score_model.isClassifier()) {\nauc = new AUC();\n\/\/ hr = new HitRatio();\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, auc, hr);\n} else {\nscore_model.calcError(frame, frame.vec(score_model.responseName()), predictions, predictions, \"Prediction error:\",\ntrue, 20, cm, null, null);\n}\n\/\/ Now call AUC and ConfusionMatrix and maybe HitRatio\nmetrics = new water.ModelMetrics(score_model.getUniqueId(),\nscore_model.getModelCategory(),\nframe.getUniqueId(),\nafter - before,\nafter,\nauc,\ncm);\n\/\/ Put the metrics into the KV store\nmetrics.putInDKV();\n} else {\n\/\/ it's already cached in the DKV\nwater.util.Log.debug(\"using ModelMetrics from the cache. . .\");\n}\nJsonObject metricsJson = metrics.toJSON();\nJsonArray metricsArray = new JsonArray();\nmetricsArray.add(metricsJson);\nJsonObject result = new JsonObject();\nresult.add(\"metrics\", metricsArray);\nreturn Response.done(result);\n}","label":[1,0,0,0]}
{"id":17712,"original_code":"public Range<Token> getRange(ByteBuffer key)\n    {\n        \/\/ TODO: naive linear search of the token map\n        Token<?> t = partitioner.getToken(key);\n        for (Range<Token> range : rangeMap.keySet())\n            if (range.contains(t))\n                return range;\n        throw new RuntimeException(\"Invalid token information returned by describe_ring: \" + rangeMap);\n    }","code":"public Range<Token> getRange(ByteBuffer key)\n    {\n       \n        Token<?> t = partitioner.getToken(key);\n        for (Range<Token> range : rangeMap.keySet())\n            if (range.contains(t))\n                return range;\n        throw new RuntimeException(\"Invalid token information returned by describe_ring: \" + rangeMap);\n    }","cleancode":"public range<token> getrange(bytebuffer key) { token<?> t = partitioner.gettoken(key); for (range<token> range : rangemap.keyset()) if (range.contains(t)) return range; throw new runtimeexception(\"invalid token information returned by describe_ring: \" + rangemap); }","comment":"\/\/ todo: naive linear search of the token map","repo":"tadeegan\/eiger-application-aware","code_context_2":"public Range<Token> getRange(ByteBuffer key)\n{\n\/\/ TODO: naive linear search of the token map\nToken<?> t = partitioner.getToken(key);\nfor (Range<Token> range : rangeMap.keySet())","code_context_10":"public Range<Token> getRange(ByteBuffer key)\n{\n\/\/ TODO: naive linear search of the token map\nToken<?> t = partitioner.getToken(key);\nfor (Range<Token> range : rangeMap.keySet())\nif (range.contains(t))\nreturn range;\nthrow new RuntimeException(\"Invalid token information returned by describe_ring: \" + rangeMap);\n}","code_context_20":"public Range<Token> getRange(ByteBuffer key)\n{\n\/\/ TODO: naive linear search of the token map\nToken<?> t = partitioner.getToken(key);\nfor (Range<Token> range : rangeMap.keySet())\nif (range.contains(t))\nreturn range;\nthrow new RuntimeException(\"Invalid token information returned by describe_ring: \" + rangeMap);\n}","label":[0,1,0,0]}
{"id":17718,"original_code":"private void populateSignatureNames() {\n        if (acroForm == null) {\n            return;\n        }\n        List<Object[]> sorter = new ArrayList<>();\n        for (Map.Entry<String, PdfFormField> entry : acroForm.getFormFields().entrySet()) {\n            PdfFormField field = entry.getValue();\n            PdfDictionary merged = field.getPdfObject();\n            if (!PdfName.Sig.equals(merged.get(PdfName.FT)))\n                continue;\n            PdfDictionary v = merged.getAsDictionary(PdfName.V);\n            if (v == null)\n                continue;\n            PdfString contents = v.getAsString(PdfName.Contents);\n            if (contents == null) {\n                continue;\n            } else {\n                contents.markAsUnencryptedObject();\n            }\n            PdfArray ro = v.getAsArray(PdfName.ByteRange);\n            if (ro == null)\n                continue;\n            int rangeSize = ro.size();\n            if (rangeSize < 2)\n                continue;\n            int length = ro.getAsNumber(rangeSize - 1).intValue() + ro.getAsNumber(rangeSize - 2).intValue();\n            sorter.add(new Object[]{entry.getKey(), new int[]{length, 0}});\n        }\n        Collections.sort(sorter, new SorterComparator());\n        if (sorter.size() > 0) {\n            try {\n                if (((int[]) sorter.get(sorter.size() - 1)[1])[0] == document.getReader().getFileLength())\n                    totalRevisions = sorter.size();\n                else\n                    totalRevisions = sorter.size() + 1;\n            } catch (IOException e) {\n                \/\/ TODO: add exception handling (at least some logger)\n            }\n            for (int k = 0; k < sorter.size(); ++k) {\n                Object[] objs = sorter.get(k);\n                String name = (String) objs[0];\n                int[] p = (int[]) objs[1];\n                p[1] = k + 1;\n                sigNames.put(name, p);\n                orderedSignatureNames.add(name);\n            }\n        }\n    }","code":"private void populateSignatureNames() {\n        if (acroForm == null) {\n            return;\n        }\n        List<Object[]> sorter = new ArrayList<>();\n        for (Map.Entry<String, PdfFormField> entry : acroForm.getFormFields().entrySet()) {\n            PdfFormField field = entry.getValue();\n            PdfDictionary merged = field.getPdfObject();\n            if (!PdfName.Sig.equals(merged.get(PdfName.FT)))\n                continue;\n            PdfDictionary v = merged.getAsDictionary(PdfName.V);\n            if (v == null)\n                continue;\n            PdfString contents = v.getAsString(PdfName.Contents);\n            if (contents == null) {\n                continue;\n            } else {\n                contents.markAsUnencryptedObject();\n            }\n            PdfArray ro = v.getAsArray(PdfName.ByteRange);\n            if (ro == null)\n                continue;\n            int rangeSize = ro.size();\n            if (rangeSize < 2)\n                continue;\n            int length = ro.getAsNumber(rangeSize - 1).intValue() + ro.getAsNumber(rangeSize - 2).intValue();\n            sorter.add(new Object[]{entry.getKey(), new int[]{length, 0}});\n        }\n        Collections.sort(sorter, new SorterComparator());\n        if (sorter.size() > 0) {\n            try {\n                if (((int[]) sorter.get(sorter.size() - 1)[1])[0] == document.getReader().getFileLength())\n                    totalRevisions = sorter.size();\n                else\n                    totalRevisions = sorter.size() + 1;\n            } catch (IOException e) {\n               \n            }\n            for (int k = 0; k < sorter.size(); ++k) {\n                Object[] objs = sorter.get(k);\n                String name = (String) objs[0];\n                int[] p = (int[]) objs[1];\n                p[1] = k + 1;\n                sigNames.put(name, p);\n                orderedSignatureNames.add(name);\n            }\n        }\n    }","cleancode":"private void populatesignaturenames() { if (acroform == null) { return; } list<object[]> sorter = new arraylist<>(); for (map.entry<string, pdfformfield> entry : acroform.getformfields().entryset()) { pdfformfield field = entry.getvalue(); pdfdictionary merged = field.getpdfobject(); if (!pdfname.sig.equals(merged.get(pdfname.ft))) continue; pdfdictionary v = merged.getasdictionary(pdfname.v); if (v == null) continue; pdfstring contents = v.getasstring(pdfname.contents); if (contents == null) { continue; } else { contents.markasunencryptedobject(); } pdfarray ro = v.getasarray(pdfname.byterange); if (ro == null) continue; int rangesize = ro.size(); if (rangesize < 2) continue; int length = ro.getasnumber(rangesize - 1).intvalue() + ro.getasnumber(rangesize - 2).intvalue(); sorter.add(new object[]{entry.getkey(), new int[]{length, 0}}); } collections.sort(sorter, new sortercomparator()); if (sorter.size() > 0) { try { if (((int[]) sorter.get(sorter.size() - 1)[1])[0] == document.getreader().getfilelength()) totalrevisions = sorter.size(); else totalrevisions = sorter.size() + 1; } catch (ioexception e) { } for (int k = 0; k < sorter.size(); ++k) { object[] objs = sorter.get(k); string name = (string) objs[0]; int[] p = (int[]) objs[1]; p[1] = k + 1; signames.put(name, p); orderedsignaturenames.add(name); } } }","comment":"\/\/ todo: add exception handling (at least some logger)","repo":"tompecina\/itext7","code_context_2":"totalRevisions = sorter.size() + 1;\n} catch (IOException e) {\n\/\/ TODO: add exception handling (at least some logger)\n}\nfor (int k = 0; k < sorter.size(); ++k) {","code_context_10":"sorter.add(new Object[]{entry.getKey(), new int[]{length, 0}});\n}\nCollections.sort(sorter, new SorterComparator());\nif (sorter.size() > 0) {\ntry {\nif (((int[]) sorter.get(sorter.size() - 1)[1])[0] == document.getReader().getFileLength())\ntotalRevisions = sorter.size();\nelse\ntotalRevisions = sorter.size() + 1;\n} catch (IOException e) {\n\/\/ TODO: add exception handling (at least some logger)\n}\nfor (int k = 0; k < sorter.size(); ++k) {\nObject[] objs = sorter.get(k);\nString name = (String) objs[0];\nint[] p = (int[]) objs[1];\np[1] = k + 1;\nsigNames.put(name, p);\norderedSignatureNames.add(name);\n}\n}","code_context_20":"} else {\ncontents.markAsUnencryptedObject();\n}\nPdfArray ro = v.getAsArray(PdfName.ByteRange);\nif (ro == null)\ncontinue;\nint rangeSize = ro.size();\nif (rangeSize < 2)\ncontinue;\nint length = ro.getAsNumber(rangeSize - 1).intValue() + ro.getAsNumber(rangeSize - 2).intValue();\nsorter.add(new Object[]{entry.getKey(), new int[]{length, 0}});\n}\nCollections.sort(sorter, new SorterComparator());\nif (sorter.size() > 0) {\ntry {\nif (((int[]) sorter.get(sorter.size() - 1)[1])[0] == document.getReader().getFileLength())\ntotalRevisions = sorter.size();\nelse\ntotalRevisions = sorter.size() + 1;\n} catch (IOException e) {\n\/\/ TODO: add exception handling (at least some logger)\n}\nfor (int k = 0; k < sorter.size(); ++k) {\nObject[] objs = sorter.get(k);\nString name = (String) objs[0];\nint[] p = (int[]) objs[1];\np[1] = k + 1;\nsigNames.put(name, p);\norderedSignatureNames.add(name);\n}\n}\n}","label":[0,1,0,0]}
{"id":25939,"original_code":"public void setEnumsSet(Map<String, Set<Object>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n    Map<String, List<Object>> enumsList = Maps.newHashMap();\n    \/\/Check that all the given keys are valid\n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n    \/\/Todo check the type of the objects, for now just set them on the enum.\n    for (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\n      String name = entry.getKey();\n      Set<Object> vals = entry.getValue();\n      Preconditions.checkNotNull(name);\n      Preconditions.checkNotNull(vals);\n      for (Object value : entry.getValue()) {\n        Preconditions.checkNotNull(value);\n      }\n      List<Object> valsList = Lists.newArrayList(vals);\n      enumsList.put(name, valsList);\n    }\n    currentEnumVals = Maps.newHashMap(enumsList);\n  }","code":"public void setEnumsSet(Map<String, Set<Object>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n    Map<String, List<Object>> enumsList = Maps.newHashMap();\n   \n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n   \n    for (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\n      String name = entry.getKey();\n      Set<Object> vals = entry.getValue();\n      Preconditions.checkNotNull(name);\n      Preconditions.checkNotNull(vals);\n      for (Object value : entry.getValue()) {\n        Preconditions.checkNotNull(value);\n      }\n      List<Object> valsList = Lists.newArrayList(vals);\n      enumsList.put(name, valsList);\n    }\n    currentEnumVals = Maps.newHashMap(enumsList);\n  }","cleancode":"public void setenumsset(map<string, set<object>> enums) { preconditions.checknotnull(enums); areenumsupdated = true; map<string, list<object>> enumslist = maps.newhashmap(); preconditions.checkargument( configurationschema.getkeydescriptor().getfields().getfields().containsall(enums.keyset()), \"the given map doesn't contain valid keys. valid keys are %s and the provided keys are %s\", configurationschema.getkeydescriptor().getfields().getfields(), enums.keyset()); for (map.entry<string, set<object>> entry : enums.entryset()) { string name = entry.getkey(); set<object> vals = entry.getvalue(); preconditions.checknotnull(name); preconditions.checknotnull(vals); for (object value : entry.getvalue()) { preconditions.checknotnull(value); } list<object> valslist = lists.newarraylist(vals); enumslist.put(name, valslist); } currentenumvals = maps.newhashmap(enumslist); }","comment":"\/** * sets the new enum lists for this schema. the sets in the provided maps are converted into lists. * * @param enums the new enum sets for this schema. *\/\n\/\/check that all the given keys are valid\n\/\/todo check the type of the objects, for now just set them on the enum.","repo":"vijaysbhat\/apex-malhar","code_context_2":"public void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();","code_context_10":"public void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\npublic void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\n\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);","code_context_20":"public void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\npublic void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\npublic void setEnumsSet(Map<String, Set<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Object>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Object> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Object> valsList = Lists.newArrayList(vals);\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}","label":[0,1,0,0]}
{"id":25940,"original_code":"@SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  public void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n    Map<String, List<Object>> enumsList = Maps.newHashMap();\n    \/\/Check that all the given keys are valid\n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n    \/\/Todo check the type of the objects, for now just set them on the enum.\n    for (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\n      String name = entry.getKey();\n      Set<Comparable> vals = entry.getValue();\n      Preconditions.checkNotNull(name);\n      Preconditions.checkNotNull(vals);\n      for (Object value : entry.getValue()) {\n        Preconditions.checkNotNull(value);\n      }\n      List<Comparable> valsListComparable = Lists.newArrayList(vals);\n      Collections.sort(valsListComparable);\n      List<Object> valsList = (List)valsListComparable;\n      enumsList.put(name, valsList);\n    }\n    currentEnumVals = Maps.newHashMap(enumsList);\n  }","code":"@SuppressWarnings({\"rawtypes\", \"unchecked\"})\n  public void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n    Map<String, List<Object>> enumsList = Maps.newHashMap();\n   \n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n   \n    for (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\n      String name = entry.getKey();\n      Set<Comparable> vals = entry.getValue();\n      Preconditions.checkNotNull(name);\n      Preconditions.checkNotNull(vals);\n      for (Object value : entry.getValue()) {\n        Preconditions.checkNotNull(value);\n      }\n      List<Comparable> valsListComparable = Lists.newArrayList(vals);\n      Collections.sort(valsListComparable);\n      List<Object> valsList = (List)valsListComparable;\n      enumsList.put(name, valsList);\n    }\n    currentEnumVals = Maps.newHashMap(enumsList);\n  }","cleancode":"@suppresswarnings({\"rawtypes\", \"unchecked\"}) public void setenumssetcomparable(map<string, set<comparable>> enums) { preconditions.checknotnull(enums); areenumsupdated = true; map<string, list<object>> enumslist = maps.newhashmap(); preconditions.checkargument( configurationschema.getkeydescriptor().getfields().getfields().containsall(enums.keyset()), \"the given map doesn't contain valid keys. valid keys are %s and the provided keys are %s\", configurationschema.getkeydescriptor().getfields().getfields(), enums.keyset()); for (map.entry<string, set<comparable>> entry : enums.entryset()) { string name = entry.getkey(); set<comparable> vals = entry.getvalue(); preconditions.checknotnull(name); preconditions.checknotnull(vals); for (object value : entry.getvalue()) { preconditions.checknotnull(value); } list<comparable> valslistcomparable = lists.newarraylist(vals); collections.sort(valslistcomparable); list<object> valslist = (list)valslistcomparable; enumslist.put(name, valslist); } currentenumvals = maps.newhashmap(enumslist); }","comment":"\/** * sets the new enum lists for this schema. the sets in the provided maps are converted into lists, and * sorted according to their natural ordering. * * @param enums the new enum sets for this schema. *\/\n\/\/check that all the given keys are valid\n\/\/todo check the type of the objects, for now just set them on the enum.","repo":"vijaysbhat\/apex-malhar","code_context_2":"@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);\nList<Object> valsList = (List)valsListComparable;\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();","code_context_10":"@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);\nList<Object> valsList = (List)valsListComparable;\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\n@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\n\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);","code_context_20":"@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);\nList<Object> valsList = (List)valsListComparable;\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}\n\n@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);\nList<Object> valsList = (List)valsListComparable;\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n\n@SuppressWarnings({\"rawtypes\", \"unchecked\"})\npublic void setEnumsSetComparable(Map<String, Set<Comparable>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\nMap<String, List<Object>> enumsList = Maps.newHashMap();\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, Set<Comparable>> entry : enums.entrySet()) {\nString name = entry.getKey();\nSet<Comparable> vals = entry.getValue();\nPreconditions.checkNotNull(name);\nPreconditions.checkNotNull(vals);\nfor (Object value : entry.getValue()) {\nPreconditions.checkNotNull(value);\n}\nList<Comparable> valsListComparable = Lists.newArrayList(vals);\nCollections.sort(valsListComparable);\nList<Object> valsList = (List)valsListComparable;\nenumsList.put(name, valsList);\n}\ncurrentEnumVals = Maps.newHashMap(enumsList);\n}","label":[0,1,0,0]}
{"id":25941,"original_code":"public void setEnumsList(Map<String, List<Object>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n    \/\/Check that all the given keys are valid\n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n    \/\/Todo check the type of the objects, for now just set them on the enum.\n    for (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\n      Preconditions.checkNotNull(entry.getKey());\n      Preconditions.checkNotNull(entry.getValue());\n    }\n    Map<String, List<Object>> tempEnums = Maps.newHashMap();\n    for (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\n      String key = entry.getKey();\n      List<?> enumValues = entry.getValue();\n      List<Object> tempEnumValues = Lists.newArrayList();\n      for (Object enumValue : enumValues) {\n        tempEnumValues.add(enumValue);\n      }\n      tempEnums.put(key, tempEnumValues);\n    }\n    currentEnumVals = tempEnums;\n  }","code":"public void setEnumsList(Map<String, List<Object>> enums)\n  {\n    Preconditions.checkNotNull(enums);\n    areEnumsUpdated = true;\n   \n    Preconditions.checkArgument(\n        configurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n        \"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\n        configurationSchema.getKeyDescriptor().getFields().getFields(),\n        enums.keySet());\n   \n    for (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\n      Preconditions.checkNotNull(entry.getKey());\n      Preconditions.checkNotNull(entry.getValue());\n    }\n    Map<String, List<Object>> tempEnums = Maps.newHashMap();\n    for (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\n      String key = entry.getKey();\n      List<?> enumValues = entry.getValue();\n      List<Object> tempEnumValues = Lists.newArrayList();\n      for (Object enumValue : enumValues) {\n        tempEnumValues.add(enumValue);\n      }\n      tempEnums.put(key, tempEnumValues);\n    }\n    currentEnumVals = tempEnums;\n  }","cleancode":"public void setenumslist(map<string, list<object>> enums) { preconditions.checknotnull(enums); areenumsupdated = true; preconditions.checkargument( configurationschema.getkeydescriptor().getfields().getfields().containsall(enums.keyset()), \"the given map doesn't contain valid keys. valid keys are %s and the provided keys are %s\", configurationschema.getkeydescriptor().getfields().getfields(), enums.keyset()); for (map.entry<string, list<object>> entry : enums.entryset()) { preconditions.checknotnull(entry.getkey()); preconditions.checknotnull(entry.getvalue()); } map<string, list<object>> tempenums = maps.newhashmap(); for (map.entry<string, list<object>> entry : enums.entryset()) { string key = entry.getkey(); list<?> enumvalues = entry.getvalue(); list<object> tempenumvalues = lists.newarraylist(); for (object enumvalue : enumvalues) { tempenumvalues.add(enumvalue); } tempenums.put(key, tempenumvalues); } currentenumvals = tempenums; }","comment":"\/** * sets the new enum lists for this schema. * * @param enums the new enum lists for this schema. *\/\n\/\/check that all the given keys are valid\n\/\/todo check the type of the objects, for now just set them on the enum.","repo":"vijaysbhat\/apex-malhar","code_context_2":"public void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {\ntempEnumValues.add(enumValue);\n}\ntempEnums.put(key, tempEnumValues);\n}\ncurrentEnumVals = tempEnums;\n}\n\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());","code_context_10":"public void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {\ntempEnumValues.add(enumValue);\n}\ntempEnums.put(key, tempEnumValues);\n}\ncurrentEnumVals = tempEnums;\n}\n\npublic void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\n\npublic void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {","code_context_20":"public void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {\ntempEnumValues.add(enumValue);\n}\ntempEnums.put(key, tempEnumValues);\n}\ncurrentEnumVals = tempEnums;\n}\n\npublic void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {\ntempEnumValues.add(enumValue);\n}\ntempEnums.put(key, tempEnumValues);\n}\n\npublic void setEnumsList(Map<String, List<Object>> enums)\n{\nPreconditions.checkNotNull(enums);\nareEnumsUpdated = true;\n\/\/Check that all the given keys are valid\nPreconditions.checkArgument(\nconfigurationSchema.getKeyDescriptor().getFields().getFields().containsAll(enums.keySet()),\n\"The given map doesn't contain valid keys. Valid keys are %s and the provided keys are %s\",\nconfigurationSchema.getKeyDescriptor().getFields().getFields(),\nenums.keySet());\n\/\/Todo check the type of the objects, for now just set them on the enum.\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nPreconditions.checkNotNull(entry.getKey());\nPreconditions.checkNotNull(entry.getValue());\n}\nMap<String, List<Object>> tempEnums = Maps.newHashMap();\nfor (Map.Entry<String, List<Object>> entry : enums.entrySet()) {\nString key = entry.getKey();\nList<?> enumValues = entry.getValue();\nList<Object> tempEnumValues = Lists.newArrayList();\nfor (Object enumValue : enumValues) {\ntempEnumValues.add(enumValue);\n}\ntempEnums.put(key, tempEnumValues);\n}\ncurrentEnumVals = tempEnums;\n}","label":[0,1,0,0]}
{"id":1407,"original_code":"public ByteBuffer allocateBufferIfNeeded() {\n    ByteBuffer buffer = getCurrentBuffer();\n    if (buffer != null && buffer.hasRemaining()) {\n      return buffer;\n    }\n    if (currentBufferIndex < bufferList.size() - 1) {\n      buffer = getBuffer(currentBufferIndex + 1);\n    } else {\n      buffer = ByteBuffer.allocate(bufferSize);\n      bufferList.add(buffer);\n    }\n    Preconditions.checkArgument(bufferList.size() <= capacity);\n    currentBufferIndex++;\n    \/\/ TODO: Turn the below precondition check on when Standalone pipeline\n    \/\/ is removed in the write path in tests\n    \/\/ Preconditions.checkArgument(buffer.position() == 0);\n    return buffer;\n  }","code":"public ByteBuffer allocateBufferIfNeeded() {\n    ByteBuffer buffer = getCurrentBuffer();\n    if (buffer != null && buffer.hasRemaining()) {\n      return buffer;\n    }\n    if (currentBufferIndex < bufferList.size() - 1) {\n      buffer = getBuffer(currentBufferIndex + 1);\n    } else {\n      buffer = ByteBuffer.allocate(bufferSize);\n      bufferList.add(buffer);\n    }\n    Preconditions.checkArgument(bufferList.size() <= capacity);\n    currentBufferIndex++;\n   \n   \n   \n    return buffer;\n  }","cleancode":"public bytebuffer allocatebufferifneeded() { bytebuffer buffer = getcurrentbuffer(); if (buffer != null && buffer.hasremaining()) { return buffer; } if (currentbufferindex < bufferlist.size() - 1) { buffer = getbuffer(currentbufferindex + 1); } else { buffer = bytebuffer.allocate(buffersize); bufferlist.add(buffer); } preconditions.checkargument(bufferlist.size() <= capacity); currentbufferindex++; return buffer; }","comment":"\/** * if the currentbufferindex is less than the buffer size - 1, * it means, the next buffer in the list has been freed up for * rewriting. reuse the next available buffer in such cases. * * in case, the currentbufferindex == buffer.size and buffer size is still * less than the capacity to be allocated, just allocate a buffer of size * chunk size. * *\/\n\/\/ todo: turn the below precondition check on when standalone pipeline \/\/ is removed in the write path in tests \/\/ preconditions.checkargument(buffer.position() == 0);","repo":"wangfanming\/hadoop","code_context_2":"public ByteBuffer allocateBufferIfNeeded() {\nByteBuffer buffer = getCurrentBuffer();\nif (buffer != null && buffer.hasRemaining()) {\nreturn buffer;\n}\nif (currentBufferIndex < bufferList.size() - 1) {\nbuffer = getBuffer(currentBufferIndex + 1);\n} else {\nbuffer = ByteBuffer.allocate(bufferSize);\nbufferList.add(buffer);\n}\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}\n\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}","code_context_10":"public ByteBuffer allocateBufferIfNeeded() {\nByteBuffer buffer = getCurrentBuffer();\nif (buffer != null && buffer.hasRemaining()) {\nreturn buffer;\n}\nif (currentBufferIndex < bufferList.size() - 1) {\nbuffer = getBuffer(currentBufferIndex + 1);\n} else {\nbuffer = ByteBuffer.allocate(bufferSize);\nbufferList.add(buffer);\n}\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}\n\nreturn buffer;\n}\nif (currentBufferIndex < bufferList.size() - 1) {\nbuffer = getBuffer(currentBufferIndex + 1);\n} else {\nbuffer = ByteBuffer.allocate(bufferSize);\nbufferList.add(buffer);\n}\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}","code_context_20":"public ByteBuffer allocateBufferIfNeeded() {\nByteBuffer buffer = getCurrentBuffer();\nif (buffer != null && buffer.hasRemaining()) {\nreturn buffer;\n}\nif (currentBufferIndex < bufferList.size() - 1) {\nbuffer = getBuffer(currentBufferIndex + 1);\n} else {\nbuffer = ByteBuffer.allocate(bufferSize);\nbufferList.add(buffer);\n}\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}\n\npublic ByteBuffer allocateBufferIfNeeded() {\nByteBuffer buffer = getCurrentBuffer();\nif (buffer != null && buffer.hasRemaining()) {\nreturn buffer;\n}\nif (currentBufferIndex < bufferList.size() - 1) {\nbuffer = getBuffer(currentBufferIndex + 1);\n} else {\nbuffer = ByteBuffer.allocate(bufferSize);\nbufferList.add(buffer);\n}\nPreconditions.checkArgument(bufferList.size() <= capacity);\ncurrentBufferIndex++;\n\/\/ TODO: Turn the below precondition check on when Standalone pipeline\n\/\/ is removed in the write path in tests\n\/\/ Preconditions.checkArgument(buffer.position() == 0);\nreturn buffer;\n}","label":[1,0,0,0]}
{"id":34186,"original_code":"@Override\n  public void onCreate(@Nullable Bundle savedInstanceState)\n  {\n    super.onCreate(savedInstanceState);\n    setContentView(R.layout.activity_map);\n    initViews();\n    Statistics.INSTANCE.trackConnectionState();\n    if (MwmApplication.get().nativeIsBenchmarking())\n      Utils.keepScreenOn(true, getWindow());\n    \/\/ TODO consider implementing other model of listeners connection, without activities being bound\n    Framework.nativeSetRoutingListener(this);\n    Framework.nativeSetRouteProgressListener(this);\n    Framework.nativeSetBalloonListener(this);\n    mSearchController = new FloatingSearchToolbarController(this);\n    mLocationPredictor = new LocationPredictor(new Handler(), this);\n    processIntent(getIntent());\n    SharingHelper.prepare();\n  }","code":"@Override\n  public void onCreate(@Nullable Bundle savedInstanceState)\n  {\n    super.onCreate(savedInstanceState);\n    setContentView(R.layout.activity_map);\n    initViews();\n    Statistics.INSTANCE.trackConnectionState();\n    if (MwmApplication.get().nativeIsBenchmarking())\n      Utils.keepScreenOn(true, getWindow());\n   \n    Framework.nativeSetRoutingListener(this);\n    Framework.nativeSetRouteProgressListener(this);\n    Framework.nativeSetBalloonListener(this);\n    mSearchController = new FloatingSearchToolbarController(this);\n    mLocationPredictor = new LocationPredictor(new Handler(), this);\n    processIntent(getIntent());\n    SharingHelper.prepare();\n  }","cleancode":"@override public void oncreate(@nullable bundle savedinstancestate) { super.oncreate(savedinstancestate); setcontentview(r.layout.activity_map); initviews(); statistics.instance.trackconnectionstate(); if (mwmapplication.get().nativeisbenchmarking()) utils.keepscreenon(true, getwindow()); framework.nativesetroutinglistener(this); framework.nativesetrouteprogresslistener(this); framework.nativesetballoonlistener(this); msearchcontroller = new floatingsearchtoolbarcontroller(this); mlocationpredictor = new locationpredictor(new handler(), this); processintent(getintent()); sharinghelper.prepare(); }","comment":"\/\/ todo consider implementing other model of listeners connection, without activities being bound","repo":"yanncoupin\/omim","code_context_2":"if (MwmApplication.get().nativeIsBenchmarking())\nUtils.keepScreenOn(true, getWindow());\n\/\/ TODO consider implementing other model of listeners connection, without activities being bound\nFramework.nativeSetRoutingListener(this);\nFramework.nativeSetRouteProgressListener(this);","code_context_10":"@Override\npublic void onCreate(@Nullable Bundle savedInstanceState)\n{\nsuper.onCreate(savedInstanceState);\nsetContentView(R.layout.activity_map);\ninitViews();\nStatistics.INSTANCE.trackConnectionState();\nif (MwmApplication.get().nativeIsBenchmarking())\nUtils.keepScreenOn(true, getWindow());\n\/\/ TODO consider implementing other model of listeners connection, without activities being bound\nFramework.nativeSetRoutingListener(this);\nFramework.nativeSetRouteProgressListener(this);\nFramework.nativeSetBalloonListener(this);\nmSearchController = new FloatingSearchToolbarController(this);\nmLocationPredictor = new LocationPredictor(new Handler(), this);\nprocessIntent(getIntent());\nSharingHelper.prepare();\n}","code_context_20":"@Override\npublic void onCreate(@Nullable Bundle savedInstanceState)\n{\nsuper.onCreate(savedInstanceState);\nsetContentView(R.layout.activity_map);\ninitViews();\nStatistics.INSTANCE.trackConnectionState();\nif (MwmApplication.get().nativeIsBenchmarking())\nUtils.keepScreenOn(true, getWindow());\n\/\/ TODO consider implementing other model of listeners connection, without activities being bound\nFramework.nativeSetRoutingListener(this);\nFramework.nativeSetRouteProgressListener(this);\nFramework.nativeSetBalloonListener(this);\nmSearchController = new FloatingSearchToolbarController(this);\nmLocationPredictor = new LocationPredictor(new Handler(), this);\nprocessIntent(getIntent());\nSharingHelper.prepare();\n}","label":[1,0,0,0]}
{"id":34226,"original_code":"private boolean isEmailValid(String email) {\n        \/\/TODO: Replace this with your own logic\n        return email.contains(\"@\");\n    }","code":"private boolean isEmailValid(String email) {\n       \n        return email.contains(\"@\");\n    }","cleancode":"private boolean isemailvalid(string email) { return email.contains(\"@\"); }","comment":"\/\/todo: replace this with your own logic","repo":"xuanliao\/MVVM_Samples","code_context_2":"private boolean isEmailValid(String email) {\n\/\/TODO: Replace this with your own logic\nreturn email.contains(\"@\");\n}","code_context_10":"private boolean isEmailValid(String email) {\n\/\/TODO: Replace this with your own logic\nreturn email.contains(\"@\");\n}","code_context_20":"private boolean isEmailValid(String email) {\n\/\/TODO: Replace this with your own logic\nreturn email.contains(\"@\");\n}","label":[0,1,0,0]}
{"id":34227,"original_code":"private boolean isPasswordValid(String password) {\n        \/\/TODO: Replace this with your own logic\n        return password.length() > 4;\n    }","code":"private boolean isPasswordValid(String password) {\n       \n        return password.length() > 4;\n    }","cleancode":"private boolean ispasswordvalid(string password) { return password.length() > 4; }","comment":"\/\/todo: replace this with your own logic","repo":"xuanliao\/MVVM_Samples","code_context_2":"private boolean isPasswordValid(String password) {\n\/\/TODO: Replace this with your own logic\nreturn password.length() > 4;\n}","code_context_10":"private boolean isPasswordValid(String password) {\n\/\/TODO: Replace this with your own logic\nreturn password.length() > 4;\n}","code_context_20":"private boolean isPasswordValid(String password) {\n\/\/TODO: Replace this with your own logic\nreturn password.length() > 4;\n}","label":[0,1,0,0]}
{"id":34249,"original_code":"@Override\n\tpublic void onStart() {\n\t\tsuper.onStart();\n\t\t\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\t\t\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\n\t\tclient.connect();\n\t\tAction viewAction = Action.newAction(\n\t\t\t\tAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\t\t\t\t\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\t\t\t\t\/\/ TODO: If you have web page content that matches this app activity's content,\n\t\t\t\t\/\/ make sure this auto-generated web page URL is correct.\n\t\t\t\t\/\/ Otherwise, set the URL to null.\n\t\t\t\tUri.parse(\"http:\/\/host\/path\"),\n\t\t\t\t\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\n\t\t\t\tUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n\t\t);\n\t\tAppIndex.AppIndexApi.start(client, viewAction);\n\t}","code":"@Override\n\tpublic void onStart() {\n\t\tsuper.onStart();\n\t\n\t\n\t\tclient.connect();\n\t\tAction viewAction = Action.newAction(\n\t\t\t\tAction.TYPE_VIEW,\n\t\t\t\t\"Sliding Page\",\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\tUri.parse(\"http:\/\/host\/path\"),\n\t\t\t\n\t\t\t\tUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n\t\t);\n\t\tAppIndex.AppIndexApi.start(client, viewAction);\n\t}","cleancode":"@override public void onstart() { super.onstart(); client.connect(); action viewaction = action.newaction( action.type_view, \"sliding page\", uri.parse(\"http:\/\/host\/path\"), uri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\") ); appindex.appindexapi.start(client, viewaction); }","comment":"\/\/ attention: this was auto-generated to implement the app indexing api. \/\/ see https:\/\/g.co\/appindexing\/androidstudio for more information.\n\/\/ todo: choose an action type.\n\/\/ todo: define a title for the content shown.\n\/\/ todo: if you have web page content that matches this app activity's content, \/\/ make sure this auto-generated web page url is correct. \/\/ otherwise, set the url to null.\n\/\/ todo: make sure this auto-generated app deep link uri is correct.","repo":"wangwenwang\/sfkc-driver-android","code_context_2":"public void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\n\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\n\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);","code_context_10":"@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}","code_context_20":"@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}\n\n@Override\npublic void onStart() {\nsuper.onStart();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nclient.connect();\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.start(client, viewAction);\n}","label":[1,1,0,0]}
{"id":34250,"original_code":"@Override\n\tpublic void onStop() {\n\t\tsuper.onStop();\n\t\t\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\t\t\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\n\t\tAction viewAction = Action.newAction(\n\t\t\t\tAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\t\t\t\t\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\t\t\t\t\/\/ TODO: If you have web page content that matches this app activity's content,\n\t\t\t\t\/\/ make sure this auto-generated web page URL is correct.\n\t\t\t\t\/\/ Otherwise, set the URL to null.\n\t\t\t\tUri.parse(\"http:\/\/host\/path\"),\n\t\t\t\t\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\n\t\t\t\tUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n\t\t);\n\t\tAppIndex.AppIndexApi.end(client, viewAction);\n\t\tclient.disconnect();\n\t}","code":"@Override\n\tpublic void onStop() {\n\t\tsuper.onStop();\n\t\n\t\n\t\tAction viewAction = Action.newAction(\n\t\t\t\tAction.TYPE_VIEW,\n\t\t\t\t\"Sliding Page\",\n\t\t\t\n\t\t\t\n\t\t\t\n\t\t\t\tUri.parse(\"http:\/\/host\/path\"),\n\t\t\t\n\t\t\t\tUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n\t\t);\n\t\tAppIndex.AppIndexApi.end(client, viewAction);\n\t\tclient.disconnect();\n\t}","cleancode":"@override public void onstop() { super.onstop(); action viewaction = action.newaction( action.type_view, \"sliding page\", uri.parse(\"http:\/\/host\/path\"), uri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\") ); appindex.appindexapi.end(client, viewaction); client.disconnect(); }","comment":"\/\/ attention: this was auto-generated to implement the app indexing api. \/\/ see https:\/\/g.co\/appindexing\/androidstudio for more information.\n\/\/ todo: choose an action type.\n\/\/ todo: define a title for the content shown.\n\/\/ todo: if you have web page content that matches this app activity's content, \/\/ make sure this auto-generated web page url is correct. \/\/ otherwise, set the url to null.\n\/\/ todo: make sure this auto-generated app deep link uri is correct.","repo":"wangwenwang\/sfkc-driver-android","code_context_2":"public void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\n\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);","code_context_10":"@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}","code_context_20":"@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}\n\n@Override\npublic void onStop() {\nsuper.onStop();\n\/\/ ATTENTION: This was auto-generated to implement the App Indexing API.\n\/\/ See https:\/\/g.co\/AppIndexing\/AndroidStudio for more information.\nAction viewAction = Action.newAction(\nAction.TYPE_VIEW, \/\/ TODO: choose an action type.\n\"Sliding Page\", \/\/ TODO: Define a title for the content shown.\n\/\/ TODO: If you have web page content that matches this app activity's content,\n\/\/ make sure this auto-generated web page URL is correct.\n\/\/ Otherwise, set the URL to null.\nUri.parse(\"http:\/\/host\/path\"),\n\/\/ TODO: Make sure this auto-generated app deep link URI is correct.\nUri.parse(\"android-app:\/\/com.kaidongyuan.app.basemodule.widget.slidingmenu.activity\/http\/host\/path\")\n);\nAppIndex.AppIndexApi.end(client, viewAction);\nclient.disconnect();\n}","label":[1,1,0,0]}
{"id":26213,"original_code":"@Test\n    public void canImportTheCorrectNumberOfRecords() throws Throwable {\n        process(shakParser, shakDao, \"data\/sks\/SHAKCOMPLETE.TXT\");\n        \/\/ FIXME: These record counts are only correct iff if duplicate keys are disregarted.\n        \/\/ This is unfortunate. Keys are currently only considered based their SKSKode.\n        \/\/ They should be a combination of type + kode + startdato based on the register doc.\n        assertEquals(1017, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Sygehus'\"));\n        assertEquals(18411, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Afdeling'\"));\n        process(sksParser, sksDao, \"data\/sks\/SKScomplete.txt\");\n        assertEquals(573, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'und'\"));\n        assertEquals(8990, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'pro'\"));\n        assertEquals(43857, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'dia'\"));\n        assertEquals(19980, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'opr'\"));\n        assertEquals(10461, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'atc'\"));\n    }","code":"@Test\n    public void canImportTheCorrectNumberOfRecords() throws Throwable {\n        process(shakParser, shakDao, \"data\/sks\/SHAKCOMPLETE.TXT\");\n       \n       \n       \n        assertEquals(1017, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Sygehus'\"));\n        assertEquals(18411, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Afdeling'\"));\n        process(sksParser, sksDao, \"data\/sks\/SKScomplete.txt\");\n        assertEquals(573, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'und'\"));\n        assertEquals(8990, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'pro'\"));\n        assertEquals(43857, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'dia'\"));\n        assertEquals(19980, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'opr'\"));\n        assertEquals(10461, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'atc'\"));\n    }","cleancode":"@test public void canimportthecorrectnumberofrecords() throws throwable { process(shakparser, shakdao, \"data\/sks\/shakcomplete.txt\"); assertequals(1017, jdbc.queryforint(\"select count(*) from class_shak where organisationstype = 'sygehus'\")); assertequals(18411, jdbc.queryforint(\"select count(*) from class_shak where organisationstype = 'afdeling'\")); process(sksparser, sksdao, \"data\/sks\/skscomplete.txt\"); assertequals(573, jdbc.queryforint(\"select count(*) from class_sks where type = 'und'\")); assertequals(8990, jdbc.queryforint(\"select count(*) from class_sks where type = 'pro'\")); assertequals(43857, jdbc.queryforint(\"select count(*) from class_sks where type = 'dia'\")); assertequals(19980, jdbc.queryforint(\"select count(*) from class_sks where type = 'opr'\")); assertequals(10461, jdbc.queryforint(\"select count(*) from class_sks where type = 'atc'\")); }","comment":"\/\/ fixme: these record counts are only correct iff if duplicate keys are disregarted. \/\/ this is unfortunate. keys are currently only considered based their skskode. \/\/ they should be a combination of type + kode + startdato based on the register doc.","repo":"trifork\/HAIBA-FGRImporter","code_context_2":"public void canImportTheCorrectNumberOfRecords() throws Throwable {\nprocess(shakParser, shakDao, \"data\/sks\/SHAKCOMPLETE.TXT\");\n\/\/ FIXME: These record counts are only correct iff if duplicate keys are disregarted.\n\/\/ This is unfortunate. Keys are currently only considered based their SKSKode.\n\/\/ They should be a combination of type + kode + startdato based on the register doc.\nassertEquals(1017, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Sygehus'\"));\nassertEquals(18411, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Afdeling'\"));","code_context_10":"@Test\npublic void canImportTheCorrectNumberOfRecords() throws Throwable {\nprocess(shakParser, shakDao, \"data\/sks\/SHAKCOMPLETE.TXT\");\n\/\/ FIXME: These record counts are only correct iff if duplicate keys are disregarted.\n\/\/ This is unfortunate. Keys are currently only considered based their SKSKode.\n\/\/ They should be a combination of type + kode + startdato based on the register doc.\nassertEquals(1017, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Sygehus'\"));\nassertEquals(18411, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Afdeling'\"));\nprocess(sksParser, sksDao, \"data\/sks\/SKScomplete.txt\");\nassertEquals(573, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'und'\"));\nassertEquals(8990, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'pro'\"));\nassertEquals(43857, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'dia'\"));\nassertEquals(19980, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'opr'\"));\nassertEquals(10461, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'atc'\"));\n}","code_context_20":"@Test\npublic void canImportTheCorrectNumberOfRecords() throws Throwable {\nprocess(shakParser, shakDao, \"data\/sks\/SHAKCOMPLETE.TXT\");\n\/\/ FIXME: These record counts are only correct iff if duplicate keys are disregarted.\n\/\/ This is unfortunate. Keys are currently only considered based their SKSKode.\n\/\/ They should be a combination of type + kode + startdato based on the register doc.\nassertEquals(1017, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Sygehus'\"));\nassertEquals(18411, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_shak WHERE Organisationstype = 'Afdeling'\"));\nprocess(sksParser, sksDao, \"data\/sks\/SKScomplete.txt\");\nassertEquals(573, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'und'\"));\nassertEquals(8990, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'pro'\"));\nassertEquals(43857, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'dia'\"));\nassertEquals(19980, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'opr'\"));\nassertEquals(10461, jdbc.queryForInt(\"SELECT COUNT(*) FROM class_sks WHERE Type = 'atc'\"));\n}","label":[0,0,1,0]}
{"id":26228,"original_code":"public SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\n        if (paginationStart < 0) {\n            throw new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n        }\n        if (numResultsPerPage < 1) {\n            throw new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n        }\n        SolrQuery solrQuery = new SolrQuery();\n        query = SearchUtil.sanitizeQuery(query);\n        solrQuery.setQuery(query);\n\/\/        SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/        if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/            solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\n        solrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/        } else {\n\/\/            solrQuery.setSort(sortClause);\n\/\/        }\n\/\/        solrQuery.setSort(sortClause);\n        solrQuery.setHighlight(true).setHighlightSnippets(1);\n        Integer fragSize = systemConfig.getSearchHighlightFragmentSize();\n        if (fragSize != null) {\n            solrQuery.setHighlightFragsize(fragSize);\n        }\n        solrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\n        solrQuery.setHighlightSimplePost(\"<\/span>\");\n        Map<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n        \/\/ TODO: Do not hard code \"Name\" etc as English here.\n        solrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\n        solrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\n        solrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\n        solrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n        \/**\n         * @todo Dataverse subject and affiliation should be highlighted but\n         * this is commented out right now because the \"friendly\" names are not\n         * being shown on the dataverse cards. See also\n         * https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n         *\/\n\/\/        solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/        solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n        \/**\n         * @todo: show highlight on file card?\n         * https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n         *\/      \n        solrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n        List<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\n        for (DatasetFieldType datasetFieldType : datasetFields) {\n            String solrField = datasetFieldType.getSolrField().getNameSearchable();\n            String displayName = datasetFieldType.getDisplayName();\n            solrFieldsToHightlightOnMap.put(solrField, displayName);\n        }\n        for (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\n            String solrField = entry.getKey();\n            \/\/ String displayName = entry.getValue();\n            solrQuery.addHighlightField(solrField);\n        }\n        solrQuery.setParam(\"fl\", \"*,score\");\n        solrQuery.setParam(\"qt\", \"\/select\");\n        solrQuery.setParam(\"facet\", \"true\");\n        \/**\n         * @todo: do we need facet.query?\n         *\/\n        solrQuery.setParam(\"facet.query\", \"*\");\n        for (String filterQuery : filterQueries) {\n            solrQuery.addFilterQuery(filterQuery);\n        }\n        \/\/ -----------------------------------\n        \/\/ PERMISSION FILTER QUERY\n        \/\/ -----------------------------------\n        String permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\n        if (permissionFilterQuery != null) {\n            solrQuery.addFilterQuery(permissionFilterQuery);\n        }\n        \/\/ -----------------------------------\n        \/\/ Facets to Retrieve\n        \/\/ -----------------------------------\n\/\/        solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/        solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\n        solrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\n        solrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/        solrQuery.addFacetField(SearchFields.AFFILIATION);\n        solrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/        solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/        solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/        solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/        solrQuery.addFacetField(SearchFields.KEYWORD);\n        \/**\n         * @todo when a new method on datasetFieldService is available\n         * (retrieveFacetsByDataverse?) only show the facets that the dataverse\n         * in question wants to show (and in the right order):\n         * https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n         *\n         * also, findAll only returns advancedSearchField = true... we should\n         * probably introduce the \"isFacetable\" boolean rather than caring about\n         * if advancedSearchField is true or false\n         *\n         *\/\n        if (dataverse != null) {\n            for (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\n                DatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\n                solrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n            }\n        }\n        solrQuery.addFacetField(SearchFields.FILE_TYPE);\n        \/**\n         * @todo: hide the extra line this shows in the GUI... at least it's\n         * last...\n         *\/\n        solrQuery.addFacetField(SearchFields.TYPE);\n        solrQuery.addFacetField(SearchFields.FILE_TAG);\n        if (!systemConfig.isPublicInstall()) {\n            solrQuery.addFacetField(SearchFields.ACCESS);\n        }\n        \/**\n         * @todo: do sanity checking... throw error if negative\n         *\/\n        solrQuery.setStart(paginationStart);\n        \/**\n         * @todo: decide if year CITATION_YEAR is good enough or if we should\n         * support CITATION_DATE\n         *\/\n\/\/        Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/        calendar.set(2010, 1, 1);\n\/\/        Date start = calendar.getTime();\n\/\/        calendar.set(2013, 1, 1);\n\/\/        Date end = calendar.getTime();\n\/\/        solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n        \/**\n         * @todo make this configurable\n         *\/\n        int thisYear = Calendar.getInstance().get(Calendar.YEAR);\n        \/**\n         * @todo: odd or even makes a difference. Couldn't find value of 2014\n         * when this was set to 2000\n         *\/\n        final int citationYearRangeStart = 1901;\n        final int citationYearRangeEnd = thisYear;\n        final int citationYearRangeSpan = 2;\n        \/**\n         * @todo: these are dates and should be \"range facets\" not \"field\n         * facets\"\n         *\n         * right now they are lumped in with the datasetFieldService.findAll()\n         * above\n         *\/\n\/\/        solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/        solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n        solrQuery.setRows(numResultsPerPage);\n        logger.fine(\"Solr query:\" + solrQuery);\n        \/\/ -----------------------------------  \n        \/\/ Make the solr query\n        \/\/ -----------------------------------\n        QueryResponse queryResponse = null;\n        try {\n            queryResponse = solrServer.query(solrQuery);\n        } catch (RemoteSolrException ex) {\n            String messageFromSolr = ex.getLocalizedMessage();\n            String error = \"Search Syntax Error: \";\n            String stringToHide = \"org.apache.solr.search.SyntaxError: \";\n            if (messageFromSolr.startsWith(stringToHide)) {\n                \/\/ hide \"org.apache.solr...\"\n                error += messageFromSolr.substring(stringToHide.length());\n            } else {\n                error += messageFromSolr;\n            }\n            logger.info(error);\n            SolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\n            exceptionSolrQueryResponse.setError(error);\n            \/\/ we can't show anything because of the search syntax error\n            long zeroNumResultsFound = 0;\n            long zeroGetResultsStart = 0;\n            List<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\n            List<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\n            Map<String, List<String>> emptySpellingSuggestion = new HashMap<>();\n            exceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\n            exceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\n            exceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\n            exceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\n            exceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\n            exceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\n            return exceptionSolrQueryResponse;\n        } catch (SolrServerException | IOException ex) {\n            throw new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n        }\n        SolrDocumentList docs = queryResponse.getResults();\n        List<SolrSearchResult> solrSearchResults = new ArrayList<>();\n        \/**\n         * @todo refactor SearchFields to a hashmap (or something? put in\n         * database? internationalize?) to avoid the crazy reflection and string\n         * manipulation below\n         *\/\n        Object searchFieldsObject = new SearchFields();\n        Field[] staticSearchFields = searchFieldsObject.getClass().getDeclaredFields();\n        String titleSolrField = null;\n        try {\n            DatasetFieldType titleDatasetField = datasetFieldService.findByName(DatasetFieldConstant.title);\n            titleSolrField = titleDatasetField.getSolrField().getNameSearchable();\n        } catch (EJBTransactionRolledbackException ex) {\n            logger.info(\"Couldn't find \" + DatasetFieldConstant.title);\n            if (ex.getCause() instanceof TransactionRolledbackLocalException) {\n                if (ex.getCause().getCause() instanceof NoResultException) {\n                    logger.info(\"Caught NoResultException\");\n                }\n            }\n        }\n        Map<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\n        Map<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\n        String baseUrl = systemConfig.getDataverseSiteUrl();\n        for (SolrDocument solrDocument : docs) {\n            String id = (String) solrDocument.getFieldValue(SearchFields.ID);\n            Long entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\n            String type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\n            float score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\n            logger.fine(\"score for \" + id + \": \" + score);\n            String identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\n            String citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\n            String citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\n            String persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\n            String name = (String) solrDocument.getFieldValue(SearchFields.NAME);\n            String nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/            ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\n            String title = (String) solrDocument.getFieldValue(titleSolrField);\n            Long datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\n            String deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/            logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/            logger.info(\"title: \" + title);\n            String filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\n            String fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\n            Date release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\n            String dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\n            String dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\n            List<String> matchedFields = new ArrayList<>();\n            List<Highlight> highlights = new ArrayList<>();\n            Map<SolrField, Highlight> highlightsMap = new HashMap<>();\n            Map<SolrField, List<String>> highlightsMap2 = new HashMap<>();\n            Map<String, Highlight> highlightsMap3 = new HashMap<>();\n            if (queryResponse.getHighlighting().get(id) != null) {\n                for (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\n                    String field = entry.getKey();\n                    String displayName = entry.getValue();\n                    List<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\n                    if (highlightSnippets != null) {\n                        matchedFields.add(field);\n                        \/**\n                         * @todo only SolrField.SolrType.STRING? that's not\n                         * right... knit the SolrField object more into the\n                         * highlighting stuff\n                         *\/\n                        SolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\n                        Highlight highlight = new Highlight(solrField, highlightSnippets, displayName);\n                        highlights.add(highlight);\n                        highlightsMap.put(solrField, highlight);\n                        highlightsMap2.put(solrField, highlightSnippets);\n                        highlightsMap3.put(field, highlight);\n                    }\n                }\n            }\n            SolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n            \/**\n             * @todo put all this in the constructor?\n             *\/\n            List<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\n            if (states != null) {\n                \/\/ set list of all statuses\n                \/\/ this method also sets booleans for individual statuses\n                solrSearchResult.setPublicationStatuses(states);\n            }\n\/\/            logger.info(id + \": \" + description);\n            solrSearchResult.setId(id);\n            solrSearchResult.setEntityId(entityid);\n            if (retrieveEntities) {\n                solrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n            }\n            solrSearchResult.setIdentifier(identifier);\n            solrSearchResult.setPersistentUrl(persistentUrl);\n            solrSearchResult.setType(type);\n            solrSearchResult.setScore(score);\n            solrSearchResult.setNameSort(nameSort);\n            solrSearchResult.setReleaseOrCreateDate(release_or_create_date);\n            solrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\n            solrSearchResult.setMatchedFields(matchedFields);\n            solrSearchResult.setHighlightsAsList(highlights);\n            solrSearchResult.setHighlightsMap(highlightsMap);\n            solrSearchResult.setHighlightsAsMap(highlightsMap3);\n            Map<String, String> parent = new HashMap<>();\n            String description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\n            solrSearchResult.setDescriptionNoSnippet(description);\n            solrSearchResult.setDeaccessionReason(deaccessionReason);\n            solrSearchResult.setDvTree(dvTree);\n            String originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\n            if (IndexServiceBean.HARVESTED.equals(originSource)) {\n                solrSearchResult.setHarvested(true);\n            }\n            \/**\n             * @todo start using SearchConstants class here\n             *\/\n            if (type.equals(\"dataverses\")) {\n                solrSearchResult.setName(name);\n                solrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n                \/\/ Do not set the ImageUrl, let the search include fragment fill in\n                \/\/ the thumbnail, similarly to how the dataset and datafile cards\n                \/\/ are handled. \n                \/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n                \/**\n                 * @todo Expose this API URL after \"dvs\" is changed to\n                 * \"dataverses\". Also, is an API token required for published\n                 * dataverses? Michael: url changed.\n                 *\/\n\/\/                solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n            } else if (type.equals(\"datasets\")) {\n                solrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\n                solrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n                \/\/Image url now set via thumbnail api\n                \/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n                \/\/ No, we don't want to set the base64 thumbnails here. \n                \/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the \n                \/\/ page has already loaded.\n                \/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n                \/\/if (datasetVersion != null){                    \n                \/\/    solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n                \/\/}\n                \/**\n                 * @todo Could use getFieldValues (plural) here.\n                 *\/\n                List<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\n                if (datasetDescriptions != null) {\n                    String firstDatasetDescription = datasetDescriptions.get(0);\n                    if (firstDatasetDescription != null) {\n                        solrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n                    }\n                }\n                solrSearchResult.setDatasetVersionId(datasetVersionId);\n                solrSearchResult.setCitation(citation);\n                solrSearchResult.setCitationHtml(citationPlainHtml);\n                if (title != null) {\n\/\/                    solrSearchResult.setTitle((String) titles.get(0));\n                    solrSearchResult.setTitle(title);\n                } else {\n                    logger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\n                    solrSearchResult.setTitle(\"\");\n                }\n                List<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\n                if (authors != null) {\n                    solrSearchResult.setDatasetAuthors(authors);\n                }\n            } else if (type.equals(\"files\")) {\n                String parentGlobalId = null;\n                Object parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\n                if (parentGlobalIdObject != null) {\n                    parentGlobalId = (String) parentGlobalIdObject;\n                    parent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n                }\n                solrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\n                solrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n                \/**\n                 * @todo We are not yet setting the API URL for files because\n                 * not all files have metadata. Only subsettable files (those\n                 * with a datatable) seem to have metadata. Furthermore, the\n                 * response is in XML whereas the rest of the Search API returns\n                 * JSON.\n                 *\/\n\/\/                solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n                \/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\n                solrSearchResult.setName(name);\n                solrSearchResult.setFiletype(filetype);\n                solrSearchResult.setFileContentType(fileContentType);\n                Object fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\n                if (fileSizeInBytesObject != null) {\n                    try {\n                        long fileSizeInBytesLong = (long) fileSizeInBytesObject;\n                        solrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n                    } catch (ClassCastException ex) {\n                        logger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n                    }\n                }\n                solrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\n                try {\n                    solrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n                } catch (IllegalArgumentException ex) {\n                    logger.info(\"Exception setting setFileChecksumType: \" + ex);\n                }\n                solrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\n                solrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\n                solrSearchResult.setDatasetVersionId(datasetVersionId);\n                List<String> fileCategories = (List) solrDocument.getFieldValues(SearchFields.FILE_TAG);\n                if (fileCategories != null) {\n                    solrSearchResult.setFileCategories(fileCategories);\n                }\n                List<String> tabularDataTags = (List) solrDocument.getFieldValues(SearchFields.TABDATA_TAG);\n                if (tabularDataTags != null) {\n                    Collections.sort(tabularDataTags);\n                    solrSearchResult.setTabularDataTags(tabularDataTags);\n                }\n            }\n            \/**\n             * @todo store PARENT_ID as a long instead and cast as such\n             *\/\n            parent.put(\"id\", (String) solrDocument.getFieldValue(SearchFields.PARENT_ID));\n            parent.put(\"name\", (String) solrDocument.getFieldValue(SearchFields.PARENT_NAME));\n            parent.put(\"citation\", (String) solrDocument.getFieldValue(SearchFields.PARENT_CITATION));\n            solrSearchResult.setParent(parent);\n            solrSearchResults.add(solrSearchResult);\n        }\n        Map<String, List<String>> spellingSuggestionsByToken = new HashMap<>();\n        SpellCheckResponse spellCheckResponse = queryResponse.getSpellCheckResponse();\n        if (spellCheckResponse != null) {\n            List<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\n            for (SpellCheckResponse.Suggestion suggestion : suggestions) {\n                spellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n            }\n        }\n        List<FacetCategory> facetCategoryList = new ArrayList<>();\n        List<FacetCategory> typeFacetCategories = new ArrayList<>();\n        boolean hidePublicationStatusFacet = true;\n        boolean draftsAvailable = false;\n        boolean unpublishedAvailable = false;\n        boolean deaccessionedAvailable = false;\n        boolean hideMetadataSourceFacet = true;\n        for (FacetField facetField : queryResponse.getFacetFields()) {\n            FacetCategory facetCategory = new FacetCategory();\n            List<FacetLabel> facetLabelList = new ArrayList<>();\n            int numMetadataSources = 0;\n            for (FacetField.Count facetFieldCount : facetField.getValues()) {\n                \/**\n                 * @todo we do want to show the count for each facet\n                 *\/\n\/\/                logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\n                if (facetFieldCount.getCount() > 0) {\n                    FacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n                    \/\/ quote field facets\n                    facetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\n                    facetLabelList.add(facetLabel);\n                    if (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\n                        if (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\n                            unpublishedAvailable = true;\n                        } else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\n                            draftsAvailable = true;\n                        } else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\n                            deaccessionedAvailable = true;\n                        }\n                    }\n                    if (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\n                        numMetadataSources++;\n                    }\n                }\n            }\n            if (numMetadataSources > 1) {\n                hideMetadataSourceFacet = false;\n            }\n            facetCategory.setName(facetField.getName());\n            \/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\n            facetCategory.setFriendlyName(facetField.getName());\n            \/\/ try to find a friendlier name to display as a facet\n            \/**\n             * @todo hmm, we thought we wanted the datasetFields array to go\n             * away once we have more granularity than findAll() available per\n             * the todo above but we need a way to lookup by Solr field, so\n             * we'll build a hashmap\n             *\/\n            for (DatasetFieldType datasetField : datasetFields) {\n                String solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\n                String friendlyName = datasetField.getDisplayName();\n                if (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n                    \/\/ give it the non-friendly name so we remember to update the reference data script for datasets\n                    facetCategory.setName(facetField.getName());\n                } else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\n                    if (friendlyName != null && !friendlyName.isEmpty()) {\n                        facetCategory.setFriendlyName(friendlyName);\n                        \/\/ stop examining available dataset fields. we found a match\n                        break;\n                    }\n                }\n                datasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n            }\n            \/**\n             * @todo get rid of this crazy reflection, per todo above... or\n             * should we... let's put into a hash the friendly names of facet\n             * categories, indexed by Solr field\n             *\/\n            for (Field fieldObject : staticSearchFields) {\n                String name = fieldObject.getName();\n                String staticSearchField = null;\n                try {\n                    staticSearchField = (String) fieldObject.get(searchFieldsObject);\n                } catch (IllegalArgumentException | IllegalAccessException ex) {\n                    Logger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n                }\n                if (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\n                    String[] parts = name.split(\"_\");\n                    StringBuilder stringBuilder = new StringBuilder();\n                    for (String part : parts) {\n                        stringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n                    }\n                    String friendlyNameWithTrailingSpace = stringBuilder.toString();\n                    String friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\n                    facetCategory.setFriendlyName(friendlyName);\n\/\/                    logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\n                    staticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n                    \/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\n                    break;\n                }\n            }\n            facetCategory.setFacetLabel(facetLabelList);\n            if (!facetLabelList.isEmpty()) {\n                if (facetCategory.getName().equals(SearchFields.TYPE)) {\n                    \/\/ the \"type\" facet is special, these are not\n                    typeFacetCategories.add(facetCategory);\n                } else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\n                    if (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\n                        hidePublicationStatusFacet = false;\n                    }\n                    if (!hidePublicationStatusFacet) {\n                        facetCategoryList.add(facetCategory);\n                    }\n                } else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\n                    if (!hideMetadataSourceFacet) {\n                        facetCategoryList.add(facetCategory);\n                    }\n                } else {\n                    facetCategoryList.add(facetCategory);\n                }\n            }\n        }\n        \/\/ for now the only range facet is citation year\n        for (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\n            FacetCategory facetCategory = new FacetCategory();\n            List<FacetLabel> facetLabelList = new ArrayList<>();\n            for (Object rfObj : rangeFacet.getCounts()) {\n                RangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\n                String valueString = rangeFacetCount.getValue();\n                Integer start = Integer.parseInt(valueString);\n                Integer end = start + Integer.parseInt(rangeFacet.getGap().toString());\n                \/\/ to avoid overlapping dates\n                end = end - 1;\n                if (rangeFacetCount.getCount() > 0) {\n                    FacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n                    \/\/ special [12 TO 34] syntax for range facets\n                    facetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\n                    facetLabelList.add(facetLabel);\n                }\n            }\n            facetCategory.setName(rangeFacet.getName());\n            facetCategory.setFacetLabel(facetLabelList);\n            \/\/ reverse to show the newest citation year range at the top\n            List<FacetLabel> facetLabelListReversed = new ArrayList<>();\n            ListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\n            while (li.hasPrevious()) {\n                facetLabelListReversed.add(li.previous());\n            }\n            facetCategory.setFacetLabel(facetLabelListReversed);\n            if (!facetLabelList.isEmpty()) {\n                facetCategoryList.add(facetCategory);\n            }\n        }\n        SolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\n        solrQueryResponse.setSolrSearchResults(solrSearchResults);\n        solrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\n        solrQueryResponse.setFacetCategoryList(facetCategoryList);\n        solrQueryResponse.setTypeFacetCategories(typeFacetCategories);\n        solrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\n        solrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\n        solrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\n        solrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\n        String[] filterQueriesArray = solrQuery.getFilterQueries();\n        if (filterQueriesArray != null) {\n            \/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\n            List<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\n            logger.fine(\"actual filter queries: \" + actualFilterQueries);\n            solrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n        } else {\n            \/\/ how often is this null?\n            logger.info(\"solrQuery.getFilterQueries() was null\");\n        }\n        solrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\n        solrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\n        return solrQueryResponse;\n    }","code":"public SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\n        if (paginationStart < 0) {\n            throw new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n        }\n        if (numResultsPerPage < 1) {\n            throw new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n        }\n        SolrQuery solrQuery = new SolrQuery();\n        query = SearchUtil.sanitizeQuery(query);\n        solrQuery.setQuery(query);\n        solrQuery.setSort(new SortClause(sortField, sortOrder));\n        solrQuery.setHighlight(true).setHighlightSnippets(1);\n        Integer fragSize = systemConfig.getSearchHighlightFragmentSize();\n        if (fragSize != null) {\n            solrQuery.setHighlightFragsize(fragSize);\n        }\n        solrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\n        solrQuery.setHighlightSimplePost(\"<\/span>\");\n        Map<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n       \n        solrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\n        solrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\n        solrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\n        solrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\n        solrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n       \n             \n        solrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n        solrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n        List<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\n        for (DatasetFieldType datasetFieldType : datasetFields) {\n            String solrField = datasetFieldType.getSolrField().getNameSearchable();\n            String displayName = datasetFieldType.getDisplayName();\n            solrFieldsToHightlightOnMap.put(solrField, displayName);\n        }\n        for (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\n            String solrField = entry.getKey();\n           \n            solrQuery.addHighlightField(solrField);\n        }\n        solrQuery.setParam(\"fl\", \"*,score\");\n        solrQuery.setParam(\"qt\", \"\/select\");\n        solrQuery.setParam(\"facet\", \"true\");\n       \n        solrQuery.setParam(\"facet.query\", \"*\");\n        for (String filterQuery : filterQueries) {\n            solrQuery.addFilterQuery(filterQuery);\n        }\n       \n       \n       \n        String permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\n        if (permissionFilterQuery != null) {\n            solrQuery.addFilterQuery(permissionFilterQuery);\n        }\n       \n       \n       \n        solrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\n        solrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n        solrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n       \n        if (dataverse != null) {\n            for (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\n                DatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\n                solrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n            }\n        }\n        solrQuery.addFacetField(SearchFields.FILE_TYPE);\n       \n        solrQuery.addFacetField(SearchFields.TYPE);\n        solrQuery.addFacetField(SearchFields.FILE_TAG);\n        if (!systemConfig.isPublicInstall()) {\n            solrQuery.addFacetField(SearchFields.ACCESS);\n        }\n       \n        solrQuery.setStart(paginationStart);\n       \n       \n        int thisYear = Calendar.getInstance().get(Calendar.YEAR);\n       \n        final int citationYearRangeStart = 1901;\n        final int citationYearRangeEnd = thisYear;\n        final int citationYearRangeSpan = 2;\n       \n        solrQuery.setRows(numResultsPerPage);\n        logger.fine(\"Solr query:\" + solrQuery);\n       \n       \n       \n        QueryResponse queryResponse = null;\n        try {\n            queryResponse = solrServer.query(solrQuery);\n        } catch (RemoteSolrException ex) {\n            String messageFromSolr = ex.getLocalizedMessage();\n            String error = \"Search Syntax Error: \";\n            String stringToHide = \"org.apache.solr.search.SyntaxError: \";\n            if (messageFromSolr.startsWith(stringToHide)) {\n               \n                error += messageFromSolr.substring(stringToHide.length());\n            } else {\n                error += messageFromSolr;\n            }\n            logger.info(error);\n            SolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\n            exceptionSolrQueryResponse.setError(error);\n           \n            long zeroNumResultsFound = 0;\n            long zeroGetResultsStart = 0;\n            List<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\n            List<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\n            Map<String, List<String>> emptySpellingSuggestion = new HashMap<>();\n            exceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\n            exceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\n            exceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\n            exceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\n            exceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\n            exceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\n            return exceptionSolrQueryResponse;\n        } catch (SolrServerException | IOException ex) {\n            throw new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n        }\n        SolrDocumentList docs = queryResponse.getResults();\n        List<SolrSearchResult> solrSearchResults = new ArrayList<>();\n       \n        Object searchFieldsObject = new SearchFields();\n        Field[] staticSearchFields = searchFieldsObject.getClass().getDeclaredFields();\n        String titleSolrField = null;\n        try {\n            DatasetFieldType titleDatasetField = datasetFieldService.findByName(DatasetFieldConstant.title);\n            titleSolrField = titleDatasetField.getSolrField().getNameSearchable();\n        } catch (EJBTransactionRolledbackException ex) {\n            logger.info(\"Couldn't find \" + DatasetFieldConstant.title);\n            if (ex.getCause() instanceof TransactionRolledbackLocalException) {\n                if (ex.getCause().getCause() instanceof NoResultException) {\n                    logger.info(\"Caught NoResultException\");\n                }\n            }\n        }\n        Map<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\n        Map<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\n        String baseUrl = systemConfig.getDataverseSiteUrl();\n        for (SolrDocument solrDocument : docs) {\n            String id = (String) solrDocument.getFieldValue(SearchFields.ID);\n            Long entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\n            String type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\n            float score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\n            logger.fine(\"score for \" + id + \": \" + score);\n            String identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\n            String citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\n            String citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\n            String persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\n            String name = (String) solrDocument.getFieldValue(SearchFields.NAME);\n            String nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n            String title = (String) solrDocument.getFieldValue(titleSolrField);\n            Long datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\n            String deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n            String filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\n            String fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\n            Date release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\n            String dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\n            String dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\n            List<String> matchedFields = new ArrayList<>();\n            List<Highlight> highlights = new ArrayList<>();\n            Map<SolrField, Highlight> highlightsMap = new HashMap<>();\n            Map<SolrField, List<String>> highlightsMap2 = new HashMap<>();\n            Map<String, Highlight> highlightsMap3 = new HashMap<>();\n            if (queryResponse.getHighlighting().get(id) != null) {\n                for (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\n                    String field = entry.getKey();\n                    String displayName = entry.getValue();\n                    List<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\n                    if (highlightSnippets != null) {\n                        matchedFields.add(field);\n                       \n                        SolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\n                        Highlight highlight = new Highlight(solrField, highlightSnippets, displayName);\n                        highlights.add(highlight);\n                        highlightsMap.put(solrField, highlight);\n                        highlightsMap2.put(solrField, highlightSnippets);\n                        highlightsMap3.put(field, highlight);\n                    }\n                }\n            }\n            SolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n           \n            List<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\n            if (states != null) {\n               \n               \n                solrSearchResult.setPublicationStatuses(states);\n            }\n            solrSearchResult.setId(id);\n            solrSearchResult.setEntityId(entityid);\n            if (retrieveEntities) {\n                solrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n            }\n            solrSearchResult.setIdentifier(identifier);\n            solrSearchResult.setPersistentUrl(persistentUrl);\n            solrSearchResult.setType(type);\n            solrSearchResult.setScore(score);\n            solrSearchResult.setNameSort(nameSort);\n            solrSearchResult.setReleaseOrCreateDate(release_or_create_date);\n            solrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\n            solrSearchResult.setMatchedFields(matchedFields);\n            solrSearchResult.setHighlightsAsList(highlights);\n            solrSearchResult.setHighlightsMap(highlightsMap);\n            solrSearchResult.setHighlightsAsMap(highlightsMap3);\n            Map<String, String> parent = new HashMap<>();\n            String description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\n            solrSearchResult.setDescriptionNoSnippet(description);\n            solrSearchResult.setDeaccessionReason(deaccessionReason);\n            solrSearchResult.setDvTree(dvTree);\n            String originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\n            if (IndexServiceBean.HARVESTED.equals(originSource)) {\n                solrSearchResult.setHarvested(true);\n            }\n           \n            if (type.equals(\"dataverses\")) {\n                solrSearchResult.setName(name);\n                solrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n               \n               \n               \n               \n               \n            } else if (type.equals(\"datasets\")) {\n                solrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\n                solrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n               \n               \n               \n               \n               \n               \n               \n               \n               \n               \n                List<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\n                if (datasetDescriptions != null) {\n                    String firstDatasetDescription = datasetDescriptions.get(0);\n                    if (firstDatasetDescription != null) {\n                        solrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n                    }\n                }\n                solrSearchResult.setDatasetVersionId(datasetVersionId);\n                solrSearchResult.setCitation(citation);\n                solrSearchResult.setCitationHtml(citationPlainHtml);\n                if (title != null) {\n                    solrSearchResult.setTitle(title);\n                } else {\n                    logger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\n                    solrSearchResult.setTitle(\"\");\n                }\n                List<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\n                if (authors != null) {\n                    solrSearchResult.setDatasetAuthors(authors);\n                }\n            } else if (type.equals(\"files\")) {\n                String parentGlobalId = null;\n                Object parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\n                if (parentGlobalIdObject != null) {\n                    parentGlobalId = (String) parentGlobalIdObject;\n                    parent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n                }\n                solrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\n                solrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n               \n               \n                solrSearchResult.setName(name);\n                solrSearchResult.setFiletype(filetype);\n                solrSearchResult.setFileContentType(fileContentType);\n                Object fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\n                if (fileSizeInBytesObject != null) {\n                    try {\n                        long fileSizeInBytesLong = (long) fileSizeInBytesObject;\n                        solrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n                    } catch (ClassCastException ex) {\n                        logger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n                    }\n                }\n                solrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\n                try {\n                    solrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n                } catch (IllegalArgumentException ex) {\n                    logger.info(\"Exception setting setFileChecksumType: \" + ex);\n                }\n                solrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\n                solrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\n                solrSearchResult.setDatasetVersionId(datasetVersionId);\n                List<String> fileCategories = (List) solrDocument.getFieldValues(SearchFields.FILE_TAG);\n                if (fileCategories != null) {\n                    solrSearchResult.setFileCategories(fileCategories);\n                }\n                List<String> tabularDataTags = (List) solrDocument.getFieldValues(SearchFields.TABDATA_TAG);\n                if (tabularDataTags != null) {\n                    Collections.sort(tabularDataTags);\n                    solrSearchResult.setTabularDataTags(tabularDataTags);\n                }\n            }\n           \n            parent.put(\"id\", (String) solrDocument.getFieldValue(SearchFields.PARENT_ID));\n            parent.put(\"name\", (String) solrDocument.getFieldValue(SearchFields.PARENT_NAME));\n            parent.put(\"citation\", (String) solrDocument.getFieldValue(SearchFields.PARENT_CITATION));\n            solrSearchResult.setParent(parent);\n            solrSearchResults.add(solrSearchResult);\n        }\n        Map<String, List<String>> spellingSuggestionsByToken = new HashMap<>();\n        SpellCheckResponse spellCheckResponse = queryResponse.getSpellCheckResponse();\n        if (spellCheckResponse != null) {\n            List<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\n            for (SpellCheckResponse.Suggestion suggestion : suggestions) {\n                spellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n            }\n        }\n        List<FacetCategory> facetCategoryList = new ArrayList<>();\n        List<FacetCategory> typeFacetCategories = new ArrayList<>();\n        boolean hidePublicationStatusFacet = true;\n        boolean draftsAvailable = false;\n        boolean unpublishedAvailable = false;\n        boolean deaccessionedAvailable = false;\n        boolean hideMetadataSourceFacet = true;\n        for (FacetField facetField : queryResponse.getFacetFields()) {\n            FacetCategory facetCategory = new FacetCategory();\n            List<FacetLabel> facetLabelList = new ArrayList<>();\n            int numMetadataSources = 0;\n            for (FacetField.Count facetFieldCount : facetField.getValues()) {\n               \n                if (facetFieldCount.getCount() > 0) {\n                    FacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n                   \n                    facetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\n                    facetLabelList.add(facetLabel);\n                    if (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\n                        if (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\n                            unpublishedAvailable = true;\n                        } else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\n                            draftsAvailable = true;\n                        } else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\n                            deaccessionedAvailable = true;\n                        }\n                    }\n                    if (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\n                        numMetadataSources++;\n                    }\n                }\n            }\n            if (numMetadataSources > 1) {\n                hideMetadataSourceFacet = false;\n            }\n            facetCategory.setName(facetField.getName());\n           \n            facetCategory.setFriendlyName(facetField.getName());\n           \n           \n            for (DatasetFieldType datasetField : datasetFields) {\n                String solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\n                String friendlyName = datasetField.getDisplayName();\n                if (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n                   \n                    facetCategory.setName(facetField.getName());\n                } else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\n                    if (friendlyName != null && !friendlyName.isEmpty()) {\n                        facetCategory.setFriendlyName(friendlyName);\n                       \n                        break;\n                    }\n                }\n                datasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n            }\n           \n            for (Field fieldObject : staticSearchFields) {\n                String name = fieldObject.getName();\n                String staticSearchField = null;\n                try {\n                    staticSearchField = (String) fieldObject.get(searchFieldsObject);\n                } catch (IllegalArgumentException | IllegalAccessException ex) {\n                    Logger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n                }\n                if (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\n                    String[] parts = name.split(\"_\");\n                    StringBuilder stringBuilder = new StringBuilder();\n                    for (String part : parts) {\n                        stringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n                    }\n                    String friendlyNameWithTrailingSpace = stringBuilder.toString();\n                    String friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\n                    facetCategory.setFriendlyName(friendlyName);\n                    staticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n                   \n                    break;\n                }\n            }\n            facetCategory.setFacetLabel(facetLabelList);\n            if (!facetLabelList.isEmpty()) {\n                if (facetCategory.getName().equals(SearchFields.TYPE)) {\n                   \n                    typeFacetCategories.add(facetCategory);\n                } else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\n                    if (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\n                        hidePublicationStatusFacet = false;\n                    }\n                    if (!hidePublicationStatusFacet) {\n                        facetCategoryList.add(facetCategory);\n                    }\n                } else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\n                    if (!hideMetadataSourceFacet) {\n                        facetCategoryList.add(facetCategory);\n                    }\n                } else {\n                    facetCategoryList.add(facetCategory);\n                }\n            }\n        }\n       \n        for (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\n            FacetCategory facetCategory = new FacetCategory();\n            List<FacetLabel> facetLabelList = new ArrayList<>();\n            for (Object rfObj : rangeFacet.getCounts()) {\n                RangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\n                String valueString = rangeFacetCount.getValue();\n                Integer start = Integer.parseInt(valueString);\n                Integer end = start + Integer.parseInt(rangeFacet.getGap().toString());\n               \n                end = end - 1;\n                if (rangeFacetCount.getCount() > 0) {\n                    FacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n                   \n                    facetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\n                    facetLabelList.add(facetLabel);\n                }\n            }\n            facetCategory.setName(rangeFacet.getName());\n            facetCategory.setFacetLabel(facetLabelList);\n           \n            List<FacetLabel> facetLabelListReversed = new ArrayList<>();\n            ListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\n            while (li.hasPrevious()) {\n                facetLabelListReversed.add(li.previous());\n            }\n            facetCategory.setFacetLabel(facetLabelListReversed);\n            if (!facetLabelList.isEmpty()) {\n                facetCategoryList.add(facetCategory);\n            }\n        }\n        SolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\n        solrQueryResponse.setSolrSearchResults(solrSearchResults);\n        solrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\n        solrQueryResponse.setFacetCategoryList(facetCategoryList);\n        solrQueryResponse.setTypeFacetCategories(typeFacetCategories);\n        solrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\n        solrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\n        solrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\n        solrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\n        String[] filterQueriesArray = solrQuery.getFilterQueries();\n        if (filterQueriesArray != null) {\n           \n            List<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\n            logger.fine(\"actual filter queries: \" + actualFilterQueries);\n            solrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n        } else {\n           \n            logger.info(\"solrQuery.getFilterQueries() was null\");\n        }\n        solrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\n        solrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\n        return solrQueryResponse;\n    }","cleancode":"public solrqueryresponse search(dataverserequest dataverserequest, dataverse dataverse, string query, list<string> filterqueries, string sortfield, string sortorder, int paginationstart, boolean onlydatatrelatedtome, int numresultsperpage, boolean retrieveentities) throws searchexception { if (paginationstart < 0) { throw new illegalargumentexception(\"paginationstart must be 0 or greater\"); } if (numresultsperpage < 1) { throw new illegalargumentexception(\"numresultsperpage must be 1 or greater\"); } solrquery solrquery = new solrquery(); query = searchutil.sanitizequery(query); solrquery.setquery(query); solrquery.setsort(new sortclause(sortfield, sortorder)); solrquery.sethighlight(true).sethighlightsnippets(1); integer fragsize = systemconfig.getsearchhighlightfragmentsize(); if (fragsize != null) { solrquery.sethighlightfragsize(fragsize); } solrquery.sethighlightsimplepre(\"<span class=\\\"search-term-match\\\">\"); solrquery.sethighlightsimplepost(\"<\/span>\"); map<string, string> solrfieldstohightlightonmap = new hashmap<>(); solrfieldstohightlightonmap.put(searchfields.name, \"name\"); solrfieldstohightlightonmap.put(searchfields.affiliation, \"affiliation\"); solrfieldstohightlightonmap.put(searchfields.file_type_friendly, \"file type\"); solrfieldstohightlightonmap.put(searchfields.description, \"description\"); solrfieldstohightlightonmap.put(searchfields.variable_name, \"variable name\"); solrfieldstohightlightonmap.put(searchfields.variable_label, \"variable label\"); solrfieldstohightlightonmap.put(searchfields.file_type_searchable, \"file type\"); solrfieldstohightlightonmap.put(searchfields.dataset_publication_date, \"publication date\"); solrfieldstohightlightonmap.put(searchfields.dataset_persistent_id, bundleutil.getstringfrombundle(\"advanced.search.datasets.persistentid\")); solrfieldstohightlightonmap.put(searchfields.file_persistent_id, bundleutil.getstringfrombundle(\"advanced.search.files.persistentid\")); solrfieldstohightlightonmap.put(searchfields.filename_without_extension, \"filename without extension\"); solrfieldstohightlightonmap.put(searchfields.file_tag_searchable, \"file tag\"); list<datasetfieldtype> datasetfields = datasetfieldservice.findallorderedbyid(); for (datasetfieldtype datasetfieldtype : datasetfields) { string solrfield = datasetfieldtype.getsolrfield().getnamesearchable(); string displayname = datasetfieldtype.getdisplayname(); solrfieldstohightlightonmap.put(solrfield, displayname); } for (map.entry<string, string> entry : solrfieldstohightlightonmap.entryset()) { string solrfield = entry.getkey(); solrquery.addhighlightfield(solrfield); } solrquery.setparam(\"fl\", \"*,score\"); solrquery.setparam(\"qt\", \"\/select\"); solrquery.setparam(\"facet\", \"true\"); solrquery.setparam(\"facet.query\", \"*\"); for (string filterquery : filterqueries) { solrquery.addfilterquery(filterquery); } string permissionfilterquery = this.getpermissionfilterquery(dataverserequest, solrquery, dataverse, onlydatatrelatedtome); if (permissionfilterquery != null) { solrquery.addfilterquery(permissionfilterquery); } solrquery.addfacetfield(searchfields.dataverse_category); solrquery.addfacetfield(searchfields.metadata_source); solrquery.addfacetfield(searchfields.publication_date); if (dataverse != null) { for (dataversefacet dataversefacet : dataverse.getdataversefacets()) { datasetfieldtype datasetfield = dataversefacet.getdatasetfieldtype(); solrquery.addfacetfield(datasetfield.getsolrfield().getnamefacetable()); } } solrquery.addfacetfield(searchfields.file_type); solrquery.addfacetfield(searchfields.type); solrquery.addfacetfield(searchfields.file_tag); if (!systemconfig.ispublicinstall()) { solrquery.addfacetfield(searchfields.access); } solrquery.setstart(paginationstart); int thisyear = calendar.getinstance().get(calendar.year); final int citationyearrangestart = 1901; final int citationyearrangeend = thisyear; final int citationyearrangespan = 2; solrquery.setrows(numresultsperpage); logger.fine(\"solr query:\" + solrquery); queryresponse queryresponse = null; try { queryresponse = solrserver.query(solrquery); } catch (remotesolrexception ex) { string messagefromsolr = ex.getlocalizedmessage(); string error = \"search syntax error: \"; string stringtohide = \"org.apache.solr.search.syntaxerror: \"; if (messagefromsolr.startswith(stringtohide)) { error += messagefromsolr.substring(stringtohide.length()); } else { error += messagefromsolr; } logger.info(error); solrqueryresponse exceptionsolrqueryresponse = new solrqueryresponse(solrquery); exceptionsolrqueryresponse.seterror(error); long zeronumresultsfound = 0; long zerogetresultsstart = 0; list<solrsearchresult> emptysolrsearchresults = new arraylist<>(); list<facetcategory> exceptionfacetcategorylist = new arraylist<>(); map<string, list<string>> emptyspellingsuggestion = new hashmap<>(); exceptionsolrqueryresponse.setnumresultsfound(zeronumresultsfound); exceptionsolrqueryresponse.setresultsstart(zerogetresultsstart); exceptionsolrqueryresponse.setsolrsearchresults(emptysolrsearchresults); exceptionsolrqueryresponse.setfacetcategorylist(exceptionfacetcategorylist); exceptionsolrqueryresponse.settypefacetcategories(exceptionfacetcategorylist); exceptionsolrqueryresponse.setspellingsuggestionsbytoken(emptyspellingsuggestion); return exceptionsolrqueryresponse; } catch (solrserverexception | ioexception ex) { throw new searchexception(\"internal dataverse search engine error\", ex); } solrdocumentlist docs = queryresponse.getresults(); list<solrsearchresult> solrsearchresults = new arraylist<>(); object searchfieldsobject = new searchfields(); field[] staticsearchfields = searchfieldsobject.getclass().getdeclaredfields(); string titlesolrfield = null; try { datasetfieldtype titledatasetfield = datasetfieldservice.findbyname(datasetfieldconstant.title); titlesolrfield = titledatasetfield.getsolrfield().getnamesearchable(); } catch (ejbtransactionrolledbackexception ex) { logger.info(\"couldn't find \" + datasetfieldconstant.title); if (ex.getcause() instanceof transactionrolledbacklocalexception) { if (ex.getcause().getcause() instanceof noresultexception) { logger.info(\"caught noresultexception\"); } } } map<string, string> datasetfieldfriendlynamesbysolrfield = new hashmap<>(); map<string, string> staticsolrfieldfriendlynamesbysolrfield = new hashmap<>(); string baseurl = systemconfig.getdataversesiteurl(); for (solrdocument solrdocument : docs) { string id = (string) solrdocument.getfieldvalue(searchfields.id); long entityid = (long) solrdocument.getfieldvalue(searchfields.entity_id); string type = (string) solrdocument.getfieldvalue(searchfields.type); float score = (float) solrdocument.getfieldvalue(searchfields.relevance); logger.fine(\"score for \" + id + \": \" + score); string identifier = (string) solrdocument.getfieldvalue(searchfields.identifier); string citation = (string) solrdocument.getfieldvalue(searchfields.dataset_citation); string citationplainhtml = (string) solrdocument.getfieldvalue(searchfields.dataset_citation_html); string persistenturl = (string) solrdocument.getfieldvalue(searchfields.persistent_url); string name = (string) solrdocument.getfieldvalue(searchfields.name); string namesort = (string) solrdocument.getfieldvalue(searchfields.name_sort); string title = (string) solrdocument.getfieldvalue(titlesolrfield); long datasetversionid = (long) solrdocument.getfieldvalue(searchfields.dataset_version_id); string deaccessionreason = (string) solrdocument.getfieldvalue(searchfields.dataset_deaccession_reason); string filetype = (string) solrdocument.getfieldvalue(searchfields.file_type_friendly); string filecontenttype = (string) solrdocument.getfieldvalue(searchfields.file_content_type); date release_or_create_date = (date) solrdocument.getfieldvalue(searchfields.release_or_create_date); string datetodisplayoncard = (string) solrdocument.getfirstvalue(searchfields.release_or_create_date_searchable_text); string dvtree = (string) solrdocument.getfirstvalue(searchfields.subtree); list<string> matchedfields = new arraylist<>(); list<highlight> highlights = new arraylist<>(); map<solrfield, highlight> highlightsmap = new hashmap<>(); map<solrfield, list<string>> highlightsmap2 = new hashmap<>(); map<string, highlight> highlightsmap3 = new hashmap<>(); if (queryresponse.gethighlighting().get(id) != null) { for (map.entry<string, string> entry : solrfieldstohightlightonmap.entryset()) { string field = entry.getkey(); string displayname = entry.getvalue(); list<string> highlightsnippets = queryresponse.gethighlighting().get(id).get(field); if (highlightsnippets != null) { matchedfields.add(field); solrfield solrfield = new solrfield(field, solrfield.solrtype.string, true, true); highlight highlight = new highlight(solrfield, highlightsnippets, displayname); highlights.add(highlight); highlightsmap.put(solrfield, highlight); highlightsmap2.put(solrfield, highlightsnippets); highlightsmap3.put(field, highlight); } } } solrsearchresult solrsearchresult = new solrsearchresult(query, name); list<string> states = (list<string>) solrdocument.getfieldvalue(searchfields.publication_status); if (states != null) { solrsearchresult.setpublicationstatuses(states); } solrsearchresult.setid(id); solrsearchresult.setentityid(entityid); if (retrieveentities) { solrsearchresult.setentity(dvobjectservice.finddvobject(entityid)); } solrsearchresult.setidentifier(identifier); solrsearchresult.setpersistenturl(persistenturl); solrsearchresult.settype(type); solrsearchresult.setscore(score); solrsearchresult.setnamesort(namesort); solrsearchresult.setreleaseorcreatedate(release_or_create_date); solrsearchresult.setdatetodisplayoncard(datetodisplayoncard); solrsearchresult.setmatchedfields(matchedfields); solrsearchresult.sethighlightsaslist(highlights); solrsearchresult.sethighlightsmap(highlightsmap); solrsearchresult.sethighlightsasmap(highlightsmap3); map<string, string> parent = new hashmap<>(); string description = (string) solrdocument.getfieldvalue(searchfields.description); solrsearchresult.setdescriptionnosnippet(description); solrsearchresult.setdeaccessionreason(deaccessionreason); solrsearchresult.setdvtree(dvtree); string originsource = (string) solrdocument.getfieldvalue(searchfields.metadata_source); if (indexservicebean.harvested.equals(originsource)) { solrsearchresult.setharvested(true); } if (type.equals(\"dataverses\")) { solrsearchresult.setname(name); solrsearchresult.sethtmlurl(baseurl + systemconfig.dataverse_path + identifier); } else if (type.equals(\"datasets\")) { solrsearchresult.sethtmlurl(baseurl + \"\/dataset.xhtml?globalid=\" + identifier); solrsearchresult.setapiurl(baseurl + \"\/api\/datasets\/\" + entityid); list<string> datasetdescriptions = (list<string>) solrdocument.getfieldvalue(searchfields.dataset_description); if (datasetdescriptions != null) { string firstdatasetdescription = datasetdescriptions.get(0); if (firstdatasetdescription != null) { solrsearchresult.setdescriptionnosnippet(firstdatasetdescription); } } solrsearchresult.setdatasetversionid(datasetversionid); solrsearchresult.setcitation(citation); solrsearchresult.setcitationhtml(citationplainhtml); if (title != null) { solrsearchresult.settitle(title); } else { logger.fine(\"no title indexed. setting to empty string to prevent npe. dataset id \" + entityid + \" and version id \" + datasetversionid); solrsearchresult.settitle(\"\"); } list<string> authors = (list) solrdocument.getfieldvalues(datasetfieldconstant.authorname); if (authors != null) { solrsearchresult.setdatasetauthors(authors); } } else if (type.equals(\"files\")) { string parentglobalid = null; object parentglobalidobject = solrdocument.getfieldvalue(searchfields.parent_identifier); if (parentglobalidobject != null) { parentglobalid = (string) parentglobalidobject; parent.put(solrsearchresult.parent_identifier, parentglobalid); } solrsearchresult.sethtmlurl(baseurl + \"\/dataset.xhtml?persistentid=\" + parentglobalid); solrsearchresult.setdownloadurl(baseurl + \"\/api\/access\/datafile\/\" + entityid); solrsearchresult.setname(name); solrsearchresult.setfiletype(filetype); solrsearchresult.setfilecontenttype(filecontenttype); object filesizeinbytesobject = solrdocument.getfieldvalue(searchfields.file_size_in_bytes); if (filesizeinbytesobject != null) { try { long filesizeinbyteslong = (long) filesizeinbytesobject; solrsearchresult.setfilesizeinbytes(filesizeinbyteslong); } catch (classcastexception ex) { logger.info(\"could not cast file \" + entityid + \" to long for \" + searchfields.file_size_in_bytes + \": \" + ex.getlocalizedmessage()); } } solrsearchresult.setfilemd5((string) solrdocument.getfieldvalue(searchfields.file_md5)); try { solrsearchresult.setfilechecksumtype(datafile.checksumtype.fromstring((string) solrdocument.getfieldvalue(searchfields.file_checksum_type))); } catch (illegalargumentexception ex) { logger.info(\"exception setting setfilechecksumtype: \" + ex); } solrsearchresult.setfilechecksumvalue((string) solrdocument.getfieldvalue(searchfields.file_checksum_value)); solrsearchresult.setunf((string) solrdocument.getfieldvalue(searchfields.unf)); solrsearchresult.setdatasetversionid(datasetversionid); list<string> filecategories = (list) solrdocument.getfieldvalues(searchfields.file_tag); if (filecategories != null) { solrsearchresult.setfilecategories(filecategories); } list<string> tabulardatatags = (list) solrdocument.getfieldvalues(searchfields.tabdata_tag); if (tabulardatatags != null) { collections.sort(tabulardatatags); solrsearchresult.settabulardatatags(tabulardatatags); } } parent.put(\"id\", (string) solrdocument.getfieldvalue(searchfields.parent_id)); parent.put(\"name\", (string) solrdocument.getfieldvalue(searchfields.parent_name)); parent.put(\"citation\", (string) solrdocument.getfieldvalue(searchfields.parent_citation)); solrsearchresult.setparent(parent); solrsearchresults.add(solrsearchresult); } map<string, list<string>> spellingsuggestionsbytoken = new hashmap<>(); spellcheckresponse spellcheckresponse = queryresponse.getspellcheckresponse(); if (spellcheckresponse != null) { list<spellcheckresponse.suggestion> suggestions = spellcheckresponse.getsuggestions(); for (spellcheckresponse.suggestion suggestion : suggestions) { spellingsuggestionsbytoken.put(suggestion.gettoken(), suggestion.getalternatives()); } } list<facetcategory> facetcategorylist = new arraylist<>(); list<facetcategory> typefacetcategories = new arraylist<>(); boolean hidepublicationstatusfacet = true; boolean draftsavailable = false; boolean unpublishedavailable = false; boolean deaccessionedavailable = false; boolean hidemetadatasourcefacet = true; for (facetfield facetfield : queryresponse.getfacetfields()) { facetcategory facetcategory = new facetcategory(); list<facetlabel> facetlabellist = new arraylist<>(); int nummetadatasources = 0; for (facetfield.count facetfieldcount : facetfield.getvalues()) { if (facetfieldcount.getcount() > 0) { facetlabel facetlabel = new facetlabel(facetfieldcount.getname(), facetfieldcount.getcount()); facetlabel.setfilterquery(facetfield.getname() + \":\\\"\" + facetfieldcount.getname() + \"\\\"\"); facetlabellist.add(facetlabel); if (facetfield.getname().equals(searchfields.publication_status)) { if (facetlabel.getname().equals(indexservicebean.getunpublished_string())) { unpublishedavailable = true; } else if (facetlabel.getname().equals(indexservicebean.getdraft_string())) { draftsavailable = true; } else if (facetlabel.getname().equals(indexservicebean.getdeaccessioned_string())) { deaccessionedavailable = true; } } if (facetfield.getname().equals(searchfields.metadata_source)) { nummetadatasources++; } } } if (nummetadatasources > 1) { hidemetadatasourcefacet = false; } facetcategory.setname(facetfield.getname()); facetcategory.setfriendlyname(facetfield.getname()); for (datasetfieldtype datasetfield : datasetfields) { string solrfieldnamefordataset = datasetfield.getsolrfield().getnamefacetable(); string friendlyname = datasetfield.getdisplayname(); if (solrfieldnamefordataset != null && facetfield.getname().endswith(datasetfield.gettmpnullfieldtypeidentifier())) { facetcategory.setname(facetfield.getname()); } else if (solrfieldnamefordataset != null && facetfield.getname().equals(solrfieldnamefordataset)) { if (friendlyname != null && !friendlyname.isempty()) { facetcategory.setfriendlyname(friendlyname); break; } } datasetfieldfriendlynamesbysolrfield.put(datasetfield.getsolrfield().getnamefacetable(), friendlyname); } for (field fieldobject : staticsearchfields) { string name = fieldobject.getname(); string staticsearchfield = null; try { staticsearchfield = (string) fieldobject.get(searchfieldsobject); } catch (illegalargumentexception | illegalaccessexception ex) { logger.getlogger(searchservicebean.class.getname()).log(level.severe, null, ex); } if (staticsearchfield != null && facetfield.getname().equals(staticsearchfield)) { string[] parts = name.split(\"_\"); stringbuilder stringbuilder = new stringbuilder(); for (string part : parts) { stringbuilder.append(getcapitalizedname(part.tolowercase()) + \" \"); } string friendlynamewithtrailingspace = stringbuilder.tostring(); string friendlyname = friendlynamewithtrailingspace.replaceall(\" $\", \"\"); facetcategory.setfriendlyname(friendlyname); staticsolrfieldfriendlynamesbysolrfield.put(staticsearchfield, friendlyname); break; } } facetcategory.setfacetlabel(facetlabellist); if (!facetlabellist.isempty()) { if (facetcategory.getname().equals(searchfields.type)) { typefacetcategories.add(facetcategory); } else if (facetcategory.getname().equals(searchfields.publication_status)) { if (unpublishedavailable || draftsavailable || deaccessionedavailable) { hidepublicationstatusfacet = false; } if (!hidepublicationstatusfacet) { facetcategorylist.add(facetcategory); } } else if (facetcategory.getname().equals(searchfields.metadata_source)) { if (!hidemetadatasourcefacet) { facetcategorylist.add(facetcategory); } } else { facetcategorylist.add(facetcategory); } } } for (rangefacet<string, string> rangefacet : queryresponse.getfacetranges()) { facetcategory facetcategory = new facetcategory(); list<facetlabel> facetlabellist = new arraylist<>(); for (object rfobj : rangefacet.getcounts()) { rangefacet.count rangefacetcount = (rangefacet.count) rfobj; string valuestring = rangefacetcount.getvalue(); integer start = integer.parseint(valuestring); integer end = start + integer.parseint(rangefacet.getgap().tostring()); end = end - 1; if (rangefacetcount.getcount() > 0) { facetlabel facetlabel = new facetlabel(start + \"-\" + end, new long(rangefacetcount.getcount())); facetlabel.setfilterquery(rangefacet.getname() + \":\" + \"[\" + start + \" to \" + end + \"]\"); facetlabellist.add(facetlabel); } } facetcategory.setname(rangefacet.getname()); facetcategory.setfacetlabel(facetlabellist); list<facetlabel> facetlabellistreversed = new arraylist<>(); listiterator<facetlabel> li = facetlabellist.listiterator(facetlabellist.size()); while (li.hasprevious()) { facetlabellistreversed.add(li.previous()); } facetcategory.setfacetlabel(facetlabellistreversed); if (!facetlabellist.isempty()) { facetcategorylist.add(facetcategory); } } solrqueryresponse solrqueryresponse = new solrqueryresponse(solrquery); solrqueryresponse.setsolrsearchresults(solrsearchresults); solrqueryresponse.setspellingsuggestionsbytoken(spellingsuggestionsbytoken); solrqueryresponse.setfacetcategorylist(facetcategorylist); solrqueryresponse.settypefacetcategories(typefacetcategories); solrqueryresponse.setnumresultsfound(queryresponse.getresults().getnumfound()); solrqueryresponse.setresultsstart(queryresponse.getresults().getstart()); solrqueryresponse.setdatasetfieldfriendlynamesbysolrfield(datasetfieldfriendlynamesbysolrfield); solrqueryresponse.setstaticsolrfieldfriendlynamesbysolrfield(staticsolrfieldfriendlynamesbysolrfield); string[] filterqueriesarray = solrquery.getfilterqueries(); if (filterqueriesarray != null) { list<string> actualfilterqueries = arrays.aslist(filterqueriesarray); logger.fine(\"actual filter queries: \" + actualfilterqueries); solrqueryresponse.setfilterqueriesactual(actualfilterqueries); } else { logger.info(\"solrquery.getfilterqueries() was null\"); } solrqueryresponse.setdvobjectcounts(queryresponse.getfacetfield(\"dvobjecttype\")); solrqueryresponse.setpublicationstatuscounts(queryresponse.getfacetfield(\"publicationstatus\")); return solrqueryresponse; }","comment":"\/** * import note: \"onlydatatrelatedtome\" relies on filterqueries for providing * access to private data for the correct user * * in other words \"onlydatatrelatedtome\", negates other filter queries * related to permissions * * * @param user * @param dataverse * @param query * @param filterqueries * @param sortfield * @param sortorder * @param paginationstart * @param onlydatatrelatedtome * @param numresultsperpage * @param retrieveentities - look up dvobject entities with .find() (potentially expensive!) * @return * @throws searchexception *\/\n\/\/ sortclause foo = new sortclause(\"name\", solrquery.order.desc); \/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) { \/\/ solrquery.setsort(new sortclause(searchfields.name_sort, solrquery.order.asc));\n\/\/ } else { \/\/ solrquery.setsort(sortclause); \/\/ } \/\/ solrquery.setsort(sortclause);\n\/\/ todo: do not hard code \"name\" etc as english here.\n\/** * @todo dataverse subject and affiliation should be highlighted but * this is commented out right now because the \"friendly\" names are not * being shown on the dataverse cards. see also * https:\/\/github.com\/iqss\/dataverse\/issues\/1431 *\/\n\/\/ solrfieldstohightlightonmap.put(searchfields.dataverse_subject, \"subject\"); \/\/ solrfieldstohightlightonmap.put(searchfields.dataverse_affiliation, \"affiliation\"); \/** * @todo: show highlight on file card? * https:\/\/redmine.hmdc.harvard.edu\/issues\/3848 *\/\n\/\/ string displayname = entry.getvalue();\n\/** * @todo: do we need facet.query? *\/\n\/\/ ----------------------------------- \/\/ permission filter query \/\/ -----------------------------------\n\/\/ ----------------------------------- \/\/ facets to retrieve \/\/ ----------------------------------- \/\/ solrquery.addfacetfield(searchfields.host_dataverse); \/\/ solrquery.addfacetfield(searchfields.author_string);\n\/\/ solrquery.addfacetfield(searchfields.affiliation);\n\/\/ solrquery.addfacetfield(searchfields.category); \/\/ solrquery.addfacetfield(searchfields.file_type_mime); \/\/ solrquery.addfacetfield(searchfields.distributor); \/\/ solrquery.addfacetfield(searchfields.keyword); \/** * @todo when a new method on datasetfieldservice is available * (retrievefacetsbydataverse?) only show the facets that the dataverse * in question wants to show (and in the right order): * https:\/\/redmine.hmdc.harvard.edu\/issues\/3490 * * also, findall only returns advancedsearchfield = true... we should * probably introduce the \"isfacetable\" boolean rather than caring about * if advancedsearchfield is true or false * *\/\n\/** * @todo: hide the extra line this shows in the gui... at least it's * last... *\/\n\/** * @todo: do sanity checking... throw error if negative *\/\n\/** * @todo: decide if year citation_year is good enough or if we should * support citation_date *\/\n\/\/ calendar calendar = calendar.getinstance(timezone.gettimezone(\"utc\"), locale.uk); \/\/ calendar.set(2010, 1, 1); \/\/ date start = calendar.gettime(); \/\/ calendar.set(2013, 1, 1); \/\/ date end = calendar.gettime(); \/\/ solrquery.adddaterangefacet(searchfields.citation_date, start, end, \"+1month\"); \/** * @todo make this configurable *\/\n\/** * @todo: odd or even makes a difference. couldn't find value of 2014 * when this was set to 2000 *\/\n\/** * @todo: these are dates and should be \"range facets\" not \"field * facets\" * * right now they are lumped in with the datasetfieldservice.findall() * above *\/\n\/\/ solrquery.addnumericrangefacet(searchfields.production_date_year_only, citationyearrangestart, citationyearrangeend, citationyearrangespan); \/\/ solrquery.addnumericrangefacet(searchfields.distribution_date_year_only, citationyearrangestart, citationyearrangeend, citationyearrangespan);\n\/\/ ----------------------------------- \/\/ make the solr query \/\/ -----------------------------------\n\/\/ hide \"org.apache.solr...\"\n\/\/ we can't show anything because of the search syntax error\n\/** * @todo refactor searchfields to a hashmap (or something? put in * database? internationalize?) to avoid the crazy reflection and string * manipulation below *\/\n\/\/ arraylist titles = (arraylist) solrdocument.getfieldvalues(searchfields.title);\n\/\/ logger.info(\"titlesolrfield: \" + titlesolrfield); \/\/ logger.info(\"title: \" + title);\n\/** * @todo only solrfield.solrtype.string? that's not * right... knit the solrfield object more into the * highlighting stuff *\/\n\/** * @todo put all this in the constructor? *\/\n\/\/ set list of all statuses \/\/ this method also sets booleans for individual statuses\n\/\/ logger.info(id + \": \" + description);\n\/** * @todo start using searchconstants class here *\/\n\/\/ do not set the imageurl, let the search include fragment fill in \/\/ the thumbnail, similarly to how the dataset and datafile cards \/\/ are handled. \/\/solrsearchresult.setimageurl(baseurl + \"\/api\/access\/dvcardimage\/\" + entityid); \/** * @todo expose this api url after \"dvs\" is changed to * \"dataverses\". also, is an api token required for published * dataverses? michael: url changed. *\/\n\/\/ solrsearchresult.setapiurl(baseurl + \"\/api\/dataverses\/\" + entityid);\n\/\/image url now set via thumbnail api \/\/solrsearchresult.setimageurl(baseurl + \"\/api\/access\/dscardimage\/\" + datasetversionid); \/\/ no, we don't want to set the base64 thumbnails here. \/\/ we want to do it inside searchincludefragment, and only once the rest of the \/\/ page has already loaded. \/\/datasetversion datasetversion = datasetversionservice.find(datasetversionid); \/\/if (datasetversion != null){ \/\/ solrsearchresult.setdatasetthumbnail(datasetversion.getdataset().getdatasetthumbnail(datasetversion)); \/\/} \/** * @todo could use getfieldvalues (plural) here. *\/\n\/\/ solrsearchresult.settitle((string) titles.get(0));\n\/** * @todo we are not yet setting the api url for files because * not all files have metadata. only subsettable files (those * with a datatable) seem to have metadata. furthermore, the * response is in xml whereas the rest of the search api returns * json. *\/\n\/\/ solrsearchresult.setapiurl(baseurl + \"\/api\/meta\/datafile\/\" + entityid); \/\/solrsearchresult.setimageurl(baseurl + \"\/api\/access\/filecardimage\/\" + entityid);\n\/** * @todo store parent_id as a long instead and cast as such *\/\n\/** * @todo we do want to show the count for each facet *\/\n\/\/ logger.info(\"field: \" + facetfield.getname() + \" \" + facetfieldcount.getname() + \" (\" + facetfieldcount.getcount() + \")\");\n\/\/ quote field facets\n\/\/ hopefully people will never see the raw facetfield.getname() because it may well have an _s at the end\n\/\/ try to find a friendlier name to display as a facet \/** * @todo hmm, we thought we wanted the datasetfields array to go * away once we have more granularity than findall() available per * the todo above but we need a way to lookup by solr field, so * we'll build a hashmap *\/\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\n\/\/ stop examining available dataset fields. we found a match\n\/** * @todo get rid of this crazy reflection, per todo above... or * should we... let's put into a hash the friendly names of facet * categories, indexed by solr field *\/\n\/\/ logger.info(\"adding <<<\" + staticsearchfield + \":\" + friendlyname + \">>>\");\n\/\/ stop examining the declared\/static fields in the searchfields object. we found a match\n\/\/ the \"type\" facet is special, these are not\n\/\/ for now the only range facet is citation year\n\/\/ to avoid overlapping dates\n\/\/ special [12 to 34] syntax for range facets\n\/\/ reverse to show the newest citation year range at the top\n\/\/ null check added because these tests were failing: mvn test -dtest=searchit\n\/\/ how often is this null?","repo":"tkmonson\/dataverse","code_context_2":"public SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n*\/\nsolrQuery.addFacetField(SearchFields.TYPE);\nsolrQuery.addFacetField(SearchFields.FILE_TAG);\nif (!systemConfig.isPublicInstall()) {\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\/**\n* @todo: decide if year CITATION_YEAR is good enough or if we should\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\nreturn exceptionSolrQueryResponse;\n} catch (SolrServerException | IOException ex) {\nthrow new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n}\nSolrDocumentList docs = queryResponse.getResults();\nList<SolrSearchResult> solrSearchResults = new ArrayList<>();\n\/**\n* @todo refactor SearchFields to a hashmap (or something? put in\n* database? internationalize?) to avoid the crazy reflection and string\n* manipulation below\n*\/\nObject searchFieldsObject = new SearchFields();\nField[] staticSearchFields = searchFieldsObject.getClass().getDeclaredFields();\nString titleSolrField = null;\ntry {\nDatasetFieldType titleDatasetField = datasetFieldService.findByName(DatasetFieldConstant.title);\ntitleSolrField = titleDatasetField.getSolrField().getNameSearchable();\n} catch (EJBTransactionRolledbackException ex) {\nlogger.info(\"Couldn't find \" + DatasetFieldConstant.title);\nif (ex.getCause() instanceof TransactionRolledbackLocalException) {\nif (ex.getCause().getCause() instanceof NoResultException) {\nlogger.info(\"Caught NoResultException\");\n}\n}\n}\nMap<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\nMap<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\nString baseUrl = systemConfig.getDataverseSiteUrl();\nfor (SolrDocument solrDocument : docs) {\nString id = (String) solrDocument.getFieldValue(SearchFields.ID);\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\nif (queryResponse.getHighlighting().get(id) != null) {\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString field = entry.getKey();\nString displayName = entry.getValue();\nList<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\nif (highlightSnippets != null) {\nmatchedFields.add(field);\n\/**\n* @todo only SolrField.SolrType.STRING? that's not\n* right... knit the SolrField object more into the\n* highlighting stuff\n*\/\nSolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\nHighlight highlight = new Highlight(solrField, highlightSnippets, displayName);\nhighlights.add(highlight);\nhighlightsMap.put(solrField, highlight);\nhighlightsMap2.put(solrField, highlightSnippets);\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\nsolrSearchResult.setReleaseOrCreateDate(release_or_create_date);\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\nString description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\nsolrSearchResult.setDescriptionNoSnippet(description);\nsolrSearchResult.setDeaccessionReason(deaccessionReason);\nsolrSearchResult.setDvTree(dvTree);\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\nString parentGlobalId = null;\nObject parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\nif (parentGlobalIdObject != null) {\nparentGlobalId = (String) parentGlobalIdObject;\nparent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n* not all files have metadata. Only subsettable files (those\n* with a datatable) seem to have metadata. Furthermore, the\n* response is in XML whereas the rest of the Search API returns\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\nsolrSearchResult.setFileContentType(fileContentType);\nObject fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\nif (fileSizeInBytesObject != null) {\ntry {\nlong fileSizeInBytesLong = (long) fileSizeInBytesObject;\nsolrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n} catch (ClassCastException ex) {\nlogger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n}\n}\nsolrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\ntry {\nsolrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n} catch (IllegalArgumentException ex) {\nlogger.info(\"Exception setting setFileChecksumType: \" + ex);\n}\nsolrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\nsolrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nList<String> fileCategories = (List) solrDocument.getFieldValues(SearchFields.FILE_TAG);\nif (fileCategories != null) {\nsolrSearchResult.setFileCategories(fileCategories);\n}\nList<String> tabularDataTags = (List) solrDocument.getFieldValues(SearchFields.TABDATA_TAG);\nif (tabularDataTags != null) {\nCollections.sort(tabularDataTags);\nsolrSearchResult.setTabularDataTags(tabularDataTags);\n}\n}\n\/**\n* @todo store PARENT_ID as a long instead and cast as such\n*\/\nparent.put(\"id\", (String) solrDocument.getFieldValue(SearchFields.PARENT_ID));\nparent.put(\"name\", (String) solrDocument.getFieldValue(SearchFields.PARENT_NAME));\nparent.put(\"citation\", (String) solrDocument.getFieldValue(SearchFields.PARENT_CITATION));\nsolrSearchResult.setParent(parent);\nsolrSearchResults.add(solrSearchResult);\n}\nMap<String, List<String>> spellingSuggestionsByToken = new HashMap<>();\nSpellCheckResponse spellCheckResponse = queryResponse.getSpellCheckResponse();\nif (spellCheckResponse != null) {\nList<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\nfor (SpellCheckResponse.Suggestion suggestion : suggestions) {\nspellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n}\n}\nList<FacetCategory> facetCategoryList = new ArrayList<>();\nList<FacetCategory> typeFacetCategories = new ArrayList<>();\nboolean hidePublicationStatusFacet = true;\nboolean draftsAvailable = false;\nboolean unpublishedAvailable = false;\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}\n\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\n\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\n\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\n\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\n\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\n\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\n\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\n\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\n\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\n\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\n\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\n\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\n\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\n\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\n\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\n\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\n\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\n\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}","code_context_10":"public SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n*\/\nsolrQuery.addFacetField(SearchFields.TYPE);\nsolrQuery.addFacetField(SearchFields.FILE_TAG);\nif (!systemConfig.isPublicInstall()) {\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\/**\n* @todo: decide if year CITATION_YEAR is good enough or if we should\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\nreturn exceptionSolrQueryResponse;\n} catch (SolrServerException | IOException ex) {\nthrow new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n}\nSolrDocumentList docs = queryResponse.getResults();\nList<SolrSearchResult> solrSearchResults = new ArrayList<>();\n\/**\n* @todo refactor SearchFields to a hashmap (or something? put in\n* database? internationalize?) to avoid the crazy reflection and string\n* manipulation below\n*\/\nObject searchFieldsObject = new SearchFields();\nField[] staticSearchFields = searchFieldsObject.getClass().getDeclaredFields();\nString titleSolrField = null;\ntry {\nDatasetFieldType titleDatasetField = datasetFieldService.findByName(DatasetFieldConstant.title);\ntitleSolrField = titleDatasetField.getSolrField().getNameSearchable();\n} catch (EJBTransactionRolledbackException ex) {\nlogger.info(\"Couldn't find \" + DatasetFieldConstant.title);\nif (ex.getCause() instanceof TransactionRolledbackLocalException) {\nif (ex.getCause().getCause() instanceof NoResultException) {\nlogger.info(\"Caught NoResultException\");\n}\n}\n}\nMap<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\nMap<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\nString baseUrl = systemConfig.getDataverseSiteUrl();\nfor (SolrDocument solrDocument : docs) {\nString id = (String) solrDocument.getFieldValue(SearchFields.ID);\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\nif (queryResponse.getHighlighting().get(id) != null) {\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString field = entry.getKey();\nString displayName = entry.getValue();\nList<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\nif (highlightSnippets != null) {\nmatchedFields.add(field);\n\/**\n* @todo only SolrField.SolrType.STRING? that's not\n* right... knit the SolrField object more into the\n* highlighting stuff\n*\/\nSolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\nHighlight highlight = new Highlight(solrField, highlightSnippets, displayName);\nhighlights.add(highlight);\nhighlightsMap.put(solrField, highlight);\nhighlightsMap2.put(solrField, highlightSnippets);\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\nsolrSearchResult.setReleaseOrCreateDate(release_or_create_date);\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\nString description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\nsolrSearchResult.setDescriptionNoSnippet(description);\nsolrSearchResult.setDeaccessionReason(deaccessionReason);\nsolrSearchResult.setDvTree(dvTree);\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\nString parentGlobalId = null;\nObject parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\nif (parentGlobalIdObject != null) {\nparentGlobalId = (String) parentGlobalIdObject;\nparent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n* not all files have metadata. Only subsettable files (those\n* with a datatable) seem to have metadata. Furthermore, the\n* response is in XML whereas the rest of the Search API returns\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\nsolrSearchResult.setFileContentType(fileContentType);\nObject fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\nif (fileSizeInBytesObject != null) {\ntry {\nlong fileSizeInBytesLong = (long) fileSizeInBytesObject;\nsolrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n} catch (ClassCastException ex) {\nlogger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n}\n}\nsolrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\ntry {\nsolrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n} catch (IllegalArgumentException ex) {\nlogger.info(\"Exception setting setFileChecksumType: \" + ex);\n}\nsolrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\nsolrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nList<String> fileCategories = (List) solrDocument.getFieldValues(SearchFields.FILE_TAG);\nif (fileCategories != null) {\nsolrSearchResult.setFileCategories(fileCategories);\n}\nList<String> tabularDataTags = (List) solrDocument.getFieldValues(SearchFields.TABDATA_TAG);\nif (tabularDataTags != null) {\nCollections.sort(tabularDataTags);\nsolrSearchResult.setTabularDataTags(tabularDataTags);\n}\n}\n\/**\n* @todo store PARENT_ID as a long instead and cast as such\n*\/\nparent.put(\"id\", (String) solrDocument.getFieldValue(SearchFields.PARENT_ID));\nparent.put(\"name\", (String) solrDocument.getFieldValue(SearchFields.PARENT_NAME));\nparent.put(\"citation\", (String) solrDocument.getFieldValue(SearchFields.PARENT_CITATION));\nsolrSearchResult.setParent(parent);\nsolrSearchResults.add(solrSearchResult);\n}\nMap<String, List<String>> spellingSuggestionsByToken = new HashMap<>();\nSpellCheckResponse spellCheckResponse = queryResponse.getSpellCheckResponse();\nif (spellCheckResponse != null) {\nList<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\nfor (SpellCheckResponse.Suggestion suggestion : suggestions) {\nspellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n}\n}\nList<FacetCategory> facetCategoryList = new ArrayList<>();\nList<FacetCategory> typeFacetCategories = new ArrayList<>();\nboolean hidePublicationStatusFacet = true;\nboolean draftsAvailable = false;\nboolean unpublishedAvailable = false;\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}\n\npublic SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\n\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\n\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\n\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\n\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\n\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\/**\n* @todo: decide if year CITATION_YEAR is good enough or if we should\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\n\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\n\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\n\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\n\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\n\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\n\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\n\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\n\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\n\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n* not all files have metadata. Only subsettable files (those\n* with a datatable) seem to have metadata. Furthermore, the\n* response is in XML whereas the rest of the Search API returns\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\nsolrSearchResult.setFileContentType(fileContentType);\nObject fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\nif (fileSizeInBytesObject != null) {\ntry {\nlong fileSizeInBytesLong = (long) fileSizeInBytesObject;\nsolrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n} catch (ClassCastException ex) {\nlogger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\n\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\n\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\n\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\n\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\n\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\n\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\n\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\n\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\n\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\n\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}","code_context_20":"public SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n*\/\nsolrQuery.addFacetField(SearchFields.TYPE);\nsolrQuery.addFacetField(SearchFields.FILE_TAG);\nif (!systemConfig.isPublicInstall()) {\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\/**\n* @todo: decide if year CITATION_YEAR is good enough or if we should\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\nreturn exceptionSolrQueryResponse;\n} catch (SolrServerException | IOException ex) {\nthrow new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n}\nSolrDocumentList docs = queryResponse.getResults();\nList<SolrSearchResult> solrSearchResults = new ArrayList<>();\n\/**\n* @todo refactor SearchFields to a hashmap (or something? put in\n* database? internationalize?) to avoid the crazy reflection and string\n* manipulation below\n*\/\nObject searchFieldsObject = new SearchFields();\nField[] staticSearchFields = searchFieldsObject.getClass().getDeclaredFields();\nString titleSolrField = null;\ntry {\nDatasetFieldType titleDatasetField = datasetFieldService.findByName(DatasetFieldConstant.title);\ntitleSolrField = titleDatasetField.getSolrField().getNameSearchable();\n} catch (EJBTransactionRolledbackException ex) {\nlogger.info(\"Couldn't find \" + DatasetFieldConstant.title);\nif (ex.getCause() instanceof TransactionRolledbackLocalException) {\nif (ex.getCause().getCause() instanceof NoResultException) {\nlogger.info(\"Caught NoResultException\");\n}\n}\n}\nMap<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\nMap<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\nString baseUrl = systemConfig.getDataverseSiteUrl();\nfor (SolrDocument solrDocument : docs) {\nString id = (String) solrDocument.getFieldValue(SearchFields.ID);\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\nif (queryResponse.getHighlighting().get(id) != null) {\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString field = entry.getKey();\nString displayName = entry.getValue();\nList<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\nif (highlightSnippets != null) {\nmatchedFields.add(field);\n\/**\n* @todo only SolrField.SolrType.STRING? that's not\n* right... knit the SolrField object more into the\n* highlighting stuff\n*\/\nSolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\nHighlight highlight = new Highlight(solrField, highlightSnippets, displayName);\nhighlights.add(highlight);\nhighlightsMap.put(solrField, highlight);\nhighlightsMap2.put(solrField, highlightSnippets);\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\nsolrSearchResult.setReleaseOrCreateDate(release_or_create_date);\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\nString description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\nsolrSearchResult.setDescriptionNoSnippet(description);\nsolrSearchResult.setDeaccessionReason(deaccessionReason);\nsolrSearchResult.setDvTree(dvTree);\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\nString parentGlobalId = null;\nObject parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\nif (parentGlobalIdObject != null) {\nparentGlobalId = (String) parentGlobalIdObject;\nparent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n* not all files have metadata. Only subsettable files (those\n* with a datatable) seem to have metadata. Furthermore, the\n* response is in XML whereas the rest of the Search API returns\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\nsolrSearchResult.setFileContentType(fileContentType);\nObject fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\nif (fileSizeInBytesObject != null) {\ntry {\nlong fileSizeInBytesLong = (long) fileSizeInBytesObject;\nsolrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n} catch (ClassCastException ex) {\nlogger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n}\n}\nsolrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\ntry {\nsolrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n} catch (IllegalArgumentException ex) {\nlogger.info(\"Exception setting setFileChecksumType: \" + ex);\n}\nsolrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\nsolrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nList<String> fileCategories = (List) solrDocument.getFieldValues(SearchFields.FILE_TAG);\nif (fileCategories != null) {\nsolrSearchResult.setFileCategories(fileCategories);\n}\nList<String> tabularDataTags = (List) solrDocument.getFieldValues(SearchFields.TABDATA_TAG);\nif (tabularDataTags != null) {\nCollections.sort(tabularDataTags);\nsolrSearchResult.setTabularDataTags(tabularDataTags);\n}\n}\n\/**\n* @todo store PARENT_ID as a long instead and cast as such\n*\/\nparent.put(\"id\", (String) solrDocument.getFieldValue(SearchFields.PARENT_ID));\nparent.put(\"name\", (String) solrDocument.getFieldValue(SearchFields.PARENT_NAME));\nparent.put(\"citation\", (String) solrDocument.getFieldValue(SearchFields.PARENT_CITATION));\nsolrSearchResult.setParent(parent);\nsolrSearchResults.add(solrSearchResult);\n}\nMap<String, List<String>> spellingSuggestionsByToken = new HashMap<>();\nSpellCheckResponse spellCheckResponse = queryResponse.getSpellCheckResponse();\nif (spellCheckResponse != null) {\nList<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\nfor (SpellCheckResponse.Suggestion suggestion : suggestions) {\nspellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n}\n}\nList<FacetCategory> facetCategoryList = new ArrayList<>();\nList<FacetCategory> typeFacetCategories = new ArrayList<>();\nboolean hidePublicationStatusFacet = true;\nboolean draftsAvailable = false;\nboolean unpublishedAvailable = false;\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}\n\npublic SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\n\npublic SolrQueryResponse search(DataverseRequest dataverseRequest, Dataverse dataverse, String query, List<String> filterQueries, String sortField, String sortOrder, int paginationStart, boolean onlyDatatRelatedToMe, int numResultsPerPage, boolean retrieveEntities) throws SearchException {\nif (paginationStart < 0) {\nthrow new IllegalArgumentException(\"paginationStart must be 0 or greater\");\n}\nif (numResultsPerPage < 1) {\nthrow new IllegalArgumentException(\"numResultsPerPage must be 1 or greater\");\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n\n}\nSolrQuery solrQuery = new SolrQuery();\nquery = SearchUtil.sanitizeQuery(query);\nsolrQuery.setQuery(query);\n\/\/ SortClause foo = new SortClause(\"name\", SolrQuery.ORDER.desc);\n\/\/ if (query.equals(\"*\") || query.equals(\"*:*\")) {\n\/\/ solrQuery.setSort(new SortClause(SearchFields.NAME_SORT, SolrQuery.ORDER.asc));\nsolrQuery.setSort(new SortClause(sortField, sortOrder));\n\/\/ } else {\n\/\/ solrQuery.setSort(sortClause);\n\/\/ }\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\n\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\n\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n* in question wants to show (and in the right order):\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3490\n*\n* also, findAll only returns advancedSearchField = true... we should\n* probably introduce the \"isFacetable\" boolean rather than caring about\n* if advancedSearchField is true or false\n*\n*\/\nif (dataverse != null) {\nfor (DataverseFacet dataverseFacet : dataverse.getDataverseFacets()) {\nDatasetFieldType datasetField = dataverseFacet.getDatasetFieldType();\nsolrQuery.addFacetField(datasetField.getSolrField().getNameFacetable());\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n*\/\nsolrQuery.addFacetField(SearchFields.TYPE);\nsolrQuery.addFacetField(SearchFields.FILE_TAG);\nif (!systemConfig.isPublicInstall()) {\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n\n}\n}\nsolrQuery.addFacetField(SearchFields.FILE_TYPE);\n\/**\n* @todo: hide the extra line this shows in the GUI... at least it's\n* last...\n*\/\nsolrQuery.addFacetField(SearchFields.TYPE);\nsolrQuery.addFacetField(SearchFields.FILE_TAG);\nif (!systemConfig.isPublicInstall()) {\nsolrQuery.addFacetField(SearchFields.ACCESS);\n}\n\/**\n* @todo: do sanity checking... throw error if negative\n*\/\nsolrQuery.setStart(paginationStart);\n\/**\n* @todo: decide if year CITATION_YEAR is good enough or if we should\n* support CITATION_DATE\n*\/\n\/\/ Calendar calendar = Calendar.getInstance(TimeZone.getTimeZone(\"UTC\"), Locale.UK);\n\/\/ calendar.set(2010, 1, 1);\n\/\/ Date start = calendar.getTime();\n\/\/ calendar.set(2013, 1, 1);\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\n\n\/\/ Date end = calendar.getTime();\n\/\/ solrQuery.addDateRangeFacet(SearchFields.CITATION_DATE, start, end, \"+1MONTH\");\n\/**\n* @todo make this configurable\n*\/\nint thisYear = Calendar.getInstance().get(Calendar.YEAR);\n\/**\n* @todo: odd or even makes a difference. Couldn't find value of 2014\n* when this was set to 2000\n*\/\nfinal int citationYearRangeStart = 1901;\nfinal int citationYearRangeEnd = thisYear;\nfinal int citationYearRangeSpan = 2;\n\/**\n* @todo: these are dates and should be \"range facets\" not \"field\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\n\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\nsolrQuery.setParam(\"facet\", \"true\");\n\/**\n* @todo: do we need facet.query?\n*\/\nsolrQuery.setParam(\"facet.query\", \"*\");\nfor (String filterQuery : filterQueries) {\nsolrQuery.addFilterQuery(filterQuery);\n}\n\/\/ -----------------------------------\n\/\/ PERMISSION FILTER QUERY\n\/\/ -----------------------------------\nString permissionFilterQuery = this.getPermissionFilterQuery(dataverseRequest, solrQuery, dataverse, onlyDatatRelatedToMe);\nif (permissionFilterQuery != null) {\nsolrQuery.addFilterQuery(permissionFilterQuery);\n}\n\/\/ -----------------------------------\n\/\/ Facets to Retrieve\n\/\/ -----------------------------------\n\/\/ solrQuery.addFacetField(SearchFields.HOST_DATAVERSE);\n\/\/ solrQuery.addFacetField(SearchFields.AUTHOR_STRING);\nsolrQuery.addFacetField(SearchFields.DATAVERSE_CATEGORY);\nsolrQuery.addFacetField(SearchFields.METADATA_SOURCE);\n\/\/ solrQuery.addFacetField(SearchFields.AFFILIATION);\nsolrQuery.addFacetField(SearchFields.PUBLICATION_DATE);\n\/\/ solrQuery.addFacetField(SearchFields.CATEGORY);\n\/\/ solrQuery.addFacetField(SearchFields.FILE_TYPE_MIME);\n\/\/ solrQuery.addFacetField(SearchFields.DISTRIBUTOR);\n\/\/ solrQuery.addFacetField(SearchFields.KEYWORD);\n\/**\n* @todo when a new method on datasetFieldService is available\n* (retrieveFacetsByDataverse?) only show the facets that the dataverse\n\n* facets\"\n*\n* right now they are lumped in with the datasetFieldService.findAll()\n* above\n*\/\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.PRODUCTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\n\/\/ solrQuery.addNumericRangeFacet(SearchFields.DISTRIBUTION_DATE_YEAR_ONLY, citationYearRangeStart, citationYearRangeEnd, citationYearRangeSpan);\nsolrQuery.setRows(numResultsPerPage);\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\nreturn exceptionSolrQueryResponse;\n\nlogger.fine(\"Solr query:\" + solrQuery);\n\/\/ -----------------------------------\n\/\/ Make the solr query\n\/\/ -----------------------------------\nQueryResponse queryResponse = null;\ntry {\nqueryResponse = solrServer.query(solrQuery);\n} catch (RemoteSolrException ex) {\nString messageFromSolr = ex.getLocalizedMessage();\nString error = \"Search Syntax Error: \";\nString stringToHide = \"org.apache.solr.search.SyntaxError: \";\nif (messageFromSolr.startsWith(stringToHide)) {\n\/\/ hide \"org.apache.solr...\"\nerror += messageFromSolr.substring(stringToHide.length());\n} else {\nerror += messageFromSolr;\n}\nlogger.info(error);\nSolrQueryResponse exceptionSolrQueryResponse = new SolrQueryResponse(solrQuery);\nexceptionSolrQueryResponse.setError(error);\n\/\/ we can't show anything because of the search syntax error\nlong zeroNumResultsFound = 0;\nlong zeroGetResultsStart = 0;\nList<SolrSearchResult> emptySolrSearchResults = new ArrayList<>();\nList<FacetCategory> exceptionFacetCategoryList = new ArrayList<>();\nMap<String, List<String>> emptySpellingSuggestion = new HashMap<>();\nexceptionSolrQueryResponse.setNumResultsFound(zeroNumResultsFound);\nexceptionSolrQueryResponse.setResultsStart(zeroGetResultsStart);\nexceptionSolrQueryResponse.setSolrSearchResults(emptySolrSearchResults);\nexceptionSolrQueryResponse.setFacetCategoryList(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setTypeFacetCategories(exceptionFacetCategoryList);\nexceptionSolrQueryResponse.setSpellingSuggestionsByToken(emptySpellingSuggestion);\nreturn exceptionSolrQueryResponse;\n} catch (SolrServerException | IOException ex) {\nthrow new SearchException(\"Internal Dataverse Search Engine Error\", ex);\n}\nSolrDocumentList docs = queryResponse.getResults();\nList<SolrSearchResult> solrSearchResults = new ArrayList<>();\n\/**\n* @todo refactor SearchFields to a hashmap (or something? put in\n* database? internationalize?) to avoid the crazy reflection and string\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\n\nif (ex.getCause().getCause() instanceof NoResultException) {\nlogger.info(\"Caught NoResultException\");\n}\n}\n}\nMap<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\nMap<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\nString baseUrl = systemConfig.getDataverseSiteUrl();\nfor (SolrDocument solrDocument : docs) {\nString id = (String) solrDocument.getFieldValue(SearchFields.ID);\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\nif (queryResponse.getHighlighting().get(id) != null) {\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString field = entry.getKey();\nString displayName = entry.getValue();\nList<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\n\n}\nMap<String, String> datasetfieldFriendlyNamesBySolrField = new HashMap<>();\nMap<String, String> staticSolrFieldFriendlyNamesBySolrField = new HashMap<>();\nString baseUrl = systemConfig.getDataverseSiteUrl();\nfor (SolrDocument solrDocument : docs) {\nString id = (String) solrDocument.getFieldValue(SearchFields.ID);\nLong entityid = (Long) solrDocument.getFieldValue(SearchFields.ENTITY_ID);\nString type = (String) solrDocument.getFieldValue(SearchFields.TYPE);\nfloat score = (Float) solrDocument.getFieldValue(SearchFields.RELEVANCE);\nlogger.fine(\"score for \" + id + \": \" + score);\nString identifier = (String) solrDocument.getFieldValue(SearchFields.IDENTIFIER);\nString citation = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION);\nString citationPlainHtml = (String) solrDocument.getFieldValue(SearchFields.DATASET_CITATION_HTML);\nString persistentUrl = (String) solrDocument.getFieldValue(SearchFields.PERSISTENT_URL);\nString name = (String) solrDocument.getFieldValue(SearchFields.NAME);\nString nameSort = (String) solrDocument.getFieldValue(SearchFields.NAME_SORT);\n\/\/ ArrayList titles = (ArrayList) solrDocument.getFieldValues(SearchFields.TITLE);\nString title = (String) solrDocument.getFieldValue(titleSolrField);\nLong datasetVersionId = (Long) solrDocument.getFieldValue(SearchFields.DATASET_VERSION_ID);\nString deaccessionReason = (String) solrDocument.getFieldValue(SearchFields.DATASET_DEACCESSION_REASON);\n\/\/ logger.info(\"titleSolrField: \" + titleSolrField);\n\/\/ logger.info(\"title: \" + title);\nString filetype = (String) solrDocument.getFieldValue(SearchFields.FILE_TYPE_FRIENDLY);\nString fileContentType = (String) solrDocument.getFieldValue(SearchFields.FILE_CONTENT_TYPE);\nDate release_or_create_date = (Date) solrDocument.getFieldValue(SearchFields.RELEASE_OR_CREATE_DATE);\nString dateToDisplayOnCard = (String) solrDocument.getFirstValue(SearchFields.RELEASE_OR_CREATE_DATE_SEARCHABLE_TEXT);\nString dvTree = (String) solrDocument.getFirstValue(SearchFields.SUBTREE);\nList<String> matchedFields = new ArrayList<>();\nList<Highlight> highlights = new ArrayList<>();\nMap<SolrField, Highlight> highlightsMap = new HashMap<>();\nMap<SolrField, List<String>> highlightsMap2 = new HashMap<>();\nMap<String, Highlight> highlightsMap3 = new HashMap<>();\nif (queryResponse.getHighlighting().get(id) != null) {\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString field = entry.getKey();\nString displayName = entry.getValue();\nList<String> highlightSnippets = queryResponse.getHighlighting().get(id).get(field);\nif (highlightSnippets != null) {\nmatchedFields.add(field);\n\/**\n* @todo only SolrField.SolrType.STRING? that's not\n* right... knit the SolrField object more into the\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\n\/**\n* @todo only SolrField.SolrType.STRING? that's not\n* right... knit the SolrField object more into the\n* highlighting stuff\n*\/\nSolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\nHighlight highlight = new Highlight(solrField, highlightSnippets, displayName);\nhighlights.add(highlight);\nhighlightsMap.put(solrField, highlight);\nhighlightsMap2.put(solrField, highlightSnippets);\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\nsolrSearchResult.setReleaseOrCreateDate(release_or_create_date);\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\n\n*\/\nSolrField solrField = new SolrField(field, SolrField.SolrType.STRING, true, true);\nHighlight highlight = new Highlight(solrField, highlightSnippets, displayName);\nhighlights.add(highlight);\nhighlightsMap.put(solrField, highlight);\nhighlightsMap2.put(solrField, highlightSnippets);\nhighlightsMap3.put(field, highlight);\n}\n}\n}\nSolrSearchResult solrSearchResult = new SolrSearchResult(query, name);\n\/**\n* @todo put all this in the constructor?\n*\/\nList<String> states = (List<String>) solrDocument.getFieldValue(SearchFields.PUBLICATION_STATUS);\nif (states != null) {\n\/\/ set list of all statuses\n\/\/ this method also sets booleans for individual statuses\nsolrSearchResult.setPublicationStatuses(states);\n}\n\/\/ logger.info(id + \": \" + description);\nsolrSearchResult.setId(id);\nsolrSearchResult.setEntityId(entityid);\nif (retrieveEntities) {\nsolrSearchResult.setEntity(dvObjectService.findDvObject(entityid));\n}\nsolrSearchResult.setIdentifier(identifier);\nsolrSearchResult.setPersistentUrl(persistentUrl);\nsolrSearchResult.setType(type);\nsolrSearchResult.setScore(score);\nsolrSearchResult.setNameSort(nameSort);\nsolrSearchResult.setReleaseOrCreateDate(release_or_create_date);\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\nString description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\nsolrSearchResult.setDescriptionNoSnippet(description);\nsolrSearchResult.setDeaccessionReason(deaccessionReason);\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\nsolrSearchResult.setDateToDisplayOnCard(dateToDisplayOnCard);\nsolrSearchResult.setMatchedFields(matchedFields);\nsolrSearchResult.setHighlightsAsList(highlights);\nsolrSearchResult.setHighlightsMap(highlightsMap);\nsolrSearchResult.setHighlightsAsMap(highlightsMap3);\nMap<String, String> parent = new HashMap<>();\nString description = (String) solrDocument.getFieldValue(SearchFields.DESCRIPTION);\nsolrSearchResult.setDescriptionNoSnippet(description);\nsolrSearchResult.setDeaccessionReason(deaccessionReason);\nsolrSearchResult.setDvTree(dvTree);\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\n\nsolrSearchResult.setDvTree(dvTree);\nString originSource = (String) solrDocument.getFieldValue(SearchFields.METADATA_SOURCE);\nif (IndexServiceBean.HARVESTED.equals(originSource)) {\nsolrSearchResult.setHarvested(true);\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n\n}\n\/**\n* @todo start using SearchConstants class here\n*\/\nif (type.equals(\"dataverses\")) {\nsolrSearchResult.setName(name);\nsolrSearchResult.setHtmlUrl(baseUrl + SystemConfig.DATAVERSE_PATH + identifier);\n\/\/ Do not set the ImageUrl, let the search include fragment fill in\n\/\/ the thumbnail, similarly to how the dataset and datafile cards\n\/\/ are handled.\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dvCardImage\/\" + entityid);\n\/**\n* @todo Expose this API URL after \"dvs\" is changed to\n* \"dataverses\". Also, is an API token required for published\n* dataverses? Michael: url changed.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/dataverses\/\" + entityid);\n} else if (type.equals(\"datasets\")) {\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?globalId=\" + identifier);\nsolrSearchResult.setApiUrl(baseUrl + \"\/api\/datasets\/\" + entityid);\n\/\/Image url now set via thumbnail api\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/dsCardImage\/\" + datasetVersionId);\n\/\/ No, we don't want to set the base64 thumbnails here.\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n\n\/\/ We want to do it inside SearchIncludeFragment, AND ONLY once the rest of the\n\/\/ page has already loaded.\n\/\/DatasetVersion datasetVersion = datasetVersionService.find(datasetVersionId);\n\/\/if (datasetVersion != null){\n\/\/ solrSearchResult.setDatasetThumbnail(datasetVersion.getDataset().getDatasetThumbnail(datasetVersion));\n\/\/}\n\/**\n* @todo Could use getFieldValues (plural) here.\n*\/\nList<String> datasetDescriptions = (List<String>) solrDocument.getFieldValue(SearchFields.DATASET_DESCRIPTION);\nif (datasetDescriptions != null) {\nString firstDatasetDescription = datasetDescriptions.get(0);\nif (firstDatasetDescription != null) {\nsolrSearchResult.setDescriptionNoSnippet(firstDatasetDescription);\n}\n}\nsolrSearchResult.setDatasetVersionId(datasetVersionId);\nsolrSearchResult.setCitation(citation);\nsolrSearchResult.setCitationHtml(citationPlainHtml);\nif (title != null) {\n\/\/ solrSearchResult.setTitle((String) titles.get(0));\nsolrSearchResult.setTitle(title);\n} else {\nlogger.fine(\"No title indexed. Setting to empty string to prevent NPE. Dataset id \" + entityid + \" and version id \" + datasetVersionId);\nsolrSearchResult.setTitle(\"\");\n}\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\nString parentGlobalId = null;\nObject parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\nif (parentGlobalIdObject != null) {\nparentGlobalId = (String) parentGlobalIdObject;\nparent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\nsolrQuery.setParam(\"fl\", \"*,score\");\nsolrQuery.setParam(\"qt\", \"\/select\");\n\nList<String> authors = (List) solrDocument.getFieldValues(DatasetFieldConstant.authorName);\nif (authors != null) {\nsolrSearchResult.setDatasetAuthors(authors);\n}\n} else if (type.equals(\"files\")) {\nString parentGlobalId = null;\nObject parentGlobalIdObject = solrDocument.getFieldValue(SearchFields.PARENT_IDENTIFIER);\nif (parentGlobalIdObject != null) {\nparentGlobalId = (String) parentGlobalIdObject;\nparent.put(SolrSearchResult.PARENT_IDENTIFIER, parentGlobalId);\n}\nsolrSearchResult.setHtmlUrl(baseUrl + \"\/dataset.xhtml?persistentId=\" + parentGlobalId);\nsolrSearchResult.setDownloadUrl(baseUrl + \"\/api\/access\/datafile\/\" + entityid);\n\/**\n* @todo We are not yet setting the API URL for files because\n* not all files have metadata. Only subsettable files (those\n* with a datatable) seem to have metadata. Furthermore, the\n* response is in XML whereas the rest of the Search API returns\n* JSON.\n*\/\n\/\/ solrSearchResult.setApiUrl(baseUrl + \"\/api\/meta\/datafile\/\" + entityid);\n\/\/solrSearchResult.setImageUrl(baseUrl + \"\/api\/access\/fileCardImage\/\" + entityid);\nsolrSearchResult.setName(name);\nsolrSearchResult.setFiletype(filetype);\nsolrSearchResult.setFileContentType(fileContentType);\nObject fileSizeInBytesObject = solrDocument.getFieldValue(SearchFields.FILE_SIZE_IN_BYTES);\nif (fileSizeInBytesObject != null) {\ntry {\nlong fileSizeInBytesLong = (long) fileSizeInBytesObject;\nsolrSearchResult.setFileSizeInBytes(fileSizeInBytesLong);\n} catch (ClassCastException ex) {\nlogger.info(\"Could not cast file \" + entityid + \" to long for \" + SearchFields.FILE_SIZE_IN_BYTES + \": \" + ex.getLocalizedMessage());\n}\n}\nsolrSearchResult.setFileMd5((String) solrDocument.getFieldValue(SearchFields.FILE_MD5));\ntry {\nsolrSearchResult.setFileChecksumType(DataFile.ChecksumType.fromString((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_TYPE)));\n} catch (IllegalArgumentException ex) {\nlogger.info(\"Exception setting setFileChecksumType: \" + ex);\n}\nsolrSearchResult.setFileChecksumValue((String) solrDocument.getFieldValue(SearchFields.FILE_CHECKSUM_VALUE));\nsolrSearchResult.setUnf((String) solrDocument.getFieldValue(SearchFields.UNF));\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\n\nList<SpellCheckResponse.Suggestion> suggestions = spellCheckResponse.getSuggestions();\nfor (SpellCheckResponse.Suggestion suggestion : suggestions) {\nspellingSuggestionsByToken.put(suggestion.getToken(), suggestion.getAlternatives());\n}\n}\nList<FacetCategory> facetCategoryList = new ArrayList<>();\nList<FacetCategory> typeFacetCategories = new ArrayList<>();\nboolean hidePublicationStatusFacet = true;\nboolean draftsAvailable = false;\nboolean unpublishedAvailable = false;\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\n\n}\n}\nList<FacetCategory> facetCategoryList = new ArrayList<>();\nList<FacetCategory> typeFacetCategories = new ArrayList<>();\nboolean hidePublicationStatusFacet = true;\nboolean draftsAvailable = false;\nboolean unpublishedAvailable = false;\nboolean deaccessionedAvailable = false;\nboolean hideMetadataSourceFacet = true;\nfor (FacetField facetField : queryResponse.getFacetFields()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nint numMetadataSources = 0;\nfor (FacetField.Count facetFieldCount : facetField.getValues()) {\n\/**\n* @todo we do want to show the count for each facet\n*\/\n\/\/ logger.info(\"field: \" + facetField.getName() + \" \" + facetFieldCount.getName() + \" (\" + facetFieldCount.getCount() + \")\");\nif (facetFieldCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(facetFieldCount.getName(), facetFieldCount.getCount());\n\/\/ quote field facets\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\nfacetLabel.setFilterQuery(facetField.getName() + \":\\\"\" + facetFieldCount.getName() + \"\\\"\");\nfacetLabelList.add(facetLabel);\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n\nif (facetField.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (facetLabel.getName().equals(IndexServiceBean.getUNPUBLISHED_STRING())) {\nunpublishedAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDRAFT_STRING())) {\ndraftsAvailable = true;\n} else if (facetLabel.getName().equals(IndexServiceBean.getDEACCESSIONED_STRING())) {\ndeaccessionedAvailable = true;\n}\n}\nif (facetField.getName().equals(SearchFields.METADATA_SOURCE)) {\nnumMetadataSources++;\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\n\n}\n}\n}\nif (numMetadataSources > 1) {\nhideMetadataSourceFacet = false;\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n\n}\nfacetCategory.setName(facetField.getName());\n\/\/ hopefully people will never see the raw facetField.getName() because it may well have an _s at the end\nfacetCategory.setFriendlyName(facetField.getName());\n\/\/ try to find a friendlier name to display as a facet\n\/**\n* @todo hmm, we thought we wanted the datasetFields array to go\n* away once we have more granularity than findAll() available per\n* the todo above but we need a way to lookup by Solr field, so\n* we'll build a hashmap\n*\/\nfor (DatasetFieldType datasetField : datasetFields) {\nString solrFieldNameForDataset = datasetField.getSolrField().getNameFacetable();\nString friendlyName = datasetField.getDisplayName();\nif (solrFieldNameForDataset != null && facetField.getName().endsWith(datasetField.getTmpNullFieldTypeIdentifier())) {\n\/\/ give it the non-friendly name so we remember to update the reference data script for datasets\nfacetCategory.setName(facetField.getName());\n} else if (solrFieldNameForDataset != null && facetField.getName().equals(solrFieldNameForDataset)) {\nif (friendlyName != null && !friendlyName.isEmpty()) {\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ stop examining available dataset fields. we found a match\nbreak;\n}\n}\ndatasetfieldFriendlyNamesBySolrField.put(datasetField.getSolrField().getNameFacetable(), friendlyName);\n}\n\/**\n* @todo get rid of this crazy reflection, per todo above... or\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\n\n\/\/ solrQuery.setSort(sortClause);\nsolrQuery.setHighlight(true).setHighlightSnippets(1);\nInteger fragSize = systemConfig.getSearchHighlightFragmentSize();\nif (fragSize != null) {\nsolrQuery.setHighlightFragsize(fragSize);\n}\nsolrQuery.setHighlightSimplePre(\"<span class=\\\"search-term-match\\\">\");\nsolrQuery.setHighlightSimplePost(\"<\/span>\");\nMap<String, String> solrFieldsToHightlightOnMap = new HashMap<>();\n\/\/ TODO: Do not hard code \"Name\" etc as English here.\nsolrFieldsToHightlightOnMap.put(SearchFields.NAME, \"Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.AFFILIATION, \"Affiliation\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_FRIENDLY, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DESCRIPTION, \"Description\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_NAME, \"Variable Name\");\nsolrFieldsToHightlightOnMap.put(SearchFields.VARIABLE_LABEL, \"Variable Label\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TYPE_SEARCHABLE, \"File Type\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PUBLICATION_DATE, \"Publication Date\");\nsolrFieldsToHightlightOnMap.put(SearchFields.DATASET_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.datasets.persistentId\"));\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_PERSISTENT_ID, BundleUtil.getStringFromBundle(\"advanced.search.files.persistentId\"));\n\/**\n* @todo Dataverse subject and affiliation should be highlighted but\n* this is commented out right now because the \"friendly\" names are not\n* being shown on the dataverse cards. See also\n* https:\/\/github.com\/IQSS\/dataverse\/issues\/1431\n*\/\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_SUBJECT, \"Subject\");\n\/\/ solrFieldsToHightlightOnMap.put(SearchFields.DATAVERSE_AFFILIATION, \"Affiliation\");\n\/**\n* @todo: show highlight on file card?\n* https:\/\/redmine.hmdc.harvard.edu\/issues\/3848\n*\/\nsolrFieldsToHightlightOnMap.put(SearchFields.FILENAME_WITHOUT_EXTENSION, \"Filename Without Extension\");\nsolrFieldsToHightlightOnMap.put(SearchFields.FILE_TAG_SEARCHABLE, \"File Tag\");\nList<DatasetFieldType> datasetFields = datasetFieldService.findAllOrderedById();\nfor (DatasetFieldType datasetFieldType : datasetFields) {\nString solrField = datasetFieldType.getSolrField().getNameSearchable();\nString displayName = datasetFieldType.getDisplayName();\nsolrFieldsToHightlightOnMap.put(solrField, displayName);\n}\nfor (Map.Entry<String, String> entry : solrFieldsToHightlightOnMap.entrySet()) {\nString solrField = entry.getKey();\n\/\/ String displayName = entry.getValue();\nsolrQuery.addHighlightField(solrField);\n}\n\n* should we... let's put into a hash the friendly names of facet\n* categories, indexed by Solr field\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n\n*\/\nfor (Field fieldObject : staticSearchFields) {\nString name = fieldObject.getName();\nString staticSearchField = null;\ntry {\nstaticSearchField = (String) fieldObject.get(searchFieldsObject);\n} catch (IllegalArgumentException | IllegalAccessException ex) {\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\n\nLogger.getLogger(SearchServiceBean.class.getName()).log(Level.SEVERE, null, ex);\n}\nif (staticSearchField != null && facetField.getName().equals(staticSearchField)) {\nString[] parts = name.split(\"_\");\nStringBuilder stringBuilder = new StringBuilder();\nfor (String part : parts) {\nstringBuilder.append(getCapitalizedName(part.toLowerCase()) + \" \");\n}\nString friendlyNameWithTrailingSpace = stringBuilder.toString();\nString friendlyName = friendlyNameWithTrailingSpace.replaceAll(\" $\", \"\");\nfacetCategory.setFriendlyName(friendlyName);\n\/\/ logger.info(\"adding <<<\" + staticSearchField + \":\" + friendlyName + \">>>\");\nstaticSolrFieldFriendlyNamesBySolrField.put(staticSearchField, friendlyName);\n\/\/ stop examining the declared\/static fields in the SearchFields object. we found a match\nbreak;\n}\n}\nfacetCategory.setFacetLabel(facetLabelList);\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\n\nif (!facetLabelList.isEmpty()) {\nif (facetCategory.getName().equals(SearchFields.TYPE)) {\n\/\/ the \"type\" facet is special, these are not\ntypeFacetCategories.add(facetCategory);\n} else if (facetCategory.getName().equals(SearchFields.PUBLICATION_STATUS)) {\nif (unpublishedAvailable || draftsAvailable || deaccessionedAvailable) {\nhidePublicationStatusFacet = false;\n}\nif (!hidePublicationStatusFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\n\nfacetCategoryList.add(facetCategory);\n}\n} else if (facetCategory.getName().equals(SearchFields.METADATA_SOURCE)) {\nif (!hideMetadataSourceFacet) {\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n\nfacetCategoryList.add(facetCategory);\n}\n} else {\nfacetCategoryList.add(facetCategory);\n}\n}\n}\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\n\n\/\/ for now the only range facet is citation year\nfor (RangeFacet<String, String> rangeFacet : queryResponse.getFacetRanges()) {\nFacetCategory facetCategory = new FacetCategory();\nList<FacetLabel> facetLabelList = new ArrayList<>();\nfor (Object rfObj : rangeFacet.getCounts()) {\nRangeFacet.Count rangeFacetCount = (RangeFacet.Count) rfObj;\nString valueString = rangeFacetCount.getValue();\nInteger start = Integer.parseInt(valueString);\nInteger end = start + Integer.parseInt(rangeFacet.getGap().toString());\n\/\/ to avoid overlapping dates\nend = end - 1;\nif (rangeFacetCount.getCount() > 0) {\nFacetLabel facetLabel = new FacetLabel(start + \"-\" + end, new Long(rangeFacetCount.getCount()));\n\/\/ special [12 TO 34] syntax for range facets\nfacetLabel.setFilterQuery(rangeFacet.getName() + \":\" + \"[\" + start + \" TO \" + end + \"]\");\nfacetLabelList.add(facetLabel);\n}\n}\nfacetCategory.setName(rangeFacet.getName());\nfacetCategory.setFacetLabel(facetLabelList);\n\/\/ reverse to show the newest citation year range at the top\nList<FacetLabel> facetLabelListReversed = new ArrayList<>();\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\n\nListIterator<FacetLabel> li = facetLabelList.listIterator(facetLabelList.size());\nwhile (li.hasPrevious()) {\nfacetLabelListReversed.add(li.previous());\n}\nfacetCategory.setFacetLabel(facetLabelListReversed);\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}\n\nif (!facetLabelList.isEmpty()) {\nfacetCategoryList.add(facetCategory);\n}\n}\nSolrQueryResponse solrQueryResponse = new SolrQueryResponse(solrQuery);\nsolrQueryResponse.setSolrSearchResults(solrSearchResults);\nsolrQueryResponse.setSpellingSuggestionsByToken(spellingSuggestionsByToken);\nsolrQueryResponse.setFacetCategoryList(facetCategoryList);\nsolrQueryResponse.setTypeFacetCategories(typeFacetCategories);\nsolrQueryResponse.setNumResultsFound(queryResponse.getResults().getNumFound());\nsolrQueryResponse.setResultsStart(queryResponse.getResults().getStart());\nsolrQueryResponse.setDatasetfieldFriendlyNamesBySolrField(datasetfieldFriendlyNamesBySolrField);\nsolrQueryResponse.setStaticSolrFieldFriendlyNamesBySolrField(staticSolrFieldFriendlyNamesBySolrField);\nString[] filterQueriesArray = solrQuery.getFilterQueries();\nif (filterQueriesArray != null) {\n\/\/ null check added because these tests were failing: mvn test -Dtest=SearchIT\nList<String> actualFilterQueries = Arrays.asList(filterQueriesArray);\nlogger.fine(\"actual filter queries: \" + actualFilterQueries);\nsolrQueryResponse.setFilterQueriesActual(actualFilterQueries);\n} else {\n\/\/ how often is this null?\nlogger.info(\"solrQuery.getFilterQueries() was null\");\n}\nsolrQueryResponse.setDvObjectCounts(queryResponse.getFacetField(\"dvObjectType\"));\nsolrQueryResponse.setPublicationStatusCounts(queryResponse.getFacetField(\"publicationStatus\"));\nreturn solrQueryResponse;\n}","label":[1,1,1,0]}
{"id":1664,"original_code":"public AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n        \/\/ TODO: is there any way to make this `get()` faster?\n        AccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\n        if(accumulatedAnimationValue != null) {\n            return accumulatedAnimationValue;\n        }\n        accumulatedAnimationValue = new AccumulatedAnimationValue(animation);\n        accumulatedAnimationValues.put(animation, accumulatedAnimationValue);\n        return accumulatedAnimationValue;\n    }","code":"public AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n       \n        AccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\n        if(accumulatedAnimationValue != null) {\n            return accumulatedAnimationValue;\n        }\n        accumulatedAnimationValue = new AccumulatedAnimationValue(animation);\n        accumulatedAnimationValues.put(animation, accumulatedAnimationValue);\n        return accumulatedAnimationValue;\n    }","cleancode":"public accumulatedanimationvalue getaccumulatedanimationvalue(additiveanimation animation) { accumulatedanimationvalue accumulatedanimationvalue = accumulatedanimationvalues.get(animation); if(accumulatedanimationvalue != null) { return accumulatedanimationvalue; } accumulatedanimationvalue = new accumulatedanimationvalue(animation); accumulatedanimationvalues.put(animation, accumulatedanimationvalue); return accumulatedanimationvalue; }","comment":"\/** * returns an accumulator to use for this animation. all animations with the same tag and target share the same accumulator. * the lookup is rather slow, so try to store the returned object somewhere you can access it directly. *\/\n\/\/ todo: is there any way to make this `get()` faster?","repo":"wirecube\/android_additive_animations","code_context_2":"public AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {\nreturn accumulatedAnimationValue;\n}\naccumulatedAnimationValue = new AccumulatedAnimationValue(animation);\naccumulatedAnimationValues.put(animation, accumulatedAnimationValue);\nreturn accumulatedAnimationValue;\n}\n\npublic AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {","code_context_10":"public AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {\nreturn accumulatedAnimationValue;\n}\naccumulatedAnimationValue = new AccumulatedAnimationValue(animation);\naccumulatedAnimationValues.put(animation, accumulatedAnimationValue);\nreturn accumulatedAnimationValue;\n}\n\npublic AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {\nreturn accumulatedAnimationValue;\n}\naccumulatedAnimationValue = new AccumulatedAnimationValue(animation);\naccumulatedAnimationValues.put(animation, accumulatedAnimationValue);\nreturn accumulatedAnimationValue;\n}","code_context_20":"public AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {\nreturn accumulatedAnimationValue;\n}\naccumulatedAnimationValue = new AccumulatedAnimationValue(animation);\naccumulatedAnimationValues.put(animation, accumulatedAnimationValue);\nreturn accumulatedAnimationValue;\n}\n\npublic AccumulatedAnimationValue getAccumulatedAnimationValue(AdditiveAnimation animation) {\n\/\/ TODO: is there any way to make this `get()` faster?\nAccumulatedAnimationValue accumulatedAnimationValue = accumulatedAnimationValues.get(animation);\nif(accumulatedAnimationValue != null) {\nreturn accumulatedAnimationValue;\n}\naccumulatedAnimationValue = new AccumulatedAnimationValue(animation);\naccumulatedAnimationValues.put(animation, accumulatedAnimationValue);\nreturn accumulatedAnimationValue;\n}","label":[1,0,0,0]}
{"id":26242,"original_code":"public DialerCall getCallWithState(int state, int positionToFind) {\n    DialerCall retval = null;\n    int position = 0;\n    for (DialerCall call : callById.values()) {\n      if (call.getState() == state) {\n        if (position >= positionToFind) {\n          retval = call;\n          break;\n        } else {\n          position++;\n        }\n      }\n    }\n    return retval;\n  }","code":"public DialerCall getCallWithState(int state, int positionToFind) {\n    DialerCall retval = null;\n    int position = 0;\n    for (DialerCall call : callById.values()) {\n      if (call.getState() == state) {\n        if (position >= positionToFind) {\n          retval = call;\n          break;\n        } else {\n          position++;\n        }\n      }\n    }\n    return retval;\n  }","cleancode":"public dialercall getcallwithstate(int state, int positiontofind) { dialercall retval = null; int position = 0; for (dialercall call : callbyid.values()) { if (call.getstate() == state) { if (position >= positiontofind) { retval = call; break; } else { position++; } } } return retval; }","comment":"\/** * returns the [position]th call found in the call map with the specified state. todo: improve * this logic to sort by call time. *\/","repo":"unisoc-android\/android_packages_apps_Dialer","code_context_2":"public DialerCall getCallWithState(int state, int positionToFind) {\nDialerCall retval = null;\nint position = 0;\nfor (DialerCall call : callById.values()) {\nif (call.getState() == state) {\nif (position >= positionToFind) {\nretval = call;\nbreak;\n} else {\nposition++;\n}\n}\n}\nreturn retval;\n}","code_context_10":"public DialerCall getCallWithState(int state, int positionToFind) {\nDialerCall retval = null;\nint position = 0;\nfor (DialerCall call : callById.values()) {\nif (call.getState() == state) {\nif (position >= positionToFind) {\nretval = call;\nbreak;\n} else {\nposition++;\n}\n}\n}\nreturn retval;\n}","code_context_20":"public DialerCall getCallWithState(int state, int positionToFind) {\nDialerCall retval = null;\nint position = 0;\nfor (DialerCall call : callById.values()) {\nif (call.getState() == state) {\nif (position >= positionToFind) {\nretval = call;\nbreak;\n} else {\nposition++;\n}\n}\n}\nreturn retval;\n}","label":[1,0,0,0]}
{"id":18099,"original_code":"private void process(String str) {\n        QuotedStringTokenizer tok = new QuotedStringTokenizer(str);\n        String cmd = tok.nextToken().trim();\n        String retstr = \"\";\n        if (cmd.equals(\"no-op\")) {\n            \/\/ Does nothing\n        }\n        \/\/ syntax:    vnmrjcmd('SQ start [<macro>]')\n        else if (cmd.equals(START)) {\n            mgr.setExecuting(true);\n            mgr.setPaused(false);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ pause [<macro>]')\n        else if (cmd.equals(PAUSE)) {\n            mgr.setExecuting(false);\n            mgr.setPaused(true);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ stop [<macro>]')\n        else if (cmd.equals(STOP)) {\n            mgr.setExecuting(false);\n            mgr.setPaused(false);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ NormalMode [<macro>]')\n        else if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\n            mgr.setMode(NORMAL_MODE);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ SubmitMode [<macro>]')\n        else if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\n            mgr.setMode(SUBMIT_MODE);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ read filename.xml [<macro>]')\n        else if (cmd.equals(READ)) {\n            String fn = tok.nextToken().trim();\n            if (mgr.isExecuting()) {\n                postWarning(\"cannot load a new study while queue is executing\");\n                return;\n            } else {\n                String path = FileUtil.openPath(fn);\n                if (path == null) {\n                    postError(\"cannot load study file \" + fn);\n                    return;\n                }\n                mgr.newTree(path);\n\t\t\/\/ set sqdirs[jviewport]=path\n\t\tsendSQpath(path);\n            }\n        }\n        \/\/ syntax:    vnmrjcmd('SQ write filename.xml [<macro>]')\n        else if (cmd.equals(WRITE)) {\n            String fn = tok.nextToken().trim();\n            String path = FileUtil.savePath(fn);\n            if (path == null) {\n                postError(\"could not write study file \" + fn);\n                return;\n            }\n            mgr.save(path);\n\t    \/\/ set sqdirs[jviewport]=path\n\t    sendSQpath(path);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ nwrite filename.xml [<macro>]')\n        else if (cmd.equals(NWRITE)) {\n            String id;\n            String path;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                path = FileUtil.savePath(tok.nextToken().trim());\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                return;\n            }\n            mgr.writeElement(dst, path);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ setids')\n        else if (cmd.equals(SETIDS)) {\n            mgr.setIds();\n        }\n        \/\/ syntax:    vnmrjcmd('SQ nesting = {true,false}\")\n        else if (cmd.equals(NESTING)) {\n            String token;\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (!token.equals(\"=\")) {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (token.equals(\"no\") || token.equals(\"false\"))\n                mgr.setAllowNesting(false);\n            else if (token.equals(\"yes\") || token.equals(\"true\"))\n                mgr.setAllowNesting(true);\n        }\n        \/\/ syntax:    vnmrjcmd('SQ validate {move,copy,all,none}\")\n        else if (cmd.equals(VALIDATE)) {\n            String token;\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            mgr.setValidateMove(false);\n            mgr.setValidateCopy(false);\n            if (token.equals(\"all\")) {\n                mgr.setValidateMove(true);\n                mgr.setValidateCopy(true);\n                return;\n            } else if (token.equals(\"move\")) {\n                mgr.setValidateMove(true);\n                return;\n            } else if (token.equals(\"copy\")) {\n                mgr.setValidateCopy(true);\n                return;\n            } else if (token.equals(\"none\")) {\n                mgr.setValidateMove(false);\n                mgr.setValidateCopy(false);\n                return;\n            } else {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n        }\n        \/\/ syntax:    vnmrjcmd('SQ delete <id>\")\n        else if (cmd.equals(DELETE)) {\n            String id;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (getCondition(id) == ProtocolBuilder.ALL) {\n                mgr.clearTree();\n\t\t\/\/ set sqdirs[jviewport]=''\n\t\tsendSQpath(\"\");\n            } else {\n                VElement obj = mgr.getElement(id);\n                if (obj == null) {\n                    if ( ! id.equals(\"tmpstudy\")) {\n                       postError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n                    }\n                    return;\n                }\n                mgr.deleteElement(obj);\n            }\n        }\n        else if (cmd.equals(ADD_QUEUE)) {\n            String queueDir = tok.nextToken();\n            mgr.addQueue(queueDir);\n        }\n        \/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n        \/\/         vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\n        else if (cmd.equals(ADD)) {\n            String id = tok.nextToken().trim();\n            String fn = null;\n            String type = \"protocol\";\n            if (id.equals(\"new\")) {\n                type = tok.nextToken();\n                Messages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\n                if (type.equals(\"action\"))\n                    fn = new_action_file;\n                else\n                    fn = new_protocol_file;\n            } else\n                fn = id;\n            String path = FileUtil.openPath(fn);\n            if (path == null) {\n                postError(\"cannot read protocol file \" + fn);\n                return;\n            }\n            id = null;\n            if (tok.hasMoreTokens()) {\n                id = tok.nextToken();\n                int cond = getCondition(id);\n                if (cond != 0) {\n                    mgr.setInsertMode(cond);\n                    id = tok.nextToken().trim();\n                }\n            }\n            VElement dst;\n            if (id == null)\n                dst = mgr.lastElement();\n            else\n                dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            mgr.insertProtocol(dst, path);\n            mgr.setInsertMode(0);\n            new_elem = mgr.getSelected();\n        }\n        \/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\n        else if (cmd.equals(MOVE)) {\n            String id;\n            boolean ignorelock = false;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n\/\/                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            VElement src = mgr.getElement(id);\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n\/\/                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int cond = getCondition(id);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                if (tok.hasMoreTokens())\n                    id = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            if (tok.hasMoreTokens()) {\n                String s = tok.nextToken().trim();\n                if (s.equals(\"false\"))\n                    ignorelock = true;\n                else if (s.equals(\"true\"))\n                    ignorelock = false;\n                else\n                    retstr = s;\n            }\n            mgr.moveElement(src, dst, ignorelock);\n            mgr.setInsertMode(0);\n        }\n        \/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\n        else if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\n            String id;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            VElement src = mgr.getElement(id);\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int cond = getCondition(id);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                id = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            boolean bpmove = false;\n            if (cmd.equals(PMOVE))\n                bpmove = true;\n            boolean ballownesting = mgr.allowNesting();\n            if (bpmove && !ballownesting)\n                mgr.setAllowNesting(true);\n            ArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\n            if (!bpmove)\n                mgr.showElementAll(\"true\");\n            mgr.moveElement(src, dst, true);\n            mgr.setHiddenNodes(alist);\n            if (bpmove)\n                mgr.setAllowNesting(ballownesting);\n            else\n                mgr.hideElements();\n            mgr.setInsertMode(0);\n        }\n        \/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\n        else if (cmd.equals(SHOW)) {\n            String value;\n            if (tok.hasMoreTokens())\n                value = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            ArrayList aListElem = new ArrayList();\n            while (tok.hasMoreTokens()) {\n                String id = tok.nextToken().trim();\n                VElement src = mgr.getElement(id);\n                if (src == null)\n                {\n                   if ( ! id.equals(\"tmpstudy\"))\n                      postError(\"invalid node id \" + id);\n                }\n                else\n                {\n                    aListElem.add(src);\n                }\n            }\n            mgr.showElement(aListElem, value);\n        }\n        \/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\n        else if (cmd.equals(COPY)) {\n            String id_src;\n            String id_dst;\n            if (tok.hasMoreTokens())\n                id_src = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                id_dst = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int cond = getCondition(id_dst);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                id_dst = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id_dst);\n            if (dst == null) {\n                if ( ! id_dst.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id_dst);\n                return;\n            }\n            VElement src = mgr.getElement(id_src);\n            if (src == null) {\n                src = mgr.readElement(id_src, dst);\n                if (src == null) {\n                    if ( ! id_src.equals(\"tmpstudy\"))\n                       postError(\"invalid node id \" + id_src);\n                    return;\n                }\n            } else\n                mgr.copyElement(src, dst);\n        }\n        \/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\n        else if (cmd.equals(SET) || cmd.equals(GET)) {\n            String arg;\n            \/\/ first token\n            if (tok.hasMoreTokens())\n                arg = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            \/\/ second token\n            if (!tok.hasMoreTokens()) {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int type = 0;\n            int scope = 0;\n            int cond = getCondition(arg);\n            String apar = null;\n            String vpar = null;\n            String id = null;\n            VElement obj = null;\n            switch (cond) {\n            case ProtocolBuilder.FIRST:\n            case ProtocolBuilder.ALL:\n                arg = tok.nextToken();\n                type = getType(arg);\n                scope = getScope(arg);\n                apar = tok.nextToken();\n                vpar = tok.nextToken();\n                break;\n            default:\n                type = getType(arg);\n                if (type == 0 || type == ProtocolBuilder.NEW) {\n                    if (type == ProtocolBuilder.NEW) {\n                        if (new_elem == null) {\n                            postError(\"must call SQ add before using new\");\n                            return;\n                        }\n                        obj = new_elem;\n                    } else {\n                        \/\/ e.g. set p2.a2 Lock on\n                        obj = mgr.getElement(arg);\n                        if (obj == null) {\n                            \/\/ NB: This can happen when chempack adds protocols\n                            \/\/ Ugly but harmless error\n                            Messages.postDebug(\"SQ\",\n                                               \"unknown identifier SQ \" + str);\n                            return;\n                        }\n                    }\n                    cond = ProtocolBuilder.ONE;\n                    type = ProtocolBuilder.ANY;\n                    scope = SINGLE;\n                } else {\n                    \/\/ e.g. set actions > p2.a2 Lock on\n                    scope = getScope(arg);\n                    arg = tok.nextToken().trim();\n                    cond = getCondition(arg);\n                    if (scope == SINGLE) {\n                        \/\/ e.g. set actions after p2.a2 Lock on\n                        if (cond == ProtocolBuilder.GT)\n                            cond = ProtocolBuilder.AFTER;\n                        else if (cond == ProtocolBuilder.LT)\n                            cond = ProtocolBuilder.BEFORE;\n                    }\n                    if (cond == 0) {\n                        id = arg;\n                        cond = ProtocolBuilder.ONE;\n                    } else\n                        id = tok.nextToken();\n                    obj = mgr.getElement(id);\n                }\n                apar = tok.nextToken();\n                vpar = tok.nextToken();\n                if (vpar.startsWith(\"\\\"\")) {\n                    try {\n                        vpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n                    } catch (NoSuchElementException e) {\n                        vpar = vpar.substring(1, vpar.length() - 1);\n                    }\n                }\n                break;\n            } \/\/ switch\n            if (apar == null || vpar == null) {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n            ArrayList list;\n            \/\/ looking for nodes in id will return a null list if id does not exist\n            if ((obj == null) && (cond == ProtocolBuilder.EQ) )\n               list = new ArrayList();\n            else\n               list = mgr.getElements(obj, cond, type);\n            if (cmd.equals(SET)) {\n                for (int i = 0; i < list.size(); i++) {\n                    obj = (VElement) list.get(i);\n                    mgr.setAttribute(obj, apar, vpar);\n                }\n                \/\/mgr.invalidateTree();\n            } else { \/\/ get\n                if (scope == SINGLE) {\n                    if (list.size() > 1) {\n                        postError(\"syntax error \" + \"SQ \" + str);\n                        return;\n                    }\n                    String alist = apar + \"=`\";\n                    String vlist = vpar + \"=`\";\n                    if (list.size() == 1) {\n                        obj = (VElement) list.get(0);\n                        list = mgr.getAttributes(obj);\n                        for (int i = 0; i < list.size(); i += 2) {\n                            String name = (String) list.get(i);\n                            String value = (String) list.get(i + 1);\n                            alist += name;\n                            vlist += value;\n                            if (i < list.size() - 2) {\n                                alist += \"`,`\";\n                                vlist += \"`,`\";\n                            }\n                        }\n                    }\n                    alist += \"`\";\n                    vlist += \"`\";\n                    retstr = alist + \" \" + vlist;\n                } else {\n                    retstr = vpar + \"=`\";\n                    for (int i = 0; i < list.size(); i++) {\n                        obj = (VElement) list.get(i);\n                        String value = obj.getAttribute(apar);\n                        retstr += value;\n                        if (i < list.size() - 1)\n                            retstr += \"`,`\";\n                    }\n                    retstr += \"`\";\n                }\n            }\n        } else if (cmd.equals(WATCH)) {\n            \/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\n            ArrayList<String> args = new ArrayList<String>();\n            while (tok.hasMoreTokens()) {\n                args.add(tok.nextToken());\n            }\n             if (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\n                 Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n             }\n\/\/            if (tok.countTokens() != 3) {\n\/\/                Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/            } else {\n\/\/                String studydir = tok.nextToken();\n\/\/                String autodir = tok.nextToken();\n\/\/                String datadir = tok.nextToken();\n\/\/                SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/            }\n        } else {\n            postError(\"command not recognized \" + \"SQ \" + cmd);\n            return;\n        }\n        while (tok.hasMoreTokens())\n            retstr += \" \" + tok.nextToken().trim();\n        if (retstr.length() > 0) {\n            setDebug(retstr);\n            Util.sendToVnmr(retstr);\n        }\n    }","code":"private void process(String str) {\n        QuotedStringTokenizer tok = new QuotedStringTokenizer(str);\n        String cmd = tok.nextToken().trim();\n        String retstr = \"\";\n        if (cmd.equals(\"no-op\")) {\n           \n        }\n       \n        else if (cmd.equals(START)) {\n            mgr.setExecuting(true);\n            mgr.setPaused(false);\n        }\n       \n        else if (cmd.equals(PAUSE)) {\n            mgr.setExecuting(false);\n            mgr.setPaused(true);\n        }\n       \n        else if (cmd.equals(STOP)) {\n            mgr.setExecuting(false);\n            mgr.setPaused(false);\n        }\n       \n        else if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\n            mgr.setMode(NORMAL_MODE);\n        }\n       \n        else if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\n            mgr.setMode(SUBMIT_MODE);\n        }\n       \n        else if (cmd.equals(READ)) {\n            String fn = tok.nextToken().trim();\n            if (mgr.isExecuting()) {\n                postWarning(\"cannot load a new study while queue is executing\");\n                return;\n            } else {\n                String path = FileUtil.openPath(fn);\n                if (path == null) {\n                    postError(\"cannot load study file \" + fn);\n                    return;\n                }\n                mgr.newTree(path);\n\t\n\t\tsendSQpath(path);\n            }\n        }\n       \n        else if (cmd.equals(WRITE)) {\n            String fn = tok.nextToken().trim();\n            String path = FileUtil.savePath(fn);\n            if (path == null) {\n                postError(\"could not write study file \" + fn);\n                return;\n            }\n            mgr.save(path);\n\t   \n\t    sendSQpath(path);\n        }\n       \n        else if (cmd.equals(NWRITE)) {\n            String id;\n            String path;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                path = FileUtil.savePath(tok.nextToken().trim());\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                return;\n            }\n            mgr.writeElement(dst, path);\n        }\n       \n        else if (cmd.equals(SETIDS)) {\n            mgr.setIds();\n        }\n       \n        else if (cmd.equals(NESTING)) {\n            String token;\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (!token.equals(\"=\")) {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (token.equals(\"no\") || token.equals(\"false\"))\n                mgr.setAllowNesting(false);\n            else if (token.equals(\"yes\") || token.equals(\"true\"))\n                mgr.setAllowNesting(true);\n        }\n       \n        else if (cmd.equals(VALIDATE)) {\n            String token;\n            if (tok.hasMoreTokens())\n                token = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            mgr.setValidateMove(false);\n            mgr.setValidateCopy(false);\n            if (token.equals(\"all\")) {\n                mgr.setValidateMove(true);\n                mgr.setValidateCopy(true);\n                return;\n            } else if (token.equals(\"move\")) {\n                mgr.setValidateMove(true);\n                return;\n            } else if (token.equals(\"copy\")) {\n                mgr.setValidateCopy(true);\n                return;\n            } else if (token.equals(\"none\")) {\n                mgr.setValidateMove(false);\n                mgr.setValidateCopy(false);\n                return;\n            } else {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n        }\n       \n        else if (cmd.equals(DELETE)) {\n            String id;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken();\n            else {\n                postError(\"insufficient command arguments \" + \"SQ \" + cmd);\n                return;\n            }\n            if (getCondition(id) == ProtocolBuilder.ALL) {\n                mgr.clearTree();\n\t\n\t\tsendSQpath(\"\");\n            } else {\n                VElement obj = mgr.getElement(id);\n                if (obj == null) {\n                    if ( ! id.equals(\"tmpstudy\")) {\n                       postError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n                    }\n                    return;\n                }\n                mgr.deleteElement(obj);\n            }\n        }\n        else if (cmd.equals(ADD_QUEUE)) {\n            String queueDir = tok.nextToken();\n            mgr.addQueue(queueDir);\n        }\n       \n       \n        else if (cmd.equals(ADD)) {\n            String id = tok.nextToken().trim();\n            String fn = null;\n            String type = \"protocol\";\n            if (id.equals(\"new\")) {\n                type = tok.nextToken();\n                Messages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\n                if (type.equals(\"action\"))\n                    fn = new_action_file;\n                else\n                    fn = new_protocol_file;\n            } else\n                fn = id;\n            String path = FileUtil.openPath(fn);\n            if (path == null) {\n                postError(\"cannot read protocol file \" + fn);\n                return;\n            }\n            id = null;\n            if (tok.hasMoreTokens()) {\n                id = tok.nextToken();\n                int cond = getCondition(id);\n                if (cond != 0) {\n                    mgr.setInsertMode(cond);\n                    id = tok.nextToken().trim();\n                }\n            }\n            VElement dst;\n            if (id == null)\n                dst = mgr.lastElement();\n            else\n                dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            mgr.insertProtocol(dst, path);\n            mgr.setInsertMode(0);\n            new_elem = mgr.getSelected();\n        }\n       \n        else if (cmd.equals(MOVE)) {\n            String id;\n            boolean ignorelock = false;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                return;\n            }\n            VElement src = mgr.getElement(id);\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                return;\n            }\n            int cond = getCondition(id);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                if (tok.hasMoreTokens())\n                    id = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            if (tok.hasMoreTokens()) {\n                String s = tok.nextToken().trim();\n                if (s.equals(\"false\"))\n                    ignorelock = true;\n                else if (s.equals(\"true\"))\n                    ignorelock = false;\n                else\n                    retstr = s;\n            }\n            mgr.moveElement(src, dst, ignorelock);\n            mgr.setInsertMode(0);\n        }\n       \n        else if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\n            String id;\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            VElement src = mgr.getElement(id);\n            if (tok.hasMoreTokens())\n                id = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int cond = getCondition(id);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                id = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id);\n            if (dst == null) {\n                if ( ! id.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id);\n                mgr.setInsertMode(0);\n                return;\n            }\n            boolean bpmove = false;\n            if (cmd.equals(PMOVE))\n                bpmove = true;\n            boolean ballownesting = mgr.allowNesting();\n            if (bpmove && !ballownesting)\n                mgr.setAllowNesting(true);\n            ArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\n            if (!bpmove)\n                mgr.showElementAll(\"true\");\n            mgr.moveElement(src, dst, true);\n            mgr.setHiddenNodes(alist);\n            if (bpmove)\n                mgr.setAllowNesting(ballownesting);\n            else\n                mgr.hideElements();\n            mgr.setInsertMode(0);\n        }\n       \n        else if (cmd.equals(SHOW)) {\n            String value;\n            if (tok.hasMoreTokens())\n                value = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            ArrayList aListElem = new ArrayList();\n            while (tok.hasMoreTokens()) {\n                String id = tok.nextToken().trim();\n                VElement src = mgr.getElement(id);\n                if (src == null)\n                {\n                   if ( ! id.equals(\"tmpstudy\"))\n                      postError(\"invalid node id \" + id);\n                }\n                else\n                {\n                    aListElem.add(src);\n                }\n            }\n            mgr.showElement(aListElem, value);\n        }\n       \n        else if (cmd.equals(COPY)) {\n            String id_src;\n            String id_dst;\n            if (tok.hasMoreTokens())\n                id_src = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            if (tok.hasMoreTokens())\n                id_dst = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int cond = getCondition(id_dst);\n            if (cond != 0) {\n                mgr.setInsertMode(cond);\n                id_dst = tok.nextToken().trim();\n            }\n            VElement dst = mgr.getElement(id_dst);\n            if (dst == null) {\n                if ( ! id_dst.equals(\"tmpstudy\"))\n                   postError(\"invalid node id \" + id_dst);\n                return;\n            }\n            VElement src = mgr.getElement(id_src);\n            if (src == null) {\n                src = mgr.readElement(id_src, dst);\n                if (src == null) {\n                    if ( ! id_src.equals(\"tmpstudy\"))\n                       postError(\"invalid node id \" + id_src);\n                    return;\n                }\n            } else\n                mgr.copyElement(src, dst);\n        }\n       \n        else if (cmd.equals(SET) || cmd.equals(GET)) {\n            String arg;\n           \n            if (tok.hasMoreTokens())\n                arg = tok.nextToken().trim();\n            else {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n           \n            if (!tok.hasMoreTokens()) {\n                postError(\"insufficient command arguments SQ \" + cmd);\n                return;\n            }\n            int type = 0;\n            int scope = 0;\n            int cond = getCondition(arg);\n            String apar = null;\n            String vpar = null;\n            String id = null;\n            VElement obj = null;\n            switch (cond) {\n            case ProtocolBuilder.FIRST:\n            case ProtocolBuilder.ALL:\n                arg = tok.nextToken();\n                type = getType(arg);\n                scope = getScope(arg);\n                apar = tok.nextToken();\n                vpar = tok.nextToken();\n                break;\n            default:\n                type = getType(arg);\n                if (type == 0 || type == ProtocolBuilder.NEW) {\n                    if (type == ProtocolBuilder.NEW) {\n                        if (new_elem == null) {\n                            postError(\"must call SQ add before using new\");\n                            return;\n                        }\n                        obj = new_elem;\n                    } else {\n                       \n                        obj = mgr.getElement(arg);\n                        if (obj == null) {\n                           \n                           \n                            Messages.postDebug(\"SQ\",\n                                               \"unknown identifier SQ \" + str);\n                            return;\n                        }\n                    }\n                    cond = ProtocolBuilder.ONE;\n                    type = ProtocolBuilder.ANY;\n                    scope = SINGLE;\n                } else {\n                   \n                    scope = getScope(arg);\n                    arg = tok.nextToken().trim();\n                    cond = getCondition(arg);\n                    if (scope == SINGLE) {\n                       \n                        if (cond == ProtocolBuilder.GT)\n                            cond = ProtocolBuilder.AFTER;\n                        else if (cond == ProtocolBuilder.LT)\n                            cond = ProtocolBuilder.BEFORE;\n                    }\n                    if (cond == 0) {\n                        id = arg;\n                        cond = ProtocolBuilder.ONE;\n                    } else\n                        id = tok.nextToken();\n                    obj = mgr.getElement(id);\n                }\n                apar = tok.nextToken();\n                vpar = tok.nextToken();\n                if (vpar.startsWith(\"\\\"\")) {\n                    try {\n                        vpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n                    } catch (NoSuchElementException e) {\n                        vpar = vpar.substring(1, vpar.length() - 1);\n                    }\n                }\n                break;\n            }\n            if (apar == null || vpar == null) {\n                postError(\"syntax error \" + \"SQ \" + str);\n                return;\n            }\n            ArrayList list;\n           \n            if ((obj == null) && (cond == ProtocolBuilder.EQ) )\n               list = new ArrayList();\n            else\n               list = mgr.getElements(obj, cond, type);\n            if (cmd.equals(SET)) {\n                for (int i = 0; i < list.size(); i++) {\n                    obj = (VElement) list.get(i);\n                    mgr.setAttribute(obj, apar, vpar);\n                }\n               \n            } else {\n                if (scope == SINGLE) {\n                    if (list.size() > 1) {\n                        postError(\"syntax error \" + \"SQ \" + str);\n                        return;\n                    }\n                    String alist = apar + \"=`\";\n                    String vlist = vpar + \"=`\";\n                    if (list.size() == 1) {\n                        obj = (VElement) list.get(0);\n                        list = mgr.getAttributes(obj);\n                        for (int i = 0; i < list.size(); i += 2) {\n                            String name = (String) list.get(i);\n                            String value = (String) list.get(i + 1);\n                            alist += name;\n                            vlist += value;\n                            if (i < list.size() - 2) {\n                                alist += \"`,`\";\n                                vlist += \"`,`\";\n                            }\n                        }\n                    }\n                    alist += \"`\";\n                    vlist += \"`\";\n                    retstr = alist + \" \" + vlist;\n                } else {\n                    retstr = vpar + \"=`\";\n                    for (int i = 0; i < list.size(); i++) {\n                        obj = (VElement) list.get(i);\n                        String value = obj.getAttribute(apar);\n                        retstr += value;\n                        if (i < list.size() - 1)\n                            retstr += \"`,`\";\n                    }\n                    retstr += \"`\";\n                }\n            }\n        } else if (cmd.equals(WATCH)) {\n           \n            ArrayList<String> args = new ArrayList<String>();\n            while (tok.hasMoreTokens()) {\n                args.add(tok.nextToken());\n            }\n             if (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\n                 Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n             }\n        } else {\n            postError(\"command not recognized \" + \"SQ \" + cmd);\n            return;\n        }\n        while (tok.hasMoreTokens())\n            retstr += \" \" + tok.nextToken().trim();\n        if (retstr.length() > 0) {\n            setDebug(retstr);\n            Util.sendToVnmr(retstr);\n        }\n    }","cleancode":"private void process(string str) { quotedstringtokenizer tok = new quotedstringtokenizer(str); string cmd = tok.nexttoken().trim(); string retstr = \"\"; if (cmd.equals(\"no-op\")) { } else if (cmd.equals(start)) { mgr.setexecuting(true); mgr.setpaused(false); } else if (cmd.equals(pause)) { mgr.setexecuting(false); mgr.setpaused(true); } else if (cmd.equals(stop)) { mgr.setexecuting(false); mgr.setpaused(false); } else if (cmd.equalsignorecase(normal_mode)) { mgr.setmode(normal_mode); } else if (cmd.equalsignorecase(submit_mode)) { mgr.setmode(submit_mode); } else if (cmd.equals(read)) { string fn = tok.nexttoken().trim(); if (mgr.isexecuting()) { postwarning(\"cannot load a new study while queue is executing\"); return; } else { string path = fileutil.openpath(fn); if (path == null) { posterror(\"cannot load study file \" + fn); return; } mgr.newtree(path); sendsqpath(path); } } else if (cmd.equals(write)) { string fn = tok.nexttoken().trim(); string path = fileutil.savepath(fn); if (path == null) { posterror(\"could not write study file \" + fn); return; } mgr.save(path); sendsqpath(path); } else if (cmd.equals(nwrite)) { string id; string path; if (tok.hasmoretokens()) id = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } if (tok.hasmoretokens()) path = fileutil.savepath(tok.nexttoken().trim()); else { posterror(\"insufficient command arguments sq \" + cmd); return; } velement dst = mgr.getelement(id); if (dst == null) { if ( ! id.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id); return; } mgr.writeelement(dst, path); } else if (cmd.equals(setids)) { mgr.setids(); } else if (cmd.equals(nesting)) { string token; if (tok.hasmoretokens()) token = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments \" + \"sq \" + cmd); return; } if (!token.equals(\"=\")) { posterror(\"syntax error \" + \"sq \" + str); return; } if (tok.hasmoretokens()) token = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments \" + \"sq \" + cmd); return; } if (token.equals(\"no\") || token.equals(\"false\")) mgr.setallownesting(false); else if (token.equals(\"yes\") || token.equals(\"true\")) mgr.setallownesting(true); } else if (cmd.equals(validate)) { string token; if (tok.hasmoretokens()) token = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments \" + \"sq \" + cmd); return; } mgr.setvalidatemove(false); mgr.setvalidatecopy(false); if (token.equals(\"all\")) { mgr.setvalidatemove(true); mgr.setvalidatecopy(true); return; } else if (token.equals(\"move\")) { mgr.setvalidatemove(true); return; } else if (token.equals(\"copy\")) { mgr.setvalidatecopy(true); return; } else if (token.equals(\"none\")) { mgr.setvalidatemove(false); mgr.setvalidatecopy(false); return; } else { posterror(\"syntax error \" + \"sq \" + str); return; } } else if (cmd.equals(delete)) { string id; if (tok.hasmoretokens()) id = tok.nexttoken(); else { posterror(\"insufficient command arguments \" + \"sq \" + cmd); return; } if (getcondition(id) == protocolbuilder.all) { mgr.cleartree(); sendsqpath(\"\"); } else { velement obj = mgr.getelement(id); if (obj == null) { if ( ! id.equals(\"tmpstudy\")) { posterror(\"node \" + id + \" not found \" + \"sq \" + cmd); } return; } mgr.deleteelement(obj); } } else if (cmd.equals(add_queue)) { string queuedir = tok.nexttoken(); mgr.addqueue(queuedir); } else if (cmd.equals(add)) { string id = tok.nexttoken().trim(); string fn = null; string type = \"protocol\"; if (id.equals(\"new\")) { type = tok.nexttoken(); messages.postdebug(\"sq\", \"--- sq add: type=\" + type); if (type.equals(\"action\")) fn = new_action_file; else fn = new_protocol_file; } else fn = id; string path = fileutil.openpath(fn); if (path == null) { posterror(\"cannot read protocol file \" + fn); return; } id = null; if (tok.hasmoretokens()) { id = tok.nexttoken(); int cond = getcondition(id); if (cond != 0) { mgr.setinsertmode(cond); id = tok.nexttoken().trim(); } } velement dst; if (id == null) dst = mgr.lastelement(); else dst = mgr.getelement(id); if (dst == null) { if ( ! id.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id); mgr.setinsertmode(0); return; } mgr.insertprotocol(dst, path); mgr.setinsertmode(0); new_elem = mgr.getselected(); } else if (cmd.equals(move)) { string id; boolean ignorelock = false; if (tok.hasmoretokens()) id = tok.nexttoken().trim(); else { return; } velement src = mgr.getelement(id); if (tok.hasmoretokens()) id = tok.nexttoken().trim(); else { return; } int cond = getcondition(id); if (cond != 0) { mgr.setinsertmode(cond); if (tok.hasmoretokens()) id = tok.nexttoken().trim(); } velement dst = mgr.getelement(id); if (dst == null) { if ( ! id.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id); mgr.setinsertmode(0); return; } if (tok.hasmoretokens()) { string s = tok.nexttoken().trim(); if (s.equals(\"false\")) ignorelock = true; else if (s.equals(\"true\")) ignorelock = false; else retstr = s; } mgr.moveelement(src, dst, ignorelock); mgr.setinsertmode(0); } else if (cmd.equals(pmove) || cmd.equals(lmove)) { string id; if (tok.hasmoretokens()) id = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } velement src = mgr.getelement(id); if (tok.hasmoretokens()) id = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } int cond = getcondition(id); if (cond != 0) { mgr.setinsertmode(cond); id = tok.nexttoken().trim(); } velement dst = mgr.getelement(id); if (dst == null) { if ( ! id.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id); mgr.setinsertmode(0); return; } boolean bpmove = false; if (cmd.equals(pmove)) bpmove = true; boolean ballownesting = mgr.allownesting(); if (bpmove && !ballownesting) mgr.setallownesting(true); arraylist alist = (arraylist) mgr.gethiddennodes().clone(); if (!bpmove) mgr.showelementall(\"true\"); mgr.moveelement(src, dst, true); mgr.sethiddennodes(alist); if (bpmove) mgr.setallownesting(ballownesting); else mgr.hideelements(); mgr.setinsertmode(0); } else if (cmd.equals(show)) { string value; if (tok.hasmoretokens()) value = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } arraylist alistelem = new arraylist(); while (tok.hasmoretokens()) { string id = tok.nexttoken().trim(); velement src = mgr.getelement(id); if (src == null) { if ( ! id.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id); } else { alistelem.add(src); } } mgr.showelement(alistelem, value); } else if (cmd.equals(copy)) { string id_src; string id_dst; if (tok.hasmoretokens()) id_src = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } if (tok.hasmoretokens()) id_dst = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } int cond = getcondition(id_dst); if (cond != 0) { mgr.setinsertmode(cond); id_dst = tok.nexttoken().trim(); } velement dst = mgr.getelement(id_dst); if (dst == null) { if ( ! id_dst.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id_dst); return; } velement src = mgr.getelement(id_src); if (src == null) { src = mgr.readelement(id_src, dst); if (src == null) { if ( ! id_src.equals(\"tmpstudy\")) posterror(\"invalid node id \" + id_src); return; } } else mgr.copyelement(src, dst); } else if (cmd.equals(set) || cmd.equals(get)) { string arg; if (tok.hasmoretokens()) arg = tok.nexttoken().trim(); else { posterror(\"insufficient command arguments sq \" + cmd); return; } if (!tok.hasmoretokens()) { posterror(\"insufficient command arguments sq \" + cmd); return; } int type = 0; int scope = 0; int cond = getcondition(arg); string apar = null; string vpar = null; string id = null; velement obj = null; switch (cond) { case protocolbuilder.first: case protocolbuilder.all: arg = tok.nexttoken(); type = gettype(arg); scope = getscope(arg); apar = tok.nexttoken(); vpar = tok.nexttoken(); break; default: type = gettype(arg); if (type == 0 || type == protocolbuilder.new) { if (type == protocolbuilder.new) { if (new_elem == null) { posterror(\"must call sq add before using new\"); return; } obj = new_elem; } else { obj = mgr.getelement(arg); if (obj == null) { messages.postdebug(\"sq\", \"unknown identifier sq \" + str); return; } } cond = protocolbuilder.one; type = protocolbuilder.any; scope = single; } else { scope = getscope(arg); arg = tok.nexttoken().trim(); cond = getcondition(arg); if (scope == single) { if (cond == protocolbuilder.gt) cond = protocolbuilder.after; else if (cond == protocolbuilder.lt) cond = protocolbuilder.before; } if (cond == 0) { id = arg; cond = protocolbuilder.one; } else id = tok.nexttoken(); obj = mgr.getelement(id); } apar = tok.nexttoken(); vpar = tok.nexttoken(); if (vpar.startswith(\"\\\"\")) { try { vpar = vpar.substring(1) + tok.nexttoken(\"\\\"\"); } catch (nosuchelementexception e) { vpar = vpar.substring(1, vpar.length() - 1); } } break; } if (apar == null || vpar == null) { posterror(\"syntax error \" + \"sq \" + str); return; } arraylist list; if ((obj == null) && (cond == protocolbuilder.eq) ) list = new arraylist(); else list = mgr.getelements(obj, cond, type); if (cmd.equals(set)) { for (int i = 0; i < list.size(); i++) { obj = (velement) list.get(i); mgr.setattribute(obj, apar, vpar); } } else { if (scope == single) { if (list.size() > 1) { posterror(\"syntax error \" + \"sq \" + str); return; } string alist = apar + \"=`\"; string vlist = vpar + \"=`\"; if (list.size() == 1) { obj = (velement) list.get(0); list = mgr.getattributes(obj); for (int i = 0; i < list.size(); i += 2) { string name = (string) list.get(i); string value = (string) list.get(i + 1); alist += name; vlist += value; if (i < list.size() - 2) { alist += \"`,`\"; vlist += \"`,`\"; } } } alist += \"`\"; vlist += \"`\"; retstr = alist + \" \" + vlist; } else { retstr = vpar + \"=`\"; for (int i = 0; i < list.size(); i++) { obj = (velement) list.get(i); string value = obj.getattribute(apar); retstr += value; if (i < list.size() - 1) retstr += \"`,`\"; } retstr += \"`\"; } } } else if (cmd.equals(watch)) { arraylist<string> args = new arraylist<string>(); while (tok.hasmoretokens()) { args.add(tok.nexttoken()); } if (!squpdater.processcommand(this, args.toarray(new string[0]))) { messages.postdebug(\"bad format for 'watch' cmd: \" + str); } } else { posterror(\"command not recognized \" + \"sq \" + cmd); return; } while (tok.hasmoretokens()) retstr += \" \" + tok.nexttoken().trim(); if (retstr.length() > 0) { setdebug(retstr); util.sendtovnmr(retstr); } }","comment":"\/************************************************** <pre> process a vnmrbg \"sq\" command. sq commands are sent from the vnmr background engine to the sq through the vnmrj-vnmrbg socket interface. usually, they are generated by the em in response to a change in the status of the experiment queue but (for testing purposes) may also be entered from the command line. general syntax: vnmrjcmd('sq <command> <arg> .. <arg> [<macro>]') if <macro> is specified, the sq sends a command to the background engine to execute the macro after other actions specified by the command are carried out. refer to studyqueueapi.spec for additional details <pre>**************************************************\/\n\/\/ does nothing\n\/\/ syntax: vnmrjcmd('sq start [<macro>]')\n\/\/ syntax: vnmrjcmd('sq pause [<macro>]')\n\/\/ syntax: vnmrjcmd('sq stop [<macro>]')\n\/\/ syntax: vnmrjcmd('sq normalmode [<macro>]')\n\/\/ syntax: vnmrjcmd('sq submitmode [<macro>]')\n\/\/ syntax: vnmrjcmd('sq read filename.xml [<macro>]')\n\/\/ set sqdirs[jviewport]=path\n\/\/ syntax: vnmrjcmd('sq write filename.xml [<macro>]')\n\/\/ set sqdirs[jviewport]=path\n\/\/ syntax: vnmrjcmd('sq nwrite filename.xml [<macro>]')\n\/\/ syntax: vnmrjcmd('sq setids')\n\/\/ syntax: vnmrjcmd('sq nesting = {true,false}\")\n\/\/ syntax: vnmrjcmd('sq validate {move,copy,all,none}\")\n\/\/ syntax: vnmrjcmd('sq delete <id>\")\n\/\/ set sqdirs[jviewport]=''\n\/\/ syntax: vnmrjcmd('sq add <file> [<cond>] [<dst>] [<macro>]') \/\/ vnmrjcmd('sq add new <type> [<cond>] [<dst>] [<macro>]')\n\/\/ syntax: vnmrjcmd('sq move <src> [<cond>] <dst> [true,false] [<macro>]')\n\/\/ posterror(\"insufficient command arguments sq \" + cmd);\n\/\/ posterror(\"insufficient command arguments sq \" + cmd);\n\/\/ syntax: vnmrjcmd('sq {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\n\/\/ syntax: vnmrjcmd('sq show <attr> <id> [<macro>]')\n\/\/ syntax: vnmrjcmd('sq copy <id> <cond> <dst> [<macro>]')\n\/\/ syntax: vnmrjcmd('sq {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\n\/\/ first token\n\/\/ second token\n\/\/ e.g. set p2.a2 lock on\n\/\/ nb: this can happen when chempack adds protocols \/\/ ugly but harmless error\n\/\/ e.g. set actions > p2.a2 lock on\n\/\/ e.g. set actions after p2.a2 lock on\n\/\/ switch\n\/\/ looking for nodes in id will return a null list if id does not exist\n\/\/mgr.invalidatetree();\n\/\/ get\n\/\/ e.g.: vnmrjcmd('sq watch auto ', cursqexp, autodir, svfdir)\n\/\/ if (tok.counttokens() != 3) { \/\/ messages.postdebug(\"bad format for 'watch' cmd: \" + str); \/\/ } else { \/\/ string studydir = tok.nexttoken(); \/\/ string autodir = tok.nexttoken(); \/\/ string datadir = tok.nexttoken(); \/\/ squpdater.startupdates(this, studydir, autodir, datadir); \/\/ }","repo":"timburrow\/openvnmrj-source","code_context_2":"private void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\nelse if (token.equals(\"yes\") || token.equals(\"true\"))\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nif (token.equals(\"all\")) {\nmgr.setValidateMove(true);\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"move\")) {\nmgr.setValidateMove(true);\nreturn;\n} else if (token.equals(\"copy\")) {\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\nString fn = null;\nString type = \"protocol\";\nif (id.equals(\"new\")) {\ntype = tok.nextToken();\nMessages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\nif (type.equals(\"action\"))\nfn = new_action_file;\nelse\nfn = new_protocol_file;\n} else\nfn = id;\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot read protocol file \" + fn);\nreturn;\n}\nid = null;\nif (tok.hasMoreTokens()) {\nid = tok.nextToken();\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\n}\nVElement dst;\nif (id == null)\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nif (tok.hasMoreTokens()) {\nString s = tok.nextToken().trim();\nif (s.equals(\"false\"))\nignorelock = true;\nelse if (s.equals(\"true\"))\nignorelock = false;\nelse\nretstr = s;\n}\nmgr.moveElement(src, dst, ignorelock);\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nboolean bpmove = false;\nif (cmd.equals(PMOVE))\nbpmove = true;\nboolean ballownesting = mgr.allowNesting();\nif (bpmove && !ballownesting)\nmgr.setAllowNesting(true);\nArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\nif (!bpmove)\nmgr.showElementAll(\"true\");\nmgr.moveElement(src, dst, true);\nmgr.setHiddenNodes(alist);\nif (bpmove)\nmgr.setAllowNesting(ballownesting);\nelse\nmgr.hideElements();\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\nif (tok.hasMoreTokens())\nvalue = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\nString id = tok.nextToken().trim();\nVElement src = mgr.getElement(id);\nif (src == null)\n{\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n}\n}\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\nString id_dst;\nif (tok.hasMoreTokens())\nid_src = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\nid_dst = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id_dst);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid_dst = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id_dst);\nif (dst == null) {\nif ( ! id_dst.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_dst);\nreturn;\n}\nVElement src = mgr.getElement(id_src);\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\nfor (int i = 0; i < list.size(); i += 2) {\nString name = (String) list.get(i);\nString value = (String) list.get(i + 1);\nalist += name;\nvlist += value;\nif (i < list.size() - 2) {\nalist += \"`,`\";\nvlist += \"`,`\";\n}\n}\n}\nalist += \"`\";\nvlist += \"`\";\nretstr = alist + \" \" + vlist;\n} else {\nretstr = vpar + \"=`\";\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\nretstr += \" \" + tok.nextToken().trim();\nif (retstr.length() > 0) {\nsetDebug(retstr);\nUtil.sendToVnmr(retstr);\n}\n}\n\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\n\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\n\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\n\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\n\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\n\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\n\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\n\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\n\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\n\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\n\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\n\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\n\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\n\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\n\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\n\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\n\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\n\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\n\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\n\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\n\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\n\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\n\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\n\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\n\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\n\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\n\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);","code_context_10":"private void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\nelse if (token.equals(\"yes\") || token.equals(\"true\"))\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nif (token.equals(\"all\")) {\nmgr.setValidateMove(true);\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"move\")) {\nmgr.setValidateMove(true);\nreturn;\n} else if (token.equals(\"copy\")) {\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\nString fn = null;\nString type = \"protocol\";\nif (id.equals(\"new\")) {\ntype = tok.nextToken();\nMessages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\nif (type.equals(\"action\"))\nfn = new_action_file;\nelse\nfn = new_protocol_file;\n} else\nfn = id;\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot read protocol file \" + fn);\nreturn;\n}\nid = null;\nif (tok.hasMoreTokens()) {\nid = tok.nextToken();\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\n}\nVElement dst;\nif (id == null)\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nif (tok.hasMoreTokens()) {\nString s = tok.nextToken().trim();\nif (s.equals(\"false\"))\nignorelock = true;\nelse if (s.equals(\"true\"))\nignorelock = false;\nelse\nretstr = s;\n}\nmgr.moveElement(src, dst, ignorelock);\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nboolean bpmove = false;\nif (cmd.equals(PMOVE))\nbpmove = true;\nboolean ballownesting = mgr.allowNesting();\nif (bpmove && !ballownesting)\nmgr.setAllowNesting(true);\nArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\nif (!bpmove)\nmgr.showElementAll(\"true\");\nmgr.moveElement(src, dst, true);\nmgr.setHiddenNodes(alist);\nif (bpmove)\nmgr.setAllowNesting(ballownesting);\nelse\nmgr.hideElements();\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\nif (tok.hasMoreTokens())\nvalue = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\nString id = tok.nextToken().trim();\nVElement src = mgr.getElement(id);\nif (src == null)\n{\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n}\n}\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\nString id_dst;\nif (tok.hasMoreTokens())\nid_src = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\nid_dst = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id_dst);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid_dst = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id_dst);\nif (dst == null) {\nif ( ! id_dst.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_dst);\nreturn;\n}\nVElement src = mgr.getElement(id_src);\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\nfor (int i = 0; i < list.size(); i += 2) {\nString name = (String) list.get(i);\nString value = (String) list.get(i + 1);\nalist += name;\nvlist += value;\nif (i < list.size() - 2) {\nalist += \"`,`\";\nvlist += \"`,`\";\n}\n}\n}\nalist += \"`\";\nvlist += \"`\";\nretstr = alist + \" \" + vlist;\n} else {\nretstr = vpar + \"=`\";\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\nretstr += \" \" + tok.nextToken().trim();\nif (retstr.length() > 0) {\nsetDebug(retstr);\nUtil.sendToVnmr(retstr);\n}\n}\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\n\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\n\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\n\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\n\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\n\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\n\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\n\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\n\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\nelse if (token.equals(\"yes\") || token.equals(\"true\"))\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\n\nreturn;\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\nString fn = null;\nString type = \"protocol\";\nif (id.equals(\"new\")) {\ntype = tok.nextToken();\nMessages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\nif (type.equals(\"action\"))\nfn = new_action_file;\nelse\n\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\n\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\n\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\n\nif (s.equals(\"false\"))\nignorelock = true;\nelse if (s.equals(\"true\"))\nignorelock = false;\nelse\nretstr = s;\n}\nmgr.moveElement(src, dst, ignorelock);\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\n\nif (!bpmove)\nmgr.showElementAll(\"true\");\nmgr.moveElement(src, dst, true);\nmgr.setHiddenNodes(alist);\nif (bpmove)\nmgr.setAllowNesting(ballownesting);\nelse\nmgr.hideElements();\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\nif (tok.hasMoreTokens())\nvalue = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\n\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n}\n}\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\nString id_dst;\nif (tok.hasMoreTokens())\nid_src = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\n\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\n\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\n\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\n\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\n\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\n\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\n\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\n\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\n\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\n\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\nretstr += \" \" + tok.nextToken().trim();\nif (retstr.length() > 0) {\nsetDebug(retstr);\nUtil.sendToVnmr(retstr);\n}","code_context_20":"private void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\nelse if (token.equals(\"yes\") || token.equals(\"true\"))\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nif (token.equals(\"all\")) {\nmgr.setValidateMove(true);\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"move\")) {\nmgr.setValidateMove(true);\nreturn;\n} else if (token.equals(\"copy\")) {\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\nString fn = null;\nString type = \"protocol\";\nif (id.equals(\"new\")) {\ntype = tok.nextToken();\nMessages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\nif (type.equals(\"action\"))\nfn = new_action_file;\nelse\nfn = new_protocol_file;\n} else\nfn = id;\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot read protocol file \" + fn);\nreturn;\n}\nid = null;\nif (tok.hasMoreTokens()) {\nid = tok.nextToken();\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\n}\nVElement dst;\nif (id == null)\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nif (tok.hasMoreTokens()) {\nString s = tok.nextToken().trim();\nif (s.equals(\"false\"))\nignorelock = true;\nelse if (s.equals(\"true\"))\nignorelock = false;\nelse\nretstr = s;\n}\nmgr.moveElement(src, dst, ignorelock);\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nboolean bpmove = false;\nif (cmd.equals(PMOVE))\nbpmove = true;\nboolean ballownesting = mgr.allowNesting();\nif (bpmove && !ballownesting)\nmgr.setAllowNesting(true);\nArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\nif (!bpmove)\nmgr.showElementAll(\"true\");\nmgr.moveElement(src, dst, true);\nmgr.setHiddenNodes(alist);\nif (bpmove)\nmgr.setAllowNesting(ballownesting);\nelse\nmgr.hideElements();\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\nif (tok.hasMoreTokens())\nvalue = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\nString id = tok.nextToken().trim();\nVElement src = mgr.getElement(id);\nif (src == null)\n{\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n}\n}\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\nString id_dst;\nif (tok.hasMoreTokens())\nid_src = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\nid_dst = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id_dst);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid_dst = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id_dst);\nif (dst == null) {\nif ( ! id_dst.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_dst);\nreturn;\n}\nVElement src = mgr.getElement(id_src);\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\nfor (int i = 0; i < list.size(); i += 2) {\nString name = (String) list.get(i);\nString value = (String) list.get(i + 1);\nalist += name;\nvlist += value;\nif (i < list.size() - 2) {\nalist += \"`,`\";\nvlist += \"`,`\";\n}\n}\n}\nalist += \"`\";\nvlist += \"`\";\nretstr = alist + \" \" + vlist;\n} else {\nretstr = vpar + \"=`\";\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\nretstr += \" \" + tok.nextToken().trim();\nif (retstr.length() > 0) {\nsetDebug(retstr);\nUtil.sendToVnmr(retstr);\n}\n}\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\n\nprivate void process(String str) {\nQuotedStringTokenizer tok = new QuotedStringTokenizer(str);\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\n\nString cmd = tok.nextToken().trim();\nString retstr = \"\";\nif (cmd.equals(\"no-op\")) {\n\/\/ Does nothing\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\n}\n\/\/ syntax: vnmrjcmd('SQ start [<macro>]')\nelse if (cmd.equals(START)) {\nmgr.setExecuting(true);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ pause [<macro>]')\nelse if (cmd.equals(PAUSE)) {\nmgr.setExecuting(false);\nmgr.setPaused(true);\n}\n\/\/ syntax: vnmrjcmd('SQ stop [<macro>]')\nelse if (cmd.equals(STOP)) {\nmgr.setExecuting(false);\nmgr.setPaused(false);\n}\n\/\/ syntax: vnmrjcmd('SQ NormalMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\n\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\n\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n\nelse if (cmd.equalsIgnoreCase(NORMAL_MODE)) {\nmgr.setMode(NORMAL_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ SubmitMode [<macro>]')\nelse if (cmd.equalsIgnoreCase(SUBMIT_MODE)) {\nmgr.setMode(SUBMIT_MODE);\n}\n\/\/ syntax: vnmrjcmd('SQ read filename.xml [<macro>]')\nelse if (cmd.equals(READ)) {\nString fn = tok.nextToken().trim();\nif (mgr.isExecuting()) {\npostWarning(\"cannot load a new study while queue is executing\");\nreturn;\n} else {\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\n\npostError(\"cannot load study file \" + fn);\nreturn;\n}\nmgr.newTree(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n}\n\/\/ syntax: vnmrjcmd('SQ write filename.xml [<macro>]')\nelse if (cmd.equals(WRITE)) {\nString fn = tok.nextToken().trim();\nString path = FileUtil.savePath(fn);\nif (path == null) {\npostError(\"could not write study file \" + fn);\nreturn;\n}\nmgr.save(path);\n\/\/ set sqdirs[jviewport]=path\nsendSQpath(path);\n}\n\/\/ syntax: vnmrjcmd('SQ nwrite filename.xml [<macro>]')\nelse if (cmd.equals(NWRITE)) {\nString id;\nString path;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\n\nreturn;\n}\nif (tok.hasMoreTokens())\npath = FileUtil.savePath(tok.nextToken().trim());\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nreturn;\n}\nmgr.writeElement(dst, path);\n}\n\/\/ syntax: vnmrjcmd('SQ setids')\nelse if (cmd.equals(SETIDS)) {\nmgr.setIds();\n}\n\/\/ syntax: vnmrjcmd('SQ nesting = {true,false}\")\nelse if (cmd.equals(NESTING)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\n\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (!token.equals(\"=\")) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (token.equals(\"no\") || token.equals(\"false\"))\nmgr.setAllowNesting(false);\nelse if (token.equals(\"yes\") || token.equals(\"true\"))\nmgr.setAllowNesting(true);\n}\n\/\/ syntax: vnmrjcmd('SQ validate {move,copy,all,none}\")\nelse if (cmd.equals(VALIDATE)) {\nString token;\nif (tok.hasMoreTokens())\ntoken = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nif (token.equals(\"all\")) {\nmgr.setValidateMove(true);\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"move\")) {\nmgr.setValidateMove(true);\nreturn;\n} else if (token.equals(\"copy\")) {\nmgr.setValidateCopy(true);\nreturn;\n\nmgr.setValidateCopy(false);\nif (token.equals(\"all\")) {\nmgr.setValidateMove(true);\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"move\")) {\nmgr.setValidateMove(true);\nreturn;\n} else if (token.equals(\"copy\")) {\nmgr.setValidateCopy(true);\nreturn;\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\n\n} else if (token.equals(\"none\")) {\nmgr.setValidateMove(false);\nmgr.setValidateCopy(false);\nreturn;\n} else {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\n}\n\/\/ syntax: vnmrjcmd('SQ delete <id>\")\nelse if (cmd.equals(DELETE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken();\nelse {\npostError(\"insufficient command arguments \" + \"SQ \" + cmd);\nreturn;\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\n\n}\nif (getCondition(id) == ProtocolBuilder.ALL) {\nmgr.clearTree();\n\/\/ set sqdirs[jviewport]=''\nsendSQpath(\"\");\n} else {\nVElement obj = mgr.getElement(id);\nif (obj == null) {\nif ( ! id.equals(\"tmpstudy\")) {\npostError(\"node \" + id + \" not found \" + \"SQ \" + cmd);\n}\nreturn;\n}\nmgr.deleteElement(obj);\n}\n}\nelse if (cmd.equals(ADD_QUEUE)) {\nString queueDir = tok.nextToken();\nmgr.addQueue(queueDir);\n}\n\/\/ syntax: vnmrjcmd('SQ add <file> [<cond>] [<dst>] [<macro>]')\n\/\/ vnmrjcmd('SQ add new <type> [<cond>] [<dst>] [<macro>]')\nelse if (cmd.equals(ADD)) {\nString id = tok.nextToken().trim();\nString fn = null;\nString type = \"protocol\";\nif (id.equals(\"new\")) {\ntype = tok.nextToken();\nMessages.postDebug(\"SQ\", \"--- SQ ADD: type=\" + type);\nif (type.equals(\"action\"))\nfn = new_action_file;\nelse\nfn = new_protocol_file;\n} else\nfn = id;\nString path = FileUtil.openPath(fn);\nif (path == null) {\npostError(\"cannot read protocol file \" + fn);\nreturn;\n}\nid = null;\nif (tok.hasMoreTokens()) {\n\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\n}\nVElement dst;\nif (id == null)\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\n\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\n\ndst = mgr.lastElement();\nelse\ndst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nmgr.insertProtocol(dst, path);\nmgr.setInsertMode(0);\nnew_elem = mgr.getSelected();\n}\n\/\/ syntax: vnmrjcmd('SQ move <src> [<cond>] <dst> [true,false] [<macro>]')\nelse if (cmd.equals(MOVE)) {\nString id;\nboolean ignorelock = false;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\n\/\/ postError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\n\n}\nVElement dst = mgr.getElement(id);\nif (dst == null) {\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\nmgr.setInsertMode(0);\nreturn;\n}\nif (tok.hasMoreTokens()) {\nString s = tok.nextToken().trim();\nif (s.equals(\"false\"))\nignorelock = true;\nelse if (s.equals(\"true\"))\nignorelock = false;\nelse\nretstr = s;\n}\nmgr.moveElement(src, dst, ignorelock);\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ {lmove,pmove} <src> [<cond>] <dst> [<macro>]')\nelse if (cmd.equals(PMOVE) || cmd.equals(LMOVE)) {\nString id;\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nVElement src = mgr.getElement(id);\nif (tok.hasMoreTokens())\nid = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid = tok.nextToken().trim();\n}\n\nmgr.setInsertMode(0);\nreturn;\n}\nboolean bpmove = false;\nif (cmd.equals(PMOVE))\nbpmove = true;\nboolean ballownesting = mgr.allowNesting();\nif (bpmove && !ballownesting)\nmgr.setAllowNesting(true);\nArrayList alist = (ArrayList) mgr.getHiddenNodes().clone();\nif (!bpmove)\nmgr.showElementAll(\"true\");\nmgr.moveElement(src, dst, true);\nmgr.setHiddenNodes(alist);\nif (bpmove)\nmgr.setAllowNesting(ballownesting);\nelse\nmgr.hideElements();\nmgr.setInsertMode(0);\n}\n\/\/ syntax: vnmrjcmd('SQ show <attr> <id> [<macro>]')\nelse if (cmd.equals(SHOW)) {\nString value;\nif (tok.hasMoreTokens())\nvalue = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\nString id = tok.nextToken().trim();\nVElement src = mgr.getElement(id);\nif (src == null)\n{\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nArrayList aListElem = new ArrayList();\nwhile (tok.hasMoreTokens()) {\nString id = tok.nextToken().trim();\nVElement src = mgr.getElement(id);\nif (src == null)\n{\nif ( ! id.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id);\n}\nelse\n{\naListElem.add(src);\n}\n}\nmgr.showElement(aListElem, value);\n}\n\/\/ syntax: vnmrjcmd('SQ copy <id> <cond> <dst> [<macro>]')\nelse if (cmd.equals(COPY)) {\nString id_src;\nString id_dst;\nif (tok.hasMoreTokens())\nid_src = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nif (tok.hasMoreTokens())\nid_dst = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint cond = getCondition(id_dst);\nif (cond != 0) {\nmgr.setInsertMode(cond);\nid_dst = tok.nextToken().trim();\n}\n\nmgr.setInsertMode(cond);\nid_dst = tok.nextToken().trim();\n}\nVElement dst = mgr.getElement(id_dst);\nif (dst == null) {\nif ( ! id_dst.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_dst);\nreturn;\n}\nVElement src = mgr.getElement(id_src);\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\n\nVElement dst = mgr.getElement(id_dst);\nif (dst == null) {\nif ( ! id_dst.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_dst);\nreturn;\n}\nVElement src = mgr.getElement(id_src);\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\n\nif (src == null) {\nsrc = mgr.readElement(id_src, dst);\nif (src == null) {\nif ( ! id_src.equals(\"tmpstudy\"))\npostError(\"invalid node id \" + id_src);\nreturn;\n}\n} else\nmgr.copyElement(src, dst);\n}\n\/\/ syntax: vnmrjcmd('SQ {get,set} <type> [<cond> <id>] <attr> <val> [<macro>]')\nelse if (cmd.equals(SET) || cmd.equals(GET)) {\nString arg;\n\/\/ first token\nif (tok.hasMoreTokens())\narg = tok.nextToken().trim();\nelse {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\n\/\/ second token\nif (!tok.hasMoreTokens()) {\npostError(\"insufficient command arguments SQ \" + cmd);\nreturn;\n}\nint type = 0;\nint scope = 0;\nint cond = getCondition(arg);\nString apar = null;\nString vpar = null;\nString id = null;\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\n\nVElement obj = null;\nswitch (cond) {\ncase ProtocolBuilder.FIRST:\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\n\ncase ProtocolBuilder.ALL:\narg = tok.nextToken();\ntype = getType(arg);\nscope = getScope(arg);\napar = tok.nextToken();\nvpar = tok.nextToken();\nbreak;\ndefault:\ntype = getType(arg);\nif (type == 0 || type == ProtocolBuilder.NEW) {\nif (type == ProtocolBuilder.NEW) {\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\n\nif (new_elem == null) {\npostError(\"must call SQ add before using new\");\nreturn;\n}\nobj = new_elem;\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\n\n} else {\n\/\/ e.g. set p2.a2 Lock on\nobj = mgr.getElement(arg);\nif (obj == null) {\n\/\/ NB: This can happen when chempack adds protocols\n\/\/ Ugly but harmless error\nMessages.postDebug(\"SQ\",\n\"unknown identifier SQ \" + str);\nreturn;\n}\n}\ncond = ProtocolBuilder.ONE;\ntype = ProtocolBuilder.ANY;\nscope = SINGLE;\n} else {\n\/\/ e.g. set actions > p2.a2 Lock on\nscope = getScope(arg);\narg = tok.nextToken().trim();\ncond = getCondition(arg);\nif (scope == SINGLE) {\n\/\/ e.g. set actions after p2.a2 Lock on\nif (cond == ProtocolBuilder.GT)\ncond = ProtocolBuilder.AFTER;\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n\nelse if (cond == ProtocolBuilder.LT)\ncond = ProtocolBuilder.BEFORE;\n}\nif (cond == 0) {\nid = arg;\ncond = ProtocolBuilder.ONE;\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\n\n} else\nid = tok.nextToken();\nobj = mgr.getElement(id);\n}\napar = tok.nextToken();\nvpar = tok.nextToken();\nif (vpar.startsWith(\"\\\"\")) {\ntry {\nvpar = vpar.substring(1) + tok.nextToken(\"\\\"\");\n} catch (NoSuchElementException e) {\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\n\nvpar = vpar.substring(1, vpar.length() - 1);\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\nfor (int i = 0; i < list.size(); i += 2) {\nString name = (String) list.get(i);\nString value = (String) list.get(i + 1);\nalist += name;\nvlist += value;\nif (i < list.size() - 2) {\nalist += \"`,`\";\nvlist += \"`,`\";\n}\n\n}\n}\nbreak;\n} \/\/ switch\nif (apar == null || vpar == null) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nArrayList list;\n\/\/ looking for nodes in id will return a null list if id does not exist\nif ((obj == null) && (cond == ProtocolBuilder.EQ) )\nlist = new ArrayList();\nelse\nlist = mgr.getElements(obj, cond, type);\nif (cmd.equals(SET)) {\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nmgr.setAttribute(obj, apar, vpar);\n}\n\/\/mgr.invalidateTree();\n} else { \/\/ get\nif (scope == SINGLE) {\nif (list.size() > 1) {\npostError(\"syntax error \" + \"SQ \" + str);\nreturn;\n}\nString alist = apar + \"=`\";\nString vlist = vpar + \"=`\";\nif (list.size() == 1) {\nobj = (VElement) list.get(0);\nlist = mgr.getAttributes(obj);\nfor (int i = 0; i < list.size(); i += 2) {\nString name = (String) list.get(i);\nString value = (String) list.get(i + 1);\nalist += name;\nvlist += value;\nif (i < list.size() - 2) {\nalist += \"`,`\";\nvlist += \"`,`\";\n}\n}\n\nvlist += \"`,`\";\n}\n}\n}\nalist += \"`\";\nvlist += \"`\";\nretstr = alist + \" \" + vlist;\n} else {\nretstr = vpar + \"=`\";\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\n\nretstr = vpar + \"=`\";\nfor (int i = 0; i < list.size(); i++) {\nobj = (VElement) list.get(i);\nString value = obj.getAttribute(apar);\nretstr += value;\nif (i < list.size() - 1)\nretstr += \"`,`\";\n}\nretstr += \"`\";\n}\n}\n} else if (cmd.equals(WATCH)) {\n\/\/ E.g.: vnmrjcmd('SQ watch auto ', cursqexp, autodir, svfdir)\nArrayList<String> args = new ArrayList<String>();\nwhile (tok.hasMoreTokens()) {\nargs.add(tok.nextToken());\n}\nif (!SQUpdater.processCommand(this, args.toArray(new String[0]))) {\nMessages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n}\n\/\/ if (tok.countTokens() != 3) {\n\/\/ Messages.postDebug(\"Bad format for 'watch' cmd: \" + str);\n\/\/ } else {\n\/\/ String studydir = tok.nextToken();\n\/\/ String autodir = tok.nextToken();\n\/\/ String datadir = tok.nextToken();\n\/\/ SQUpdater.startUpdates(this, studydir, autodir, datadir);\n\/\/ }\n} else {\npostError(\"command not recognized \" + \"SQ \" + cmd);\nreturn;\n}\nwhile (tok.hasMoreTokens())\nretstr += \" \" + tok.nextToken().trim();\nif (retstr.length() > 0) {\nsetDebug(retstr);\nUtil.sendToVnmr(retstr);\n}\n}","label":[1,0,0,0]}
{"id":1780,"original_code":"@Override\n    public boolean onTouch(View v, MotionEvent event) {\n        Layout layout = ((TextView) v).getLayout();\n        if (layout == null) {\n            return false;\n        }\n        int x = (int) event.getX();\n        int y = (int) event.getY();\n        int line = layout.getLineForVertical(y);\n        int offset = layout.getOffsetForHorizontal(line, x);\n        TextView tv = (TextView) v;\n        SpannableString value = SpannableString.valueOf(tv.getText());\n        switch (event.getActionMasked()) {\n            case MotionEvent.ACTION_DOWN:\n                MyURLSpan[] urlSpans = value.getSpans(0, value.length(), MyURLSpan.class);\n                int findStart = 0;\n                int findEnd = 0;\n                for (MyURLSpan urlSpan : urlSpans) {\n                    int start = value.getSpanStart(urlSpan);\n                    int end = value.getSpanEnd(urlSpan);\n                    if (start <= offset && offset <= end) {\n                        find = true;\n                        findStart = start;\n                        findEnd = end;\n                        break;\n                    }\n                }\n                float lineWidth = layout.getLineWidth(line);\n                find &= (lineWidth >= x);\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                    BackgroundColorSpan backgroundColorSpan = new BackgroundColorSpan(0xFFE9E9E9);\n                    value.setSpan(backgroundColorSpan, findStart, findEnd,\n                            Spanned.SPAN_INCLUSIVE_INCLUSIVE);\n                    \/\/Android has a bug, sometime TextView wont change its value when you modify SpannableString,\n                    \/\/ so you must setText again, test on Android 4.3 Nexus4\n                    tv.setText(value);\n                }\n                return find;\n            case MotionEvent.ACTION_MOVE:\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                }\n                break;\n            case MotionEvent.ACTION_CANCEL:\n            case MotionEvent.ACTION_UP:\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                    LongClickableLinkMovementMethod.getInstance().removeLongClickCallback();\n                    BackgroundColorSpan[] backgroundColorSpans = value\n                            .getSpans(0, value.length(), BackgroundColorSpan.class);\n                    for (BackgroundColorSpan backgroundColorSpan : backgroundColorSpans) {\n                        value.removeSpan(backgroundColorSpan);\n                    }\n                    tv.setText(value);\n                    find = false;\n                }\n                break;\n        }\n        return false;\n    }","code":"@Override\n    public boolean onTouch(View v, MotionEvent event) {\n        Layout layout = ((TextView) v).getLayout();\n        if (layout == null) {\n            return false;\n        }\n        int x = (int) event.getX();\n        int y = (int) event.getY();\n        int line = layout.getLineForVertical(y);\n        int offset = layout.getOffsetForHorizontal(line, x);\n        TextView tv = (TextView) v;\n        SpannableString value = SpannableString.valueOf(tv.getText());\n        switch (event.getActionMasked()) {\n            case MotionEvent.ACTION_DOWN:\n                MyURLSpan[] urlSpans = value.getSpans(0, value.length(), MyURLSpan.class);\n                int findStart = 0;\n                int findEnd = 0;\n                for (MyURLSpan urlSpan : urlSpans) {\n                    int start = value.getSpanStart(urlSpan);\n                    int end = value.getSpanEnd(urlSpan);\n                    if (start <= offset && offset <= end) {\n                        find = true;\n                        findStart = start;\n                        findEnd = end;\n                        break;\n                    }\n                }\n                float lineWidth = layout.getLineWidth(line);\n                find &= (lineWidth >= x);\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                    BackgroundColorSpan backgroundColorSpan = new BackgroundColorSpan(0xFFE9E9E9);\n                    value.setSpan(backgroundColorSpan, findStart, findEnd,\n                            Spanned.SPAN_INCLUSIVE_INCLUSIVE);\n                   \n                   \n                    tv.setText(value);\n                }\n                return find;\n            case MotionEvent.ACTION_MOVE:\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                }\n                break;\n            case MotionEvent.ACTION_CANCEL:\n            case MotionEvent.ACTION_UP:\n                if (find) {\n                    LongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n                    LongClickableLinkMovementMethod.getInstance().removeLongClickCallback();\n                    BackgroundColorSpan[] backgroundColorSpans = value\n                            .getSpans(0, value.length(), BackgroundColorSpan.class);\n                    for (BackgroundColorSpan backgroundColorSpan : backgroundColorSpans) {\n                        value.removeSpan(backgroundColorSpan);\n                    }\n                    tv.setText(value);\n                    find = false;\n                }\n                break;\n        }\n        return false;\n    }","cleancode":"@override public boolean ontouch(view v, motionevent event) { layout layout = ((textview) v).getlayout(); if (layout == null) { return false; } int x = (int) event.getx(); int y = (int) event.gety(); int line = layout.getlineforvertical(y); int offset = layout.getoffsetforhorizontal(line, x); textview tv = (textview) v; spannablestring value = spannablestring.valueof(tv.gettext()); switch (event.getactionmasked()) { case motionevent.action_down: myurlspan[] urlspans = value.getspans(0, value.length(), myurlspan.class); int findstart = 0; int findend = 0; for (myurlspan urlspan : urlspans) { int start = value.getspanstart(urlspan); int end = value.getspanend(urlspan); if (start <= offset && offset <= end) { find = true; findstart = start; findend = end; break; } } float linewidth = layout.getlinewidth(line); find &= (linewidth >= x); if (find) { longclickablelinkmovementmethod.getinstance().ontouchevent(tv, value, event); backgroundcolorspan backgroundcolorspan = new backgroundcolorspan(0xffe9e9e9); value.setspan(backgroundcolorspan, findstart, findend, spanned.span_inclusive_inclusive); tv.settext(value); } return find; case motionevent.action_move: if (find) { longclickablelinkmovementmethod.getinstance().ontouchevent(tv, value, event); } break; case motionevent.action_cancel: case motionevent.action_up: if (find) { longclickablelinkmovementmethod.getinstance().ontouchevent(tv, value, event); longclickablelinkmovementmethod.getinstance().removelongclickcallback(); backgroundcolorspan[] backgroundcolorspans = value .getspans(0, value.length(), backgroundcolorspan.class); for (backgroundcolorspan backgroundcolorspan : backgroundcolorspans) { value.removespan(backgroundcolorspan); } tv.settext(value); find = false; } break; } return false; }","comment":"\/\/android has a bug, sometime textview wont change its value when you modify spannablestring, \/\/ so you must settext again, test on android 4.3 nexus4","repo":"zhe525069676\/WeiBoLayout","code_context_2":"value.setSpan(backgroundColorSpan, findStart, findEnd,\nSpanned.SPAN_INCLUSIVE_INCLUSIVE);\n\/\/Android has a bug, sometime TextView wont change its value when you modify SpannableString,\n\/\/ so you must setText again, test on Android 4.3 Nexus4\ntv.setText(value);\n}","code_context_10":"break;\n}\n}\nfloat lineWidth = layout.getLineWidth(line);\nfind &= (lineWidth >= x);\nif (find) {\nLongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\nBackgroundColorSpan backgroundColorSpan = new BackgroundColorSpan(0xFFE9E9E9);\nvalue.setSpan(backgroundColorSpan, findStart, findEnd,\nSpanned.SPAN_INCLUSIVE_INCLUSIVE);\n\/\/Android has a bug, sometime TextView wont change its value when you modify SpannableString,\n\/\/ so you must setText again, test on Android 4.3 Nexus4\ntv.setText(value);\n}\nreturn find;\ncase MotionEvent.ACTION_MOVE:\nif (find) {\nLongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n}\nbreak;\ncase MotionEvent.ACTION_CANCEL:\ncase MotionEvent.ACTION_UP:","code_context_20":"MyURLSpan[] urlSpans = value.getSpans(0, value.length(), MyURLSpan.class);\nint findStart = 0;\nint findEnd = 0;\nfor (MyURLSpan urlSpan : urlSpans) {\nint start = value.getSpanStart(urlSpan);\nint end = value.getSpanEnd(urlSpan);\nif (start <= offset && offset <= end) {\nfind = true;\nfindStart = start;\nfindEnd = end;\nbreak;\n}\n}\nfloat lineWidth = layout.getLineWidth(line);\nfind &= (lineWidth >= x);\nif (find) {\nLongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\nBackgroundColorSpan backgroundColorSpan = new BackgroundColorSpan(0xFFE9E9E9);\nvalue.setSpan(backgroundColorSpan, findStart, findEnd,\nSpanned.SPAN_INCLUSIVE_INCLUSIVE);\n\/\/Android has a bug, sometime TextView wont change its value when you modify SpannableString,\n\/\/ so you must setText again, test on Android 4.3 Nexus4\ntv.setText(value);\n}\nreturn find;\ncase MotionEvent.ACTION_MOVE:\nif (find) {\nLongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\n}\nbreak;\ncase MotionEvent.ACTION_CANCEL:\ncase MotionEvent.ACTION_UP:\nif (find) {\nLongClickableLinkMovementMethod.getInstance().onTouchEvent(tv, value, event);\nLongClickableLinkMovementMethod.getInstance().removeLongClickCallback();\nBackgroundColorSpan[] backgroundColorSpans = value\n.getSpans(0, value.length(), BackgroundColorSpan.class);\nfor (BackgroundColorSpan backgroundColorSpan : backgroundColorSpans) {\nvalue.removeSpan(backgroundColorSpan);\n}\ntv.setText(value);\nfind = false;","label":[0,0,1,0]}
{"id":34679,"original_code":"@Override\n    public Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\n        Set<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\n        for(ConfigKey<?> key: configKeys) {\n            @SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\n            ConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\n            subscriptionKeys.add(invariant);\n        }\n        CloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\n        testGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\n        activeSubscribers.put(subscriber, 0);\n        return subscriber;\n    }","code":"@Override\n    public Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\n        Set<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\n        for(ConfigKey<?> key: configKeys) {\n            @SuppressWarnings(\"unchecked\")\n            ConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\n            subscriptionKeys.add(invariant);\n        }\n        CloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\n        testGeneration.ifPresent(subscriber.subscriber::reload);\n        activeSubscribers.put(subscriber, 0);\n        return subscriber;\n    }","cleancode":"@override public subscriber getsubscriber(set<? extends configkey<?>> configkeys) { set<configkey<configinstance>> subscriptionkeys = new hashset<>(); for(configkey<?> key: configkeys) { @suppresswarnings(\"unchecked\") configkey<configinstance> invariant = (configkey<configinstance>) key; subscriptionkeys.add(invariant); } cloudsubscriber subscriber = new cloudsubscriber(subscriptionkeys, configsource); testgeneration.ifpresent(subscriber.subscriber::reload); activesubscribers.put(subscriber, 0); return subscriber; }","comment":"\/\/ configkey is defined as <configclass extends configinstance>\n\/\/ todo: test specific code, remove","repo":"yehzu\/vespa","code_context_2":"Set<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\nfor(ConfigKey<?> key: configKeys) {\n@SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\nConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\nsubscriptionKeys.add(invariant);\n\n}\nCloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\ntestGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\nactiveSubscribers.put(subscriber, 0);\nreturn subscriber;","code_context_10":"@Override\npublic Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\nSet<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\nfor(ConfigKey<?> key: configKeys) {\n@SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\nConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\nsubscriptionKeys.add(invariant);\n}\nCloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\ntestGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\nactiveSubscribers.put(subscriber, 0);\nreturn subscriber;\n}\n\n@Override\npublic Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\nSet<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\nfor(ConfigKey<?> key: configKeys) {\n@SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\nConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\nsubscriptionKeys.add(invariant);\n}\nCloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\ntestGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\nactiveSubscribers.put(subscriber, 0);\nreturn subscriber;\n}","code_context_20":"@Override\npublic Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\nSet<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\nfor(ConfigKey<?> key: configKeys) {\n@SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\nConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\nsubscriptionKeys.add(invariant);\n}\nCloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\ntestGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\nactiveSubscribers.put(subscriber, 0);\nreturn subscriber;\n}\n\n@Override\npublic Subscriber getSubscriber(Set<? extends ConfigKey<?>> configKeys) {\nSet<ConfigKey<ConfigInstance>> subscriptionKeys = new HashSet<>();\nfor(ConfigKey<?> key: configKeys) {\n@SuppressWarnings(\"unchecked\") \/\/ ConfigKey is defined as <CONFIGCLASS extends ConfigInstance>\nConfigKey<ConfigInstance> invariant = (ConfigKey<ConfigInstance>) key;\nsubscriptionKeys.add(invariant);\n}\nCloudSubscriber subscriber = new CloudSubscriber(subscriptionKeys, configSource);\ntestGeneration.ifPresent(subscriber.subscriber::reload); \/\/ TODO: test specific code, remove\nactiveSubscribers.put(subscriber, 0);\nreturn subscriber;\n}","label":[0,0,0,1]}
{"id":34680,"original_code":"@Override\n    public void reloadActiveSubscribers(long generation) {\n        testGeneration = Optional.of(generation);\n        List<CloudSubscriber> subscribers = new ArrayList<>(activeSubscribers.keySet());\n        subscribers.forEach(s -> s.subscriber.reload(generation));\n    }","code":"@Override\n    public void reloadActiveSubscribers(long generation) {\n        testGeneration = Optional.of(generation);\n        List<CloudSubscriber> subscribers = new ArrayList<>(activeSubscribers.keySet());\n        subscribers.forEach(s -> s.subscriber.reload(generation));\n    }","cleancode":"@override public void reloadactivesubscribers(long generation) { testgeneration = optional.of(generation); list<cloudsubscriber> subscribers = new arraylist<>(activesubscribers.keyset()); subscribers.foreach(s -> s.subscriber.reload(generation)); }","comment":"\/\/todo: test specific code, remove","repo":"yehzu\/vespa","code_context_2":"@Override\npublic void reloadActiveSubscribers(long generation) {\ntestGeneration = Optional.of(generation);\nList<CloudSubscriber> subscribers = new ArrayList<>(activeSubscribers.keySet());\nsubscribers.forEach(s -> s.subscriber.reload(generation));\n}","code_context_10":"@Override\npublic void reloadActiveSubscribers(long generation) {\ntestGeneration = Optional.of(generation);\nList<CloudSubscriber> subscribers = new ArrayList<>(activeSubscribers.keySet());\nsubscribers.forEach(s -> s.subscriber.reload(generation));\n}","code_context_20":"@Override\npublic void reloadActiveSubscribers(long generation) {\ntestGeneration = Optional.of(generation);\nList<CloudSubscriber> subscribers = new ArrayList<>(activeSubscribers.keySet());\nsubscribers.forEach(s -> s.subscriber.reload(generation));\n}","label":[0,0,0,1]}
{"id":1975,"original_code":"@Override\n    protected void doGetWithSubjectAndActor(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException\n    {\n        \/\/ TODO filtering??? request.getParameter(\"filter\"); \/\/ filter=1,2,3   \/groups\/*\/*\n        Map<String,Object> structure = generateStructure(getBroker(), Broker.class);\n        sendJsonResponse(structure, request, response);\n    }","code":"@Override\n    protected void doGetWithSubjectAndActor(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException\n    {\n       \n        Map<String,Object> structure = generateStructure(getBroker(), Broker.class);\n        sendJsonResponse(structure, request, response);\n    }","cleancode":"@override protected void dogetwithsubjectandactor(httpservletrequest request, httpservletresponse response) throws ioexception, servletexception { map<string,object> structure = generatestructure(getbroker(), broker.class); sendjsonresponse(structure, request, response); }","comment":"\/\/ todo filtering??? request.getparameter(\"filter\"); \/\/ filter=1,2,3 \/groups\/*\/*","repo":"vbohinc\/qpid-java","code_context_2":"protected void doGetWithSubjectAndActor(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException\n{\n\/\/ TODO filtering??? request.getParameter(\"filter\"); \/\/ filter=1,2,3 \/groups\/*\/*\nMap<String,Object> structure = generateStructure(getBroker(), Broker.class);\nsendJsonResponse(structure, request, response);","code_context_10":"@Override\nprotected void doGetWithSubjectAndActor(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException\n{\n\/\/ TODO filtering??? request.getParameter(\"filter\"); \/\/ filter=1,2,3 \/groups\/*\/*\nMap<String,Object> structure = generateStructure(getBroker(), Broker.class);\nsendJsonResponse(structure, request, response);\n}","code_context_20":"@Override\nprotected void doGetWithSubjectAndActor(HttpServletRequest request, HttpServletResponse response) throws IOException, ServletException\n{\n\/\/ TODO filtering??? request.getParameter(\"filter\"); \/\/ filter=1,2,3 \/groups\/*\/*\nMap<String,Object> structure = generateStructure(getBroker(), Broker.class);\nsendJsonResponse(structure, request, response);\n}","label":[0,1,0,0]}
{"id":2003,"original_code":"@Test\n  public void testTest1() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"timestamp\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"col1\", \"col2\"))),\n        new OrcInputFormat(null, null, new Configuration()),\n        \"example\/test_1.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      Assert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\n      Assert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\n      Assert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\n      Assert.assertEquals(1.1, row.getMetric(\"val1\").doubleValue(), 0.001);\n      Assert.assertFalse(iterator.hasNext());\n    }\n  }","code":"@Test\n  public void testTest1() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"timestamp\", \"auto\", null),\n        new DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"col1\", \"col2\"))),\n        new OrcInputFormat(null, null, new Configuration()),\n        \"example\/test_1.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      Assert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\n      Assert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\n      Assert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\n      Assert.assertEquals(1.1, row.getMetric(\"val1\").doubleValue(), 0.001);\n      Assert.assertFalse(iterator.hasNext());\n    }\n  }","cleancode":"@test public void testtest1() throws ioexception { final inputentityreader reader = createreader( new timestampspec(\"timestamp\", \"auto\", null), new dimensionsspec(dimensionsspec.getdefaultschemas(immutablelist.of(\"col1\", \"col2\"))), new orcinputformat(null, null, new configuration()), \"example\/test_1.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { assert.asserttrue(iterator.hasnext()); final inputrow row = iterator.next(); assert.assertequals(datetimes.of(\"2016-01-01t00:00:00.000z\"), row.gettimestamp()); assert.assertequals(\"bar\", iterables.getonlyelement(row.getdimension(\"col1\"))); assert.assertequals(immutablelist.of(\"dat1\", \"dat2\", \"dat3\"), row.getdimension(\"col2\")); assert.assertequals(1.1, row.getmetric(\"val1\").doublevalue(), 0.001); assert.assertfalse(iterator.hasnext()); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testTest1() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"col1\", \"col2\"))),\nnew OrcInputFormat(null, null, new Configuration()),\n\"example\/test_1.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(1.1, row.getMetric(\"val1\").doubleValue(), 0.001);\nAssert.assertFalse(iterator.hasNext());\n}\n}","code_context_10":"@Test\npublic void testTest1() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"col1\", \"col2\"))),\nnew OrcInputFormat(null, null, new Configuration()),\n\"example\/test_1.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(1.1, row.getMetric(\"val1\").doubleValue(), 0.001);\nAssert.assertFalse(iterator.hasNext());\n}\n}","code_context_20":"@Test\npublic void testTest1() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(DimensionsSpec.getDefaultSchemas(ImmutableList.of(\"col1\", \"col2\"))),\nnew OrcInputFormat(null, null, new Configuration()),\n\"example\/test_1.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(1.1, row.getMetric(\"val1\").doubleValue(), 0.001);\nAssert.assertFalse(iterator.hasNext());\n}\n}","label":[0,0,0,0]}
{"id":2004,"original_code":"@Test\n  public void testTest2() throws IOException\n  {\n    final InputFormat inputFormat = new OrcInputFormat(\n        new JSONPathSpec(\n            true,\n            Collections.singletonList(new JSONPathFieldSpec(JSONPathFieldType.PATH, \"col7-subcol7\", \"$.col7.subcol7\"))\n        ),\n        null,\n        new Configuration()\n    );\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"timestamp\", \"auto\", null),\n        new DimensionsSpec(null),\n        inputFormat,\n        \"example\/test_2.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      Assert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\n      Assert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\n      Assert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\n      Assert.assertEquals(\"1.1\", Iterables.getOnlyElement(row.getDimension(\"col3\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"col4\")));\n      Assert.assertEquals(\"3.5\", Iterables.getOnlyElement(row.getDimension(\"col5\")));\n      Assert.assertTrue(row.getDimension(\"col6\").isEmpty());\n      Assert.assertFalse(iterator.hasNext());\n    }\n  }","code":"@Test\n  public void testTest2() throws IOException\n  {\n    final InputFormat inputFormat = new OrcInputFormat(\n        new JSONPathSpec(\n            true,\n            Collections.singletonList(new JSONPathFieldSpec(JSONPathFieldType.PATH, \"col7-subcol7\", \"$.col7.subcol7\"))\n        ),\n        null,\n        new Configuration()\n    );\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"timestamp\", \"auto\", null),\n        new DimensionsSpec(null),\n        inputFormat,\n        \"example\/test_2.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      Assert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\n      Assert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\n      Assert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\n      Assert.assertEquals(\"1.1\", Iterables.getOnlyElement(row.getDimension(\"col3\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"col4\")));\n      Assert.assertEquals(\"3.5\", Iterables.getOnlyElement(row.getDimension(\"col5\")));\n      Assert.assertTrue(row.getDimension(\"col6\").isEmpty());\n      Assert.assertFalse(iterator.hasNext());\n    }\n  }","cleancode":"@test public void testtest2() throws ioexception { final inputformat inputformat = new orcinputformat( new jsonpathspec( true, collections.singletonlist(new jsonpathfieldspec(jsonpathfieldtype.path, \"col7-subcol7\", \"$.col7.subcol7\")) ), null, new configuration() ); final inputentityreader reader = createreader( new timestampspec(\"timestamp\", \"auto\", null), new dimensionsspec(null), inputformat, \"example\/test_2.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { assert.asserttrue(iterator.hasnext()); final inputrow row = iterator.next(); assert.assertequals(datetimes.of(\"2016-01-01t00:00:00.000z\"), row.gettimestamp()); assert.assertequals(\"bar\", iterables.getonlyelement(row.getdimension(\"col1\"))); assert.assertequals(immutablelist.of(\"dat1\", \"dat2\", \"dat3\"), row.getdimension(\"col2\")); assert.assertequals(\"1.1\", iterables.getonlyelement(row.getdimension(\"col3\"))); assert.assertequals(\"2\", iterables.getonlyelement(row.getdimension(\"col4\"))); assert.assertequals(\"3.5\", iterables.getonlyelement(row.getdimension(\"col5\"))); assert.asserttrue(row.getdimension(\"col6\").isempty()); assert.assertfalse(iterator.hasnext()); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testTest2() throws IOException\n{\nfinal InputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nCollections.singletonList(new JSONPathFieldSpec(JSONPathFieldType.PATH, \"col7-subcol7\", \"$.col7.subcol7\"))\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/test_2.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(\"1.1\", Iterables.getOnlyElement(row.getDimension(\"col3\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"col4\")));\nAssert.assertEquals(\"3.5\", Iterables.getOnlyElement(row.getDimension(\"col5\")));\nAssert.assertTrue(row.getDimension(\"col6\").isEmpty());\nAssert.assertFalse(iterator.hasNext());\n}\n}","code_context_10":"@Test\npublic void testTest2() throws IOException\n{\nfinal InputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nCollections.singletonList(new JSONPathFieldSpec(JSONPathFieldType.PATH, \"col7-subcol7\", \"$.col7.subcol7\"))\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/test_2.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(\"1.1\", Iterables.getOnlyElement(row.getDimension(\"col3\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"col4\")));\nAssert.assertEquals(\"3.5\", Iterables.getOnlyElement(row.getDimension(\"col5\")));\nAssert.assertTrue(row.getDimension(\"col6\").isEmpty());\nAssert.assertFalse(iterator.hasNext());\n}\n}","code_context_20":"@Test\npublic void testTest2() throws IOException\n{\nfinal InputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nCollections.singletonList(new JSONPathFieldSpec(JSONPathFieldType.PATH, \"col7-subcol7\", \"$.col7.subcol7\"))\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"timestamp\", \"auto\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/test_2.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nAssert.assertEquals(DateTimes.of(\"2016-01-01T00:00:00.000Z\"), row.getTimestamp());\nAssert.assertEquals(\"bar\", Iterables.getOnlyElement(row.getDimension(\"col1\")));\nAssert.assertEquals(ImmutableList.of(\"dat1\", \"dat2\", \"dat3\"), row.getDimension(\"col2\"));\nAssert.assertEquals(\"1.1\", Iterables.getOnlyElement(row.getDimension(\"col3\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"col4\")));\nAssert.assertEquals(\"3.5\", Iterables.getOnlyElement(row.getDimension(\"col5\")));\nAssert.assertTrue(row.getDimension(\"col6\").isEmpty());\nAssert.assertFalse(iterator.hasNext());\n}\n}","label":[0,0,0,0]}
{"id":2005,"original_code":"@Test\n  public void testOrcFile11Format() throws IOException\n  {\n    final OrcInputFormat inputFormat = new OrcInputFormat(\n        new JSONPathSpec(\n            true,\n            ImmutableList.of(\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n            )\n        ),\n        null,\n        new Configuration()\n    );\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"ts\", \"millis\", null),\n        new DimensionsSpec(null),\n        inputFormat,\n        \"example\/orc-file-11-format.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      \/\/ Check the first row\n      Assert.assertTrue(iterator.hasNext());\n      InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\n      Assert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\n      Assert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\n      Assert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\n      Assert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\n      Assert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\n      Assert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\n      Assert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\n      Assert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\n      Assert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\n      Assert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\n      Assert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        row = iterator.next();\n      }\n      \/\/ Check the last row\n      Assert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\n      Assert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\n      Assert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\n      Assert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\n      Assert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\n      Assert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\n      Assert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\n      Assert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\n      Assert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\n      Assert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\n      Assert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\n      Assert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\n      Assert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\n      Assert.assertEquals(7500, actualRowCount);\n    }\n  }","code":"@Test\n  public void testOrcFile11Format() throws IOException\n  {\n    final OrcInputFormat inputFormat = new OrcInputFormat(\n        new JSONPathSpec(\n            true,\n            ImmutableList.of(\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\n                new JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n            )\n        ),\n        null,\n        new Configuration()\n    );\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"ts\", \"millis\", null),\n        new DimensionsSpec(null),\n        inputFormat,\n        \"example\/orc-file-11-format.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n     \n      Assert.assertTrue(iterator.hasNext());\n      InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\n      Assert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\n      Assert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\n      Assert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\n      Assert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\n      Assert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\n      Assert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\n      Assert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\n      Assert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\n      Assert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\n      Assert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\n      Assert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        row = iterator.next();\n      }\n     \n      Assert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\n      Assert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\n      Assert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\n      Assert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\n      Assert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\n      Assert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\n      Assert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\n      Assert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\n      Assert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\n      Assert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\n      Assert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\n      Assert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\n      Assert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\n      Assert.assertEquals(7500, actualRowCount);\n    }\n  }","cleancode":"@test public void testorcfile11format() throws ioexception { final orcinputformat inputformat = new orcinputformat( new jsonpathspec( true, immutablelist.of( new jsonpathfieldspec(jsonpathfieldtype.path, \"struct_list_struct_int\", \"$.middle.list[1].int1\"), new jsonpathfieldspec(jsonpathfieldtype.path, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"), new jsonpathfieldspec(jsonpathfieldtype.path, \"list_struct_string\", \"$.list[0].string1\"), new jsonpathfieldspec(jsonpathfieldtype.path, \"map_struct_int\", \"$.map.chani.int1\") ) ), null, new configuration() ); final inputentityreader reader = createreader( new timestampspec(\"ts\", \"millis\", null), new dimensionsspec(null), inputformat, \"example\/orc-file-11-format.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { int actualrowcount = 0; assert.asserttrue(iterator.hasnext()); inputrow row = iterator.next(); actualrowcount++; assert.assertequals(\"false\", iterables.getonlyelement(row.getdimension(\"boolean1\"))); assert.assertequals(\"1\", iterables.getonlyelement(row.getdimension(\"byte1\"))); assert.assertequals(\"1024\", iterables.getonlyelement(row.getdimension(\"short1\"))); assert.assertequals(\"65536\", iterables.getonlyelement(row.getdimension(\"int1\"))); assert.assertequals(\"9223372036854775807\", iterables.getonlyelement(row.getdimension(\"long1\"))); assert.assertequals(\"1.0\", iterables.getonlyelement(row.getdimension(\"float1\"))); assert.assertequals(\"-15.0\", iterables.getonlyelement(row.getdimension(\"double1\"))); assert.assertequals(\"aaecawqaaa==\", iterables.getonlyelement(row.getdimension(\"bytes1\"))); assert.assertequals(\"hi\", iterables.getonlyelement(row.getdimension(\"string1\"))); assert.assertequals(\"1.23456786547456e7\", iterables.getonlyelement(row.getdimension(\"decimal1\"))); assert.assertequals(\"2\", iterables.getonlyelement(row.getdimension(\"struct_list_struct_int\"))); assert.assertequals(immutablelist.of(\"1\", \"2\"), row.getdimension(\"struct_list_struct_intlist\")); assert.assertequals(\"good\", iterables.getonlyelement(row.getdimension(\"list_struct_string\"))); assert.assertequals(datetimes.of(\"2000-03-12t15:00:00.0z\"), row.gettimestamp()); while (iterator.hasnext()) { actualrowcount++; row = iterator.next(); } assert.assertequals(\"true\", iterables.getonlyelement(row.getdimension(\"boolean1\"))); assert.assertequals(\"100\", iterables.getonlyelement(row.getdimension(\"byte1\"))); assert.assertequals(\"2048\", iterables.getonlyelement(row.getdimension(\"short1\"))); assert.assertequals(\"65536\", iterables.getonlyelement(row.getdimension(\"int1\"))); assert.assertequals(\"9223372036854775807\", iterables.getonlyelement(row.getdimension(\"long1\"))); assert.assertequals(\"2.0\", iterables.getonlyelement(row.getdimension(\"float1\"))); assert.assertequals(\"-5.0\", iterables.getonlyelement(row.getdimension(\"double1\"))); assert.assertequals(\"\", iterables.getonlyelement(row.getdimension(\"bytes1\"))); assert.assertequals(\"bye\", iterables.getonlyelement(row.getdimension(\"string1\"))); assert.assertequals(\"1.23456786547457e7\", iterables.getonlyelement(row.getdimension(\"decimal1\"))); assert.assertequals(\"2\", iterables.getonlyelement(row.getdimension(\"struct_list_struct_int\"))); assert.assertequals(immutablelist.of(\"1\", \"2\"), row.getdimension(\"struct_list_struct_intlist\")); assert.assertequals(\"cat\", iterables.getonlyelement(row.getdimension(\"list_struct_string\"))); assert.assertequals(\"5\", iterables.getonlyelement(row.getdimension(\"map_struct_int\"))); assert.assertequals(datetimes.of(\"2000-03-12t15:00:01.000z\"), row.gettimestamp()); assert.assertequals(7500, actualrowcount); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest\n\/\/ check the first row\n\/\/ check the last row","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testOrcFile11Format() throws IOException\n{\nfinal OrcInputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nImmutableList.of(\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n)\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/orc-file-11-format.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\nAssert.assertEquals(7500, actualRowCount);\n}\n}\n\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\n\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));","code_context_10":"@Test\npublic void testOrcFile11Format() throws IOException\n{\nfinal OrcInputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nImmutableList.of(\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n)\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/orc-file-11-format.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\nAssert.assertEquals(7500, actualRowCount);\n}\n}\n\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/orc-file-11-format.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\n\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));","code_context_20":"@Test\npublic void testOrcFile11Format() throws IOException\n{\nfinal OrcInputFormat inputFormat = new OrcInputFormat(\nnew JSONPathSpec(\ntrue,\nImmutableList.of(\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n)\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/orc-file-11-format.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\nAssert.assertEquals(7500, actualRowCount);\n}\n}\n\nnew JSONPathSpec(\ntrue,\nImmutableList.of(\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_int\", \"$.middle.list[1].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"struct_list_struct_intlist\", \"$.middle.list[*].int1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"list_struct_string\", \"$.list[0].string1\"),\nnew JSONPathFieldSpec(JSONPathFieldType.PATH, \"map_struct_int\", \"$.map.chani.int1\")\n)\n),\nnull,\nnew Configuration()\n);\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\ninputFormat,\n\"example\/orc-file-11-format.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\n\/\/ Check the first row\nAssert.assertTrue(iterator.hasNext());\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n\nInputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(\"false\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"1\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"1024\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"1.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-15.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"AAECAwQAAA==\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"hi\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547456E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"good\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:00.0Z\"), row.getTimestamp());\nwhile (iterator.hasNext()) {\nactualRowCount++;\nrow = iterator.next();\n}\n\/\/ Check the last row\nAssert.assertEquals(\"true\", Iterables.getOnlyElement(row.getDimension(\"boolean1\")));\nAssert.assertEquals(\"100\", Iterables.getOnlyElement(row.getDimension(\"byte1\")));\nAssert.assertEquals(\"2048\", Iterables.getOnlyElement(row.getDimension(\"short1\")));\nAssert.assertEquals(\"65536\", Iterables.getOnlyElement(row.getDimension(\"int1\")));\nAssert.assertEquals(\"9223372036854775807\", Iterables.getOnlyElement(row.getDimension(\"long1\")));\nAssert.assertEquals(\"2.0\", Iterables.getOnlyElement(row.getDimension(\"float1\")));\nAssert.assertEquals(\"-5.0\", Iterables.getOnlyElement(row.getDimension(\"double1\")));\nAssert.assertEquals(\"\", Iterables.getOnlyElement(row.getDimension(\"bytes1\")));\nAssert.assertEquals(\"bye\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"1.23456786547457E7\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"struct_list_struct_int\")));\nAssert.assertEquals(ImmutableList.of(\"1\", \"2\"), row.getDimension(\"struct_list_struct_intlist\"));\nAssert.assertEquals(\"cat\", Iterables.getOnlyElement(row.getDimension(\"list_struct_string\")));\nAssert.assertEquals(\"5\", Iterables.getOnlyElement(row.getDimension(\"map_struct_int\")));\nAssert.assertEquals(DateTimes.of(\"2000-03-12T15:00:01.000Z\"), row.getTimestamp());\nAssert.assertEquals(7500, actualRowCount);\n}\n}","label":[0,0,0,0]}
{"id":2006,"original_code":"@Test\n  public void testOrcSplitElim() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"ts\", \"millis\", null),\n        new DimensionsSpec(null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/orc_split_elim.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(DateTimes.of(\"1969-12-31T16:00:00.0Z\"), row.getTimestamp());\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"userid\")));\n      Assert.assertEquals(\"foo\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"0.8\", Iterables.getOnlyElement(row.getDimension(\"subtype\")));\n      Assert.assertEquals(\"1.2\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(25000, actualRowCount);\n    }\n  }","code":"@Test\n  public void testOrcSplitElim() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"ts\", \"millis\", null),\n        new DimensionsSpec(null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/orc_split_elim.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(DateTimes.of(\"1969-12-31T16:00:00.0Z\"), row.getTimestamp());\n      Assert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"userid\")));\n      Assert.assertEquals(\"foo\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\n      Assert.assertEquals(\"0.8\", Iterables.getOnlyElement(row.getDimension(\"subtype\")));\n      Assert.assertEquals(\"1.2\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(25000, actualRowCount);\n    }\n  }","cleancode":"@test public void testorcsplitelim() throws ioexception { final inputentityreader reader = createreader( new timestampspec(\"ts\", \"millis\", null), new dimensionsspec(null), new orcinputformat(new jsonpathspec(true, null), null, new configuration()), \"example\/orc_split_elim.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { int actualrowcount = 0; assert.asserttrue(iterator.hasnext()); final inputrow row = iterator.next(); actualrowcount++; assert.assertequals(datetimes.of(\"1969-12-31t16:00:00.0z\"), row.gettimestamp()); assert.assertequals(\"2\", iterables.getonlyelement(row.getdimension(\"userid\"))); assert.assertequals(\"foo\", iterables.getonlyelement(row.getdimension(\"string1\"))); assert.assertequals(\"0.8\", iterables.getonlyelement(row.getdimension(\"subtype\"))); assert.assertequals(\"1.2\", iterables.getonlyelement(row.getdimension(\"decimal1\"))); while (iterator.hasnext()) { actualrowcount++; iterator.next(); } assert.assertequals(25000, actualrowcount); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testOrcSplitElim() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/orc_split_elim.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(DateTimes.of(\"1969-12-31T16:00:00.0Z\"), row.getTimestamp());\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"userid\")));\nAssert.assertEquals(\"foo\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"0.8\", Iterables.getOnlyElement(row.getDimension(\"subtype\")));\nAssert.assertEquals(\"1.2\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(25000, actualRowCount);\n}\n}","code_context_10":"@Test\npublic void testOrcSplitElim() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/orc_split_elim.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(DateTimes.of(\"1969-12-31T16:00:00.0Z\"), row.getTimestamp());\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"userid\")));\nAssert.assertEquals(\"foo\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"0.8\", Iterables.getOnlyElement(row.getDimension(\"subtype\")));\nAssert.assertEquals(\"1.2\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(25000, actualRowCount);\n}\n}","code_context_20":"@Test\npublic void testOrcSplitElim() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"ts\", \"millis\", null),\nnew DimensionsSpec(null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/orc_split_elim.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(DateTimes.of(\"1969-12-31T16:00:00.0Z\"), row.getTimestamp());\nAssert.assertEquals(\"2\", Iterables.getOnlyElement(row.getDimension(\"userid\")));\nAssert.assertEquals(\"foo\", Iterables.getOnlyElement(row.getDimension(\"string1\")));\nAssert.assertEquals(\"0.8\", Iterables.getOnlyElement(row.getDimension(\"subtype\")));\nAssert.assertEquals(\"1.2\", Iterables.getOnlyElement(row.getDimension(\"decimal1\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(25000, actualRowCount);\n}\n}","label":[0,0,0,0]}
{"id":2007,"original_code":"@Test\n  public void testDate1900() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"time\", \"millis\", null),\n        new DimensionsSpec(null, Collections.singletonList(\"time\"), null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/TestOrcFile.testDate1900.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(1, row.getDimensions().size());\n      Assert.assertEquals(DateTimes.of(\"1900-05-05T12:34:56.1Z\"), row.getTimestamp());\n      Assert.assertEquals(\"1900-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(70000, actualRowCount);\n    }\n  }","code":"@Test\n  public void testDate1900() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"time\", \"millis\", null),\n        new DimensionsSpec(null, Collections.singletonList(\"time\"), null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/TestOrcFile.testDate1900.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(1, row.getDimensions().size());\n      Assert.assertEquals(DateTimes.of(\"1900-05-05T12:34:56.1Z\"), row.getTimestamp());\n      Assert.assertEquals(\"1900-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(70000, actualRowCount);\n    }\n  }","cleancode":"@test public void testdate1900() throws ioexception { final inputentityreader reader = createreader( new timestampspec(\"time\", \"millis\", null), new dimensionsspec(null, collections.singletonlist(\"time\"), null), new orcinputformat(new jsonpathspec(true, null), null, new configuration()), \"example\/testorcfile.testdate1900.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { int actualrowcount = 0; assert.asserttrue(iterator.hasnext()); final inputrow row = iterator.next(); actualrowcount++; assert.assertequals(1, row.getdimensions().size()); assert.assertequals(datetimes.of(\"1900-05-05t12:34:56.1z\"), row.gettimestamp()); assert.assertequals(\"1900-12-25t00:00:00.000z\", iterables.getonlyelement(row.getdimension(\"date\"))); while (iterator.hasnext()) { actualrowcount++; iterator.next(); } assert.assertequals(70000, actualrowcount); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testDate1900() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate1900.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"1900-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"1900-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(70000, actualRowCount);\n}\n}","code_context_10":"@Test\npublic void testDate1900() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate1900.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"1900-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"1900-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(70000, actualRowCount);\n}\n}","code_context_20":"@Test\npublic void testDate1900() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate1900.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"1900-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"1900-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(70000, actualRowCount);\n}\n}","label":[0,0,0,0]}
{"id":2008,"original_code":"@Test\n  public void testDate2038() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"time\", \"millis\", null),\n        new DimensionsSpec(null, Collections.singletonList(\"time\"), null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/TestOrcFile.testDate2038.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(1, row.getDimensions().size());\n      Assert.assertEquals(DateTimes.of(\"2038-05-05T12:34:56.1Z\"), row.getTimestamp());\n      Assert.assertEquals(\"2038-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(212000, actualRowCount);\n    }\n  }","code":"@Test\n  public void testDate2038() throws IOException\n  {\n    final InputEntityReader reader = createReader(\n        new TimestampSpec(\"time\", \"millis\", null),\n        new DimensionsSpec(null, Collections.singletonList(\"time\"), null),\n        new OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n        \"example\/TestOrcFile.testDate2038.orc\"\n    );\n    try (CloseableIterator<InputRow> iterator = reader.read()) {\n      int actualRowCount = 0;\n      Assert.assertTrue(iterator.hasNext());\n      final InputRow row = iterator.next();\n      actualRowCount++;\n      Assert.assertEquals(1, row.getDimensions().size());\n      Assert.assertEquals(DateTimes.of(\"2038-05-05T12:34:56.1Z\"), row.getTimestamp());\n      Assert.assertEquals(\"2038-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\n      while (iterator.hasNext()) {\n        actualRowCount++;\n        iterator.next();\n      }\n      Assert.assertEquals(212000, actualRowCount);\n    }\n  }","cleancode":"@test public void testdate2038() throws ioexception { final inputentityreader reader = createreader( new timestampspec(\"time\", \"millis\", null), new dimensionsspec(null, collections.singletonlist(\"time\"), null), new orcinputformat(new jsonpathspec(true, null), null, new configuration()), \"example\/testorcfile.testdate2038.orc\" ); try (closeableiterator<inputrow> iterator = reader.read()) { int actualrowcount = 0; assert.asserttrue(iterator.hasnext()); final inputrow row = iterator.next(); actualrowcount++; assert.assertequals(1, row.getdimensions().size()); assert.assertequals(datetimes.of(\"2038-05-05t12:34:56.1z\"), row.gettimestamp()); assert.assertequals(\"2038-12-25t00:00:00.000z\", iterables.getonlyelement(row.getdimension(\"date\"))); while (iterator.hasnext()) { actualrowcount++; iterator.next(); } assert.assertequals(212000, actualrowcount); } }","comment":"\/\/ this test is migrated from orchadoopinputrowparsertest","repo":"weishiuntsai\/druid","code_context_2":"@Test\npublic void testDate2038() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate2038.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"2038-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"2038-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(212000, actualRowCount);\n}\n}","code_context_10":"@Test\npublic void testDate2038() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate2038.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"2038-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"2038-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(212000, actualRowCount);\n}\n}","code_context_20":"@Test\npublic void testDate2038() throws IOException\n{\nfinal InputEntityReader reader = createReader(\nnew TimestampSpec(\"time\", \"millis\", null),\nnew DimensionsSpec(null, Collections.singletonList(\"time\"), null),\nnew OrcInputFormat(new JSONPathSpec(true, null), null, new Configuration()),\n\"example\/TestOrcFile.testDate2038.orc\"\n);\ntry (CloseableIterator<InputRow> iterator = reader.read()) {\nint actualRowCount = 0;\nAssert.assertTrue(iterator.hasNext());\nfinal InputRow row = iterator.next();\nactualRowCount++;\nAssert.assertEquals(1, row.getDimensions().size());\nAssert.assertEquals(DateTimes.of(\"2038-05-05T12:34:56.1Z\"), row.getTimestamp());\nAssert.assertEquals(\"2038-12-25T00:00:00.000Z\", Iterables.getOnlyElement(row.getDimension(\"date\")));\nwhile (iterator.hasNext()) {\nactualRowCount++;\niterator.next();\n}\nAssert.assertEquals(212000, actualRowCount);\n}\n}","label":[0,0,0,0]}
{"id":34800,"original_code":"public HttpResponse doAct(@QueryParameter String no) throws IOException {\n        if(no!=null) { \/\/ dismiss\n            disable(true);\n            \/\/ of course the irony is that this redirect won't work\n            return HttpResponses.redirectViaContextPath(\"\/manage\");\n        } else {\n            return new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n        }\n    }","code":"public HttpResponse doAct(@QueryParameter String no) throws IOException {\n        if(no!=null) {\n            disable(true);\n           \n            return HttpResponses.redirectViaContextPath(\"\/manage\");\n        } else {\n            return new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n        }\n    }","cleancode":"public httpresponse doact(@queryparameter string no) throws ioexception { if(no!=null) { disable(true); return httpresponses.redirectviacontextpath(\"\/manage\"); } else { return new httpredirect(\"https:\/\/wiki.jenkins-ci.org\/display\/jenkins\/jenkins+says+my+reverse+proxy+setup+is+broken\"); } }","comment":"\/** * depending on whether the user said \"yes\" or \"no\", send him to the right place. *\/\n\/\/ dismiss\n\/\/ of course the irony is that this redirect won't work","repo":"wasimdocker\/hudson","code_context_2":"public HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}\n\npublic HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\n\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {","code_context_10":"public HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}\n\npublic HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}\n\npublic HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}","code_context_20":"public HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}\n\npublic HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}\n\npublic HttpResponse doAct(@QueryParameter String no) throws IOException {\nif(no!=null) { \/\/ dismiss\ndisable(true);\n\/\/ of course the irony is that this redirect won't work\nreturn HttpResponses.redirectViaContextPath(\"\/manage\");\n} else {\nreturn new HttpRedirect(\"https:\/\/wiki.jenkins-ci.org\/display\/JENKINS\/Jenkins+says+my+reverse+proxy+setup+is+broken\");\n}\n}","label":[0,0,1,0]}
{"id":18435,"original_code":"private void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n        \/\/ TODO add your handling code here:\n\/\/        JOptionPane.showMessageDialog(null,evt.paramString());\n        if (isBtigual() ){\n            setBtigual(false);\n            textResult.setText(\"\");\n            this.vtmp=0;\n            textResult.setText(textResult.getText() + evt.getActionCommand());\n            textResult.requestFocusInWindow(); \/\/posicionar cursor\n        }else{\n            textResult.setText(textResult.getText() + evt.getActionCommand());\n            textResult.requestFocusInWindow(); \/\/posicionar cursor\n        }\n    }","code":"private void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {       \n        if (isBtigual() ){\n            setBtigual(false);\n            textResult.setText(\"\");\n            this.vtmp=0;\n            textResult.setText(textResult.getText() + evt.getActionCommand());\n            textResult.requestFocusInWindow();\n        }else{\n            textResult.setText(textResult.getText() + evt.getActionCommand());\n            textResult.requestFocusInWindow();\n        }\n    }","cleancode":"private void bnt0actionperformed(java.awt.event.actionevent evt) { if (isbtigual() ){ setbtigual(false); textresult.settext(\"\"); this.vtmp=0; textresult.settext(textresult.gettext() + evt.getactioncommand()); textresult.requestfocusinwindow(); }else{ textresult.settext(textresult.gettext() + evt.getactioncommand()); textresult.requestfocusinwindow(); } }","comment":"\/\/gen-first:event_bnt0actionperformed\n\/\/ todo add your handling code here: \/\/ joptionpane.showmessagedialog(null,evt.paramstring());\n\/\/posicionar cursor\n\/\/posicionar cursor","repo":"vinte2\/Calc","code_context_2":"private void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\n\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\n\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());","code_context_10":"private void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}","code_context_20":"private void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}\n\nprivate void bnt0ActionPerformed(java.awt.event.ActionEvent evt) {\/\/GEN-FIRST:event_bnt0ActionPerformed\n\/\/ TODO add your handling code here:\n\/\/ JOptionPane.showMessageDialog(null,evt.paramString());\nif (isBtigual() ){\nsetBtigual(false);\ntextResult.setText(\"\");\nthis.vtmp=0;\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}else{\ntextResult.setText(textResult.getText() + evt.getActionCommand());\ntextResult.requestFocusInWindow(); \/\/posicionar cursor\n}\n}","label":[0,1,0,0]}
{"id":18533,"original_code":"private void showClearIcon(boolean show) {\n        \/\/ TODO: should probably use setVisibility method, but seems to not working.\n        if (clearDrawable != null) {\n            clearDrawable.setAlpha(show ? 255 : 0);\n        }\n    }","code":"private void showClearIcon(boolean show) {\n       \n        if (clearDrawable != null) {\n            clearDrawable.setAlpha(show ? 255 : 0);\n        }\n    }","cleancode":"private void showclearicon(boolean show) { if (cleardrawable != null) { cleardrawable.setalpha(show ? 255 : 0); } }","comment":"\/** * displays clear icon in clearableedittext. * * @param show pass true to display icon, otherwise false to hide. *\/\n\/\/ todo: should probably use setvisibility method, but seems to not working.","repo":"wellplayedstudios\/twilio-video-app-android","code_context_2":"private void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);\n}\n}\n\nprivate void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);","code_context_10":"private void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);\n}\n}\n\nprivate void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);\n}\n}","code_context_20":"private void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);\n}\n}\n\nprivate void showClearIcon(boolean show) {\n\/\/ TODO: should probably use setVisibility method, but seems to not working.\nif (clearDrawable != null) {\nclearDrawable.setAlpha(show ? 255 : 0);\n}\n}","label":[1,0,0,0]}
{"id":18549,"original_code":"private Map<String, Object> validateJwt(String token, JWTPolicyBean config)\n            throws ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n        \/\/ check if we have to use jwk(s)\n        if (urlValidator.isValid(config.getSigningKeyString())){\n            if (provider == null){\n                provider = getNewJwksProvider(config.getSigningKeyString());\n            }\n            Jwk jwk;\n            try {\n                jwk = provider.get(config.getKid());\n                if (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\n                    config.setSigningKey(jwk.getPublicKey());\n                }\n            } catch (JwkException e) {\n               throw new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n            }\n        }\n        JwtParser parser = Jwts.parser()\n                .setSigningKey(config.getSigningKey())\n                .setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n        \/\/ Set all claims\n        config.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n            .forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\n        return parser.parse(token, new ConfigCheckingJwtHandler(config));\n    }","code":"private Map<String, Object> validateJwt(String token, JWTPolicyBean config)\n            throws ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n       \n        if (urlValidator.isValid(config.getSigningKeyString())){\n            if (provider == null){\n                provider = getNewJwksProvider(config.getSigningKeyString());\n            }\n            Jwk jwk;\n            try {\n                jwk = provider.get(config.getKid());\n                if (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\n                    config.setSigningKey(jwk.getPublicKey());\n                }\n            } catch (JwkException e) {\n               throw new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n            }\n        }\n        JwtParser parser = Jwts.parser()\n                .setSigningKey(config.getSigningKey())\n                .setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n       \n        config.getRequiredClaims().stream()\n            .forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\n        return parser.parse(token, new ConfigCheckingJwtHandler(config));\n    }","cleancode":"private map<string, object> validatejwt(string token, jwtpolicybean config) throws expiredjwtexception, prematurejwtexception, malformedjwtexception, signatureexception, invalidclaimexception { if (urlvalidator.isvalid(config.getsigningkeystring())){ if (provider == null){ provider = getnewjwksprovider(config.getsigningkeystring()); } jwk jwk; try { jwk = provider.get(config.getkid()); if (config.getsigningkey() == null || !(config.getsigningkey().equals(jwk.getpublickey()))) { config.setsigningkey(jwk.getpublickey()); } } catch (jwkexception e) { throw new signatureexception(\"jwk was not found with kid: \" + config.getkid(), e); } } jwtparser parser = jwts.parser() .setsigningkey(config.getsigningkey()) .setallowedclockskewseconds(config.getallowedclockskew()); config.getrequiredclaims().stream() .foreach(requiredclaim -> parser.require(requiredclaim.getclaimname(), requiredclaim.getclaimvalue())); return parser.parse(token, new configcheckingjwthandler(config)); }","comment":"\/\/ check if we have to use jwk(s)\n\/\/ set all claims\n\/\/ todo add type variable to allow dates, etc","repo":"tevosouza\/apiman-plugins","code_context_2":"private Map<String, Object> validateJwt(String token, JWTPolicyBean config)\nthrows ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n\/\/ check if we have to use jwk(s)\nif (urlValidator.isValid(config.getSigningKeyString())){\nif (provider == null){\n\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\n\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\nreturn parser.parse(token, new ConfigCheckingJwtHandler(config));","code_context_10":"private Map<String, Object> validateJwt(String token, JWTPolicyBean config)\nthrows ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n\/\/ check if we have to use jwk(s)\nif (urlValidator.isValid(config.getSigningKeyString())){\nif (provider == null){\nprovider = getNewJwksProvider(config.getSigningKeyString());\n}\nJwk jwk;\ntry {\njwk = provider.get(config.getKid());\nif (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\nconfig.setSigningKey(jwk.getPublicKey());\n}\n\nif (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\nconfig.setSigningKey(jwk.getPublicKey());\n}\n} catch (JwkException e) {\nthrow new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n}\n}\nJwtParser parser = Jwts.parser()\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\nreturn parser.parse(token, new ConfigCheckingJwtHandler(config));\n}\n\nconfig.setSigningKey(jwk.getPublicKey());\n}\n} catch (JwkException e) {\nthrow new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n}\n}\nJwtParser parser = Jwts.parser()\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\nreturn parser.parse(token, new ConfigCheckingJwtHandler(config));\n}","code_context_20":"private Map<String, Object> validateJwt(String token, JWTPolicyBean config)\nthrows ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n\/\/ check if we have to use jwk(s)\nif (urlValidator.isValid(config.getSigningKeyString())){\nif (provider == null){\nprovider = getNewJwksProvider(config.getSigningKeyString());\n}\nJwk jwk;\ntry {\njwk = provider.get(config.getKid());\nif (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\nconfig.setSigningKey(jwk.getPublicKey());\n}\n} catch (JwkException e) {\nthrow new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n}\n}\nJwtParser parser = Jwts.parser()\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\n\nprivate Map<String, Object> validateJwt(String token, JWTPolicyBean config)\nthrows ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n\/\/ check if we have to use jwk(s)\nif (urlValidator.isValid(config.getSigningKeyString())){\nif (provider == null){\nprovider = getNewJwksProvider(config.getSigningKeyString());\n}\nJwk jwk;\ntry {\njwk = provider.get(config.getKid());\nif (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\nconfig.setSigningKey(jwk.getPublicKey());\n}\n} catch (JwkException e) {\nthrow new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n}\n}\nJwtParser parser = Jwts.parser()\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\nreturn parser.parse(token, new ConfigCheckingJwtHandler(config));\n}\n\nthrows ExpiredJwtException, PrematureJwtException, MalformedJwtException, SignatureException, InvalidClaimException {\n\/\/ check if we have to use jwk(s)\nif (urlValidator.isValid(config.getSigningKeyString())){\nif (provider == null){\nprovider = getNewJwksProvider(config.getSigningKeyString());\n}\nJwk jwk;\ntry {\njwk = provider.get(config.getKid());\nif (config.getSigningKey() == null || !(config.getSigningKey().equals(jwk.getPublicKey()))) {\nconfig.setSigningKey(jwk.getPublicKey());\n}\n} catch (JwkException e) {\nthrow new SignatureException(\"JWK was not found with kid: \" + config.getKid(), e);\n}\n}\nJwtParser parser = Jwts.parser()\n.setSigningKey(config.getSigningKey())\n.setAllowedClockSkewSeconds(config.getAllowedClockSkew());\n\/\/ Set all claims\nconfig.getRequiredClaims().stream() \/\/ TODO add type variable to allow dates, etc\n.forEach(requiredClaim -> parser.require(requiredClaim.getClaimName(), requiredClaim.getClaimValue()));\nreturn parser.parse(token, new ConfigCheckingJwtHandler(config));\n}","label":[0,1,0,0]}
{"id":18600,"original_code":"public PrismObject<ShadowType> getResourceObject(ProvisioningContext ctx, \n\t\t\tCollection<? extends ResourceAttribute<?>> identifiers, boolean fetchAssociations, OperationResult parentResult)\n\t\t\t\t\tthrows ObjectNotFoundException, CommunicationException, SchemaException, ConfigurationException,\n\t\t\t\t\tSecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\n\t\tLOGGER.trace(\"Getting resource object {}\", identifiers);\n\t\tAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\tPrismObject<ShadowType> resourceShadow = fetchResourceObject(ctx, identifiers, \n\t\t\t\tattributesToReturn, fetchAssociations, parentResult);\t\t\t\/\/ todo consider whether it is always necessary to fetch the entitlements\n\t\tLOGGER.trace(\"Got resource object\\n{}\", resourceShadow.debugDumpLazily());\n\t\treturn resourceShadow;\n\t}","code":"public PrismObject<ShadowType> getResourceObject(ProvisioningContext ctx, \n\t\t\tCollection<? extends ResourceAttribute<?>> identifiers, boolean fetchAssociations, OperationResult parentResult)\n\t\t\t\t\tthrows ObjectNotFoundException, CommunicationException, SchemaException, ConfigurationException,\n\t\t\t\t\tSecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\n\t\tLOGGER.trace(\"Getting resource object {}\", identifiers);\n\t\tAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\tPrismObject<ShadowType> resourceShadow = fetchResourceObject(ctx, identifiers, \n\t\t\t\tattributesToReturn, fetchAssociations, parentResult);\t\t\n\t\tLOGGER.trace(\"Got resource object\\n{}\", resourceShadow.debugDumpLazily());\n\t\treturn resourceShadow;\n\t}","cleancode":"public prismobject<shadowtype> getresourceobject(provisioningcontext ctx, collection<? extends resourceattribute<?>> identifiers, boolean fetchassociations, operationresult parentresult) throws objectnotfoundexception, communicationexception, schemaexception, configurationexception, securityviolationexception, genericconnectorexception, expressionevaluationexception { logger.trace(\"getting resource object {}\", identifiers); attributestoreturn attributestoreturn = provisioningutil.createattributestoreturn(ctx); prismobject<shadowtype> resourceshadow = fetchresourceobject(ctx, identifiers, attributestoreturn, fetchassociations, parentresult); logger.trace(\"got resource object\\n{}\", resourceshadow.debugdumplazily()); return resourceshadow; }","comment":"\/\/ todo consider whether it is always necessary to fetch the entitlements","repo":"valtri\/midpoint","code_context_2":"AttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nPrismObject<ShadowType> resourceShadow = fetchResourceObject(ctx, identifiers,\nattributesToReturn, fetchAssociations, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nLOGGER.trace(\"Got resource object\\n{}\", resourceShadow.debugDumpLazily());\nreturn resourceShadow;","code_context_10":"public PrismObject<ShadowType> getResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, boolean fetchAssociations, OperationResult parentResult)\nthrows ObjectNotFoundException, CommunicationException, SchemaException, ConfigurationException,\nSecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Getting resource object {}\", identifiers);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nPrismObject<ShadowType> resourceShadow = fetchResourceObject(ctx, identifiers,\nattributesToReturn, fetchAssociations, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nLOGGER.trace(\"Got resource object\\n{}\", resourceShadow.debugDumpLazily());\nreturn resourceShadow;\n}","code_context_20":"public PrismObject<ShadowType> getResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, boolean fetchAssociations, OperationResult parentResult)\nthrows ObjectNotFoundException, CommunicationException, SchemaException, ConfigurationException,\nSecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Getting resource object {}\", identifiers);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nPrismObject<ShadowType> resourceShadow = fetchResourceObject(ctx, identifiers,\nattributesToReturn, fetchAssociations, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nLOGGER.trace(\"Got resource object\\n{}\", resourceShadow.debugDumpLazily());\nreturn resourceShadow;\n}","label":[1,0,0,0]}
{"id":18601,"original_code":"public PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\n\t\t\tCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\n\t\t\tCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\n\t\tLOGGER.trace(\"Locating resource object {}\", identifiers);\n\t\tConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\n\t\tAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\tif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\n\t\t\treturn fetchResourceObject(ctx, identifiers, \n\t\t\t\t\tattributesToReturn, true, parentResult);\t\/\/ todo consider whether it is always necessary to fetch the entitlements\n\t\t} else {\n\t\t\t\/\/ Search\n\t\t\tCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\t\t\t\/\/ Assume single secondary identifier for simplicity\n\t\t\tif (secondaryIdentifierDefs.size() > 1) {\n\t\t\t\tthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n\t\t\t} else if (secondaryIdentifierDefs.isEmpty()) {\n\t\t\t\tthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n\t\t\t}\n\t\t\tRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\n\t\t\tResourceAttribute<?> secondaryIdentifier = null;\n\t\t\tfor (ResourceAttribute<?> identifier: identifiers) {\n\t\t\t\tif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\n\t\t\t\t\tsecondaryIdentifier = identifier;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (secondaryIdentifier == null) {\n\t\t\t\tthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n\t\t\t}\n\t\t\tfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\n            List<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\n            PrismPropertyValue<String> secondaryIdentifierValue;\n            if (secondaryIdentifierValues.size() > 1) {\n                throw new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());\n            } else if (secondaryIdentifierValues.size() == 1) {\n                secondaryIdentifierValue = secondaryIdentifierValues.get(0).clone();\n            } else {\n                secondaryIdentifierValue = null;\n            }\n            ObjectQuery query = prismContext.queryFor(ShadowType.class)\n\t\t\t\t\t.itemWithDef(secondaryIdentifierDef, ShadowType.F_ATTRIBUTES, secondaryIdentifierDef.getName()).eq(secondaryIdentifierValue)\n\t\t\t\t\t.build();\n\t\t\tfinal Holder<PrismObject<ShadowType>> shadowHolder = new Holder<>();\n\t\t\tShadowResultHandler handler = new ShadowResultHandler() {\n\t\t\t\t@Override\n\t\t\t\tpublic boolean handle(PrismObject<ShadowType> shadow) {\n\t\t\t\t\tif (!shadowHolder.isEmpty()) {\n\t\t\t\t\t\tthrow new IllegalStateException(\"More than one value found for secondary identifier \"+finalSecondaryIdentifier);\n\t\t\t\t\t}\n\t\t\t\t\tshadowHolder.setValue(shadow);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t};\n\t\t\ttry {\n\t\t\t\tconnector.search(ctx.getObjectClassDefinition(), query, handler, attributesToReturn, null, null, ctx, parentResult);\n\t\t\t\tif (shadowHolder.isEmpty()) {\n\t\t\t\t\tthrow new ObjectNotFoundException(\"No object found for secondary identifier \"+secondaryIdentifier);\n\t\t\t\t}\n\t\t\t\tPrismObject<ShadowType> shadow = shadowHolder.getValue();\n\t\t\t\tPrismObject<ShadowType> finalShadow = postProcessResourceObjectRead(ctx, shadow, true, parentResult);\n\t\t\t\tLOGGER.trace(\"Located resource object {}\", finalShadow);\n\t\t\t\treturn finalShadow;\n\t\t\t} catch (GenericFrameworkException e) {\n\t\t\t\tthrow new GenericConnectorException(e.getMessage(), e);\n\t\t\t}\n\t\t}\n\t}","code":"public PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\n\t\t\tCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\n\t\t\tCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\n\t\tLOGGER.trace(\"Locating resource object {}\", identifiers);\n\t\tConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\n\t\tAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\tif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\n\t\t\treturn fetchResourceObject(ctx, identifiers, \n\t\t\t\t\tattributesToReturn, true, parentResult);\n\t\t} else {\n\t\t\n\t\t\tCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\t\t\n\t\t\tif (secondaryIdentifierDefs.size() > 1) {\n\t\t\t\tthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n\t\t\t} else if (secondaryIdentifierDefs.isEmpty()) {\n\t\t\t\tthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n\t\t\t}\n\t\t\tRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\n\t\t\tResourceAttribute<?> secondaryIdentifier = null;\n\t\t\tfor (ResourceAttribute<?> identifier: identifiers) {\n\t\t\t\tif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\n\t\t\t\t\tsecondaryIdentifier = identifier;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (secondaryIdentifier == null) {\n\t\t\t\tthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n\t\t\t}\n\t\t\tfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\n            List<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\n            PrismPropertyValue<String> secondaryIdentifierValue;\n            if (secondaryIdentifierValues.size() > 1) {\n                throw new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());\n            } else if (secondaryIdentifierValues.size() == 1) {\n                secondaryIdentifierValue = secondaryIdentifierValues.get(0).clone();\n            } else {\n                secondaryIdentifierValue = null;\n            }\n            ObjectQuery query = prismContext.queryFor(ShadowType.class)\n\t\t\t\t\t.itemWithDef(secondaryIdentifierDef, ShadowType.F_ATTRIBUTES, secondaryIdentifierDef.getName()).eq(secondaryIdentifierValue)\n\t\t\t\t\t.build();\n\t\t\tfinal Holder<PrismObject<ShadowType>> shadowHolder = new Holder<>();\n\t\t\tShadowResultHandler handler = new ShadowResultHandler() {\n\t\t\t\t@Override\n\t\t\t\tpublic boolean handle(PrismObject<ShadowType> shadow) {\n\t\t\t\t\tif (!shadowHolder.isEmpty()) {\n\t\t\t\t\t\tthrow new IllegalStateException(\"More than one value found for secondary identifier \"+finalSecondaryIdentifier);\n\t\t\t\t\t}\n\t\t\t\t\tshadowHolder.setValue(shadow);\n\t\t\t\t\treturn true;\n\t\t\t\t}\n\t\t\t};\n\t\t\ttry {\n\t\t\t\tconnector.search(ctx.getObjectClassDefinition(), query, handler, attributesToReturn, null, null, ctx, parentResult);\n\t\t\t\tif (shadowHolder.isEmpty()) {\n\t\t\t\t\tthrow new ObjectNotFoundException(\"No object found for secondary identifier \"+secondaryIdentifier);\n\t\t\t\t}\n\t\t\t\tPrismObject<ShadowType> shadow = shadowHolder.getValue();\n\t\t\t\tPrismObject<ShadowType> finalShadow = postProcessResourceObjectRead(ctx, shadow, true, parentResult);\n\t\t\t\tLOGGER.trace(\"Located resource object {}\", finalShadow);\n\t\t\t\treturn finalShadow;\n\t\t\t} catch (GenericFrameworkException e) {\n\t\t\t\tthrow new GenericConnectorException(e.getMessage(), e);\n\t\t\t}\n\t\t}\n\t}","cleancode":"public prismobject<shadowtype> locateresourceobject(provisioningcontext ctx, collection<? extends resourceattribute<?>> identifiers, operationresult parentresult) throws objectnotfoundexception, communicationexception, schemaexception, configurationexception, securityviolationexception, genericconnectorexception, expressionevaluationexception { logger.trace(\"locating resource object {}\", identifiers); connectorinstance connector = ctx.getconnector(readcapabilitytype.class, parentresult); attributestoreturn attributestoreturn = provisioningutil.createattributestoreturn(ctx); if (hasallidentifiers(identifiers, ctx.getobjectclassdefinition())) { return fetchresourceobject(ctx, identifiers, attributestoreturn, true, parentresult); } else { collection<? extends refinedattributedefinition> secondaryidentifierdefs = ctx.getobjectclassdefinition().getsecondaryidentifiers(); if (secondaryidentifierdefs.size() > 1) { throw new unsupportedoperationexception(\"composite secondary identifier is not supported yet\"); } else if (secondaryidentifierdefs.isempty()) { throw new schemaexception(\"no secondary identifier defined, cannot search\"); } refinedattributedefinition<string> secondaryidentifierdef = secondaryidentifierdefs.iterator().next(); resourceattribute<?> secondaryidentifier = null; for (resourceattribute<?> identifier: identifiers) { if (identifier.getelementname().equals(secondaryidentifierdef.getname())) { secondaryidentifier = identifier; } } if (secondaryidentifier == null) { throw new schemaexception(\"no secondary identifier present, cannot search. identifiers: \"+identifiers); } final resourceattribute<?> finalsecondaryidentifier = secondaryidentifier; list<prismpropertyvalue<string>> secondaryidentifiervalues = (list) secondaryidentifier.getvalues(); prismpropertyvalue<string> secondaryidentifiervalue; if (secondaryidentifiervalues.size() > 1) { throw new illegalstateexception(\"secondary identifier has more than one value: \" + secondaryidentifier.getvalues()); } else if (secondaryidentifiervalues.size() == 1) { secondaryidentifiervalue = secondaryidentifiervalues.get(0).clone(); } else { secondaryidentifiervalue = null; } objectquery query = prismcontext.queryfor(shadowtype.class) .itemwithdef(secondaryidentifierdef, shadowtype.f_attributes, secondaryidentifierdef.getname()).eq(secondaryidentifiervalue) .build(); final holder<prismobject<shadowtype>> shadowholder = new holder<>(); shadowresulthandler handler = new shadowresulthandler() { @override public boolean handle(prismobject<shadowtype> shadow) { if (!shadowholder.isempty()) { throw new illegalstateexception(\"more than one value found for secondary identifier \"+finalsecondaryidentifier); } shadowholder.setvalue(shadow); return true; } }; try { connector.search(ctx.getobjectclassdefinition(), query, handler, attributestoreturn, null, null, ctx, parentresult); if (shadowholder.isempty()) { throw new objectnotfoundexception(\"no object found for secondary identifier \"+secondaryidentifier); } prismobject<shadowtype> shadow = shadowholder.getvalue(); prismobject<shadowtype> finalshadow = postprocessresourceobjectread(ctx, shadow, true, parentresult); logger.trace(\"located resource object {}\", finalshadow); return finalshadow; } catch (genericframeworkexception e) { throw new genericconnectorexception(e.getmessage(), e); } } }","comment":"\/** * tries to get the object directly if primary identifiers are present. tries to search for the object if they are not. *\/\n\/\/ todo consider whether it is always necessary to fetch the entitlements\n\/\/ search\n\/\/ assume single secondary identifier for simplicity","repo":"valtri\/midpoint","code_context_2":"public PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\nList<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\nPrismPropertyValue<String> secondaryIdentifierValue;\nif (secondaryIdentifierValues.size() > 1) {\nthrow new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());\n} else if (secondaryIdentifierValues.size() == 1) {\nsecondaryIdentifierValue = secondaryIdentifierValues.get(0).clone();\n} else {\nsecondaryIdentifierValue = null;\n}\nObjectQuery query = prismContext.queryFor(ShadowType.class)\n.itemWithDef(secondaryIdentifierDef, ShadowType.F_ATTRIBUTES, secondaryIdentifierDef.getName()).eq(secondaryIdentifierValue)\n.build();\nfinal Holder<PrismObject<ShadowType>> shadowHolder = new Holder<>();\nShadowResultHandler handler = new ShadowResultHandler() {\n@Override\npublic boolean handle(PrismObject<ShadowType> shadow) {\nif (!shadowHolder.isEmpty()) {\nthrow new IllegalStateException(\"More than one value found for secondary identifier \"+finalSecondaryIdentifier);\n}\nshadowHolder.setValue(shadow);\nreturn true;\n}\n};\ntry {\nconnector.search(ctx.getObjectClassDefinition(), query, handler, attributesToReturn, null, null, ctx, parentResult);\nif (shadowHolder.isEmpty()) {\nthrow new ObjectNotFoundException(\"No object found for secondary identifier \"+secondaryIdentifier);\n}\nPrismObject<ShadowType> shadow = shadowHolder.getValue();\nPrismObject<ShadowType> finalShadow = postProcessResourceObjectRead(ctx, shadow, true, parentResult);\nLOGGER.trace(\"Located resource object {}\", finalShadow);\nreturn finalShadow;\n} catch (GenericFrameworkException e) {\nthrow new GenericConnectorException(e.getMessage(), e);\n}\n}\n}\n\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\n\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\n\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");","code_context_10":"public PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\nList<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\nPrismPropertyValue<String> secondaryIdentifierValue;\nif (secondaryIdentifierValues.size() > 1) {\nthrow new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());\n} else if (secondaryIdentifierValues.size() == 1) {\nsecondaryIdentifierValue = secondaryIdentifierValues.get(0).clone();\n} else {\nsecondaryIdentifierValue = null;\n}\nObjectQuery query = prismContext.queryFor(ShadowType.class)\n.itemWithDef(secondaryIdentifierDef, ShadowType.F_ATTRIBUTES, secondaryIdentifierDef.getName()).eq(secondaryIdentifierValue)\n.build();\nfinal Holder<PrismObject<ShadowType>> shadowHolder = new Holder<>();\nShadowResultHandler handler = new ShadowResultHandler() {\n@Override\npublic boolean handle(PrismObject<ShadowType> shadow) {\nif (!shadowHolder.isEmpty()) {\nthrow new IllegalStateException(\"More than one value found for secondary identifier \"+finalSecondaryIdentifier);\n}\nshadowHolder.setValue(shadow);\nreturn true;\n}\n};\ntry {\nconnector.search(ctx.getObjectClassDefinition(), query, handler, attributesToReturn, null, null, ctx, parentResult);\nif (shadowHolder.isEmpty()) {\nthrow new ObjectNotFoundException(\"No object found for secondary identifier \"+secondaryIdentifier);\n}\nPrismObject<ShadowType> shadow = shadowHolder.getValue();\nPrismObject<ShadowType> finalShadow = postProcessResourceObjectRead(ctx, shadow, true, parentResult);\nLOGGER.trace(\"Located resource object {}\", finalShadow);\nreturn finalShadow;\n} catch (GenericFrameworkException e) {\nthrow new GenericConnectorException(e.getMessage(), e);\n}\n}\n}\n\npublic PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\n\npublic PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\n\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;","code_context_20":"public PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\nList<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\nPrismPropertyValue<String> secondaryIdentifierValue;\nif (secondaryIdentifierValues.size() > 1) {\nthrow new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());\n} else if (secondaryIdentifierValues.size() == 1) {\nsecondaryIdentifierValue = secondaryIdentifierValues.get(0).clone();\n} else {\nsecondaryIdentifierValue = null;\n}\nObjectQuery query = prismContext.queryFor(ShadowType.class)\n.itemWithDef(secondaryIdentifierDef, ShadowType.F_ATTRIBUTES, secondaryIdentifierDef.getName()).eq(secondaryIdentifierValue)\n.build();\nfinal Holder<PrismObject<ShadowType>> shadowHolder = new Holder<>();\nShadowResultHandler handler = new ShadowResultHandler() {\n@Override\npublic boolean handle(PrismObject<ShadowType> shadow) {\nif (!shadowHolder.isEmpty()) {\nthrow new IllegalStateException(\"More than one value found for secondary identifier \"+finalSecondaryIdentifier);\n}\nshadowHolder.setValue(shadow);\nreturn true;\n}\n};\ntry {\nconnector.search(ctx.getObjectClassDefinition(), query, handler, attributesToReturn, null, null, ctx, parentResult);\nif (shadowHolder.isEmpty()) {\nthrow new ObjectNotFoundException(\"No object found for secondary identifier \"+secondaryIdentifier);\n}\nPrismObject<ShadowType> shadow = shadowHolder.getValue();\nPrismObject<ShadowType> finalShadow = postProcessResourceObjectRead(ctx, shadow, true, parentResult);\nLOGGER.trace(\"Located resource object {}\", finalShadow);\nreturn finalShadow;\n} catch (GenericFrameworkException e) {\nthrow new GenericConnectorException(e.getMessage(), e);\n}\n}\n}\n\npublic PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\n\npublic PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\nList<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\nPrismPropertyValue<String> secondaryIdentifierValue;\n\npublic PrismObject<ShadowType> locateResourceObject(ProvisioningContext ctx,\nCollection<? extends ResourceAttribute<?>> identifiers, OperationResult parentResult) throws ObjectNotFoundException,\nCommunicationException, SchemaException, ConfigurationException, SecurityViolationException, GenericConnectorException, ExpressionEvaluationException {\nLOGGER.trace(\"Locating resource object {}\", identifiers);\nConnectorInstance connector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nAttributesToReturn attributesToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\nif (hasAllIdentifiers(identifiers, ctx.getObjectClassDefinition())) {\nreturn fetchResourceObject(ctx, identifiers,\nattributesToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\n} else {\n\/\/ Search\nCollection<? extends RefinedAttributeDefinition> secondaryIdentifierDefs = ctx.getObjectClassDefinition().getSecondaryIdentifiers();\n\/\/ Assume single secondary identifier for simplicity\nif (secondaryIdentifierDefs.size() > 1) {\nthrow new UnsupportedOperationException(\"Composite secondary identifier is not supported yet\");\n} else if (secondaryIdentifierDefs.isEmpty()) {\nthrow new SchemaException(\"No secondary identifier defined, cannot search\");\n}\nRefinedAttributeDefinition<String> secondaryIdentifierDef = secondaryIdentifierDefs.iterator().next();\nResourceAttribute<?> secondaryIdentifier = null;\nfor (ResourceAttribute<?> identifier: identifiers) {\nif (identifier.getElementName().equals(secondaryIdentifierDef.getName())) {\nsecondaryIdentifier = identifier;\n}\n}\nif (secondaryIdentifier == null) {\nthrow new SchemaException(\"No secondary identifier present, cannot search. Identifiers: \"+identifiers);\n}\nfinal ResourceAttribute<?> finalSecondaryIdentifier = secondaryIdentifier;\nList<PrismPropertyValue<String>> secondaryIdentifierValues = (List) secondaryIdentifier.getValues();\nPrismPropertyValue<String> secondaryIdentifierValue;\nif (secondaryIdentifierValues.size() > 1) {\nthrow new IllegalStateException(\"Secondary identifier has more than one value: \" + secondaryIdentifier.getValues());","label":[1,0,0,0]}
{"id":18602,"original_code":"private void updateQuantum(ProvisioningContext ctx, ConnectorInstance connectorUsedForOperation, AsynchronousOperationResult aResult, OperationResult parentResult) throws ObjectNotFoundException, SchemaException, CommunicationException, ConfigurationException, ExpressionEvaluationException {\n\t\tConnectorInstance readConnector = ctx.getConnector(ReadCapabilityType.class, parentResult);\n\t\tif (readConnector != connectorUsedForOperation) {\n\t\t\t\/\/ Writing by different connector that we are going to use for reading: danger of quantum effects\n\t\t\taResult.setQuantumOperation(true);\n\t\t}\n\t}","code":"private void updateQuantum(ProvisioningContext ctx, ConnectorInstance connectorUsedForOperation, AsynchronousOperationResult aResult, OperationResult parentResult) throws ObjectNotFoundException, SchemaException, CommunicationException, ConfigurationException, ExpressionEvaluationException {\n\t\tConnectorInstance readConnector = ctx.getConnector(ReadCapabilityType.class, parentResult);\n\t\tif (readConnector != connectorUsedForOperation) {\n\t\t\n\t\t\taResult.setQuantumOperation(true);\n\t\t}\n\t}","cleancode":"private void updatequantum(provisioningcontext ctx, connectorinstance connectorusedforoperation, asynchronousoperationresult aresult, operationresult parentresult) throws objectnotfoundexception, schemaexception, communicationexception, configurationexception, expressionevaluationexception { connectorinstance readconnector = ctx.getconnector(readcapabilitytype.class, parentresult); if (readconnector != connectorusedforoperation) { aresult.setquantumoperation(true); } }","comment":"\/\/ writing by different connector that we are going to use for reading: danger of quantum effects","repo":"valtri\/midpoint","code_context_2":"ConnectorInstance readConnector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nif (readConnector != connectorUsedForOperation) {\n\/\/ Writing by different connector that we are going to use for reading: danger of quantum effects\naResult.setQuantumOperation(true);\n}","code_context_10":"private void updateQuantum(ProvisioningContext ctx, ConnectorInstance connectorUsedForOperation, AsynchronousOperationResult aResult, OperationResult parentResult) throws ObjectNotFoundException, SchemaException, CommunicationException, ConfigurationException, ExpressionEvaluationException {\nConnectorInstance readConnector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nif (readConnector != connectorUsedForOperation) {\n\/\/ Writing by different connector that we are going to use for reading: danger of quantum effects\naResult.setQuantumOperation(true);\n}\n}","code_context_20":"private void updateQuantum(ProvisioningContext ctx, ConnectorInstance connectorUsedForOperation, AsynchronousOperationResult aResult, OperationResult parentResult) throws ObjectNotFoundException, SchemaException, CommunicationException, ConfigurationException, ExpressionEvaluationException {\nConnectorInstance readConnector = ctx.getConnector(ReadCapabilityType.class, parentResult);\nif (readConnector != connectorUsedForOperation) {\n\/\/ Writing by different connector that we are going to use for reading: danger of quantum effects\naResult.setQuantumOperation(true);\n}\n}","label":[1,0,0,0]}
{"id":18608,"original_code":"public List<Change> fetchChanges(ProvisioningContext ctx, PrismProperty<?> lastToken,\n\t\t\tOperationResult parentResult) throws SchemaException,\n\t\t\tCommunicationException, ConfigurationException, SecurityViolationException, GenericFrameworkException, ObjectNotFoundException, ExpressionEvaluationException {\n\t\tValidate.notNull(parentResult, \"Operation result must not be null.\");\n\t\tLOGGER.trace(\"START fetch changes, objectClass: {}\", ctx.getObjectClassDefinition());\n\t\tAttributesToReturn attrsToReturn = null;\n\t\tif (!ctx.isWildcard()) {\n\t\t\tattrsToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\t}\n\t\tConnectorInstance connector = ctx.getConnector(LiveSyncCapabilityType.class, parentResult);\n\t\t\/\/ get changes from the connector\n\t\tList<Change> changes = connector.fetchChanges(ctx.getObjectClassDefinition(), lastToken, attrsToReturn, ctx, parentResult);\n\t\tIterator<Change> iterator = changes.iterator();\n\t\twhile (iterator.hasNext()) {\n\t\t\tChange change = iterator.next();\n\t\t\tLOGGER.trace(\"Original change:\\n{}\", change.debugDump());\n\t\t\tif (change.isTokenOnly()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tProvisioningContext shadowCtx = ctx;\n\t\t\tAttributesToReturn shadowAttrsToReturn = attrsToReturn;\n\t\t\tPrismObject<ShadowType> currentShadow = change.getCurrentShadow();\n\t\t\tObjectClassComplexTypeDefinition changeObjectClassDefinition = change.getObjectClassDefinition();\n\t\t\tif (changeObjectClassDefinition == null) {\n\t\t\t\tif (!ctx.isWildcard() || change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\n\t\t\t\t\tthrow new SchemaException(\"No object class definition in change \"+change);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (ctx.isWildcard() && changeObjectClassDefinition != null) {\n\t\t\t\tshadowCtx = ctx.spawn(changeObjectClassDefinition.getTypeName());\n\t\t\t\tif (shadowCtx.isWildcard()) {\n\t\t\t\t\tString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\n\t\t\t\t\tparentResult.recordFatalError(message);\n\t\t\t\t\tthrow new SchemaException(message);\n\t\t\t\t}\n\t\t\t\tchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\n\t\t\t\tshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n\t\t\t}\n\t\t\tif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\n\t\t\t\tif (currentShadow == null) {\n\t\t\t\t\t\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\n\t\t\t\t\ttry {\n\t\t\t\t\t\tLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\n\t\t\t\t\t\tcurrentShadow = fetchResourceObject(shadowCtx, \n\t\t\t\t\t\t\t\tchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult);\t\/\/ todo consider whether it is always necessary to fetch the entitlements\n\t\t\t\t\t\tchange.setCurrentShadow(currentShadow);\n\t\t\t\t\t} catch (ObjectNotFoundException ex) {\n\t\t\t\t\t\tparentResult.recordHandledError(\n\t\t\t\t\t\t\t\t\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\n\t\t\t\t\t\tLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n\t\t\t\t\t\t\t\t+ ex.getMessage());\n\t\t\t\t\t\t\/\/ TODO: Maybe change to DELETE instead of this?\n\t\t\t\t\t\titerator.remove();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (ctx.isWildcard()) {\n\t\t\t\t\t\tif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\t\t\t\t\t\t\t\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\n\t\t\t\t\t\t\tResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(), \n\t\t\t\t\t\t\t\t\tchange.getIdentifiers());\n\t\t\t\t\t\t\tidentification.validatePrimaryIdenfiers();\n\t\t\t\t\t\t\tLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\n\t\t\t\t\t\t\tcurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tPrismObject<ShadowType> processedCurrentShadow = postProcessResourceObjectRead(shadowCtx,\n\t\t\t\t\t\t\tcurrentShadow, true, parentResult);\n\t\t\t\t\tchange.setCurrentShadow(processedCurrentShadow);\n\t\t\t\t}\n\t\t\t}\n\t\t\tLOGGER.trace(\"Processed change\\n:{}\", change.debugDump());\n\t\t}\n\t\tcomputeResultStatus(parentResult);\n\t\tLOGGER.trace(\"END fetch changes ({} changes)\", changes == null ? \"null\" : changes.size());\n\t\treturn changes;\n\t}","code":"public List<Change> fetchChanges(ProvisioningContext ctx, PrismProperty<?> lastToken,\n\t\t\tOperationResult parentResult) throws SchemaException,\n\t\t\tCommunicationException, ConfigurationException, SecurityViolationException, GenericFrameworkException, ObjectNotFoundException, ExpressionEvaluationException {\n\t\tValidate.notNull(parentResult, \"Operation result must not be null.\");\n\t\tLOGGER.trace(\"START fetch changes, objectClass: {}\", ctx.getObjectClassDefinition());\n\t\tAttributesToReturn attrsToReturn = null;\n\t\tif (!ctx.isWildcard()) {\n\t\t\tattrsToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n\t\t}\n\t\tConnectorInstance connector = ctx.getConnector(LiveSyncCapabilityType.class, parentResult);\n\t\n\t\tList<Change> changes = connector.fetchChanges(ctx.getObjectClassDefinition(), lastToken, attrsToReturn, ctx, parentResult);\n\t\tIterator<Change> iterator = changes.iterator();\n\t\twhile (iterator.hasNext()) {\n\t\t\tChange change = iterator.next();\n\t\t\tLOGGER.trace(\"Original change:\\n{}\", change.debugDump());\n\t\t\tif (change.isTokenOnly()) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tProvisioningContext shadowCtx = ctx;\n\t\t\tAttributesToReturn shadowAttrsToReturn = attrsToReturn;\n\t\t\tPrismObject<ShadowType> currentShadow = change.getCurrentShadow();\n\t\t\tObjectClassComplexTypeDefinition changeObjectClassDefinition = change.getObjectClassDefinition();\n\t\t\tif (changeObjectClassDefinition == null) {\n\t\t\t\tif (!ctx.isWildcard() || change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\n\t\t\t\t\tthrow new SchemaException(\"No object class definition in change \"+change);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (ctx.isWildcard() && changeObjectClassDefinition != null) {\n\t\t\t\tshadowCtx = ctx.spawn(changeObjectClassDefinition.getTypeName());\n\t\t\t\tif (shadowCtx.isWildcard()) {\n\t\t\t\t\tString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\n\t\t\t\t\tparentResult.recordFatalError(message);\n\t\t\t\t\tthrow new SchemaException(message);\n\t\t\t\t}\n\t\t\t\tchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\n\t\t\t\tshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n\t\t\t}\n\t\t\tif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\n\t\t\t\tif (currentShadow == null) {\n\t\t\t\t\n\t\t\t\t\ttry {\n\t\t\t\t\t\tLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\n\t\t\t\t\t\tcurrentShadow = fetchResourceObject(shadowCtx, \n\t\t\t\t\t\t\t\tchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult);\n\t\t\t\t\t\tchange.setCurrentShadow(currentShadow);\n\t\t\t\t\t} catch (ObjectNotFoundException ex) {\n\t\t\t\t\t\tparentResult.recordHandledError(\n\t\t\t\t\t\t\t\t\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\n\t\t\t\t\t\tLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n\t\t\t\t\t\t\t\t+ ex.getMessage());\n\t\t\t\t\t\n\t\t\t\t\t\titerator.remove();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\tif (ctx.isWildcard()) {\n\t\t\t\t\t\tif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(), \n\t\t\t\t\t\t\t\t\tchange.getIdentifiers());\n\t\t\t\t\t\t\tidentification.validatePrimaryIdenfiers();\n\t\t\t\t\t\t\tLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\n\t\t\t\t\t\t\tcurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tPrismObject<ShadowType> processedCurrentShadow = postProcessResourceObjectRead(shadowCtx,\n\t\t\t\t\t\t\tcurrentShadow, true, parentResult);\n\t\t\t\t\tchange.setCurrentShadow(processedCurrentShadow);\n\t\t\t\t}\n\t\t\t}\n\t\t\tLOGGER.trace(\"Processed change\\n:{}\", change.debugDump());\n\t\t}\n\t\tcomputeResultStatus(parentResult);\n\t\tLOGGER.trace(\"END fetch changes ({} changes)\", changes == null ? \"null\" : changes.size());\n\t\treturn changes;\n\t}","cleancode":"public list<change> fetchchanges(provisioningcontext ctx, prismproperty<?> lasttoken, operationresult parentresult) throws schemaexception, communicationexception, configurationexception, securityviolationexception, genericframeworkexception, objectnotfoundexception, expressionevaluationexception { validate.notnull(parentresult, \"operation result must not be null.\"); logger.trace(\"start fetch changes, objectclass: {}\", ctx.getobjectclassdefinition()); attributestoreturn attrstoreturn = null; if (!ctx.iswildcard()) { attrstoreturn = provisioningutil.createattributestoreturn(ctx); } connectorinstance connector = ctx.getconnector(livesynccapabilitytype.class, parentresult); list<change> changes = connector.fetchchanges(ctx.getobjectclassdefinition(), lasttoken, attrstoreturn, ctx, parentresult); iterator<change> iterator = changes.iterator(); while (iterator.hasnext()) { change change = iterator.next(); logger.trace(\"original change:\\n{}\", change.debugdump()); if (change.istokenonly()) { continue; } provisioningcontext shadowctx = ctx; attributestoreturn shadowattrstoreturn = attrstoreturn; prismobject<shadowtype> currentshadow = change.getcurrentshadow(); objectclasscomplextypedefinition changeobjectclassdefinition = change.getobjectclassdefinition(); if (changeobjectclassdefinition == null) { if (!ctx.iswildcard() || change.getobjectdelta() == null || !change.getobjectdelta().isdelete()) { throw new schemaexception(\"no object class definition in change \"+change); } } if (ctx.iswildcard() && changeobjectclassdefinition != null) { shadowctx = ctx.spawn(changeobjectclassdefinition.gettypename()); if (shadowctx.iswildcard()) { string message = \"unkown object class \"+changeobjectclassdefinition.gettypename()+\" found in synchronization delta\"; parentresult.recordfatalerror(message); throw new schemaexception(message); } change.setobjectclassdefinition(shadowctx.getobjectclassdefinition()); shadowattrstoreturn = provisioningutil.createattributestoreturn(shadowctx); } if (change.getobjectdelta() == null || !change.getobjectdelta().isdelete()) { if (currentshadow == null) { try { logger.trace(\"re-fetching object {} because it is not in the change\", change.getidentifiers()); currentshadow = fetchresourceobject(shadowctx, change.getidentifiers(), shadowattrstoreturn, true, parentresult); change.setcurrentshadow(currentshadow); } catch (objectnotfoundexception ex) { parentresult.recordhandlederror( \"object detected in change log no longer exist on the resource. skipping processing this object.\", ex); logger.warn(\"object detected in change log no longer exist on the resource. skipping processing this object \" + ex.getmessage()); iterator.remove(); continue; } } else { if (ctx.iswildcard()) { if (!miscutil.equals(shadowattrstoreturn, attrstoreturn)) { resourceobjectidentification identification = resourceobjectidentification.create(shadowctx.getobjectclassdefinition(), change.getidentifiers()); identification.validateprimaryidenfiers(); logger.trace(\"re-fetching object {} because of attrstoreturn\", identification); currentshadow = connector.fetchobject(identification, shadowattrstoreturn, ctx, parentresult); } } prismobject<shadowtype> processedcurrentshadow = postprocessresourceobjectread(shadowctx, currentshadow, true, parentresult); change.setcurrentshadow(processedcurrentshadow); } } logger.trace(\"processed change\\n:{}\", change.debugdump()); } computeresultstatus(parentresult); logger.trace(\"end fetch changes ({} changes)\", changes == null ? \"null\" : changes.size()); return changes; }","comment":"\/\/ get changes from the connector\n\/\/ there is no current shadow in a change. add it by fetching it explicitly.\n\/\/ todo consider whether it is always necessary to fetch the entitlements\n\/\/ todo: maybe change to delete instead of this?\n\/\/ re-fetch the shadow if necessary (if attributestoget does not match)","repo":"valtri\/midpoint","code_context_2":"}\nConnectorInstance connector = ctx.getConnector(LiveSyncCapabilityType.class, parentResult);\n\/\/ get changes from the connector\nList<Change> changes = connector.fetchChanges(ctx.getObjectClassDefinition(), lastToken, attrsToReturn, ctx, parentResult);\nIterator<Change> iterator = changes.iterator();\n\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\n\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\n\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());","code_context_10":"public List<Change> fetchChanges(ProvisioningContext ctx, PrismProperty<?> lastToken,\nOperationResult parentResult) throws SchemaException,\nCommunicationException, ConfigurationException, SecurityViolationException, GenericFrameworkException, ObjectNotFoundException, ExpressionEvaluationException {\nValidate.notNull(parentResult, \"Operation result must not be null.\");\nLOGGER.trace(\"START fetch changes, objectClass: {}\", ctx.getObjectClassDefinition());\nAttributesToReturn attrsToReturn = null;\nif (!ctx.isWildcard()) {\nattrsToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n}\nConnectorInstance connector = ctx.getConnector(LiveSyncCapabilityType.class, parentResult);\n\/\/ get changes from the connector\nList<Change> changes = connector.fetchChanges(ctx.getObjectClassDefinition(), lastToken, attrsToReturn, ctx, parentResult);\nIterator<Change> iterator = changes.iterator();\nwhile (iterator.hasNext()) {\nChange change = iterator.next();\nLOGGER.trace(\"Original change:\\n{}\", change.debugDump());\nif (change.isTokenOnly()) {\ncontinue;\n}\nProvisioningContext shadowCtx = ctx;\nAttributesToReturn shadowAttrsToReturn = attrsToReturn;\n\nif (shadowCtx.isWildcard()) {\nString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\nparentResult.recordFatalError(message);\nthrow new SchemaException(message);\n}\nchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\nshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n}\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\n}\nchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\nshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n}\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\nidentification.validatePrimaryIdenfiers();\n\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\nidentification.validatePrimaryIdenfiers();\nLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\ncurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n}\n}\nPrismObject<ShadowType> processedCurrentShadow = postProcessResourceObjectRead(shadowCtx,\ncurrentShadow, true, parentResult);\nchange.setCurrentShadow(processedCurrentShadow);","code_context_20":"public List<Change> fetchChanges(ProvisioningContext ctx, PrismProperty<?> lastToken,\nOperationResult parentResult) throws SchemaException,\nCommunicationException, ConfigurationException, SecurityViolationException, GenericFrameworkException, ObjectNotFoundException, ExpressionEvaluationException {\nValidate.notNull(parentResult, \"Operation result must not be null.\");\nLOGGER.trace(\"START fetch changes, objectClass: {}\", ctx.getObjectClassDefinition());\nAttributesToReturn attrsToReturn = null;\nif (!ctx.isWildcard()) {\nattrsToReturn = ProvisioningUtil.createAttributesToReturn(ctx);\n}\nConnectorInstance connector = ctx.getConnector(LiveSyncCapabilityType.class, parentResult);\n\/\/ get changes from the connector\nList<Change> changes = connector.fetchChanges(ctx.getObjectClassDefinition(), lastToken, attrsToReturn, ctx, parentResult);\nIterator<Change> iterator = changes.iterator();\nwhile (iterator.hasNext()) {\nChange change = iterator.next();\nLOGGER.trace(\"Original change:\\n{}\", change.debugDump());\nif (change.isTokenOnly()) {\ncontinue;\n}\nProvisioningContext shadowCtx = ctx;\nAttributesToReturn shadowAttrsToReturn = attrsToReturn;\nPrismObject<ShadowType> currentShadow = change.getCurrentShadow();\nObjectClassComplexTypeDefinition changeObjectClassDefinition = change.getObjectClassDefinition();\nif (changeObjectClassDefinition == null) {\nif (!ctx.isWildcard() || change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nthrow new SchemaException(\"No object class definition in change \"+change);\n}\n}\nif (ctx.isWildcard() && changeObjectClassDefinition != null) {\nshadowCtx = ctx.spawn(changeObjectClassDefinition.getTypeName());\nif (shadowCtx.isWildcard()) {\n\nAttributesToReturn shadowAttrsToReturn = attrsToReturn;\nPrismObject<ShadowType> currentShadow = change.getCurrentShadow();\nObjectClassComplexTypeDefinition changeObjectClassDefinition = change.getObjectClassDefinition();\nif (changeObjectClassDefinition == null) {\nif (!ctx.isWildcard() || change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nthrow new SchemaException(\"No object class definition in change \"+change);\n}\n}\nif (ctx.isWildcard() && changeObjectClassDefinition != null) {\nshadowCtx = ctx.spawn(changeObjectClassDefinition.getTypeName());\nif (shadowCtx.isWildcard()) {\nString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\nparentResult.recordFatalError(message);\nthrow new SchemaException(message);\n}\nchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\nshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n}\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\n\nif (!ctx.isWildcard() || change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nthrow new SchemaException(\"No object class definition in change \"+change);\n}\n}\nif (ctx.isWildcard() && changeObjectClassDefinition != null) {\nshadowCtx = ctx.spawn(changeObjectClassDefinition.getTypeName());\nif (shadowCtx.isWildcard()) {\nString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\nparentResult.recordFatalError(message);\nthrow new SchemaException(message);\n}\nchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\nshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n}\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\nidentification.validatePrimaryIdenfiers();\nLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\ncurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n}\n\nString message = \"Unkown object class \"+changeObjectClassDefinition.getTypeName()+\" found in synchronization delta\";\nparentResult.recordFatalError(message);\nthrow new SchemaException(message);\n}\nchange.setObjectClassDefinition(shadowCtx.getObjectClassDefinition());\nshadowAttrsToReturn = ProvisioningUtil.createAttributesToReturn(shadowCtx);\n}\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\nidentification.validatePrimaryIdenfiers();\nLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\ncurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n}\n}\nPrismObject<ShadowType> processedCurrentShadow = postProcessResourceObjectRead(shadowCtx,\ncurrentShadow, true, parentResult);\nchange.setCurrentShadow(processedCurrentShadow);\n}\n}\nLOGGER.trace(\"Processed change\\n:{}\", change.debugDump());\n\nif (change.getObjectDelta() == null || !change.getObjectDelta().isDelete()) {\nif (currentShadow == null) {\n\/\/ There is no current shadow in a change. Add it by fetching it explicitly.\ntry {\nLOGGER.trace(\"Re-fetching object {} because it is not in the change\", change.getIdentifiers());\ncurrentShadow = fetchResourceObject(shadowCtx,\nchange.getIdentifiers(), shadowAttrsToReturn, true, parentResult); \/\/ todo consider whether it is always necessary to fetch the entitlements\nchange.setCurrentShadow(currentShadow);\n} catch (ObjectNotFoundException ex) {\nparentResult.recordHandledError(\n\"Object detected in change log no longer exist on the resource. Skipping processing this object.\", ex);\nLOGGER.warn(\"Object detected in change log no longer exist on the resource. Skipping processing this object \"\n+ ex.getMessage());\n\/\/ TODO: Maybe change to DELETE instead of this?\niterator.remove();\ncontinue;\n}\n} else {\nif (ctx.isWildcard()) {\nif (!MiscUtil.equals(shadowAttrsToReturn, attrsToReturn)) {\n\/\/ re-fetch the shadow if necessary (if attributesToGet does not match)\nResourceObjectIdentification identification = ResourceObjectIdentification.create(shadowCtx.getObjectClassDefinition(),\nchange.getIdentifiers());\nidentification.validatePrimaryIdenfiers();\nLOGGER.trace(\"Re-fetching object {} because of attrsToReturn\", identification);\ncurrentShadow = connector.fetchObject(identification, shadowAttrsToReturn, ctx, parentResult);\n}\n}\nPrismObject<ShadowType> processedCurrentShadow = postProcessResourceObjectRead(shadowCtx,\ncurrentShadow, true, parentResult);\nchange.setCurrentShadow(processedCurrentShadow);\n}\n}\nLOGGER.trace(\"Processed change\\n:{}\", change.debugDump());\n}\ncomputeResultStatus(parentResult);\nLOGGER.trace(\"END fetch changes ({} changes)\", changes == null ? \"null\" : changes.size());\nreturn changes;\n}","label":[1,0,0,0]}
{"id":10424,"original_code":"@Override\n            public void run() {\n                if (TokenList.this.cancel.get()) {\n                    return ;\n                }\n                topLevel = TokenHierarchy.get(doc).tokenSequence();\n                topLevelIsJava = topLevel.language() == JavaTokenId.language();\n                if (topLevelIsJava) {\n                    ts = topLevel;\n                    ts.moveStart();\n                    ts.moveNext(); \/\/XXX: what about empty document\n                }\n            }","code":"@Override\n            public void run() {\n                if (TokenList.this.cancel.get()) {\n                    return ;\n                }\n                topLevel = TokenHierarchy.get(doc).tokenSequence();\n                topLevelIsJava = topLevel.language() == JavaTokenId.language();\n                if (topLevelIsJava) {\n                    ts = topLevel;\n                    ts.moveStart();\n                    ts.moveNext();\n                }\n            }","cleancode":"@override public void run() { if (tokenlist.this.cancel.get()) { return ; } toplevel = tokenhierarchy.get(doc).tokensequence(); toplevelisjava = toplevel.language() == javatokenid.language(); if (toplevelisjava) { ts = toplevel; ts.movestart(); ts.movenext(); } }","comment":"\/\/xxx: what about empty document","repo":"timfel\/netbeans","code_context_2":"ts = topLevel;\nts.moveStart();\nts.moveNext(); \/\/XXX: what about empty document\n}\n}","code_context_10":"@Override\npublic void run() {\nif (TokenList.this.cancel.get()) {\nreturn ;\n}\ntopLevel = TokenHierarchy.get(doc).tokenSequence();\ntopLevelIsJava = topLevel.language() == JavaTokenId.language();\nif (topLevelIsJava) {\nts = topLevel;\nts.moveStart();\nts.moveNext(); \/\/XXX: what about empty document\n}\n}","code_context_20":"@Override\npublic void run() {\nif (TokenList.this.cancel.get()) {\nreturn ;\n}\ntopLevel = TokenHierarchy.get(doc).tokenSequence();\ntopLevelIsJava = topLevel.language() == JavaTokenId.language();\nif (topLevelIsJava) {\nts = topLevel;\nts.moveStart();\nts.moveNext(); \/\/XXX: what about empty document\n}\n}","label":[0,0,1,0]}
{"id":18754,"original_code":"@RequestMapping(value = \"\/products\", method=RequestMethod.GET)\n\t@ResponseBody\n\tpublic ReadableProductList getFiltered(\n\t\t\t@RequestParam(value = \"lang\", required=false) String lang, \n\t\t\t@RequestParam(value = \"category\", required=false) Long category, \n\t\t\t@RequestParam(value = \"manufacturer\", required=false) Long manufacturer,\n\t\t\t@RequestParam(value = \"status\", required=false) String status,\n\t\t\t@RequestParam(value = \"owner\", required=false) Long owner,\n\t\t\t@RequestParam(value = \"start\", required=false) Integer start,\n\t\t\t@RequestParam(value = \"count\", required=false) Integer count,\n\t\t\tHttpServletRequest request, HttpServletResponse response) throws Exception {\n\t\tProductCriteria criteria = new ProductCriteria();\n\t\tif(!StringUtils.isBlank(lang)) {\n\t\t\tcriteria.setLanguage(lang);\n\t\t}\n\t\tif(!StringUtils.isBlank(status)) {\n\t\t\tcriteria.setStatus(status);\n\t\t}\n\t\tif(category != null) {\n\t\t\tList<Long> categoryIds = new ArrayList<Long>();\n\t\t\tcategoryIds.add(category);\n\t\t\tcriteria.setCategoryIds(categoryIds);\n\t\t}\n\t\tif(manufacturer != null) {\n\t\t\tcriteria.setManufacturerId(manufacturer);\n\t\t}\n\t\tif(owner != null) {\n\t\t\tcriteria.setOwnerId(owner);\n\t\t}\n\t\tif(start != null) {\n\t\t\tcriteria.setStartIndex(start);\n\t\t}\n\t\tif(count != null) {\n\t\t\tcriteria.setMaxCount(count);\n\t\t}\n\t\t\/\/TODO\n\t\t\/\/RENTAL add filter by owner\n\t\t\/\/REPOSITORY to use the new filters\n\t\ttry {\n\t\t\tMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\n\t\t\tLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\t\n\t\t\tReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\n\t\t\treturn productList;\n\t\t} catch(Exception e) {\n\t\t\tLOGGER.error(\"Error while filtering products product\",e);\n\t\t\ttry {\n\t\t\t\tresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n\t\t\t} catch (Exception ignore) {\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}","code":"@RequestMapping(value = \"\/products\", method=RequestMethod.GET)\n\t@ResponseBody\n\tpublic ReadableProductList getFiltered(\n\t\t\t@RequestParam(value = \"lang\", required=false) String lang, \n\t\t\t@RequestParam(value = \"category\", required=false) Long category, \n\t\t\t@RequestParam(value = \"manufacturer\", required=false) Long manufacturer,\n\t\t\t@RequestParam(value = \"status\", required=false) String status,\n\t\t\t@RequestParam(value = \"owner\", required=false) Long owner,\n\t\t\t@RequestParam(value = \"start\", required=false) Integer start,\n\t\t\t@RequestParam(value = \"count\", required=false) Integer count,\n\t\t\tHttpServletRequest request, HttpServletResponse response) throws Exception {\n\t\tProductCriteria criteria = new ProductCriteria();\n\t\tif(!StringUtils.isBlank(lang)) {\n\t\t\tcriteria.setLanguage(lang);\n\t\t}\n\t\tif(!StringUtils.isBlank(status)) {\n\t\t\tcriteria.setStatus(status);\n\t\t}\n\t\tif(category != null) {\n\t\t\tList<Long> categoryIds = new ArrayList<Long>();\n\t\t\tcategoryIds.add(category);\n\t\t\tcriteria.setCategoryIds(categoryIds);\n\t\t}\n\t\tif(manufacturer != null) {\n\t\t\tcriteria.setManufacturerId(manufacturer);\n\t\t}\n\t\tif(owner != null) {\n\t\t\tcriteria.setOwnerId(owner);\n\t\t}\n\t\tif(start != null) {\n\t\t\tcriteria.setStartIndex(start);\n\t\t}\n\t\tif(count != null) {\n\t\t\tcriteria.setMaxCount(count);\n\t\t}\n\t\n\t\n\t\n\t\ttry {\n\t\t\tMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\n\t\t\tLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\t\n\t\t\tReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\n\t\t\treturn productList;\n\t\t} catch(Exception e) {\n\t\t\tLOGGER.error(\"Error while filtering products product\",e);\n\t\t\ttry {\n\t\t\t\tresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n\t\t\t} catch (Exception ignore) {\n\t\t\t}\n\t\t\treturn null;\n\t\t}\n\t}","cleancode":"@requestmapping(value = \"\/products\", method=requestmethod.get) @responsebody public readableproductlist getfiltered( @requestparam(value = \"lang\", required=false) string lang, @requestparam(value = \"category\", required=false) long category, @requestparam(value = \"manufacturer\", required=false) long manufacturer, @requestparam(value = \"status\", required=false) string status, @requestparam(value = \"owner\", required=false) long owner, @requestparam(value = \"start\", required=false) integer start, @requestparam(value = \"count\", required=false) integer count, httpservletrequest request, httpservletresponse response) throws exception { productcriteria criteria = new productcriteria(); if(!stringutils.isblank(lang)) { criteria.setlanguage(lang); } if(!stringutils.isblank(status)) { criteria.setstatus(status); } if(category != null) { list<long> categoryids = new arraylist<long>(); categoryids.add(category); criteria.setcategoryids(categoryids); } if(manufacturer != null) { criteria.setmanufacturerid(manufacturer); } if(owner != null) { criteria.setownerid(owner); } if(start != null) { criteria.setstartindex(start); } if(count != null) { criteria.setmaxcount(count); } try { merchantstore merchantstore = storefacade.getbycode(com.salesmanager.core.business.constants.constants.default_store); language language = languageutils.getrestlanguage(request, merchantstore); readableproductlist productlist = productfacade.getproductlistsbycriterias(merchantstore, language, criteria); return productlist; } catch(exception e) { logger.error(\"error while filtering products product\",e); try { response.senderror(503, \"error while filtering products \" + e.getmessage()); } catch (exception ignore) { } return null; } }","comment":"\/** * filtering product lists based on product attributes * ?category=1 * &manufacturer=2 * &type=... * &lang=en|fr not required, will use request language * &start=0 not required, can be used for pagination * &count=10 not required, can be used to limit item count * @param model * @param request * @param response * @return * @throws exception *\/\n\/\/todo \/\/rental add filter by owner \/\/repository to use the new filters","repo":"wxlfrank\/shopizer","code_context_2":"@RequestMapping(value = \"\/products\", method=RequestMethod.GET)\n@ResponseBody\npublic ReadableProductList getFiltered(\n@RequestParam(value = \"lang\", required=false) String lang,\n@RequestParam(value = \"category\", required=false) Long category,\n@RequestParam(value = \"manufacturer\", required=false) Long manufacturer,\n@RequestParam(value = \"status\", required=false) String status,\n@RequestParam(value = \"owner\", required=false) Long owner,\n@RequestParam(value = \"start\", required=false) Integer start,\n@RequestParam(value = \"count\", required=false) Integer count,\nHttpServletRequest request, HttpServletResponse response) throws Exception {\nProductCriteria criteria = new ProductCriteria();\nif(!StringUtils.isBlank(lang)) {\ncriteria.setLanguage(lang);\n}\nif(!StringUtils.isBlank(status)) {\ncriteria.setStatus(status);\n}\nif(category != null) {\nList<Long> categoryIds = new ArrayList<Long>();\ncategoryIds.add(category);\ncriteria.setCategoryIds(categoryIds);\n}\nif(manufacturer != null) {\ncriteria.setManufacturerId(manufacturer);\n}\nif(owner != null) {\ncriteria.setOwnerId(owner);\n}\nif(start != null) {\ncriteria.setStartIndex(start);\n}\nif(count != null) {\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\nLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\nReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\nreturn productList;\n} catch(Exception e) {\nLOGGER.error(\"Error while filtering products product\",e);\ntry {\nresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n} catch (Exception ignore) {\n}\nreturn null;\n}\n}\n\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);","code_context_10":"@RequestMapping(value = \"\/products\", method=RequestMethod.GET)\n@ResponseBody\npublic ReadableProductList getFiltered(\n@RequestParam(value = \"lang\", required=false) String lang,\n@RequestParam(value = \"category\", required=false) Long category,\n@RequestParam(value = \"manufacturer\", required=false) Long manufacturer,\n@RequestParam(value = \"status\", required=false) String status,\n@RequestParam(value = \"owner\", required=false) Long owner,\n@RequestParam(value = \"start\", required=false) Integer start,\n@RequestParam(value = \"count\", required=false) Integer count,\nHttpServletRequest request, HttpServletResponse response) throws Exception {\nProductCriteria criteria = new ProductCriteria();\nif(!StringUtils.isBlank(lang)) {\ncriteria.setLanguage(lang);\n}\nif(!StringUtils.isBlank(status)) {\ncriteria.setStatus(status);\n}\nif(category != null) {\nList<Long> categoryIds = new ArrayList<Long>();\ncategoryIds.add(category);\ncriteria.setCategoryIds(categoryIds);\n}\nif(manufacturer != null) {\ncriteria.setManufacturerId(manufacturer);\n}\nif(owner != null) {\ncriteria.setOwnerId(owner);\n}\nif(start != null) {\ncriteria.setStartIndex(start);\n}\nif(count != null) {\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\nLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\nReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\nreturn productList;\n} catch(Exception e) {\nLOGGER.error(\"Error while filtering products product\",e);\ntry {\nresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n} catch (Exception ignore) {\n}\nreturn null;\n}\n}\n\n}\nif(owner != null) {\ncriteria.setOwnerId(owner);\n}\nif(start != null) {\ncriteria.setStartIndex(start);\n}\nif(count != null) {\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\nLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\nReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\nreturn productList;\n} catch(Exception e) {\nLOGGER.error(\"Error while filtering products product\",e);\ntry {\nresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n} catch (Exception ignore) {","code_context_20":"@RequestMapping(value = \"\/products\", method=RequestMethod.GET)\n@ResponseBody\npublic ReadableProductList getFiltered(\n@RequestParam(value = \"lang\", required=false) String lang,\n@RequestParam(value = \"category\", required=false) Long category,\n@RequestParam(value = \"manufacturer\", required=false) Long manufacturer,\n@RequestParam(value = \"status\", required=false) String status,\n@RequestParam(value = \"owner\", required=false) Long owner,\n@RequestParam(value = \"start\", required=false) Integer start,\n@RequestParam(value = \"count\", required=false) Integer count,\nHttpServletRequest request, HttpServletResponse response) throws Exception {\nProductCriteria criteria = new ProductCriteria();\nif(!StringUtils.isBlank(lang)) {\ncriteria.setLanguage(lang);\n}\nif(!StringUtils.isBlank(status)) {\ncriteria.setStatus(status);\n}\nif(category != null) {\nList<Long> categoryIds = new ArrayList<Long>();\ncategoryIds.add(category);\ncriteria.setCategoryIds(categoryIds);\n}\nif(manufacturer != null) {\ncriteria.setManufacturerId(manufacturer);\n}\nif(owner != null) {\ncriteria.setOwnerId(owner);\n}\nif(start != null) {\ncriteria.setStartIndex(start);\n}\nif(count != null) {\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\nLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\nReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\nreturn productList;\n} catch(Exception e) {\nLOGGER.error(\"Error while filtering products product\",e);\ntry {\nresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n} catch (Exception ignore) {\n}\nreturn null;\n}\n}\n\nif(!StringUtils.isBlank(status)) {\ncriteria.setStatus(status);\n}\nif(category != null) {\nList<Long> categoryIds = new ArrayList<Long>();\ncategoryIds.add(category);\ncriteria.setCategoryIds(categoryIds);\n}\nif(manufacturer != null) {\ncriteria.setManufacturerId(manufacturer);\n}\nif(owner != null) {\ncriteria.setOwnerId(owner);\n}\nif(start != null) {\ncriteria.setStartIndex(start);\n}\nif(count != null) {\ncriteria.setMaxCount(count);\n}\n\/\/TODO\n\/\/RENTAL add filter by owner\n\/\/REPOSITORY to use the new filters\ntry {\nMerchantStore merchantStore = storeFacade.getByCode(com.salesmanager.core.business.constants.Constants.DEFAULT_STORE);\nLanguage language = languageUtils.getRESTLanguage(request, merchantStore);\nReadableProductList productList = productFacade.getProductListsByCriterias(merchantStore, language, criteria);\nreturn productList;\n} catch(Exception e) {\nLOGGER.error(\"Error while filtering products product\",e);\ntry {\nresponse.sendError(503, \"Error while filtering products \" + e.getMessage());\n} catch (Exception ignore) {\n}\nreturn null;\n}\n}","label":[0,1,0,0]}
{"id":10651,"original_code":"public synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/\t\tString transactionId = null;\n\/\/\t\ttry {\n\/\/\t\t\tjavax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/\t\t\tTransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/\t\t\tif (transaction == null)\n\/\/\t\t\t\treturn;\n\/\/\t\t\t\n\/\/\t\t\tint status = transaction.getStatus();\n\/\/\t\t\ttransactionId = transaction.get_uid().stringForm();\n\/\/\t\t\t\/\/transactionId = TransactionManager.getTransactionId();\n\/\/\t\t} catch (Exception e) {\n\/\/\t\t\te.printStackTrace();\n\/\/\t\t\treturn;\n\/\/\t\t}\n\t\tBasicAction currentAction = ThreadActionData.currentAction();\n\t\tif (currentAction == null)\n\t\t\treturn;\n\t\tString transactionId = ThreadActionData.currentAction().get_uid().toString();\n\t\tif (transactionId == null)\n\t\t\t\/\/TODO follow specified TX policy\n\t\t\treturn;\n\t\t\/\/ we cannot proceed while a (another) prepare is in progress\n\t\twhile (isLocked()) {\n\t\t\ttry {\n\t\t\t\twait();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\/\/ ignore\n\t\t\t}\n\t\t}\n\t\tT derivedState = getDerivedState(transactionId);\n\t\tif (derivedState != null) {\n\t\t\tif (!processor.validateState(derivedState)) {\n\t\t\t\t\/\/TODO get error message from processor\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\t\/\/ update the number of booked and free seats in the derived state\n\t\t\tprocessor.updateState(derivedState);\n\t\t} else {\n\t\t\tif (!processor.validateState(currentState)) {\n\t\t\t\t\/\/TODO get error message from processor\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\t\/\/ create a state derived from the current state which holds the new value(s)\n\t\t\tT childState = currentState.getDerivedState();\n\t\t\t\/\/ updates current state using values from the specified derived state\n\t\t\tprocessor.updateState(childState);\n\t\t\t\/\/ install the specified derived state as the current transaction state\n\t\t\tputDerivedState(transactionId, childState);\n\t\t\t\/\/currentState = childState;\n\t\t}\n\t}","code":"public synchronized void updateState(ServiceStateProcessor<T> processor) {\n\t\tBasicAction currentAction = ThreadActionData.currentAction();\n\t\tif (currentAction == null)\n\t\t\treturn;\n\t\tString transactionId = ThreadActionData.currentAction().get_uid().toString();\n\t\tif (transactionId == null)\n\t\t\n\t\t\treturn;\n\t\n\t\twhile (isLocked()) {\n\t\t\ttry {\n\t\t\t\twait();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\n\t\t\t}\n\t\t}\n\t\tT derivedState = getDerivedState(transactionId);\n\t\tif (derivedState != null) {\n\t\t\tif (!processor.validateState(derivedState)) {\n\t\t\t\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\n\t\t\tprocessor.updateState(derivedState);\n\t\t} else {\n\t\t\tif (!processor.validateState(currentState)) {\n\t\t\t\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\n\t\t\tT childState = currentState.getDerivedState();\n\t\t\n\t\t\tprocessor.updateState(childState);\n\t\t\n\t\t\tputDerivedState(transactionId, childState);\n\t\t\n\t\t}\n\t}","cleancode":"public synchronized void updatestate(servicestateprocessor<t> processor) { basicaction currentaction = threadactiondata.currentaction(); if (currentaction == null) return; string transactionid = threadactiondata.currentaction().get_uid().tostring(); if (transactionid == null) return; while (islocked()) { try { wait(); } catch (interruptedexception e) { } } t derivedstate = getderivedstate(transactionid); if (derivedstate != null) { if (!processor.validatestate(derivedstate)) { throw new webserviceexception(\"invalid request\"); } processor.updatestate(derivedstate); } else { if (!processor.validatestate(currentstate)) { throw new webserviceexception(\"invalid request\"); } t childstate = currentstate.getderivedstate(); processor.updatestate(childstate); putderivedstate(transactionid, childstate); } }","comment":"\/*****************************************************************************\/ \/* implementation of execution entry method *\/ \/*****************************************************************************\/\n\/\/ string transactionid = null; \/\/ try { \/\/ javax.transaction.transactionmanager transactionmanager = com.arjuna.ats.jta.transactionmanager.transactionmanager(); \/\/ transactionimple transaction = (transactionimple) transactionmanager.gettransaction(); \/\/ if (transaction == null) \/\/ return; \/\/ \/\/ int status = transaction.getstatus(); \/\/ transactionid = transaction.get_uid().stringform(); \/\/ \/\/transactionid = transactionmanager.gettransactionid(); \/\/ } catch (exception e) { \/\/ e.printstacktrace(); \/\/ return; \/\/ }\n\/\/todo follow specified tx policy\n\/\/ we cannot proceed while a (another) prepare is in progress\n\/\/ ignore\n\/\/todo get error message from processor\n\/\/ update the number of booked and free seats in the derived state\n\/\/todo get error message from processor\n\/\/ create a state derived from the current state which holds the new value(s)\n\/\/ updates current state using values from the specified derived state\n\/\/ install the specified derived state as the current transaction state\n\/\/currentstate = childstate;","repo":"tfisher1226\/ARIES","code_context_2":"public synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\npublic synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\n\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\n\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\n\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\n\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\n\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\n\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\n\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}","code_context_10":"public synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\npublic synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\n\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\n\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\n\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\n\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}","code_context_20":"public synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\npublic synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n\npublic synchronized void updateState(ServiceStateProcessor<T> processor) {\n\/\/ String transactionId = null;\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\n\n\/\/ try {\n\/\/ javax.transaction.TransactionManager transactionManager = com.arjuna.ats.jta.TransactionManager.transactionManager();\n\/\/ TransactionImple transaction = (TransactionImple) transactionManager.getTransaction();\n\/\/ if (transaction == null)\n\/\/ return;\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\n\/\/\n\/\/ int status = transaction.getStatus();\n\/\/ transactionId = transaction.get_uid().stringForm();\n\/\/ \/\/transactionId = TransactionManager.getTransactionId();\n\/\/ } catch (Exception e) {\n\/\/ e.printStackTrace();\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\n\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\n\/\/ return;\n\/\/ }\nBasicAction currentAction = ThreadActionData.currentAction();\nif (currentAction == null)\nreturn;\nString transactionId = ThreadActionData.currentAction().get_uid().toString();\nif (transactionId == null)\n\/\/TODO follow specified TX policy\nreturn;\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}\n\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n\/\/currentState = childState;\n}\n}","label":[1,1,0,0]}
{"id":10652,"original_code":"public synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\t\t\/\/ we cannot proceed while a (another) prepare is in progress\n\t\twhile (isLocked()) {\n\t\t\ttry {\n\t\t\t\twait();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\/\/ ignore\n\t\t\t}\n\t\t}\n\t\tT derivedState = getDerivedState(transactionId);\n\t\tif (derivedState != null) {\n\t\t\tif (!processor.validateState(derivedState)) {\n\t\t\t\t\/\/TODO get error message from processor\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\t\/\/ update the number of booked and free seats in the derived state\n\t\t\tprocessor.updateState(derivedState);\n\t\t} else {\n\t\t\tif (!processor.validateState(currentState)) {\n\t\t\t\t\/\/TODO get error message from processor\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\t\/\/ create a state derived from the current state which holds the new value(s)\n\t\t\tT childState = currentState.getDerivedState();\n\t\t\t\/\/ updates the current state using values from the specified derived state\n\t\t\tprocessor.updateState(childState);\n\t\t\t\/\/ install the specified derived state as the current transaction state\n\t\t\tputDerivedState(transactionId, childState);\n\t\t}\n\t}","code":"public synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\t\n\t\twhile (isLocked()) {\n\t\t\ttry {\n\t\t\t\twait();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\n\t\t\t}\n\t\t}\n\t\tT derivedState = getDerivedState(transactionId);\n\t\tif (derivedState != null) {\n\t\t\tif (!processor.validateState(derivedState)) {\n\t\t\t\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\n\t\t\tprocessor.updateState(derivedState);\n\t\t} else {\n\t\t\tif (!processor.validateState(currentState)) {\n\t\t\t\n\t\t\t\tthrow new WebServiceException(\"Invalid request\");\n\t\t\t}\n\t\t\n\t\t\tT childState = currentState.getDerivedState();\n\t\t\n\t\t\tprocessor.updateState(childState);\n\t\t\n\t\t\tputDerivedState(transactionId, childState);\n\t\t}\n\t}","cleancode":"public synchronized void execute(servicestateprocessor<t> processor, string transactionid) { while (islocked()) { try { wait(); } catch (interruptedexception e) { } } t derivedstate = getderivedstate(transactionid); if (derivedstate != null) { if (!processor.validatestate(derivedstate)) { throw new webserviceexception(\"invalid request\"); } processor.updatestate(derivedstate); } else { if (!processor.validatestate(currentstate)) { throw new webserviceexception(\"invalid request\"); } t childstate = currentstate.getderivedstate(); processor.updatestate(childstate); putderivedstate(transactionid, childstate); } }","comment":"\/*****************************************************************************\/ \/* implementation of execution entry method *\/ \/*****************************************************************************\/\n\/\/ we cannot proceed while a (another) prepare is in progress\n\/\/ ignore\n\/\/todo get error message from processor\n\/\/ update the number of booked and free seats in the derived state\n\/\/todo get error message from processor\n\/\/ create a state derived from the current state which holds the new value(s)\n\/\/ updates the current state using values from the specified derived state\n\/\/ install the specified derived state as the current transaction state","repo":"tfisher1226\/ARIES","code_context_2":"public synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\n\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\n\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\n\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\n\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\n\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}","code_context_10":"public synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\n\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\n\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}","code_context_20":"public synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\npublic synchronized void execute(ServiceStateProcessor<T> processor, String transactionId) {\n\/\/ we cannot proceed while a (another) prepare is in progress\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\nwhile (isLocked()) {\ntry {\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\nwait();\n} catch (InterruptedException e) {\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}\n\n\/\/ ignore\n}\n}\nT derivedState = getDerivedState(transactionId);\nif (derivedState != null) {\nif (!processor.validateState(derivedState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ update the number of booked and free seats in the derived state\nprocessor.updateState(derivedState);\n} else {\nif (!processor.validateState(currentState)) {\n\/\/TODO get error message from processor\nthrow new WebServiceException(\"Invalid request\");\n}\n\/\/ create a state derived from the current state which holds the new value(s)\nT childState = currentState.getDerivedState();\n\/\/ updates the current state using values from the specified derived state\nprocessor.updateState(childState);\n\/\/ install the specified derived state as the current transaction state\nputDerivedState(transactionId, childState);\n}\n}","label":[0,1,0,0]}
{"id":2461,"original_code":"private void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\t\t\/\/ TODO Packet logging for ice4j is not supported at this time.\n\t\tStunStack.setPacketLogger(null);\n\t\t\/\/ Make all ice4j properties system properties.\n\t\tif (cfg != null) {\n\t\t\tList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\n\t\t\tif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\n\t\t\t\tfor (String propertyName : ice4jPropertyNames) {\n\t\t\t\t\tString propertyValue = cfg.getString(propertyName);\n\t\t\t\t\t\/\/ we expect the getString to return either null or a\n\t\t\t\t\t\/\/ non-empty String object.\n\t\t\t\t\tif (propertyValue != null)\n\t\t\t\t\t\tSystem.setProperty(propertyName, propertyValue);\n\t\t\t\t}\n\t\t\t}\n\t\t\t\/\/ These properties are moved to ice4j. This is to make sure that we\n\t\t\t\/\/ still support the old names.\n\t\t\tString oldPrefix = \"org.jitsi.videobridge\";\n\t\t\tString newPrefix = \"org.ice4j.ice.harvest\";\n\t\t\tfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\n\t\t\t\t\tHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\n\t\t\t\t\tHarvesterConfiguration.FORCE_AWS_HARVESTER,\n\t\t\t\t\tHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\n\t\t\t\tString propertyValue = cfg.getString(propertyName);\n\t\t\t\tif (propertyValue != null) {\n\t\t\t\t\tString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\n\t\t\t\t\tSystem.setProperty(newPropertyName, propertyValue);\n\t\t\t\t}\n\t\t\t}\n\t\t\tString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\n\t\t\tif (enableLipSync != null) {\n\t\t\t\tSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n\t\t\t}\n\t\t\tString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\n\t\t\tif (disableNackTerminaton != null) {\n\t\t\t\tSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n\t\t\t}\n\t\t}\n\t\t\/\/ Initialize the the host candidate interface filters in the ice4j\n\t\t\/\/ stack.\n\t\ttry {\n\t\t\tHostCandidateHarvester.initializeInterfaceFilters();\n\t\t} catch (Exception e) {\n\t\t\tlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n\t\t}\n\t\t\/\/ Start the initialization of the mapping candidate harvesters.\n\t\t\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\t\t\/\/ time to initialize.\n\t\tnew Thread(MappingCandidateHarvesters::initialize).start();\n\t}","code":"private void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\t\n\t\tStunStack.setPacketLogger(null);\n\t\n\t\tif (cfg != null) {\n\t\t\tList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\n\t\t\tif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\n\t\t\t\tfor (String propertyName : ice4jPropertyNames) {\n\t\t\t\t\tString propertyValue = cfg.getString(propertyName);\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t\tif (propertyValue != null)\n\t\t\t\t\t\tSystem.setProperty(propertyName, propertyValue);\n\t\t\t\t}\n\t\t\t}\n\t\t\n\t\t\n\t\t\tString oldPrefix = \"org.jitsi.videobridge\";\n\t\t\tString newPrefix = \"org.ice4j.ice.harvest\";\n\t\t\tfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\n\t\t\t\t\tHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\n\t\t\t\t\tHarvesterConfiguration.FORCE_AWS_HARVESTER,\n\t\t\t\t\tHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\n\t\t\t\tString propertyValue = cfg.getString(propertyName);\n\t\t\t\tif (propertyValue != null) {\n\t\t\t\t\tString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\n\t\t\t\t\tSystem.setProperty(newPropertyName, propertyValue);\n\t\t\t\t}\n\t\t\t}\n\t\t\tString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\n\t\t\tif (enableLipSync != null) {\n\t\t\t\tSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n\t\t\t}\n\t\t\tString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\n\t\t\tif (disableNackTerminaton != null) {\n\t\t\t\tSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n\t\t\t}\n\t\t}\n\t\n\t\n\t\ttry {\n\t\t\tHostCandidateHarvester.initializeInterfaceFilters();\n\t\t} catch (Exception e) {\n\t\t\tlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n\t\t}\n\t\n\t\n\t\n\t\tnew Thread(MappingCandidateHarvesters::initialize).start();\n\t}","cleancode":"private void startice4j(bundlecontext bundlecontext, configurationservice cfg) { stunstack.setpacketlogger(null); if (cfg != null) { list<string> ice4jpropertynames = cfg.getpropertynamesbyprefix(\"org.ice4j.\", false); if (ice4jpropertynames != null && !ice4jpropertynames.isempty()) { for (string propertyname : ice4jpropertynames) { string propertyvalue = cfg.getstring(propertyname); if (propertyvalue != null) system.setproperty(propertyname, propertyvalue); } } string oldprefix = \"org.jitsi.videobridge\"; string newprefix = \"org.ice4j.ice.harvest\"; for (string propertyname : new string[] { harvesterconfiguration.nat_harvester_local_address, harvesterconfiguration.nat_harvester_public_address, harvesterconfiguration.disable_aws_harvester, harvesterconfiguration.force_aws_harvester, harvesterconfiguration.stun_mapping_harvester_addresses }) { string propertyvalue = cfg.getstring(propertyname); if (propertyvalue != null) { string newpropertyname = newprefix + propertyname.substring(oldprefix.length()); system.setproperty(newpropertyname, propertyvalue); } } string enablelipsync = cfg.getstring(endpoint.enable_lipsync_hack_pname); if (enablelipsync != null) { system.setproperty(videochannel.enable_lipsync_hack_pname, enablelipsync); } string disablenackterminaton = cfg.getstring(videochannel.disable_nack_termination_pname); if (disablenackterminaton != null) { system.setproperty(rtxtransformer.disable_nack_termination_pname, disablenackterminaton); } } try { hostcandidateharvester.initializeinterfacefilters(); } catch (exception e) { logger.warn(\"there were errors during host candidate interface filters\" + \" initialization.\", e); } new thread(mappingcandidateharvesters::initialize).start(); }","comment":"\/** * implements the ice4j-related portion of {@link #start(bundlecontext)}. * * @param bundlecontext the {@code bundlecontext} in which this * {@code videobridge} is to start * @param cfg the {@code configurationservice} registered in * {@code bundlecontext}. explicitly provided for the sake * of performance. *\/\n\/\/ todo packet logging for ice4j is not supported at this time.\n\/\/ make all ice4j properties system properties.\n\/\/ we expect the getstring to return either null or a \/\/ non-empty string object.\n\/\/ these properties are moved to ice4j. this is to make sure that we \/\/ still support the old names.\n\/\/ initialize the the host candidate interface filters in the ice4j \/\/ stack.\n\/\/ start the initialization of the mapping candidate harvesters. \/\/ asynchronous, because the aws and stun harvester may take a long \/\/ time to initialize.","repo":"yatyanng\/jvb","code_context_2":"private void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\n\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\n\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\n\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}","code_context_10":"private void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\n\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}\n\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}","code_context_20":"private void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\n\nprivate void startIce4j(BundleContext bundleContext, ConfigurationService cfg) {\n\/\/ TODO Packet logging for ice4j is not supported at this time.\nStunStack.setPacketLogger(null);\n\/\/ Make all ice4j properties system properties.\nif (cfg != null) {\nList<String> ice4jPropertyNames = cfg.getPropertyNamesByPrefix(\"org.ice4j.\", false);\nif (ice4jPropertyNames != null && !ice4jPropertyNames.isEmpty()) {\nfor (String propertyName : ice4jPropertyNames) {\nString propertyValue = cfg.getString(propertyName);\n\/\/ we expect the getString to return either null or a\n\/\/ non-empty String object.\nif (propertyValue != null)\nSystem.setProperty(propertyName, propertyValue);\n}\n}\n\/\/ These properties are moved to ice4j. This is to make sure that we\n\/\/ still support the old names.\nString oldPrefix = \"org.jitsi.videobridge\";\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n\nString newPrefix = \"org.ice4j.ice.harvest\";\nfor (String propertyName : new String[] { HarvesterConfiguration.NAT_HARVESTER_LOCAL_ADDRESS,\nHarvesterConfiguration.NAT_HARVESTER_PUBLIC_ADDRESS, HarvesterConfiguration.DISABLE_AWS_HARVESTER,\nHarvesterConfiguration.FORCE_AWS_HARVESTER,\nHarvesterConfiguration.STUN_MAPPING_HARVESTER_ADDRESSES }) {\nString propertyValue = cfg.getString(propertyName);\nif (propertyValue != null) {\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}\n\nString newPropertyName = newPrefix + propertyName.substring(oldPrefix.length());\nSystem.setProperty(newPropertyName, propertyValue);\n}\n}\nString enableLipSync = cfg.getString(Endpoint.ENABLE_LIPSYNC_HACK_PNAME);\nif (enableLipSync != null) {\nSystem.setProperty(VideoChannel.ENABLE_LIPSYNC_HACK_PNAME, enableLipSync);\n}\nString disableNackTerminaton = cfg.getString(VideoChannel.DISABLE_NACK_TERMINATION_PNAME);\nif (disableNackTerminaton != null) {\nSystem.setProperty(RtxTransformer.DISABLE_NACK_TERMINATION_PNAME, disableNackTerminaton);\n}\n}\n\/\/ Initialize the the host candidate interface filters in the ice4j\n\/\/ stack.\ntry {\nHostCandidateHarvester.initializeInterfaceFilters();\n} catch (Exception e) {\nlogger.warn(\"There were errors during host candidate interface filters\" + \" initialization.\", e);\n}\n\/\/ Start the initialization of the mapping candidate harvesters.\n\/\/ Asynchronous, because the AWS and STUN harvester may take a long\n\/\/ time to initialize.\nnew Thread(MappingCandidateHarvesters::initialize).start();\n}","label":[0,0,1,0]}
{"id":10668,"original_code":"@RequiresApi(api = Build.VERSION_CODES.JELLY_BEAN_MR1)\n    private void registerDisplayListener() {\n        final DisplayManager displayManager =\n                (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);\n        final Handler handler = new Handler(Looper.getMainLooper());\n        displayManager.registerDisplayListener(mDisplayListener, handler);\n    }","code":"@RequiresApi(api = Build.VERSION_CODES.JELLY_BEAN_MR1)\n    private void registerDisplayListener() {\n        final DisplayManager displayManager =\n                (DisplayManager) getSystemService(Context.DISPLAY_SERVICE);\n        final Handler handler = new Handler(Looper.getMainLooper());\n        displayManager.registerDisplayListener(mDisplayListener, handler);\n    }","cleancode":"@requiresapi(api = build.version_codes.jelly_bean_mr1) private void registerdisplaylistener() { final displaymanager displaymanager = (displaymanager) getsystemservice(context.display_service); final handler handler = new handler(looper.getmainlooper()); displaymanager.registerdisplaylistener(mdisplaylistener, handler); }","comment":"\/** * this method registers a display listener for jb mr1 and higher to workaround a android * deficiency with regard to 180 degree landscape rotation. see {@link displaychangelistener} * documentation for more information. *\/","repo":"thereiskeks\/HayaiLauncher","code_context_2":"@RequiresApi(api = Build.VERSION_CODES.JELLY_BEAN_MR1)\nprivate void registerDisplayListener() {\nfinal DisplayManager displayManager =\n(DisplayManager) getSystemService(Context.DISPLAY_SERVICE);\nfinal Handler handler = new Handler(Looper.getMainLooper());\ndisplayManager.registerDisplayListener(mDisplayListener, handler);\n}","code_context_10":"@RequiresApi(api = Build.VERSION_CODES.JELLY_BEAN_MR1)\nprivate void registerDisplayListener() {\nfinal DisplayManager displayManager =\n(DisplayManager) getSystemService(Context.DISPLAY_SERVICE);\nfinal Handler handler = new Handler(Looper.getMainLooper());\ndisplayManager.registerDisplayListener(mDisplayListener, handler);\n}","code_context_20":"@RequiresApi(api = Build.VERSION_CODES.JELLY_BEAN_MR1)\nprivate void registerDisplayListener() {\nfinal DisplayManager displayManager =\n(DisplayManager) getSystemService(Context.DISPLAY_SERVICE);\nfinal Handler handler = new Handler(Looper.getMainLooper());\ndisplayManager.registerDisplayListener(mDisplayListener, handler);\n}","label":[0,0,0,0]}
{"id":10727,"original_code":"private Point getAbsoluteLocation() throws UiGuardException {\n\t\tif(UiGuardSettings.isIECore()){\n\t\t\treturn getIECoreAbsoluteLocation();\n\t\t}else if(UiGuardSettings.isChromeCore()){\n\t\t\treturn getChromeCoreAbsoluteLocation();\n\t\t}else if(UiGuardSettings.isFirefoxCore()){\n\t\t\treturn getFireFoxCoreAbsoluteLocation();\n\t\t}else{\n\t\t\t\/\/TODO more browser should be supported\n\t\t\tthrow new UiGuardException(\"[Error][This function only support IE,CHROME,FIREFOX by this time]\");\n\t\t}\n\t}","code":"private Point getAbsoluteLocation() throws UiGuardException {\n\t\tif(UiGuardSettings.isIECore()){\n\t\t\treturn getIECoreAbsoluteLocation();\n\t\t}else if(UiGuardSettings.isChromeCore()){\n\t\t\treturn getChromeCoreAbsoluteLocation();\n\t\t}else if(UiGuardSettings.isFirefoxCore()){\n\t\t\treturn getFireFoxCoreAbsoluteLocation();\n\t\t}else{\n\t\t\n\t\t\tthrow new UiGuardException(\"[Error][This function only support IE,CHROME,FIREFOX by this time]\");\n\t\t}\n\t}","cleancode":"private point getabsolutelocation() throws uiguardexception { if(uiguardsettings.isiecore()){ return getiecoreabsolutelocation(); }else if(uiguardsettings.ischromecore()){ return getchromecoreabsolutelocation(); }else if(uiguardsettings.isfirefoxcore()){ return getfirefoxcoreabsolutelocation(); }else{ throw new uiguardexception(\"[error][this function only support ie,chrome,firefox by this time]\"); } }","comment":"\/\/todo more browser should be supported","repo":"uiguard\/uiguard","code_context_2":"return getFireFoxCoreAbsoluteLocation();\n}else{\n\/\/TODO more browser should be supported\nthrow new UiGuardException(\"[Error][This function only support IE,CHROME,FIREFOX by this time]\");\n}","code_context_10":"private Point getAbsoluteLocation() throws UiGuardException {\nif(UiGuardSettings.isIECore()){\nreturn getIECoreAbsoluteLocation();\n}else if(UiGuardSettings.isChromeCore()){\nreturn getChromeCoreAbsoluteLocation();\n}else if(UiGuardSettings.isFirefoxCore()){\nreturn getFireFoxCoreAbsoluteLocation();\n}else{\n\/\/TODO more browser should be supported\nthrow new UiGuardException(\"[Error][This function only support IE,CHROME,FIREFOX by this time]\");\n}\n}","code_context_20":"private Point getAbsoluteLocation() throws UiGuardException {\nif(UiGuardSettings.isIECore()){\nreturn getIECoreAbsoluteLocation();\n}else if(UiGuardSettings.isChromeCore()){\nreturn getChromeCoreAbsoluteLocation();\n}else if(UiGuardSettings.isFirefoxCore()){\nreturn getFireFoxCoreAbsoluteLocation();\n}else{\n\/\/TODO more browser should be supported\nthrow new UiGuardException(\"[Error][This function only support IE,CHROME,FIREFOX by this time]\");\n}\n}","label":[0,1,0,0]}
{"id":10867,"original_code":"public static void addJsonToGrid (\n            OutputStream outputStream,\n            AccessibilityResult accessibilityResult,\n            List<TaskError> scenarioApplicationWarnings,\n            List<TaskError> scenarioApplicationInfo,\n            PathResult pathResult\n    ) throws IOException {\n        var jsonBlock = new GridJsonBlock();\n        jsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\n        jsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\n        if (accessibilityResult != null) {\n            \/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n            \/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n            \/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\n            jsonBlock.accessibility = accessibilityResult.getIntValues();\n        }\n        jsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\n        LOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n        \/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n        \/\/ But then you also have to handle the case where you are returning raw bytes.\n        JsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\n        LOG.debug(\"Done writing\");\n    }","code":"public static void addJsonToGrid (\n            OutputStream outputStream,\n            AccessibilityResult accessibilityResult,\n            List<TaskError> scenarioApplicationWarnings,\n            List<TaskError> scenarioApplicationInfo,\n            PathResult pathResult\n    ) throws IOException {\n        var jsonBlock = new GridJsonBlock();\n        jsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\n        jsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\n        if (accessibilityResult != null) {\n           \n           \n           \n            jsonBlock.accessibility = accessibilityResult.getIntValues();\n        }\n        jsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\n        LOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n       \n       \n        JsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\n        LOG.debug(\"Done writing\");\n    }","cleancode":"public static void addjsontogrid ( outputstream outputstream, accessibilityresult accessibilityresult, list<taskerror> scenarioapplicationwarnings, list<taskerror> scenarioapplicationinfo, pathresult pathresult ) throws ioexception { var jsonblock = new gridjsonblock(); jsonblock.scenarioapplicationinfo = scenarioapplicationinfo; jsonblock.scenarioapplicationwarnings = scenarioapplicationwarnings; if (accessibilityresult != null) { jsonblock.accessibility = accessibilityresult.getintvalues(); } jsonblock.pathsummaries = pathresult == null ? collections.empty_list : pathresult.getpathiterationsfordestination(); log.debug(\"travel time surface written, appending {}.\", jsonblock); jsonutilities.objectmapper.writevalue(outputstream, jsonblock); log.debug(\"done writing\"); }","comment":"\/** * our binary travel time grid format ends with a block of json containing additional structured data. * this includes * this is somewhat hackish - when we want to return errors to the ui, we just append them as json at the end of * we always append this json even when it won't contain anything so the ui has something to decode. * the response's http status code is set by the caller - it may be an error or not. if we only have warnings * and no serious errors, we use a success error code. * todo distinguish between warnings and errors - we already distinguish between info and warnings. * this could be turned into a gridjsonblock constructor, with the json writing code in an instance method. *\/\n\/\/ due to the application of distance decay functions, we may want to make the shift to non-integer \/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole \/\/ study area). but we'd need to control the number of decimal places serialized into the json.\n\/\/ we could do this when setting up the spark handler, supplying writevalue as the response transformer \/\/ but then you also have to handle the case where you are returning raw bytes.","repo":"vlc\/r5","code_context_2":"public static void addJsonToGrid (\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}\n\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\n\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");","code_context_10":"public static void addJsonToGrid (\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}\n\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}\n\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}","code_context_20":"public static void addJsonToGrid (\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}\n\npublic static void addJsonToGrid (\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}\n\npublic static void addJsonToGrid (\nOutputStream outputStream,\nAccessibilityResult accessibilityResult,\nList<TaskError> scenarioApplicationWarnings,\nList<TaskError> scenarioApplicationInfo,\nPathResult pathResult\n) throws IOException {\nvar jsonBlock = new GridJsonBlock();\njsonBlock.scenarioApplicationInfo = scenarioApplicationInfo;\njsonBlock.scenarioApplicationWarnings = scenarioApplicationWarnings;\nif (accessibilityResult != null) {\n\/\/ Due to the application of distance decay functions, we may want to make the shift to non-integer\n\/\/ accessibility values (especially for cases where there are relatively few opportunities across the whole\n\/\/ study area). But we'd need to control the number of decimal places serialized into the JSON.\njsonBlock.accessibility = accessibilityResult.getIntValues();\n}\njsonBlock.pathSummaries = pathResult == null ? Collections.EMPTY_LIST : pathResult.getPathIterationsForDestination();\nLOG.debug(\"Travel time surface written, appending {}.\", jsonBlock);\n\/\/ We could do this when setting up the Spark handler, supplying writeValue as the response transformer\n\/\/ But then you also have to handle the case where you are returning raw bytes.\nJsonUtilities.objectMapper.writeValue(outputStream, jsonBlock);\nLOG.debug(\"Done writing\");\n}","label":[1,0,0,0]}
{"id":2693,"original_code":"public void testArrayEnumerationWithDataModification() throws CouchbaseLiteException {\n        MutableArray array = new MutableArray();\n        for (int i = 0; i < 2; i++)\n            array.addValue(i);\n        Iterator<Object> itr = array.iterator();\n        int count = 0;\n        try {\n            while (itr.hasNext()) {\n                itr.next();\n                if (count++ == 0)\n                    array.addValue(2);\n            }\n            fail(\"Expected ConcurrentModificationException\");\n        } catch (ConcurrentModificationException e) {\n        }\n        assertEquals(3, array.count());\n        assertEquals(Arrays.asList(0, 1, 2).toString(), array.toList().toString());\n        MutableDocument doc = createMutableDocument(\"doc1\");\n        doc.setValue(\"array\", array);\n        doc = save(doc).toMutable();\n        array = doc.getArray(\"array\");\n        itr = array.iterator();\n        count = 0;\n        try {\n            while (itr.hasNext()) {\n                itr.next();\n                if (count++ == 0)\n                    array.addValue(3);\n            }\n            fail(\"Expected ConcurrentModificationException\");\n        } catch (ConcurrentModificationException e) {\n        }\n        assertEquals(4, array.count());\n        assertEquals(Arrays.asList(0, 1, 2, 3).toString(), array.toList().toString());\n    }","code":"public void testArrayEnumerationWithDataModification() throws CouchbaseLiteException {\n        MutableArray array = new MutableArray();\n        for (int i = 0; i < 2; i++)\n            array.addValue(i);\n        Iterator<Object> itr = array.iterator();\n        int count = 0;\n        try {\n            while (itr.hasNext()) {\n                itr.next();\n                if (count++ == 0)\n                    array.addValue(2);\n            }\n            fail(\"Expected ConcurrentModificationException\");\n        } catch (ConcurrentModificationException e) {\n        }\n        assertEquals(3, array.count());\n        assertEquals(Arrays.asList(0, 1, 2).toString(), array.toList().toString());\n        MutableDocument doc = createMutableDocument(\"doc1\");\n        doc.setValue(\"array\", array);\n        doc = save(doc).toMutable();\n        array = doc.getArray(\"array\");\n        itr = array.iterator();\n        count = 0;\n        try {\n            while (itr.hasNext()) {\n                itr.next();\n                if (count++ == 0)\n                    array.addValue(3);\n            }\n            fail(\"Expected ConcurrentModificationException\");\n        } catch (ConcurrentModificationException e) {\n        }\n        assertEquals(4, array.count());\n        assertEquals(Arrays.asList(0, 1, 2, 3).toString(), array.toList().toString());\n    }","cleancode":"public void testarrayenumerationwithdatamodification() throws couchbaseliteexception { mutablearray array = new mutablearray(); for (int i = 0; i < 2; i++) array.addvalue(i); iterator<object> itr = array.iterator(); int count = 0; try { while (itr.hasnext()) { itr.next(); if (count++ == 0) array.addvalue(2); } fail(\"expected concurrentmodificationexception\"); } catch (concurrentmodificationexception e) { } assertequals(3, array.count()); assertequals(arrays.aslist(0, 1, 2).tostring(), array.tolist().tostring()); mutabledocument doc = createmutabledocument(\"doc1\"); doc.setvalue(\"array\", array); doc = save(doc).tomutable(); array = doc.getarray(\"array\"); itr = array.iterator(); count = 0; try { while (itr.hasnext()) { itr.next(); if (count++ == 0) array.addvalue(3); } fail(\"expected concurrentmodificationexception\"); } catch (concurrentmodificationexception e) { } assertequals(4, array.count()); assertequals(arrays.aslist(0, 1, 2, 3).tostring(), array.tolist().tostring()); }","comment":"\/\/ todo: marray has ismuated() method, but unable to check mutated to mutated. \/\/ @test","repo":"zebra1024\/couchbase-lite-android","code_context_2":"public void testArrayEnumerationWithDataModification() throws CouchbaseLiteException {\nMutableArray array = new MutableArray();\nfor (int i = 0; i < 2; i++)\narray.addValue(i);\nIterator<Object> itr = array.iterator();\nint count = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(2);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(3, array.count());\nassertEquals(Arrays.asList(0, 1, 2).toString(), array.toList().toString());\nMutableDocument doc = createMutableDocument(\"doc1\");\ndoc.setValue(\"array\", array);\ndoc = save(doc).toMutable();\narray = doc.getArray(\"array\");\nitr = array.iterator();\ncount = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(3);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(4, array.count());\nassertEquals(Arrays.asList(0, 1, 2, 3).toString(), array.toList().toString());\n}","code_context_10":"public void testArrayEnumerationWithDataModification() throws CouchbaseLiteException {\nMutableArray array = new MutableArray();\nfor (int i = 0; i < 2; i++)\narray.addValue(i);\nIterator<Object> itr = array.iterator();\nint count = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(2);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(3, array.count());\nassertEquals(Arrays.asList(0, 1, 2).toString(), array.toList().toString());\nMutableDocument doc = createMutableDocument(\"doc1\");\ndoc.setValue(\"array\", array);\ndoc = save(doc).toMutable();\narray = doc.getArray(\"array\");\nitr = array.iterator();\ncount = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(3);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(4, array.count());\nassertEquals(Arrays.asList(0, 1, 2, 3).toString(), array.toList().toString());\n}","code_context_20":"public void testArrayEnumerationWithDataModification() throws CouchbaseLiteException {\nMutableArray array = new MutableArray();\nfor (int i = 0; i < 2; i++)\narray.addValue(i);\nIterator<Object> itr = array.iterator();\nint count = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(2);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(3, array.count());\nassertEquals(Arrays.asList(0, 1, 2).toString(), array.toList().toString());\nMutableDocument doc = createMutableDocument(\"doc1\");\ndoc.setValue(\"array\", array);\ndoc = save(doc).toMutable();\narray = doc.getArray(\"array\");\nitr = array.iterator();\ncount = 0;\ntry {\nwhile (itr.hasNext()) {\nitr.next();\nif (count++ == 0)\narray.addValue(3);\n}\nfail(\"Expected ConcurrentModificationException\");\n} catch (ConcurrentModificationException e) {\n}\nassertEquals(4, array.count());\nassertEquals(Arrays.asList(0, 1, 2, 3).toString(), array.toList().toString());\n}","label":[0,0,0,1]}
{"id":19120,"original_code":"@GET\n    @Path(\"updates\")\n    public Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\n        return worldRepository.inSession(session -> {\n            \/\/ FIXME: not supported\n            \/\/          session.setJdbcBatchSize(worlds.size());\n            session.setFlushMode(FlushMode.MANUAL);\n            var worlds = randomWorldForRead(session, parseQueryCount(queries));\n            return worlds.flatMap(worldsCollection -> {\n                worldsCollection.forEach( w -> {\n                    \/\/Read the one field, as required by the following rule:\n                    \/\/ # vi. At least the randomNumber field must be read from the database result set.\n                    final int previousRead = w.getRandomNumber();\n                    \/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n                    \/\/the verification:\n                    w.setRandomNumber(randomWorldNumber(previousRead));\n                } );\n                return worldRepository.update(session, worldsCollection);\n            });\n        });\n    }","code":"@GET\n    @Path(\"updates\")\n    public Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\n        return worldRepository.inSession(session -> {\n           \n           \n            session.setFlushMode(FlushMode.MANUAL);\n            var worlds = randomWorldForRead(session, parseQueryCount(queries));\n            return worlds.flatMap(worldsCollection -> {\n                worldsCollection.forEach( w -> {\n                   \n                   \n                    final int previousRead = w.getRandomNumber();\n                   \n                   \n                    w.setRandomNumber(randomWorldNumber(previousRead));\n                } );\n                return worldRepository.update(session, worldsCollection);\n            });\n        });\n    }","cleancode":"@get @path(\"updates\") public uni<collection<world>> updates(@queryparam(\"queries\") string queries) { return worldrepository.insession(session -> { session.setflushmode(flushmode.manual); var worlds = randomworldforread(session, parsequerycount(queries)); return worlds.flatmap(worldscollection -> { worldscollection.foreach( w -> { final int previousread = w.getrandomnumber(); w.setrandomnumber(randomworldnumber(previousread)); } ); return worldrepository.update(session, worldscollection); }); }); }","comment":"\/\/ fixme: not supported \/\/ session.setjdbcbatchsize(worlds.size());\n\/\/read the one field, as required by the following rule: \/\/ # vi. at least the randomnumber field must be read from the database result set.\n\/\/update it, but make sure to exclude the current number as hibernate optimisations would have us \"fail\" \/\/the verification:","repo":"tommilligan\/FrameworkBenchmarks","code_context_2":"public Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\n\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );","code_context_10":"@GET\n@Path(\"updates\")\npublic Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n\n@GET\n@Path(\"updates\")\npublic Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );\nreturn worldRepository.update(session, worldsCollection);\n});\n});\n}\n\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );\nreturn worldRepository.update(session, worldsCollection);\n});\n});\n}","code_context_20":"@GET\n@Path(\"updates\")\npublic Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );\nreturn worldRepository.update(session, worldsCollection);\n});\n});\n}\n\n@GET\n@Path(\"updates\")\npublic Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );\nreturn worldRepository.update(session, worldsCollection);\n});\n});\n}\n\n@GET\n@Path(\"updates\")\npublic Uni<Collection<World>> updates(@QueryParam(\"queries\") String queries) {\nreturn worldRepository.inSession(session -> {\n\/\/ FIXME: not supported\n\/\/ session.setJdbcBatchSize(worlds.size());\nsession.setFlushMode(FlushMode.MANUAL);\nvar worlds = randomWorldForRead(session, parseQueryCount(queries));\nreturn worlds.flatMap(worldsCollection -> {\nworldsCollection.forEach( w -> {\n\/\/Read the one field, as required by the following rule:\n\/\/ # vi. At least the randomNumber field must be read from the database result set.\nfinal int previousRead = w.getRandomNumber();\n\/\/Update it, but make sure to exclude the current number as Hibernate optimisations would have us \"fail\"\n\/\/the verification:\nw.setRandomNumber(randomWorldNumber(previousRead));\n} );\nreturn worldRepository.update(session, worldsCollection);\n});\n});\n}","label":[0,0,1,0]}
{"id":19230,"original_code":"public static LocalDefUse fromBundleFragment(Map<String, Object> bundleFragment) {\n        \/\/ TODO deserialize the lambda block...\n        return new LocalDefUse(null);\n    }","code":"public static LocalDefUse fromBundleFragment(Map<String, Object> bundleFragment) {\n       \n        return new LocalDefUse(null);\n    }","cleancode":"public static localdefuse frombundlefragment(map<string, object> bundlefragment) { return new localdefuse(null); }","comment":"\/\/ todo deserialize the lambda block...","repo":"undeadinu\/viskell","code_context_2":"public static LocalDefUse fromBundleFragment(Map<String, Object> bundleFragment) {\n\/\/ TODO deserialize the lambda block...\nreturn new LocalDefUse(null);\n}","code_context_10":"public static LocalDefUse fromBundleFragment(Map<String, Object> bundleFragment) {\n\/\/ TODO deserialize the lambda block...\nreturn new LocalDefUse(null);\n}","code_context_20":"public static LocalDefUse fromBundleFragment(Map<String, Object> bundleFragment) {\n\/\/ TODO deserialize the lambda block...\nreturn new LocalDefUse(null);\n}","label":[0,1,0,0]}
{"id":19238,"original_code":"int getRankInBlock(int rankPosition) {\n    if (rank == null) {\n      return -1;\n    }\n    assert rankPosition == denseRankPosition(rankPosition);\n    int rankIndex = rankPosition >> RANK_BLOCK_BITS;\n    return rankIndex >= rank.size() ? -1 : (int) rank.get(rankIndex);\n  }","code":"int getRankInBlock(int rankPosition) {\n    if (rank == null) {\n      return -1;\n    }\n    assert rankPosition == denseRankPosition(rankPosition);\n    int rankIndex = rankPosition >> RANK_BLOCK_BITS;\n    return rankIndex >= rank.size() ? -1 : (int) rank.get(rankIndex);\n  }","cleancode":"int getrankinblock(int rankposition) { if (rank == null) { return -1; } assert rankposition == denserankposition(rankposition); int rankindex = rankposition >> rank_block_bits; return rankindex >= rank.size() ? -1 : (int) rank.get(rankindex); }","comment":"\/** * get the rank (index) for all set bits up to just before the given rankposition in the block. * the caller is responsible for deriving the count of bits up to the docid target from the rankposition. * the caller is also responsible for keeping track of set bits up to the current block. * important: this only accepts rankpositions that aligns to {@link #rank_block} boundaries. * note 1: use {@link #denserankposition(int)} to obtain a calid rankposition for a wanted docid. * note 2: the caller should seek to the rankposition in the underlying slice to keep everything in sync. * @param rankposition a docid target that aligns to {@link #rank_block}. * @return the rank (index \/ set bits count) up to just before the given rankposition. * if rank is disabled, -1 is returned. *\/ \/\/ todo: this method requires a lot of knowledge of the intrinsics of the cache. usage should be simplified","repo":"tafgit\/ToF-Test","code_context_2":"int getRankInBlock(int rankPosition) {\nif (rank == null) {\nreturn -1;\n}\nassert rankPosition == denseRankPosition(rankPosition);\nint rankIndex = rankPosition >> RANK_BLOCK_BITS;\nreturn rankIndex >= rank.size() ? -1 : (int) rank.get(rankIndex);\n}","code_context_10":"int getRankInBlock(int rankPosition) {\nif (rank == null) {\nreturn -1;\n}\nassert rankPosition == denseRankPosition(rankPosition);\nint rankIndex = rankPosition >> RANK_BLOCK_BITS;\nreturn rankIndex >= rank.size() ? -1 : (int) rank.get(rankIndex);\n}","code_context_20":"int getRankInBlock(int rankPosition) {\nif (rank == null) {\nreturn -1;\n}\nassert rankPosition == denseRankPosition(rankPosition);\nint rankIndex = rankPosition >> RANK_BLOCK_BITS;\nreturn rankIndex >= rank.size() ? -1 : (int) rank.get(rankIndex);\n}","label":[1,0,0,0]}
{"id":2942,"original_code":"@Override\n    public Boolean visit(CFieldReference pE) {\n      return !alreadyAssigned.contains(pE);\n    }","code":"@Override\n    public Boolean visit(CFieldReference pE) {\n      return !alreadyAssigned.contains(pE);\n    }","cleancode":"@override public boolean visit(cfieldreference pe) { return !alreadyassigned.contains(pe); }","comment":"\/\/todo complex cast","repo":"wqythu13\/Test","code_context_2":"@Override\npublic Boolean visit(CFieldReference pE) {\nreturn !alreadyAssigned.contains(pE);\n}","code_context_10":"@Override\npublic Boolean visit(CFieldReference pE) {\nreturn !alreadyAssigned.contains(pE);\n}","code_context_20":"@Override\npublic Boolean visit(CFieldReference pE) {\nreturn !alreadyAssigned.contains(pE);\n}","label":[1,0,0,0]}
{"id":3182,"original_code":"protected List<T> getList(String[] projection, String selection, String[] selectionArgs,\n                              String sortOrder, Integer limit) {\n        List<T> rows = new ArrayList<>();\n        \/\/noinspection TryWithIdenticalCatches\n        try {\n            Cursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\n            if (c != null) {\n                if (c.moveToFirst()) {\n                    int i = 0;\n                    Constructor<T> constructor =\n                        mTableRowClass.getConstructor(this.getClass(), Cursor.class);\n                    do {\n                        rows.add(constructor.newInstance(this, c));\n                        i++;\n                    } while ((limit == null || limit > i) && c.moveToNext());\n                }\n                c.close();\n            }\n        } catch (NoSuchMethodException e) {\n            e.printStackTrace();\n            \/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n            \/\/ then, we would have to handle this on every object instantiation, but these\n            \/\/ exceptions should never throw in production, since these are static code issues\n            \/\/ (wrongly defined classes) which should be handled once, straight away and then\n            \/\/ never change again.\n            System.exit(-1);\n        } catch (InstantiationException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        } catch (InvocationTargetException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        }\n        return rows;\n    }","code":"protected List<T> getList(String[] projection, String selection, String[] selectionArgs,\n                              String sortOrder, Integer limit) {\n        List<T> rows = new ArrayList<>();\n       \n        try {\n            Cursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\n            if (c != null) {\n                if (c.moveToFirst()) {\n                    int i = 0;\n                    Constructor<T> constructor =\n                        mTableRowClass.getConstructor(this.getClass(), Cursor.class);\n                    do {\n                        rows.add(constructor.newInstance(this, c));\n                        i++;\n                    } while ((limit == null || limit > i) && c.moveToNext());\n                }\n                c.close();\n            }\n        } catch (NoSuchMethodException e) {\n            e.printStackTrace();\n           \n           \n           \n           \n           \n            System.exit(-1);\n        } catch (InstantiationException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        } catch (IllegalAccessException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        } catch (InvocationTargetException e) {\n            e.printStackTrace();\n            System.exit(-1);\n        }\n        return rows;\n    }","cleancode":"protected list<t> getlist(string[] projection, string selection, string[] selectionargs, string sortorder, integer limit) { list<t> rows = new arraylist<>(); try { cursor c = mcr.query(muri, projection, selection, selectionargs, sortorder); if (c != null) { if (c.movetofirst()) { int i = 0; constructor<t> constructor = mtablerowclass.getconstructor(this.getclass(), cursor.class); do { rows.add(constructor.newinstance(this, c)); i++; } while ((limit == null || limit > i) && c.movetonext()); } c.close(); } } catch (nosuchmethodexception e) { e.printstacktrace(); system.exit(-1); } catch (instantiationexception e) { e.printstacktrace(); system.exit(-1); } catch (illegalaccessexception e) { e.printstacktrace(); system.exit(-1); } catch (invocationtargetexception e) { e.printstacktrace(); system.exit(-1); } return rows; }","comment":"\/** * <p> * fetch the selected rows ordered by the given order with limit. * <p> * your {@link tablerow} implementation will need a constructor like this: * {@link tablerow#tablerow(table, cursor)} \u2013 otherwise this method will fail horribly, in order * to warn you as early as possible about the design failure. * <\/p> * * @param projection * a list of which columns to return. passing null will return all columns, which * is inefficient. * @param selection * a filter declaring which rows to return, formatted as an sql where clause * (excluding the where itself). * passing null will return all rows for the given uri. * @param selectionargs * you may include ?s in selection, which will be replaced by the values * from selectionargs, in the order that they appear in the selection. * the values will be bound as strings. * @param sortorder * how to order the rows, formatted as an sql order by clause (excluding the * order by itself). passing null will use the default sort order, * which may be unordered. * @param limit * a maximum amount of result entries. * @return a {@link list} of {@link tablerow}s, possibly empty, never null. *\/\n\/\/noinspection trywithidenticalcatches\n\/\/ we don't want to pass the exceptions up or rethrow a more generic exception, since \/\/ then, we would have to handle this on every object instantiation, but these \/\/ exceptions should never throw in production, since these are static code issues \/\/ (wrongly defined classes) which should be handled once, straight away and then \/\/ never change again.","repo":"tladesignz\/DNATools","code_context_2":"protected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (IllegalAccessException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (InvocationTargetException e) {\ne.printStackTrace();\nSystem.exit(-1);\n}\nreturn rows;\n}\n\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\n\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {","code_context_10":"protected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (IllegalAccessException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (InvocationTargetException e) {\ne.printStackTrace();\nSystem.exit(-1);\n}\nreturn rows;\n}\n\nprotected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (IllegalAccessException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (InvocationTargetException e) {\ne.printStackTrace();\nSystem.exit(-1);","code_context_20":"protected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (IllegalAccessException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (InvocationTargetException e) {\ne.printStackTrace();\nSystem.exit(-1);\n}\nreturn rows;\n}\n\nprotected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\nprotected List<T> getList(String[] projection, String selection, String[] selectionArgs,\nString sortOrder, Integer limit) {\nList<T> rows = new ArrayList<>();\n\/\/noinspection TryWithIdenticalCatches\ntry {\nCursor c = mCr.query(mUri, projection, selection, selectionArgs, sortOrder);\nif (c != null) {\nif (c.moveToFirst()) {\nint i = 0;\nConstructor<T> constructor =\nmTableRowClass.getConstructor(this.getClass(), Cursor.class);\ndo {\nrows.add(constructor.newInstance(this, c));\ni++;\n} while ((limit == null || limit > i) && c.moveToNext());\n}\nc.close();\n}\n} catch (NoSuchMethodException e) {\ne.printStackTrace();\n\/\/ We don't want to pass the exceptions up or rethrow a more generic exception, since\n\/\/ then, we would have to handle this on every object instantiation, but these\n\/\/ exceptions should never throw in production, since these are static code issues\n\/\/ (wrongly defined classes) which should be handled once, straight away and then\n\/\/ never change again.\nSystem.exit(-1);\n} catch (InstantiationException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (IllegalAccessException e) {\ne.printStackTrace();\nSystem.exit(-1);\n} catch (InvocationTargetException e) {\ne.printStackTrace();\nSystem.exit(-1);\n}\nreturn rows;\n}","label":[0,0,1,0]}
{"id":3186,"original_code":"protected List<T> getList(String selection) {\n        return getList(selection, null);\n    }","code":"protected List<T> getList(String selection) {\n        return getList(selection, null);\n    }","cleancode":"protected list<t> getlist(string selection) { return getlist(selection, null); }","comment":"\/** * <p> * fetch the selected rows unordered and unlimited. * <p> * your {@link tablerow} implementation will need a constructor like this: * {@link tablerow#tablerow(table, cursor)} \u2013 otherwise this method will fail horribly, in order * to warn you as early as possible about the design failure. * <\/p> * * @param selection * a filter declaring which rows to return, formatted as an sql where clause * (excluding the where itself). * passing null will return all rows for the given uri. * @return a list of {@link tablerow}s, possibly empty, never null. *\/","repo":"tladesignz\/DNATools","code_context_2":"protected List<T> getList(String selection) {\nreturn getList(selection, null);\n}","code_context_10":"protected List<T> getList(String selection) {\nreturn getList(selection, null);\n}","code_context_20":"protected List<T> getList(String selection) {\nreturn getList(selection, null);\n}","label":[0,0,1,0]}
{"id":3187,"original_code":"@SuppressWarnings(\"unused\")\n    protected List<T> getList() {\n        return getList(null);\n    }","code":"@SuppressWarnings(\"unused\")\n    protected List<T> getList() {\n        return getList(null);\n    }","cleancode":"@suppresswarnings(\"unused\") protected list<t> getlist() { return getlist(null); }","comment":"\/** * <p> * fetch all rows in the table, unordered. * <p> * your {@link tablerow} implementation will need a constructor like this: * {@link tablerow#tablerow(table, cursor)} \u2013 otherwise this method will fail horribly, in order * to warn you as early as possible about the design failure. * <\/p> * * @return a {@link list} of {@link tablerow}s, possibly empty, never null. *\/","repo":"tladesignz\/DNATools","code_context_2":"@SuppressWarnings(\"unused\")\nprotected List<T> getList() {\nreturn getList(null);\n}","code_context_10":"@SuppressWarnings(\"unused\")\nprotected List<T> getList() {\nreturn getList(null);\n}","code_context_20":"@SuppressWarnings(\"unused\")\nprotected List<T> getList() {\nreturn getList(null);\n}","label":[0,0,1,0]}
{"id":3192,"original_code":"@SuppressWarnings(\"unused\")\n    protected T get(String[] selectionArgs) {\n        return get(mUniqueRowSelection, selectionArgs);\n    }","code":"@SuppressWarnings(\"unused\")\n    protected T get(String[] selectionArgs) {\n        return get(mUniqueRowSelection, selectionArgs);\n    }","cleancode":"@suppresswarnings(\"unused\") protected t get(string[] selectionargs) { return get(muniquerowselection, selectionargs); }","comment":"\/** * <p> * fetch a unique row as defined in the constructor. * <p> * your {@link tablerow} implementation will need a constructor like this: * {@link tablerow#tablerow(table, cursor)} \u2013 otherwise this method will fail horribly, in order * to warn you as early as possible about the design failure. * <\/p> * * @param selectionargs * values for all columns which identify a row uniquely. * * @return a {@link tablerow}, possibly null. *\/","repo":"tladesignz\/DNATools","code_context_2":"@SuppressWarnings(\"unused\")\nprotected T get(String[] selectionArgs) {\nreturn get(mUniqueRowSelection, selectionArgs);\n}","code_context_10":"@SuppressWarnings(\"unused\")\nprotected T get(String[] selectionArgs) {\nreturn get(mUniqueRowSelection, selectionArgs);\n}","code_context_20":"@SuppressWarnings(\"unused\")\nprotected T get(String[] selectionArgs) {\nreturn get(mUniqueRowSelection, selectionArgs);\n}","label":[0,0,1,0]}
{"id":19585,"original_code":"@Override\n    public boolean onPaymentAppCreated(PaymentApp paymentApp) {\n        \/\/ Ignores the service worker payment apps in WebLayer until -\n        \/\/ TODO(crbug.com\/1224420): WebLayer supports Service worker payment apps.\n        return paymentApp.getPaymentAppType() != PaymentAppType.SERVICE_WORKER_APP;\n    }","code":"@Override\n    public boolean onPaymentAppCreated(PaymentApp paymentApp) {\n       \n       \n        return paymentApp.getPaymentAppType() != PaymentAppType.SERVICE_WORKER_APP;\n    }","cleancode":"@override public boolean onpaymentappcreated(paymentapp paymentapp) { return paymentapp.getpaymentapptype() != paymentapptype.service_worker_app; }","comment":"\/\/ ignores the service worker payment apps in weblayer until - \/\/ todo(crbug.com\/1224420): weblayer supports service worker payment apps.","repo":"zealoussnow\/chromium","code_context_2":"@Override\npublic boolean onPaymentAppCreated(PaymentApp paymentApp) {\n\/\/ Ignores the service worker payment apps in WebLayer until -\n\/\/ TODO(crbug.com\/1224420): WebLayer supports Service worker payment apps.\nreturn paymentApp.getPaymentAppType() != PaymentAppType.SERVICE_WORKER_APP;\n}","code_context_10":"@Override\npublic boolean onPaymentAppCreated(PaymentApp paymentApp) {\n\/\/ Ignores the service worker payment apps in WebLayer until -\n\/\/ TODO(crbug.com\/1224420): WebLayer supports Service worker payment apps.\nreturn paymentApp.getPaymentAppType() != PaymentAppType.SERVICE_WORKER_APP;\n}","code_context_20":"@Override\npublic boolean onPaymentAppCreated(PaymentApp paymentApp) {\n\/\/ Ignores the service worker payment apps in WebLayer until -\n\/\/ TODO(crbug.com\/1224420): WebLayer supports Service worker payment apps.\nreturn paymentApp.getPaymentAppType() != PaymentAppType.SERVICE_WORKER_APP;\n}","label":[0,1,0,0]}
{"id":11432,"original_code":"public String toXml(int indentLevel){\n        String indent = \"\";\n        for (int i = 1; i <= indentLevel; i++)\n            indent = indent + \"\\t\";\n        String xml = indent + \"<MonitorCategory id='\" + this.id + \"' name='\" +\n                this.name + \"' priority='\" + this.priority + \"' status='\" +\n                this.status + \"' delete_time='\" +\n                this.deleteTime + \"' note='\" +\n                this.note + \"' \/>\";\n        return xml;\n    }","code":"public String toXml(int indentLevel){\n        String indent = \"\";\n        for (int i = 1; i <= indentLevel; i++)\n            indent = indent + \"\\t\";\n        String xml = indent + \"<MonitorCategory id='\" + this.id + \"' name='\" +\n                this.name + \"' priority='\" + this.priority + \"' status='\" +\n                this.status + \"' delete_time='\" +\n                this.deleteTime + \"' note='\" +\n                this.note + \"' \/>\";\n        return xml;\n    }","cleancode":"public string toxml(int indentlevel){ string indent = \"\"; for (int i = 1; i <= indentlevel; i++) indent = indent + \"\\t\"; string xml = indent + \"<monitorcategory id='\" + this.id + \"' name='\" + this.name + \"' priority='\" + this.priority + \"' status='\" + this.status + \"' delete_time='\" + this.deletetime + \"' note='\" + this.note + \"' \/>\"; return xml; }","comment":"\/** * todo comment em * @return *\/","repo":"tabneib\/petimo","code_context_2":"public String toXml(int indentLevel){\nString indent = \"\";\nfor (int i = 1; i <= indentLevel; i++)\nindent = indent + \"\\t\";\nString xml = indent + \"<MonitorCategory id='\" + this.id + \"' name='\" +\nthis.name + \"' priority='\" + this.priority + \"' status='\" +\nthis.status + \"' delete_time='\" +\nthis.deleteTime + \"' note='\" +\nthis.note + \"' \/>\";\nreturn xml;\n}","code_context_10":"public String toXml(int indentLevel){\nString indent = \"\";\nfor (int i = 1; i <= indentLevel; i++)\nindent = indent + \"\\t\";\nString xml = indent + \"<MonitorCategory id='\" + this.id + \"' name='\" +\nthis.name + \"' priority='\" + this.priority + \"' status='\" +\nthis.status + \"' delete_time='\" +\nthis.deleteTime + \"' note='\" +\nthis.note + \"' \/>\";\nreturn xml;\n}","code_context_20":"public String toXml(int indentLevel){\nString indent = \"\";\nfor (int i = 1; i <= indentLevel; i++)\nindent = indent + \"\\t\";\nString xml = indent + \"<MonitorCategory id='\" + this.id + \"' name='\" +\nthis.name + \"' priority='\" + this.priority + \"' status='\" +\nthis.status + \"' delete_time='\" +\nthis.deleteTime + \"' note='\" +\nthis.note + \"' \/>\";\nreturn xml;\n}","label":[0,0,0,0]}
{"id":19939,"original_code":"public boolean reachedAllGoals ( ) {\n\t\tfor ( EarliestLayerSVA goal : this.g ) {\n\t\t\tif ( goal == null || goal.earliestLayer == -1 ) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}","code":"public boolean reachedAllGoals ( ) {\n\t\tfor ( EarliestLayerSVA goal : this.g ) {\n\t\t\tif ( goal == null || goal.earliestLayer == -1 ) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}","cleancode":"public boolean reachedallgoals ( ) { for ( earliestlayersva goal : this.g ) { if ( goal == null || goal.earliestlayer == -1 ) { return false; } } return true; }","comment":"\/** * test if all goals were reached. * todo: this goal can be null due to problems with initial state (probably unreachable goal\/missing initial state variable) * @return <code>true<\/code> if all goals are reached, <code>false<\/code> otherwise. *\/","repo":"uwe-koeckemann\/SpiderPlan","code_context_2":"public boolean reachedAllGoals ( ) {\nfor ( EarliestLayerSVA goal : this.g ) {\nif ( goal == null || goal.earliestLayer == -1 ) {\nreturn false;\n}\n}\nreturn true;\n}","code_context_10":"public boolean reachedAllGoals ( ) {\nfor ( EarliestLayerSVA goal : this.g ) {\nif ( goal == null || goal.earliestLayer == -1 ) {\nreturn false;\n}\n}\nreturn true;\n}","code_context_20":"public boolean reachedAllGoals ( ) {\nfor ( EarliestLayerSVA goal : this.g ) {\nif ( goal == null || goal.earliestLayer == -1 ) {\nreturn false;\n}\n}\nreturn true;\n}","label":[0,0,0,1]}
{"id":19996,"original_code":"@Override\n\tpublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\t\t\/\/ TODO Need to code this check somehow =\/\n\t\t[5D 00] \/\/ Opcode\n\t\t[02] \/\/ Map Portal\n\t\t[06 00 68 69 64 65 30 32] \/\/the entered portal name\n\t\t[6B 0D] \/\/ to x\n\t\t[30 01] \/\/ to y\n\t\t[C5 00] \/\/ x\n\t\t[C4 01] \/\/ y\n\t\tslea.readByte();\n\t\tString portal = slea.readMapleAsciiString();\n\t\tint toX = slea.readShort();\n\t\tint toY = slea.readShort();\n\t\tint X = slea.readShort();\n\t\tint Y = slea.readShort();\t\t\t\n\t\tlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n *\/\n\t}","code":"@Override\n\tpublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\t}","cleancode":"@override public void handlepacket(seekablelittleendianaccessor slea, mapleclient c) { }","comment":"\/\/ private static org.slf4j.logger log = loggerfactory.getlogger(specialportalhandler.class);\n\/* \/\/ todo need to code this check somehow =\/ [5d 00] \/\/ opcode [02] \/\/ map portal [06 00 68 69 64 65 30 32] \/\/the entered portal name [6b 0d] \/\/ to x [30 01] \/\/ to y [c5 00] \/\/ x [c4 01] \/\/ y slea.readbyte(); string portal = slea.readmapleasciistring(); int tox = slea.readshort(); int toy = slea.readshort(); int x = slea.readshort(); int y = slea.readshort(); log.info(\"[hacks] player {} is trying to jump to a different map portal rather than the correct one\"); *\/","repo":"xzs603\/codeLearning","code_context_2":"@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}\n\n@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}","code_context_10":"@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}\n\n@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}","code_context_20":"@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}\n\n@Override\npublic void handlePacket(SeekableLittleEndianAccessor slea, MapleClient c) {\n\/*\n\/\/ TODO Need to code this check somehow =\/\n[5D 00] \/\/ Opcode\n[02] \/\/ Map Portal\n[06 00 68 69 64 65 30 32] \/\/the entered portal name\n[6B 0D] \/\/ to x\n[30 01] \/\/ to y\n[C5 00] \/\/ x\n[C4 01] \/\/ y\nslea.readByte();\nString portal = slea.readMapleAsciiString();\nint toX = slea.readShort();\nint toY = slea.readShort();\nint X = slea.readShort();\nint Y = slea.readShort();\nlog.info(\"[Hacks] Player {} is trying to jump to a different map portal rather than the correct one\");\n*\/\n}","label":[0,1,0,0]}
{"id":20016,"original_code":"private HashMap<String, Object> createAttributesMap () {\n        HashMap<String, Object> attributes = new HashMap<String, Object>(2);\n        \/\/ XXX add more if requested\n        if(getInfo() != null) {\n            attributes.put(ATTRIBUTE_DISPLAY_NAME, getDisplayName());\n            attributes.put(ATTRIBUTE_URL, getUrl());\n        }\n        return attributes;\n    }","code":"private HashMap<String, Object> createAttributesMap () {\n        HashMap<String, Object> attributes = new HashMap<String, Object>(2);\n       \n        if(getInfo() != null) {\n            attributes.put(ATTRIBUTE_DISPLAY_NAME, getDisplayName());\n            attributes.put(ATTRIBUTE_URL, getUrl());\n        }\n        return attributes;\n    }","cleancode":"private hashmap<string, object> createattributesmap () { hashmap<string, object> attributes = new hashmap<string, object>(2); if(getinfo() != null) { attributes.put(attribute_display_name, getdisplayname()); attributes.put(attribute_url, geturl()); } return attributes; }","comment":"\/\/ xxx add more if requested","repo":"timfel\/netbeans","code_context_2":"private HashMap<String, Object> createAttributesMap () {\nHashMap<String, Object> attributes = new HashMap<String, Object>(2);\n\/\/ XXX add more if requested\nif(getInfo() != null) {\nattributes.put(ATTRIBUTE_DISPLAY_NAME, getDisplayName());","code_context_10":"private HashMap<String, Object> createAttributesMap () {\nHashMap<String, Object> attributes = new HashMap<String, Object>(2);\n\/\/ XXX add more if requested\nif(getInfo() != null) {\nattributes.put(ATTRIBUTE_DISPLAY_NAME, getDisplayName());\nattributes.put(ATTRIBUTE_URL, getUrl());\n}\nreturn attributes;\n}","code_context_20":"private HashMap<String, Object> createAttributesMap () {\nHashMap<String, Object> attributes = new HashMap<String, Object>(2);\n\/\/ XXX add more if requested\nif(getInfo() != null) {\nattributes.put(ATTRIBUTE_DISPLAY_NAME, getDisplayName());\nattributes.put(ATTRIBUTE_URL, getUrl());\n}\nreturn attributes;\n}","label":[0,1,0,0]}
{"id":3666,"original_code":"public static Boolean isMuted () {\n        return muteAudio_b;\n    }","code":"public static Boolean isMuted () {\n        return muteAudio_b;\n    }","cleancode":"public static boolean ismuted () { return muteaudio_b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * @return the muteaudio_b *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public static Boolean isMuted () {\nreturn muteAudio_b;\n}","code_context_10":"public static Boolean isMuted () {\nreturn muteAudio_b;\n}","code_context_20":"public static Boolean isMuted () {\nreturn muteAudio_b;\n}","label":[0,0,0,0]}
{"id":3667,"original_code":"public static void setMuteAudio ( Boolean b ) {\n        muteAudio_b = b;\n    }","code":"public static void setMuteAudio ( Boolean b ) {\n        muteAudio_b = b;\n    }","cleancode":"public static void setmuteaudio ( boolean b ) { muteaudio_b = b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * @param b the muteaudio_b to set *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public static void setMuteAudio ( Boolean b ) {\nmuteAudio_b = b;\n}","code_context_10":"public static void setMuteAudio ( Boolean b ) {\nmuteAudio_b = b;\n}","code_context_20":"public static void setMuteAudio ( Boolean b ) {\nmuteAudio_b = b;\n}","label":[0,0,0,0]}
{"id":3668,"original_code":"public Boolean getSliderHasBeenMoved () {\n        return sliderHasBeenMoved_b;\n    }","code":"public Boolean getSliderHasBeenMoved () {\n        return sliderHasBeenMoved_b;\n    }","cleancode":"public boolean getsliderhasbeenmoved () { return sliderhasbeenmoved_b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * * @return the sliderhasbeenmoved_b *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public Boolean getSliderHasBeenMoved () {\nreturn sliderHasBeenMoved_b;\n}","code_context_10":"public Boolean getSliderHasBeenMoved () {\nreturn sliderHasBeenMoved_b;\n}","code_context_20":"public Boolean getSliderHasBeenMoved () {\nreturn sliderHasBeenMoved_b;\n}","label":[0,0,0,0]}
{"id":3669,"original_code":"public void setSliderHasBeenMoved ( Boolean b ) {\n        sliderHasBeenMoved_b = b;\n    }","code":"public void setSliderHasBeenMoved ( Boolean b ) {\n        sliderHasBeenMoved_b = b;\n    }","cleancode":"public void setsliderhasbeenmoved ( boolean b ) { sliderhasbeenmoved_b = b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * * @param b the sliderhasbeenmoved_b to set *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public void setSliderHasBeenMoved ( Boolean b ) {\nsliderHasBeenMoved_b = b;\n}","code_context_10":"public void setSliderHasBeenMoved ( Boolean b ) {\nsliderHasBeenMoved_b = b;\n}","code_context_20":"public void setSliderHasBeenMoved ( Boolean b ) {\nsliderHasBeenMoved_b = b;\n}","label":[0,0,0,0]}
{"id":3670,"original_code":"public static Boolean getCaptureAudio () {\n        return captureAudio_b;\n    }","code":"public static Boolean getCaptureAudio () {\n        return captureAudio_b;\n    }","cleancode":"public static boolean getcaptureaudio () { return captureaudio_b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * @return the captureaudio_b *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public static Boolean getCaptureAudio () {\nreturn captureAudio_b;\n}","code_context_10":"public static Boolean getCaptureAudio () {\nreturn captureAudio_b;\n}","code_context_20":"public static Boolean getCaptureAudio () {\nreturn captureAudio_b;\n}","label":[0,0,0,0]}
{"id":3671,"original_code":"public static void setCaptureAudio ( Boolean b ) {\n        captureAudio_b = b;\n    }","code":"public static void setCaptureAudio ( Boolean b ) {\n        captureAudio_b = b;\n    }","cleancode":"public static void setcaptureaudio ( boolean b ) { captureaudio_b = b; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * @param b the captureaudio_b to set *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public static void setCaptureAudio ( Boolean b ) {\ncaptureAudio_b = b;\n}","code_context_10":"public static void setCaptureAudio ( Boolean b ) {\ncaptureAudio_b = b;\n}","code_context_20":"public static void setCaptureAudio ( Boolean b ) {\ncaptureAudio_b = b;\n}","label":[0,0,0,0]}
{"id":3672,"original_code":"public static LFDMS_GUI getAudioPlaybackOwner () {\n        return audioPlaybackOwner;\n    }","code":"public static LFDMS_GUI getAudioPlaybackOwner () {\n        return audioPlaybackOwner;\n    }","cleancode":"public static lfdms_gui getaudioplaybackowner () { return audioplaybackowner; }","comment":"\/** * [todo] * documentation. * unit test. * [\/] * @return the audioplaybackowner *\/","repo":"tuxjsmith\/logFarmDMS","code_context_2":"public static LFDMS_GUI getAudioPlaybackOwner () {\nreturn audioPlaybackOwner;\n}","code_context_10":"public static LFDMS_GUI getAudioPlaybackOwner () {\nreturn audioPlaybackOwner;\n}","code_context_20":"public static LFDMS_GUI getAudioPlaybackOwner () {\nreturn audioPlaybackOwner;\n}","label":[0,0,0,0]}
{"id":20094,"original_code":"private ClusterConfig buildNormalClusterConfig(DalConnectionStringConfigure configure) {\n        ClusterConfigWithNoVersion clusterConfig =\n                new ClusterConfigWithNoVersion(configure.getName(), ClusterType.NORMAL, DatabaseCategory.MYSQL);\n        DatabaseShardConfigImpl databaseShardConfig = new DatabaseShardConfigImpl(clusterConfig, 0);\n        DatabaseConfigImpl databaseConfig = new DatabaseConfigImpl(databaseShardConfig);\n        HostAndPort hostAndPort = ConnectionStringParser.parseHostPortFromURL(configure.getConnectionUrl());\n        databaseConfig.setIp(hostAndPort.getHost());\n        databaseConfig.setPort(hostAndPort.getPort());\n        databaseConfig.setDbName(provider.getDbName());\n        databaseConfig.setUid(configure.getUserName());\n        databaseConfig.setPwd(configure.getPassword());\n        databaseShardConfig.addDatabaseConfig(databaseConfig);\n        clusterConfig.addDatabaseShardConfig(databaseShardConfig);\n        \/\/ todo-lhj  make configurable RouteStrategy of\n        clusterConfig.setRouteStrategyConfig(new DefaultClusterRouteStrategyConfig(RouteStrategyEnum.READ_MASTER.name()));\n        clusterConfig.setCustomizedOption(new DefaultDalConfigCustomizedOption());\n        return clusterConfig;\n    }","code":"private ClusterConfig buildNormalClusterConfig(DalConnectionStringConfigure configure) {\n        ClusterConfigWithNoVersion clusterConfig =\n                new ClusterConfigWithNoVersion(configure.getName(), ClusterType.NORMAL, DatabaseCategory.MYSQL);\n        DatabaseShardConfigImpl databaseShardConfig = new DatabaseShardConfigImpl(clusterConfig, 0);\n        DatabaseConfigImpl databaseConfig = new DatabaseConfigImpl(databaseShardConfig);\n        HostAndPort hostAndPort = ConnectionStringParser.parseHostPortFromURL(configure.getConnectionUrl());\n        databaseConfig.setIp(hostAndPort.getHost());\n        databaseConfig.setPort(hostAndPort.getPort());\n        databaseConfig.setDbName(provider.getDbName());\n        databaseConfig.setUid(configure.getUserName());\n        databaseConfig.setPwd(configure.getPassword());\n        databaseShardConfig.addDatabaseConfig(databaseConfig);\n        clusterConfig.addDatabaseShardConfig(databaseShardConfig);\n       \n        clusterConfig.setRouteStrategyConfig(new DefaultClusterRouteStrategyConfig(RouteStrategyEnum.READ_MASTER.name()));\n        clusterConfig.setCustomizedOption(new DefaultDalConfigCustomizedOption());\n        return clusterConfig;\n    }","cleancode":"private clusterconfig buildnormalclusterconfig(dalconnectionstringconfigure configure) { clusterconfigwithnoversion clusterconfig = new clusterconfigwithnoversion(configure.getname(), clustertype.normal, databasecategory.mysql); databaseshardconfigimpl databaseshardconfig = new databaseshardconfigimpl(clusterconfig, 0); databaseconfigimpl databaseconfig = new databaseconfigimpl(databaseshardconfig); hostandport hostandport = connectionstringparser.parsehostportfromurl(configure.getconnectionurl()); databaseconfig.setip(hostandport.gethost()); databaseconfig.setport(hostandport.getport()); databaseconfig.setdbname(provider.getdbname()); databaseconfig.setuid(configure.getusername()); databaseconfig.setpwd(configure.getpassword()); databaseshardconfig.adddatabaseconfig(databaseconfig); clusterconfig.adddatabaseshardconfig(databaseshardconfig); clusterconfig.setroutestrategyconfig(new defaultclusterroutestrategyconfig(routestrategyenum.read_master.name())); clusterconfig.setcustomizedoption(new defaultdalconfigcustomizedoption()); return clusterconfig; }","comment":"\/\/ todo-lhj make configurable routestrategy of","repo":"wwjiang007\/dal","code_context_2":"databaseShardConfig.addDatabaseConfig(databaseConfig);\nclusterConfig.addDatabaseShardConfig(databaseShardConfig);\n\/\/ todo-lhj make configurable RouteStrategy of\nclusterConfig.setRouteStrategyConfig(new DefaultClusterRouteStrategyConfig(RouteStrategyEnum.READ_MASTER.name()));\nclusterConfig.setCustomizedOption(new DefaultDalConfigCustomizedOption());","code_context_10":"DatabaseShardConfigImpl databaseShardConfig = new DatabaseShardConfigImpl(clusterConfig, 0);\nDatabaseConfigImpl databaseConfig = new DatabaseConfigImpl(databaseShardConfig);\nHostAndPort hostAndPort = ConnectionStringParser.parseHostPortFromURL(configure.getConnectionUrl());\ndatabaseConfig.setIp(hostAndPort.getHost());\ndatabaseConfig.setPort(hostAndPort.getPort());\ndatabaseConfig.setDbName(provider.getDbName());\ndatabaseConfig.setUid(configure.getUserName());\ndatabaseConfig.setPwd(configure.getPassword());\ndatabaseShardConfig.addDatabaseConfig(databaseConfig);\nclusterConfig.addDatabaseShardConfig(databaseShardConfig);\n\/\/ todo-lhj make configurable RouteStrategy of\nclusterConfig.setRouteStrategyConfig(new DefaultClusterRouteStrategyConfig(RouteStrategyEnum.READ_MASTER.name()));\nclusterConfig.setCustomizedOption(new DefaultDalConfigCustomizedOption());\nreturn clusterConfig;\n}","code_context_20":"private ClusterConfig buildNormalClusterConfig(DalConnectionStringConfigure configure) {\nClusterConfigWithNoVersion clusterConfig =\nnew ClusterConfigWithNoVersion(configure.getName(), ClusterType.NORMAL, DatabaseCategory.MYSQL);\nDatabaseShardConfigImpl databaseShardConfig = new DatabaseShardConfigImpl(clusterConfig, 0);\nDatabaseConfigImpl databaseConfig = new DatabaseConfigImpl(databaseShardConfig);\nHostAndPort hostAndPort = ConnectionStringParser.parseHostPortFromURL(configure.getConnectionUrl());\ndatabaseConfig.setIp(hostAndPort.getHost());\ndatabaseConfig.setPort(hostAndPort.getPort());\ndatabaseConfig.setDbName(provider.getDbName());\ndatabaseConfig.setUid(configure.getUserName());\ndatabaseConfig.setPwd(configure.getPassword());\ndatabaseShardConfig.addDatabaseConfig(databaseConfig);\nclusterConfig.addDatabaseShardConfig(databaseShardConfig);\n\/\/ todo-lhj make configurable RouteStrategy of\nclusterConfig.setRouteStrategyConfig(new DefaultClusterRouteStrategyConfig(RouteStrategyEnum.READ_MASTER.name()));\nclusterConfig.setCustomizedOption(new DefaultDalConfigCustomizedOption());\nreturn clusterConfig;\n}","label":[1,0,0,0]}
{"id":20104,"original_code":"static BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\n            String title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n            @BookmarkType int bookmarkType) {\n        parent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\n        BookmarkItem parentItem = null;\n        if (parent != null) {\n            parentItem = bookmarkModel.getBookmarkById(parent);\n        }\n        if (parent == null || parentItem == null || parentItem.isManaged()\n                || !parentItem.isFolder()) {\n            parent = bookmarkModel.getDefaultFolder();\n        }\n        \/\/ Reading list items will be added when either one of the 2 conditions is met:\n        \/\/ 1. The bookmark type explicitly specifies READING_LIST.\n        \/\/ 2. The last used parent implicitly specifies READING_LIST.\n        if (ReadingListFeatures.isReadingListEnabled()\n                && (bookmarkType == BookmarkType.READING_LIST\n                        || parent.getType() == BookmarkType.READING_LIST)) {\n            return bookmarkModel.addToReadingList(title, url);\n        }\n        BookmarkId bookmarkId = null;\n        \/\/ Use \"New tab\" as title for both incognito and regular NTP.\n        if (url.getSpec().equals(UrlConstants.NTP_URL)) {\n            title = context.getResources().getString(R.string.new_tab_title);\n        }\n        \/\/ The shopping list experiment saves extra metadata along with the bookmark.\n        if (ChromeFeatureList.isInitialized()\n                && ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\n            bookmarkId = bookmarkModel.addPowerBookmark(\n                    webContents, parent, bookmarkModel.getChildCount(parent), title, url);\n        } else {\n            bookmarkId = bookmarkModel.addBookmark(\n                    parent, bookmarkModel.getChildCount(parent), title, url);\n        }\n        \/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\n        if (bookmarkId == null) {\n            Log.e(TAG,\n                    \"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n                            + \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\n                    parent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\n                    parentItem == null ? \"null\"\n                                       : (parentItem.isEditable() + \" \" + parentItem.isManaged()\n                                               + \" \" + parentItem.isFolder()));\n            setLastUsedParent(context, bookmarkModel.getDefaultFolder());\n        }\n        return bookmarkId;\n    }","code":"static BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\n            String title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n            @BookmarkType int bookmarkType) {\n        parent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\n        BookmarkItem parentItem = null;\n        if (parent != null) {\n            parentItem = bookmarkModel.getBookmarkById(parent);\n        }\n        if (parent == null || parentItem == null || parentItem.isManaged()\n                || !parentItem.isFolder()) {\n            parent = bookmarkModel.getDefaultFolder();\n        }\n       \n       \n       \n        if (ReadingListFeatures.isReadingListEnabled()\n                && (bookmarkType == BookmarkType.READING_LIST\n                        || parent.getType() == BookmarkType.READING_LIST)) {\n            return bookmarkModel.addToReadingList(title, url);\n        }\n        BookmarkId bookmarkId = null;\n       \n        if (url.getSpec().equals(UrlConstants.NTP_URL)) {\n            title = context.getResources().getString(R.string.new_tab_title);\n        }\n       \n        if (ChromeFeatureList.isInitialized()\n                && ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\n            bookmarkId = bookmarkModel.addPowerBookmark(\n                    webContents, parent, bookmarkModel.getChildCount(parent), title, url);\n        } else {\n            bookmarkId = bookmarkModel.addBookmark(\n                    parent, bookmarkModel.getChildCount(parent), title, url);\n        }\n       \n        if (bookmarkId == null) {\n            Log.e(TAG,\n                    \"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n                            + \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\n                    parent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\n                    parentItem == null ? \"null\"\n                                       : (parentItem.isEditable() + \" \" + parentItem.isManaged()\n                                               + \" \" + parentItem.isFolder()));\n            setLastUsedParent(context, bookmarkModel.getDefaultFolder());\n        }\n        return bookmarkId;\n    }","cleancode":"static bookmarkid addbookmarkinternal(context context, bookmarkmodel bookmarkmodel, string title, gurl url, webcontents webcontents, @nullable bookmarkid parent, @bookmarktype int bookmarktype) { parent = parent == null ? getlastusedparent(context, bookmarkmodel) : parent; bookmarkitem parentitem = null; if (parent != null) { parentitem = bookmarkmodel.getbookmarkbyid(parent); } if (parent == null || parentitem == null || parentitem.ismanaged() || !parentitem.isfolder()) { parent = bookmarkmodel.getdefaultfolder(); } if (readinglistfeatures.isreadinglistenabled() && (bookmarktype == bookmarktype.reading_list || parent.gettype() == bookmarktype.reading_list)) { return bookmarkmodel.addtoreadinglist(title, url); } bookmarkid bookmarkid = null; if (url.getspec().equals(urlconstants.ntp_url)) { title = context.getresources().getstring(r.string.new_tab_title); } if (chromefeaturelist.isinitialized() && chromefeaturelist.isenabled(chromefeaturelist.shopping_list)) { bookmarkid = bookmarkmodel.addpowerbookmark( webcontents, parent, bookmarkmodel.getchildcount(parent), title, url); } else { bookmarkid = bookmarkmodel.addbookmark( parent, bookmarkmodel.getchildcount(parent), title, url); } if (bookmarkid == null) { log.e(tag, \"failed to add bookmarks: parenttypeandid %s, defaultfoldertypeandid %s, \" + \"mobilefoldertypeandid %s, parenteditable managed isfolder %s,\", parent, bookmarkmodel.getdefaultfolder(), bookmarkmodel.getmobilefolderid(), parentitem == null ? \"null\" : (parentitem.iseditable() + \" \" + parentitem.ismanaged() + \" \" + parentitem.isfolder())); setlastusedparent(context, bookmarkmodel.getdefaultfolder()); } return bookmarkid; }","comment":"\/** * adds a bookmark with the given {@link tab}. this will reset last used parent if it fails to * add a bookmark. * * @param context the current android {@link context}. * @param bookmarkmodel the current {@link bookmarkmodel} which talks to native. * @param tab the current {@link tab} which bookmark properties are pulled. * @param bookmarktype the {@link bookmarktype} of the bookmark. *\/\n\/\/ reading list items will be added when either one of the 2 conditions is met: \/\/ 1. the bookmark type explicitly specifies reading_list. \/\/ 2. the last used parent implicitly specifies reading_list.\n\/\/ use \"new tab\" as title for both incognito and regular ntp.\n\/\/ the shopping list experiment saves extra metadata along with the bookmark.\n\/\/ todo(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978","repo":"zealoussnow\/chromium","code_context_2":"static BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\nString title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}\nreturn bookmarkId;\n}\n\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\n\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,","code_context_10":"static BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\nString title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}\nreturn bookmarkId;\n}\n\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\n\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\n\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}","code_context_20":"static BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\nString title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}\nreturn bookmarkId;\n}\n\nstatic BookmarkId addBookmarkInternal(Context context, BookmarkModel bookmarkModel,\nString title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\n\nString title, GURL url, WebContents webContents, @Nullable BookmarkId parent,\n@BookmarkType int bookmarkType) {\nparent = parent == null ? getLastUsedParent(context, bookmarkModel) : parent;\nBookmarkItem parentItem = null;\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n\nif (parent != null) {\nparentItem = bookmarkModel.getBookmarkById(parent);\n}\nif (parent == null || parentItem == null || parentItem.isManaged()\n|| !parentItem.isFolder()) {\nparent = bookmarkModel.getDefaultFolder();\n}\n\/\/ Reading list items will be added when either one of the 2 conditions is met:\n\/\/ 1. The bookmark type explicitly specifies READING_LIST.\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}\nreturn bookmarkId;\n\n\/\/ 2. The last used parent implicitly specifies READING_LIST.\nif (ReadingListFeatures.isReadingListEnabled()\n&& (bookmarkType == BookmarkType.READING_LIST\n|| parent.getType() == BookmarkType.READING_LIST)) {\nreturn bookmarkModel.addToReadingList(title, url);\n}\nBookmarkId bookmarkId = null;\n\/\/ Use \"New tab\" as title for both incognito and regular NTP.\nif (url.getSpec().equals(UrlConstants.NTP_URL)) {\ntitle = context.getResources().getString(R.string.new_tab_title);\n}\n\/\/ The shopping list experiment saves extra metadata along with the bookmark.\nif (ChromeFeatureList.isInitialized()\n&& ChromeFeatureList.isEnabled(ChromeFeatureList.SHOPPING_LIST)) {\nbookmarkId = bookmarkModel.addPowerBookmark(\nwebContents, parent, bookmarkModel.getChildCount(parent), title, url);\n} else {\nbookmarkId = bookmarkModel.addBookmark(\nparent, bookmarkModel.getChildCount(parent), title, url);\n}\n\/\/ TODO(lazzzis): remove log after bookmark sync is fixed, crbug.com\/986978\nif (bookmarkId == null) {\nLog.e(TAG,\n\"Failed to add bookmarks: parentTypeAndId %s, defaultFolderTypeAndId %s, \"\n+ \"mobileFolderTypeAndId %s, parentEditable Managed isFolder %s,\",\nparent, bookmarkModel.getDefaultFolder(), bookmarkModel.getMobileFolderId(),\nparentItem == null ? \"null\"\n: (parentItem.isEditable() + \" \" + parentItem.isManaged()\n+ \" \" + parentItem.isFolder()));\nsetLastUsedParent(context, bookmarkModel.getDefaultFolder());\n}\nreturn bookmarkId;\n}","label":[1,0,0,0]}
{"id":3803,"original_code":"public void testPartionedQuadtreeNodeIndex() throws Exception {\n\t\tPartitionedQuadtreeNodeIndexFile pf = new PartitionedQuadtreeNodeIndexFile(\"testData\", false, true);\n\t\tpf.setID(48.11,  11.48, 77);\n\t\tassertEquals(77, pf.getID(48.11,  11.48));\n\t\tpf.setID(48.11,  11.48, 55);\n\t\tpf.setID(33.11,  22.48, 44);\n\t\tassertEquals(55, pf.getID(48.11,  11.48));\n\t\tassertEquals(44, pf.getID(33.11,  22.48));\n\t\t\/* just testing ... this is wrong\n\t\tpf.setID(48.11001,  11.48, 55);\n\t\tpf.setID(48.11002,  11.48, 56);\n\t\tList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\n\t\tSystem.out.println(l);\n\t\t*\/\n\t\tfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\n\t\t\tfor( double lng = 11.0; lng < 12; lng += 0.009)\n\t\t\t\tpf.setID(lat,  lng, (int)lat * (int)(lng * 100.0));\n\t\tfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\n\t\t\tfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\t\t\t\t\/\/System.out.println(\" \" + lat + \" \" + lng);\n\t\t\t\tassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat,  lng ));\n\t\t\t}\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tpf.setID(lat,  lng, (int)(lat * lng));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tassertEquals((int)(lat * lng), pf.getID(lat,  lng ));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tpf.setID(lat,  lng, (int)(lat * lng));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tassertEquals((int)(lat * lng), pf.getID(lat,  lng ));\n\t}","code":"public void testPartionedQuadtreeNodeIndex() throws Exception {\n\t\tPartitionedQuadtreeNodeIndexFile pf = new PartitionedQuadtreeNodeIndexFile(\"testData\", false, true);\n\t\tpf.setID(48.11,  11.48, 77);\n\t\tassertEquals(77, pf.getID(48.11,  11.48));\n\t\tpf.setID(48.11,  11.48, 55);\n\t\tpf.setID(33.11,  22.48, 44);\n\t\tassertEquals(55, pf.getID(48.11,  11.48));\n\t\tassertEquals(44, pf.getID(33.11,  22.48));\n\t\n\t\tfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\n\t\t\tfor( double lng = 11.0; lng < 12; lng += 0.009)\n\t\t\t\tpf.setID(lat,  lng, (int)lat * (int)(lng * 100.0));\n\t\tfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\n\t\t\tfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\t\t\t\n\t\t\t\tassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat,  lng ));\n\t\t\t}\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tpf.setID(lat,  lng, (int)(lat * lng));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tassertEquals((int)(lat * lng), pf.getID(lat,  lng ));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tpf.setID(lat,  lng, (int)(lat * lng));\n\t\tfor( double lat = 50.0; lat < 60; lat += 0.3)\n\t\t\tfor( double lng = -120.0; lng < 60; lng += 0.8)\n\t\t\t\tassertEquals((int)(lat * lng), pf.getID(lat,  lng ));\n\t}","cleancode":"public void testpartionedquadtreenodeindex() throws exception { partitionedquadtreenodeindexfile pf = new partitionedquadtreenodeindexfile(\"testdata\", false, true); pf.setid(48.11, 11.48, 77); assertequals(77, pf.getid(48.11, 11.48)); pf.setid(48.11, 11.48, 55); pf.setid(33.11, 22.48, 44); assertequals(55, pf.getid(48.11, 11.48)); assertequals(44, pf.getid(33.11, 22.48)); for( double lat = 50.0; lat < 50.4; lat += 0.00001) for( double lng = 11.0; lng < 12; lng += 0.009) pf.setid(lat, lng, (int)lat * (int)(lng * 100.0)); for( double lat = 50.0; lat < 50.4; lat += 0.00001) for( double lng = 11.0; lng < 12; lng += 0.009) { assertequals((int)lat * (int)(lng * 100.0), pf.getid(lat, lng )); } for( double lat = 50.0; lat < 60; lat += 0.3) for( double lng = -120.0; lng < 60; lng += 0.8) pf.setid(lat, lng, (int)(lat * lng)); for( double lat = 50.0; lat < 60; lat += 0.3) for( double lng = -120.0; lng < 60; lng += 0.8) assertequals((int)(lat * lng), pf.getid(lat, lng )); for( double lat = 50.0; lat < 60; lat += 0.3) for( double lng = -120.0; lng < 60; lng += 0.8) pf.setid(lat, lng, (int)(lat * lng)); for( double lat = 50.0; lat < 60; lat += 0.3) for( double lng = -120.0; lng < 60; lng += 0.8) assertequals((int)(lat * lng), pf.getid(lat, lng )); }","comment":"\/* just testing ... this is wrong pf.setid(48.11001, 11.48, 55); pf.setid(48.11002, 11.48, 56); list<nodeindexnodedescriptor> l = pf.getidplussourroundingids(48.11001, 11.48, 0); system.out.println(l); *\/\n\/\/system.out.println(\" \" + lat + \" \" + lng);","repo":"tomhenne\/Jerusalem","code_context_2":"assertEquals(55, pf.getID(48.11, 11.48));\nassertEquals(44, pf.getID(33.11, 22.48));\n\/* just testing ... this is wrong\npf.setID(48.11001, 11.48, 55);\npf.setID(48.11002, 11.48, 56);\nList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\nSystem.out.println(l);\n*\/\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009)\n\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\/\/System.out.println(\" \" + lat + \" \" + lng);\nassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat, lng ));\n}","code_context_10":"public void testPartionedQuadtreeNodeIndex() throws Exception {\nPartitionedQuadtreeNodeIndexFile pf = new PartitionedQuadtreeNodeIndexFile(\"testData\", false, true);\npf.setID(48.11, 11.48, 77);\nassertEquals(77, pf.getID(48.11, 11.48));\npf.setID(48.11, 11.48, 55);\npf.setID(33.11, 22.48, 44);\nassertEquals(55, pf.getID(48.11, 11.48));\nassertEquals(44, pf.getID(33.11, 22.48));\n\/* just testing ... this is wrong\npf.setID(48.11001, 11.48, 55);\npf.setID(48.11002, 11.48, 56);\nList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\nSystem.out.println(l);\n*\/\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009)\npf.setID(lat, lng, (int)lat * (int)(lng * 100.0));\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\/\/System.out.println(\" \" + lat + \" \" + lng);\nassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat, lng ));\n}\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\n\npf.setID(48.11001, 11.48, 55);\npf.setID(48.11002, 11.48, 56);\nList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\nSystem.out.println(l);\n*\/\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009)\npf.setID(lat, lng, (int)lat * (int)(lng * 100.0));\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\/\/System.out.println(\" \" + lat + \" \" + lng);\nassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat, lng ));\n}\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\npf.setID(lat, lng, (int)(lat * lng));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\nassertEquals((int)(lat * lng), pf.getID(lat, lng ));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)","code_context_20":"public void testPartionedQuadtreeNodeIndex() throws Exception {\nPartitionedQuadtreeNodeIndexFile pf = new PartitionedQuadtreeNodeIndexFile(\"testData\", false, true);\npf.setID(48.11, 11.48, 77);\nassertEquals(77, pf.getID(48.11, 11.48));\npf.setID(48.11, 11.48, 55);\npf.setID(33.11, 22.48, 44);\nassertEquals(55, pf.getID(48.11, 11.48));\nassertEquals(44, pf.getID(33.11, 22.48));\n\/* just testing ... this is wrong\npf.setID(48.11001, 11.48, 55);\npf.setID(48.11002, 11.48, 56);\nList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\nSystem.out.println(l);\n*\/\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009)\npf.setID(lat, lng, (int)lat * (int)(lng * 100.0));\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\/\/System.out.println(\" \" + lat + \" \" + lng);\nassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat, lng ));\n}\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\npf.setID(lat, lng, (int)(lat * lng));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\nassertEquals((int)(lat * lng), pf.getID(lat, lng ));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\npf.setID(lat, lng, (int)(lat * lng));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\nassertEquals((int)(lat * lng), pf.getID(lat, lng ));\n\npublic void testPartionedQuadtreeNodeIndex() throws Exception {\nPartitionedQuadtreeNodeIndexFile pf = new PartitionedQuadtreeNodeIndexFile(\"testData\", false, true);\npf.setID(48.11, 11.48, 77);\nassertEquals(77, pf.getID(48.11, 11.48));\npf.setID(48.11, 11.48, 55);\npf.setID(33.11, 22.48, 44);\nassertEquals(55, pf.getID(48.11, 11.48));\nassertEquals(44, pf.getID(33.11, 22.48));\n\/* just testing ... this is wrong\npf.setID(48.11001, 11.48, 55);\npf.setID(48.11002, 11.48, 56);\nList<NodeIndexNodeDescriptor> l = pf.getIDPlusSourroundingIDs(48.11001, 11.48, 0);\nSystem.out.println(l);\n*\/\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009)\npf.setID(lat, lng, (int)lat * (int)(lng * 100.0));\nfor( double lat = 50.0; lat < 50.4; lat += 0.00001)\nfor( double lng = 11.0; lng < 12; lng += 0.009) {\n\/\/System.out.println(\" \" + lat + \" \" + lng);\nassertEquals((int)lat * (int)(lng * 100.0), pf.getID(lat, lng ));\n}\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\npf.setID(lat, lng, (int)(lat * lng));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\nassertEquals((int)(lat * lng), pf.getID(lat, lng ));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\npf.setID(lat, lng, (int)(lat * lng));\nfor( double lat = 50.0; lat < 60; lat += 0.3)\nfor( double lng = -120.0; lng < 60; lng += 0.8)\nassertEquals((int)(lat * lng), pf.getID(lat, lng ));\n}","label":[0,0,0,1]}
{"id":20385,"original_code":"private static File extractElf(String elfName,\n                                   File apkFile) {\n        File file = new File(\"classes.dex\");\n        ZipInputStream zipFile;\n        try {\n            zipFile = new ZipInputStream(new FileInputStream(apkFile));\n            ZipEntry zipEntry;\n            while (true) {\n                zipEntry = zipFile.getNextEntry();\n                if (zipEntry == null) {\n                    break;\n                }\n                if (zipEntry.getName().equals(elfName)) {\n                    String fName = elfName;\n                    String ext = \"so\";\n                    file = SherlockHash.INSTANCE.getFileFromZipStream(apkFile, zipFile, fName, ext);\n                    break;\n                }\n            }\n            zipFile.close();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return file;\n    }","code":"private static File extractElf(String elfName,\n                                   File apkFile) {\n        File file = new File(\"classes.dex\");\n        ZipInputStream zipFile;\n        try {\n            zipFile = new ZipInputStream(new FileInputStream(apkFile));\n            ZipEntry zipEntry;\n            while (true) {\n                zipEntry = zipFile.getNextEntry();\n                if (zipEntry == null) {\n                    break;\n                }\n                if (zipEntry.getName().equals(elfName)) {\n                    String fName = elfName;\n                    String ext = \"so\";\n                    file = SherlockHash.INSTANCE.getFileFromZipStream(apkFile, zipFile, fName, ext);\n                    break;\n                }\n            }\n            zipFile.close();\n        } catch (Exception e) {\n            e.printStackTrace();\n        }\n        return file;\n    }","cleancode":"private static file extractelf(string elfname, file apkfile) { file file = new file(\"classes.dex\"); zipinputstream zipfile; try { zipfile = new zipinputstream(new fileinputstream(apkfile)); zipentry zipentry; while (true) { zipentry = zipfile.getnextentry(); if (zipentry == null) { break; } if (zipentry.getname().equals(elfname)) { string fname = elfname; string ext = \"so\"; file = sherlockhash.instance.getfilefromzipstream(apkfile, zipfile, fname, ext); break; } } zipfile.close(); } catch (exception e) { e.printstacktrace(); } return file; }","comment":"\/\/ todo currently support only dexes, here is how to do for jar \/\/ todo https:\/\/github.com\/adamheinrich\/native-utils\/blob\/master\/nativeutils.java","repo":"yongjhih\/docker-classyshark","code_context_2":"private static File extractElf(String elfName,\nFile apkFile) {\nFile file = new File(\"classes.dex\");\nZipInputStream zipFile;\ntry {\nzipFile = new ZipInputStream(new FileInputStream(apkFile));\nZipEntry zipEntry;\nwhile (true) {\nzipEntry = zipFile.getNextEntry();\nif (zipEntry == null) {\nbreak;\n}\nif (zipEntry.getName().equals(elfName)) {\nString fName = elfName;\nString ext = \"so\";\nfile = SherlockHash.INSTANCE.getFileFromZipStream(apkFile, zipFile, fName, ext);\nbreak;\n}\n}\nzipFile.close();\n} catch (Exception e) {\ne.printStackTrace();\n}\nreturn file;\n}","code_context_10":"private static File extractElf(String elfName,\nFile apkFile) {\nFile file = new File(\"classes.dex\");\nZipInputStream zipFile;\ntry {\nzipFile = new ZipInputStream(new FileInputStream(apkFile));\nZipEntry zipEntry;\nwhile (true) {\nzipEntry = zipFile.getNextEntry();\nif (zipEntry == null) {\nbreak;\n}\nif (zipEntry.getName().equals(elfName)) {\nString fName = elfName;\nString ext = \"so\";\nfile = SherlockHash.INSTANCE.getFileFromZipStream(apkFile, zipFile, fName, ext);\nbreak;\n}\n}\nzipFile.close();\n} catch (Exception e) {\ne.printStackTrace();\n}\nreturn file;\n}","code_context_20":"private static File extractElf(String elfName,\nFile apkFile) {\nFile file = new File(\"classes.dex\");\nZipInputStream zipFile;\ntry {\nzipFile = new ZipInputStream(new FileInputStream(apkFile));\nZipEntry zipEntry;\nwhile (true) {\nzipEntry = zipFile.getNextEntry();\nif (zipEntry == null) {\nbreak;\n}\nif (zipEntry.getName().equals(elfName)) {\nString fName = elfName;\nString ext = \"so\";\nfile = SherlockHash.INSTANCE.getFileFromZipStream(apkFile, zipFile, fName, ext);\nbreak;\n}\n}\nzipFile.close();\n} catch (Exception e) {\ne.printStackTrace();\n}\nreturn file;\n}","label":[0,1,0,0]}
{"id":20395,"original_code":"public static boolean isInterdicted(SegmentController ship, Vector3i position) {\n        \/\/TODO add interdiction check for target sector\n        JumpAddOn warpdrive;\n        if(ship instanceof ManagedSegmentController<?>) {\n            warpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n        } else {\n            return false;\n        }\n        \/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\n        assert warpdrive.isOnServer();\n        GameServerState gameServerState;\n        Sector sector;\n        boolean retVal = false;\n        Vector3i neighbourSectorPos = new Vector3i();\n        \/\/debug jumpdrive level\n        if(ship.hasActiveReactors()){\n        \/\/    DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n        }\n        try {\n            sector = GameServer.getUniverse().getSector(position);\n        } catch (IOException e) {\n            e.printStackTrace();\n            return false;\n        }\n        if (sector == null) {\n            return false;\n        }\n        int checkRange = 3; \/\/range to check for inhibitors [sectors]\n        int shipReactorLvl = 0;\n        try {\n            shipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n        } catch (Exception e) {\n            e.printStackTrace();\n            DebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\n            DebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\n            DebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\n            return true;\n        }\n        int inhibitorStrength = 0;\n        int catchesLvl = 0;\n        double inhRange = 0;\n        Vector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\n        for (int x = -checkRange; x <= checkRange; ++x) {\n            for (int y = -checkRange; y <= checkRange; ++y) {\n                for (int z = -checkRange; z <= checkRange; ++z) {\n                    neighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\n                    Sector neighbourSector;\n                    if ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\n                        continue; \/\/sector is not loaded\n                    }\n                    \/\/get inhibitor level \/\/returns [0..9]\n                    inhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\n                    catchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n                    \/\/max inhRange of inhibitor\n                    inhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE,  1));\n                    int dx = Math.abs(currentSec.x - neighbourSectorPos.x);\n                    int dy = Math.abs(currentSec.y - neighbourSectorPos.y);\n                    int dz = Math.abs(currentSec.z - neighbourSectorPos.z);\n                    double distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n                    \/\/TODO change config entry of inhibition power consumption\n                    if (inhibitorStrength <= 1 || (distance > inhRange)) {\n                        continue;\n                    }\n                    \/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\n                    if (catchesLvl >= shipReactorLvl) {\n                        warpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\n                        retVal = true;\n                        break;\n                    }\n                }\n            }\n        }\n        return retVal;\n    }","code":"public static boolean isInterdicted(SegmentController ship, Vector3i position) {\n       \n        JumpAddOn warpdrive;\n        if(ship instanceof ManagedSegmentController<?>) {\n            warpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n        } else {\n            return false;\n        }\n       \n        assert warpdrive.isOnServer();\n        GameServerState gameServerState;\n        Sector sector;\n        boolean retVal = false;\n        Vector3i neighbourSectorPos = new Vector3i();\n       \n        if(ship.hasActiveReactors()){\n       \n        }\n        try {\n            sector = GameServer.getUniverse().getSector(position);\n        } catch (IOException e) {\n            e.printStackTrace();\n            return false;\n        }\n        if (sector == null) {\n            return false;\n        }\n        int checkRange = 3;\n        int shipReactorLvl = 0;\n        try {\n            shipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n        } catch (Exception e) {\n            e.printStackTrace();\n            DebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\n            DebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\n            DebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\n            return true;\n        }\n        int inhibitorStrength = 0;\n        int catchesLvl = 0;\n        double inhRange = 0;\n        Vector3i currentSec = ship.getSector(new Vector3i());\n        for (int x = -checkRange; x <= checkRange; ++x) {\n            for (int y = -checkRange; y <= checkRange; ++y) {\n                for (int z = -checkRange; z <= checkRange; ++z) {\n                    neighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\n                    Sector neighbourSector;\n                    if ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\n                        continue;\n                    }\n                   \n                    inhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1);\n                    catchesLvl = inhibitorStrength * 60;\n                   \n                    inhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE,  1));\n                    int dx = Math.abs(currentSec.x - neighbourSectorPos.x);\n                    int dy = Math.abs(currentSec.y - neighbourSectorPos.y);\n                    int dz = Math.abs(currentSec.z - neighbourSectorPos.z);\n                    double distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n                   \n                    if (inhibitorStrength <= 1 || (distance > inhRange)) {\n                        continue;\n                    }\n                   \n                    if (catchesLvl >= shipReactorLvl) {\n                        warpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\n                        retVal = true;\n                        break;\n                    }\n                }\n            }\n        }\n        return retVal;\n    }","cleancode":"public static boolean isinterdicted(segmentcontroller ship, vector3i position) { jumpaddon warpdrive; if(ship instanceof managedsegmentcontroller<?>) { warpdrive =((ship)ship).getmanagercontainer().getjumpaddon(); } else { return false; } assert warpdrive.isonserver(); gameserverstate gameserverstate; sector sector; boolean retval = false; vector3i neighboursectorpos = new vector3i(); if(ship.hasactivereactors()){ } try { sector = gameserver.getuniverse().getsector(position); } catch (ioexception e) { e.printstacktrace(); return false; } if (sector == null) { return false; } int checkrange = 3; int shipreactorlvl = 0; try { shipreactorlvl = ((managedsegmentcontroller<?>)ship).getmanagercontainer().getpowerinterface().getactivereactor().getlevel(); } catch (exception e) { e.printstacktrace(); debugfile.log(\"managercontainer null: \" + (((managedsegmentcontroller<?>)ship).getmanagercontainer() == null)); debugfile.log(\"powerinterface null: \" + (((managedsegmentcontroller<?>)ship).getmanagercontainer().getpowerinterface() == null)); debugfile.log(\"activereactor null: \" + (((managedsegmentcontroller<?>)ship).getmanagercontainer().getpowerinterface().getactivereactor() == null)); return true; } int inhibitorstrength = 0; int catcheslvl = 0; double inhrange = 0; vector3i currentsec = ship.getsector(new vector3i()); for (int x = -checkrange; x <= checkrange; ++x) { for (int y = -checkrange; y <= checkrange; ++y) { for (int z = -checkrange; z <= checkrange; ++z) { neighboursectorpos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x); sector neighboursector; if ((neighboursector = gameserverstate.instance.getuniverse().getsectorwithoutloading(neighboursectorpos)) == null) { continue; } inhibitorstrength = neighboursector.getremotesector().getconfigmanager().apply(statuseffecttype.warp_interdiction_strength, 1); catcheslvl = inhibitorstrength * 60; inhrange = math.max(0, neighboursector.getremotesector().getconfigmanager().apply(statuseffecttype.warp_interdiction_distance, 1)); int dx = math.abs(currentsec.x - neighboursectorpos.x); int dy = math.abs(currentsec.y - neighboursectorpos.y); int dz = math.abs(currentsec.z - neighboursectorpos.z); double distance = math.pow(dx * dx + dy * dy + dz * dz,0.5); if (inhibitorstrength <= 1 || (distance > inhrange)) { continue; } if (catcheslvl >= shipreactorlvl) { warpdrive.getsegmentcontroller().sendcontrollingplayersservermessage(new object[]{\" inhibitor detected in \" + neighboursectorpos.tostring()}, 3); retval = true; break; } } } } return retval; }","comment":"\/** * check if this ship is\/would be interdicted at specified position. * @param ship ship * @param position positon to check from * @return *\/\n\/\/todo add interdiction check for target sector\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\n\/\/debug jumpdrive level\n\/\/ debugfile.log (\"warpdrive of \"+ ship.getname() + \" has level: \" + ((managedsegmentcontroller<?>)ship).getmanagercontainer().getpowerinterface().getactivereactor().getlevel());\n\/\/range to check for inhibitors [sectors]\n\/\/todo refactor me and make me pretty\n\/\/sector is not loaded\n\/\/get inhibitor level \/\/returns [0..9]\n\/\/todo change apply value to 300k?\n\/\/will catch anything up to\n\/\/max inhrange of inhibitor\n\/\/todo change config entry of inhibition power consumption\n\/\/debugfile.log(\"inhibitor has strength: \" + inhibitorstrength + \" catches rkt level: \" + catcheslvl + \" power cons: \" + inhibitorstrength * 60000 + \" range: \" + inhrange + \" vs: \" + distance);","repo":"taswin\/Warpspace","code_context_2":"public static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\n\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\n\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\n\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\n\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\n\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\n\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\n\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\n\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\n\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);","code_context_10":"public static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\n\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\n\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\n\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\n\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\n\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\n\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\n\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}","code_context_20":"public static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\n\npublic static boolean isInterdicted(SegmentController ship, Vector3i position) {\n\/\/TODO add interdiction check for target sector\nJumpAddOn warpdrive;\nif(ship instanceof ManagedSegmentController<?>) {\nwarpdrive =((Ship)ship).getManagerContainer().getJumpAddOn();\n} else {\nreturn false;\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n\n}\n\/\/use vanilla check method - check one sector in each direction for jumpaddons that interdict this one.\nassert warpdrive.isOnServer();\nGameServerState gameServerState;\nSector sector;\nboolean retVal = false;\nVector3i neighbourSectorPos = new Vector3i();\n\/\/debug jumpdrive level\nif(ship.hasActiveReactors()){\n\/\/ DebugFile.log (\"warpdrive of \"+ ship.getName() + \" has level: \" + ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel());\n}\ntry {\nsector = GameServer.getUniverse().getSector(position);\n} catch (IOException e) {\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\n\ne.printStackTrace();\nreturn false;\n}\nif (sector == null) {\nreturn false;\n}\nint checkRange = 3; \/\/range to check for inhibitors [sectors]\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n\nint shipReactorLvl = 0;\ntry {\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n\nshipReactorLvl = ((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor().getLevel();\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n\n} catch (Exception e) {\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\n\ne.printStackTrace();\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n\nDebugFile.log(\"managercontainer null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer() == null));\nDebugFile.log(\"powerinterface null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface() == null));\nDebugFile.log(\"activereactor null: \" + (((ManagedSegmentController<?>)ship).getManagerContainer().getPowerInterface().getActiveReactor() == null));\nreturn true;\n}\nint inhibitorStrength = 0;\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}\n\nint catchesLvl = 0;\ndouble inhRange = 0;\nVector3i currentSec = ship.getSector(new Vector3i()); \/\/TODO refactor me and make me pretty\nfor (int x = -checkRange; x <= checkRange; ++x) {\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}\n\nfor (int y = -checkRange; y <= checkRange; ++y) {\nfor (int z = -checkRange; z <= checkRange; ++z) {\nneighbourSectorPos.set(sector.pos.x + z, sector.pos.y + y, sector.pos.z + x);\nSector neighbourSector;\nif ((neighbourSector = GameServerState.instance.getUniverse().getSectorWithoutLoading(neighbourSectorPos)) == null) {\ncontinue; \/\/sector is not loaded\n}\n\/\/get inhibitor level \/\/returns [0..9]\ninhibitorStrength = neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_STRENGTH, 1); \/\/TODO change apply value to 300K?\ncatchesLvl = inhibitorStrength * 60; \/\/will catch anything up to\n\/\/max inhRange of inhibitor\ninhRange = Math.max(0, neighbourSector.getRemoteSector().getConfigManager().apply(StatusEffectType.WARP_INTERDICTION_DISTANCE, 1));\nint dx = Math.abs(currentSec.x - neighbourSectorPos.x);\nint dy = Math.abs(currentSec.y - neighbourSectorPos.y);\nint dz = Math.abs(currentSec.z - neighbourSectorPos.z);\ndouble distance = Math.pow(dx * dx + dy * dy + dz * dz,0.5);\n\/\/TODO change config entry of inhibition power consumption\nif (inhibitorStrength <= 1 || (distance > inhRange)) {\ncontinue;\n}\n\/\/DebugFile.log(\"inhibitor has strength: \" + inhibitorStrength + \" catches rkt level: \" + catchesLvl + \" power cons: \" + inhibitorStrength * 60000 + \" range: \" + inhRange + \" vs: \" + distance);\nif (catchesLvl >= shipReactorLvl) {\nwarpdrive.getSegmentController().sendControllingPlayersServerMessage(new Object[]{\" inhibitor detected in \" + neighbourSectorPos.toString()}, 3);\nretVal = true;\nbreak;\n}\n}\n}\n}\nreturn retVal;\n}","label":[1,1,0,0]}
{"id":12225,"original_code":"public Map act( Redirector redirector,\n                    SourceResolver resolver,\n                    Map objectModel,\n                    String source,\n                    Parameters par )\n    throws Exception {\n        Source src = null;\n        try {\n            \/\/ Figure out what script to open.  A missing script name is caught\n            \/\/ by the resolver\/SystemId grouping later on and causes an exception\n            String scriptName = source;\n            \/\/ Locate the appropriate file on the filesytem\n            src = resolver.resolve(scriptName);\n            String systemID = src.getSystemId();\n            if (this.getLogger().isDebugEnabled()) {\n                getLogger().debug(\"script source [\" + scriptName + \"]\");\n                getLogger().debug(\"script resolved to [\" + systemID + \"]\");\n            }\n            \/\/ TODO: why doesn't this work?\n            \/\/ Reader in = src.getCharacterStream();\n            Reader in = new InputStreamReader(src.getInputStream());\n            \/\/ Set up the BSF manager and register relevant helper \"beans\"\n            BSFManager mgr = new BSFManager();\n            HashMap actionMap = new HashMap();\n            \/\/ parameters to act(...)\n            mgr.registerBean(\"resolver\", resolver);\n            mgr.registerBean(\"objectModel\", objectModel);\n            mgr.registerBean(\"parameters\", par);\n            \/\/ ScriptAction housekeeping\n            mgr.registerBean(\"actionMap\", actionMap);\n            \/\/ helpers\n            \/\/ TODO: should we check for a null request object here or let the script handle it?\n            mgr.registerBean(\"logger\", getLogger());\n            mgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\n            mgr.registerBean(\"scriptaction\", this );\n            mgr.registerBean(\"manager\", this.manager );\n            getLogger().debug(\"BSFManager execution begining\");\n            \/\/ Execute the script\n            mgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\n                    IOUtils.getStringFromReader(in));\n            getLogger().debug(\"BSFManager execution complete\");\n            \/\/ Figure out what to return\n            \/\/ TODO: decide on a more robust communication method\n            if ( actionMap.containsKey( \"scriptaction-continue\" ) )\n            {\n                return ( Collections.unmodifiableMap(actionMap) );\n            }\n            else\n            {\n                return ( null );\n            }\n        } catch (ProcessingException e) {\n            throw e;\n        } catch (Exception e) {\n            throw new ProcessingException(\n                    \"Exception in ScriptAction.act()\", e);\n        } finally {\n            if (src != null) src.recycle();\n        } \/\/ try\/catch\n    }","code":"public Map act( Redirector redirector,\n                    SourceResolver resolver,\n                    Map objectModel,\n                    String source,\n                    Parameters par )\n    throws Exception {\n        Source src = null;\n        try {\n           \n           \n            String scriptName = source;\n           \n            src = resolver.resolve(scriptName);\n            String systemID = src.getSystemId();\n            if (this.getLogger().isDebugEnabled()) {\n                getLogger().debug(\"script source [\" + scriptName + \"]\");\n                getLogger().debug(\"script resolved to [\" + systemID + \"]\");\n            }\n           \n           \n            Reader in = new InputStreamReader(src.getInputStream());\n           \n            BSFManager mgr = new BSFManager();\n            HashMap actionMap = new HashMap();\n           \n            mgr.registerBean(\"resolver\", resolver);\n            mgr.registerBean(\"objectModel\", objectModel);\n            mgr.registerBean(\"parameters\", par);\n           \n            mgr.registerBean(\"actionMap\", actionMap);\n           \n           \n            mgr.registerBean(\"logger\", getLogger());\n            mgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\n            mgr.registerBean(\"scriptaction\", this );\n            mgr.registerBean(\"manager\", this.manager );\n            getLogger().debug(\"BSFManager execution begining\");\n           \n            mgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\n                    IOUtils.getStringFromReader(in));\n            getLogger().debug(\"BSFManager execution complete\");\n           \n           \n            if ( actionMap.containsKey( \"scriptaction-continue\" ) )\n            {\n                return ( Collections.unmodifiableMap(actionMap) );\n            }\n            else\n            {\n                return ( null );\n            }\n        } catch (ProcessingException e) {\n            throw e;\n        } catch (Exception e) {\n            throw new ProcessingException(\n                    \"Exception in ScriptAction.act()\", e);\n        } finally {\n            if (src != null) src.recycle();\n        }\n    }","cleancode":"public map act( redirector redirector, sourceresolver resolver, map objectmodel, string source, parameters par ) throws exception { source src = null; try { string scriptname = source; src = resolver.resolve(scriptname); string systemid = src.getsystemid(); if (this.getlogger().isdebugenabled()) { getlogger().debug(\"script source [\" + scriptname + \"]\"); getlogger().debug(\"script resolved to [\" + systemid + \"]\"); } reader in = new inputstreamreader(src.getinputstream()); bsfmanager mgr = new bsfmanager(); hashmap actionmap = new hashmap(); mgr.registerbean(\"resolver\", resolver); mgr.registerbean(\"objectmodel\", objectmodel); mgr.registerbean(\"parameters\", par); mgr.registerbean(\"actionmap\", actionmap); mgr.registerbean(\"logger\", getlogger()); mgr.registerbean(\"request\", ( (request) objectmodel.get(constants.request_object) ) ); mgr.registerbean(\"scriptaction\", this ); mgr.registerbean(\"manager\", this.manager ); getlogger().debug(\"bsfmanager execution begining\"); mgr.exec(bsfmanager.getlangfromfilename(systemid), systemid, 0, 0, ioutils.getstringfromreader(in)); getlogger().debug(\"bsfmanager execution complete\"); if ( actionmap.containskey( \"scriptaction-continue\" ) ) { return ( collections.unmodifiablemap(actionmap) ); } else { return ( null ); } } catch (processingexception e) { throw e; } catch (exception e) { throw new processingexception( \"exception in scriptaction.act()\", e); } finally { if (src != null) src.recycle(); } }","comment":"\/\/ figure out what script to open. a missing script name is caught \/\/ by the resolver\/systemid grouping later on and causes an exception\n\/\/ locate the appropriate file on the filesytem\n\/\/ todo: why doesn't this work? \/\/ reader in = src.getcharacterstream();\n\/\/ set up the bsf manager and register relevant helper \"beans\"\n\/\/ parameters to act(...)\n\/\/ scriptaction housekeeping\n\/\/ helpers \/\/ todo: should we check for a null request object here or let the script handle it?\n\/\/ execute the script\n\/\/ figure out what to return \/\/ todo: decide on a more robust communication method\n\/\/ try\/catch","repo":"tharindusathis\/sourcecodes-of-CodeReadingTheOpenSourcePerspective","code_context_2":"Source src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\n\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\n\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\n\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\n\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\n\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\n\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\n\n} finally {\nif (src != null) src.recycle();\n} \/\/ try\/catch\n}","code_context_10":"public Map act( Redirector redirector,\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\n\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\n\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\n\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\n\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\n\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\nthrow e;\n\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\nthrow e;\n} catch (Exception e) {\nthrow new ProcessingException(\n\"Exception in ScriptAction.act()\", e);\n} finally {\nif (src != null) src.recycle();\n} \/\/ try\/catch\n}","code_context_20":"public Map act( Redirector redirector,\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\npublic Map act( Redirector redirector,\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\n\npublic Map act( Redirector redirector,\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\n\nSourceResolver resolver,\nMap objectModel,\nString source,\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\nParameters par )\nthrows Exception {\nSource src = null;\ntry {\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\n\n\/\/ Figure out what script to open. A missing script name is caught\n\/\/ by the resolver\/SystemId grouping later on and causes an exception\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\n\nString scriptName = source;\n\/\/ Locate the appropriate file on the filesytem\nsrc = resolver.resolve(scriptName);\nString systemID = src.getSystemId();\nif (this.getLogger().isDebugEnabled()) {\ngetLogger().debug(\"script source [\" + scriptName + \"]\");\ngetLogger().debug(\"script resolved to [\" + systemID + \"]\");\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\n\n}\n\/\/ TODO: why doesn't this work?\n\/\/ Reader in = src.getCharacterStream();\nReader in = new InputStreamReader(src.getInputStream());\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\nthrow e;\n} catch (Exception e) {\nthrow new ProcessingException(\n\"Exception in ScriptAction.act()\", e);\n} finally {\nif (src != null) src.recycle();\n\n\/\/ Set up the BSF manager and register relevant helper \"beans\"\nBSFManager mgr = new BSFManager();\nHashMap actionMap = new HashMap();\n\/\/ parameters to act(...)\nmgr.registerBean(\"resolver\", resolver);\nmgr.registerBean(\"objectModel\", objectModel);\nmgr.registerBean(\"parameters\", par);\n\/\/ ScriptAction housekeeping\nmgr.registerBean(\"actionMap\", actionMap);\n\/\/ helpers\n\/\/ TODO: should we check for a null request object here or let the script handle it?\nmgr.registerBean(\"logger\", getLogger());\nmgr.registerBean(\"request\", ( (Request) objectModel.get(Constants.REQUEST_OBJECT) ) );\nmgr.registerBean(\"scriptaction\", this );\nmgr.registerBean(\"manager\", this.manager );\ngetLogger().debug(\"BSFManager execution begining\");\n\/\/ Execute the script\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\nthrow e;\n} catch (Exception e) {\nthrow new ProcessingException(\n\"Exception in ScriptAction.act()\", e);\n} finally {\nif (src != null) src.recycle();\n} \/\/ try\/catch\n}\n\nmgr.exec(BSFManager.getLangFromFilename(systemID), systemID, 0, 0,\nIOUtils.getStringFromReader(in));\ngetLogger().debug(\"BSFManager execution complete\");\n\/\/ Figure out what to return\n\/\/ TODO: decide on a more robust communication method\nif ( actionMap.containsKey( \"scriptaction-continue\" ) )\n{\nreturn ( Collections.unmodifiableMap(actionMap) );\n}\nelse\n{\nreturn ( null );\n}\n} catch (ProcessingException e) {\nthrow e;\n} catch (Exception e) {\nthrow new ProcessingException(\n\"Exception in ScriptAction.act()\", e);\n} finally {\nif (src != null) src.recycle();\n} \/\/ try\/catch\n}","label":[1,0,1,0]}
{"id":12505,"original_code":"private void readAnnotations(final Document<D> doc, final String annSet, final String path) {\n    final File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/    log.info(\"Reading annotations from {}\", file.getPath());\n    if (!file.exists() || file.length() == 0) {\n      \/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n       * Also its super annoying so I commented it out...\n       * :'(\n       *\/\n\/\/      noAnnotationsCount++;\n\/\/      if (noAnnotationsCount % 100 == 1) {\n\/\/        log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/      }\n    }\n    else {\n      try (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n        \/\/ until the end of this json object\n        while (jp.nextToken() != JsonToken.END_OBJECT) {\n          \/\/ skip types\n          if (\"types\".equals(jp.getCurrentName())) {\n            while (jp.nextToken() != JsonToken.END_OBJECT) {\n              ; \/\/ do nothing: we just want to increment the parser's position\n            }\n          }\n          JsonToken jt;\n          \/\/ annotation map\n          if (\"annotations\".equals(jp.getCurrentName())) {\n            String type;\n            jp.nextToken();\n            while ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\n              if (jt == JsonToken.START_OBJECT) {\n                type = jp.getCurrentName();\n                while(jp.nextToken() != JsonToken.END_OBJECT) {\n                  readAnnotation(jp, doc, annSet, type);\n                }\n              }\n            }\n          }\n          \/\/relation map\n          if (\"relations\".equals(jp.getCurrentName())) {\n            String type;\n            jp.nextToken();\n            while ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\n              if (jt == JsonToken.START_OBJECT) {\n                type = jp.getCurrentName();\n                while(jp.nextToken() != JsonToken.END_OBJECT) {\n                  readRelation(jp, doc, annSet, type);\n                }\n              }\n            }\n          }\n        }\n      } catch (IOException | ClassNotFoundException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }","code":"private void readAnnotations(final Document<D> doc, final String annSet, final String path) {\n    final File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n    if (!file.exists() || file.length() == 0) {\n     \n    }\n    else {\n      try (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n       \n        while (jp.nextToken() != JsonToken.END_OBJECT) {\n         \n          if (\"types\".equals(jp.getCurrentName())) {\n            while (jp.nextToken() != JsonToken.END_OBJECT) {\n              ;\n            }\n          }\n          JsonToken jt;\n         \n          if (\"annotations\".equals(jp.getCurrentName())) {\n            String type;\n            jp.nextToken();\n            while ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\n              if (jt == JsonToken.START_OBJECT) {\n                type = jp.getCurrentName();\n                while(jp.nextToken() != JsonToken.END_OBJECT) {\n                  readAnnotation(jp, doc, annSet, type);\n                }\n              }\n            }\n          }\n         \n          if (\"relations\".equals(jp.getCurrentName())) {\n            String type;\n            jp.nextToken();\n            while ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\n              if (jt == JsonToken.START_OBJECT) {\n                type = jp.getCurrentName();\n                while(jp.nextToken() != JsonToken.END_OBJECT) {\n                  readRelation(jp, doc, annSet, type);\n                }\n              }\n            }\n          }\n        }\n      } catch (IOException | ClassNotFoundException e) {\n        throw new RuntimeException(e);\n      }\n    }\n  }","cleancode":"private void readannotations(final document<d> doc, final string annset, final string path) { final file file = new file(path + file.separator + doc.get(basedocument.id) + \".json\"); if (!file.exists() || file.length() == 0) { } else { try (jsonparser jp = jf.createparser(compression.inputwrapper.apply(files.newinputstream(file.topath())))) { while (jp.nexttoken() != jsontoken.end_object) { if (\"types\".equals(jp.getcurrentname())) { while (jp.nexttoken() != jsontoken.end_object) { ; } } jsontoken jt; if (\"annotations\".equals(jp.getcurrentname())) { string type; jp.nexttoken(); while ((jt = jp.nexttoken()) != jsontoken.end_object) { if (jt == jsontoken.start_object) { type = jp.getcurrentname(); while(jp.nexttoken() != jsontoken.end_object) { readannotation(jp, doc, annset, type); } } } } if (\"relations\".equals(jp.getcurrentname())) { string type; jp.nexttoken(); while ((jt = jp.nexttoken()) != jsontoken.end_object) { if (jt == jsontoken.start_object) { type = jp.getcurrentname(); while(jp.nexttoken() != jsontoken.end_object) { readrelation(jp, doc, annset, type); } } } } } } catch (ioexception | classnotfoundexception e) { throw new runtimeexception(e); } } }","comment":"\/\/ read from <annpath>\/<annset>\/<tiering>\/<docid>.json\n\/\/ log.info(\"reading annotations from {}\", file.getpath());\n\/* todo: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy * also its super annoying so i commented it out... * :'( *\/\n\/\/ noannotationscount++; \/\/ if (noannotationscount % 100 == 1) { \/\/ log.debug(\"{} document(s) do not have {} annotations\", noannotationscount, annset); \/\/ }\n\/\/ until the end of this json object\n\/\/ skip types\n\/\/ do nothing: we just want to increment the parser's position\n\/\/ annotation map\n\/\/relation map","repo":"utd-hltri\/scribe","code_context_2":"private void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadRelation(jp, doc, annSet, type);\n}\n}\n}\n}\n}\n} catch (IOException | ClassNotFoundException e) {\nthrow new RuntimeException(e);\n}\n}\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\n\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\n\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\n\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\n\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;","code_context_10":"private void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadRelation(jp, doc, annSet, type);\n}\n}\n}\n}\n}\n} catch (IOException | ClassNotFoundException e) {\nthrow new RuntimeException(e);\n}\n}\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\n\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\n\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\n\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadRelation(jp, doc, annSet, type);\n}\n}","code_context_20":"private void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadRelation(jp, doc, annSet, type);\n}\n}\n}\n}\n}\n} catch (IOException | ClassNotFoundException e) {\nthrow new RuntimeException(e);\n}\n}\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\n\nprivate void readAnnotations(final Document<D> doc, final String annSet, final String path) {\nfinal File file = new File(path + File.separator + doc.get(BaseDocument.id) + \".json\");\n\/\/ log.info(\"Reading annotations from {}\", file.getPath());\nif (!file.exists() || file.length() == 0) {\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\n\n\/* TODO: this doesn't work -- if you have multiple streams or processes sharing a json corpus the counts get crazy\n* Also its super annoying so I commented it out...\n* :'(\n*\/\n\/\/ noAnnotationsCount++;\n\/\/ if (noAnnotationsCount % 100 == 1) {\n\/\/ log.debug(\"{} document(s) do not have {} annotations\", noAnnotationsCount, annSet);\n\/\/ }\n}\nelse {\ntry (JsonParser jp = jf.createParser(compression.inputWrapper.apply(Files.newInputStream(file.toPath())))) {\n\/\/ until the end of this json object\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\n\n\/\/ skip types\nif (\"types\".equals(jp.getCurrentName())) {\nwhile (jp.nextToken() != JsonToken.END_OBJECT) {\n; \/\/ do nothing: we just want to increment the parser's position\n}\n}\nJsonToken jt;\n\/\/ annotation map\nif (\"annotations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadAnnotation(jp, doc, annSet, type);\n}\n}\n}\n}\n\/\/relation map\nif (\"relations\".equals(jp.getCurrentName())) {\nString type;\njp.nextToken();\nwhile ((jt = jp.nextToken()) != JsonToken.END_OBJECT) {\nif (jt == JsonToken.START_OBJECT) {\ntype = jp.getCurrentName();\nwhile(jp.nextToken() != JsonToken.END_OBJECT) {\nreadRelation(jp, doc, annSet, type);\n}\n}\n}\n}\n}\n} catch (IOException | ClassNotFoundException e) {\nthrow new RuntimeException(e);\n}\n}\n}","label":[0,0,1,0]}
{"id":20711,"original_code":"@Override\n        public boolean equals(Object o) {\n            if (this == o) return true;\n            if (o == null || getClass() != o.getClass()) return false;\n            SummaryDefinition that = (SummaryDefinition) o;\n            if (isRegex != that.isRegex) return false;\n            if (!name.equals(that.name)) return false;\n            if (!function.equals(that.function)) return false;\n            if (!target.equals(that.target)) return false;\n            \/\/ Probably incorrect - comparing Object[] arrays with Arrays.equals\n            return Arrays.equals(arguments, that.arguments);\n        }","code":"@Override\n        public boolean equals(Object o) {\n            if (this == o) return true;\n            if (o == null || getClass() != o.getClass()) return false;\n            SummaryDefinition that = (SummaryDefinition) o;\n            if (isRegex != that.isRegex) return false;\n            if (!name.equals(that.name)) return false;\n            if (!function.equals(that.function)) return false;\n            if (!target.equals(that.target)) return false;\n           \n            return Arrays.equals(arguments, that.arguments);\n        }","cleancode":"@override public boolean equals(object o) { if (this == o) return true; if (o == null || getclass() != o.getclass()) return false; summarydefinition that = (summarydefinition) o; if (isregex != that.isregex) return false; if (!name.equals(that.name)) return false; if (!function.equals(that.function)) return false; if (!target.equals(that.target)) return false; return arrays.equals(arguments, that.arguments); }","comment":"\/\/ probably incorrect - comparing object[] arrays with arrays.equals","repo":"viewserver\/viewserver","code_context_2":"if (!function.equals(that.function)) return false;\nif (!target.equals(that.target)) return false;\n\/\/ Probably incorrect - comparing Object[] arrays with Arrays.equals\nreturn Arrays.equals(arguments, that.arguments);\n}","code_context_10":"@Override\npublic boolean equals(Object o) {\nif (this == o) return true;\nif (o == null || getClass() != o.getClass()) return false;\nSummaryDefinition that = (SummaryDefinition) o;\nif (isRegex != that.isRegex) return false;\nif (!name.equals(that.name)) return false;\nif (!function.equals(that.function)) return false;\nif (!target.equals(that.target)) return false;\n\/\/ Probably incorrect - comparing Object[] arrays with Arrays.equals\nreturn Arrays.equals(arguments, that.arguments);\n}","code_context_20":"@Override\npublic boolean equals(Object o) {\nif (this == o) return true;\nif (o == null || getClass() != o.getClass()) return false;\nSummaryDefinition that = (SummaryDefinition) o;\nif (isRegex != that.isRegex) return false;\nif (!name.equals(that.name)) return false;\nif (!function.equals(that.function)) return false;\nif (!target.equals(that.target)) return false;\n\/\/ Probably incorrect - comparing Object[] arrays with Arrays.equals\nreturn Arrays.equals(arguments, that.arguments);\n}","label":[1,0,0,0]}
{"id":20954,"original_code":"public void saveNewPlayList(String name) {\n        Playlist pl = new Playlist();\n        pl.setName(name);\n        pl.save();\n        List<String> selectedVideos = videoGridAdapter.getCheckedItems();\n        List<Video> myVideos = new ArrayList<>();\n        \/\/ TODO Here I define the order for which I want the videos to play.\n        \/\/ Could try diferent ordering for the playlists\n        \/\/ For now it just accepts the gridAdapter selected array order\n        int order = 0;\n        for (String vid : selectedVideos) {\n            Video video = new Video();\n            video.setUri(vid);\n            video.setPlaylist(pl);\n            video.setOrder(order);\n            order++;\n            myVideos.add(video);\n        }\n        Video.saveAll(myVideos);\n        updatePlaylistList();\n        cancelCreatePlaylist();\n    }","code":"public void saveNewPlayList(String name) {\n        Playlist pl = new Playlist();\n        pl.setName(name);\n        pl.save();\n        List<String> selectedVideos = videoGridAdapter.getCheckedItems();\n        List<Video> myVideos = new ArrayList<>();\n       \n       \n       \n        int order = 0;\n        for (String vid : selectedVideos) {\n            Video video = new Video();\n            video.setUri(vid);\n            video.setPlaylist(pl);\n            video.setOrder(order);\n            order++;\n            myVideos.add(video);\n        }\n        Video.saveAll(myVideos);\n        updatePlaylistList();\n        cancelCreatePlaylist();\n    }","cleancode":"public void savenewplaylist(string name) { playlist pl = new playlist(); pl.setname(name); pl.save(); list<string> selectedvideos = videogridadapter.getcheckeditems(); list<video> myvideos = new arraylist<>(); int order = 0; for (string vid : selectedvideos) { video video = new video(); video.seturi(vid); video.setplaylist(pl); video.setorder(order); order++; myvideos.add(video); } video.saveall(myvideos); updateplaylistlist(); cancelcreateplaylist(); }","comment":"\/\/ todo here i define the order for which i want the videos to play. \/\/ could try diferent ordering for the playlists \/\/ for now it just accepts the gridadapter selected array order","repo":"zepedropaixao\/videoplayer","code_context_2":"List<String> selectedVideos = videoGridAdapter.getCheckedItems();\nList<Video> myVideos = new ArrayList<>();\n\/\/ TODO Here I define the order for which I want the videos to play.\n\/\/ Could try diferent ordering for the playlists\n\/\/ For now it just accepts the gridAdapter selected array order\nint order = 0;\nfor (String vid : selectedVideos) {","code_context_10":"public void saveNewPlayList(String name) {\nPlaylist pl = new Playlist();\npl.setName(name);\npl.save();\nList<String> selectedVideos = videoGridAdapter.getCheckedItems();\nList<Video> myVideos = new ArrayList<>();\n\/\/ TODO Here I define the order for which I want the videos to play.\n\/\/ Could try diferent ordering for the playlists\n\/\/ For now it just accepts the gridAdapter selected array order\nint order = 0;\nfor (String vid : selectedVideos) {\nVideo video = new Video();\nvideo.setUri(vid);\nvideo.setPlaylist(pl);\nvideo.setOrder(order);\norder++;\nmyVideos.add(video);\n}\nVideo.saveAll(myVideos);","code_context_20":"public void saveNewPlayList(String name) {\nPlaylist pl = new Playlist();\npl.setName(name);\npl.save();\nList<String> selectedVideos = videoGridAdapter.getCheckedItems();\nList<Video> myVideos = new ArrayList<>();\n\/\/ TODO Here I define the order for which I want the videos to play.\n\/\/ Could try diferent ordering for the playlists\n\/\/ For now it just accepts the gridAdapter selected array order\nint order = 0;\nfor (String vid : selectedVideos) {\nVideo video = new Video();\nvideo.setUri(vid);\nvideo.setPlaylist(pl);\nvideo.setOrder(order);\norder++;\nmyVideos.add(video);\n}\nVideo.saveAll(myVideos);\nupdatePlaylistList();\ncancelCreatePlaylist();\n}","label":[1,0,0,0]}
{"id":12771,"original_code":"@Override\n        public void notify(FlowTableBatchEvent event) {\n            final FlowTableBatchRequest request = event.subject();\n            switch (event.type()) {\n            case BATCH_OPERATION_REQUESTED:\n                \/\/ Request has been forwarded to MASTER Node, and was\n                request.ops().stream().forEach(\n                        op -> {\n                            switch (op.operator()) {\n                                case ADD:\n                                    post(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\n                                                           op.target()));\n                                    break;\n                                case REMOVE:\n                                    post(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\n                                                           op.target()));\n                                    break;\n                                case MODIFY:\n                                    \/\/TODO: do something here when the time comes.\n                                    break;\n                                default:\n                                    log.warn(\"Unknown flow operation operator: {}\", op.operator());\n                            }\n                        }\n                );\n                DeviceId deviceId = event.deviceId();\n                FlowTableBatchOperation batchOperation =\n                        request.asBatchOperation(deviceId);\n                FlowTableProvider flowTableProvider = getProvider(deviceId);\n                if (flowTableProvider != null) {\n                    flowTableProvider.executeBatch(batchOperation);\n                }\n                break;\n            case BATCH_OPERATION_COMPLETED:\n                FlowOperationsProcessor fops = pendingFlowOperations.remove(\n                        event.subject().batchId());\n                if (event.result().isSuccess()) {\n                    if (fops != null) {\n                        fops.satisfy(event.deviceId());\n                    }\n                } else {\n                    fops.fail(event.deviceId(), event.result().failedItems());\n                }\n                break;\n            default:\n                break;\n            }\n        }","code":"@Override\n        public void notify(FlowTableBatchEvent event) {\n            final FlowTableBatchRequest request = event.subject();\n            switch (event.type()) {\n            case BATCH_OPERATION_REQUESTED:\n               \n                request.ops().stream().forEach(\n                        op -> {\n                            switch (op.operator()) {\n                                case ADD:\n                                    post(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\n                                                           op.target()));\n                                    break;\n                                case REMOVE:\n                                    post(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\n                                                           op.target()));\n                                    break;\n                                case MODIFY:\n                                   \n                                    break;\n                                default:\n                                    log.warn(\"Unknown flow operation operator: {}\", op.operator());\n                            }\n                        }\n                );\n                DeviceId deviceId = event.deviceId();\n                FlowTableBatchOperation batchOperation =\n                        request.asBatchOperation(deviceId);\n                FlowTableProvider flowTableProvider = getProvider(deviceId);\n                if (flowTableProvider != null) {\n                    flowTableProvider.executeBatch(batchOperation);\n                }\n                break;\n            case BATCH_OPERATION_COMPLETED:\n                FlowOperationsProcessor fops = pendingFlowOperations.remove(\n                        event.subject().batchId());\n                if (event.result().isSuccess()) {\n                    if (fops != null) {\n                        fops.satisfy(event.deviceId());\n                    }\n                } else {\n                    fops.fail(event.deviceId(), event.result().failedItems());\n                }\n                break;\n            default:\n                break;\n            }\n        }","cleancode":"@override public void notify(flowtablebatchevent event) { final flowtablebatchrequest request = event.subject(); switch (event.type()) { case batch_operation_requested: request.ops().stream().foreach( op -> { switch (op.operator()) { case add: post(new flowtableevent(flowtableevent.type.table_add_requested, op.target())); break; case remove: post(new flowtableevent(flowtableevent.type.table_remove_requested, op.target())); break; case modify: break; default: log.warn(\"unknown flow operation operator: {}\", op.operator()); } } ); deviceid deviceid = event.deviceid(); flowtablebatchoperation batchoperation = request.asbatchoperation(deviceid); flowtableprovider flowtableprovider = getprovider(deviceid); if (flowtableprovider != null) { flowtableprovider.executebatch(batchoperation); } break; case batch_operation_completed: flowoperationsprocessor fops = pendingflowoperations.remove( event.subject().batchid()); if (event.result().issuccess()) { if (fops != null) { fops.satisfy(event.deviceid()); } } else { fops.fail(event.deviceid(), event.result().faileditems()); } break; default: break; } }","comment":"\/\/ todo: right now we only dispatch events at individual flowentry level. \/\/ it may be more efficient for also dispatch events as a batch.\n\/\/ request has been forwarded to master node, and was\n\/\/todo: do something here when the time comes.","repo":"ustc-fhq\/onos","code_context_2":"@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\nFlowTableBatchOperation batchOperation =\nrequest.asBatchOperation(deviceId);\nFlowTableProvider flowTableProvider = getProvider(deviceId);\nif (flowTableProvider != null) {\nflowTableProvider.executeBatch(batchOperation);\n}\nbreak;\ncase BATCH_OPERATION_COMPLETED:\nFlowOperationsProcessor fops = pendingFlowOperations.remove(\nevent.subject().batchId());\nif (event.result().isSuccess()) {\nif (fops != null) {\nfops.satisfy(event.deviceId());\n}\n} else {\nfops.fail(event.deviceId(), event.result().failedItems());\n}\nbreak;\ndefault:\nbreak;\n}\n}\n\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\n\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:","code_context_10":"@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\nFlowTableBatchOperation batchOperation =\nrequest.asBatchOperation(deviceId);\nFlowTableProvider flowTableProvider = getProvider(deviceId);\nif (flowTableProvider != null) {\nflowTableProvider.executeBatch(batchOperation);\n}\nbreak;\ncase BATCH_OPERATION_COMPLETED:\nFlowOperationsProcessor fops = pendingFlowOperations.remove(\nevent.subject().batchId());\nif (event.result().isSuccess()) {\nif (fops != null) {\nfops.satisfy(event.deviceId());\n}\n} else {\nfops.fail(event.deviceId(), event.result().failedItems());\n}\nbreak;\ndefault:\nbreak;\n}\n}\n\n@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\n\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\nFlowTableBatchOperation batchOperation =\nrequest.asBatchOperation(deviceId);\nFlowTableProvider flowTableProvider = getProvider(deviceId);","code_context_20":"@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\nFlowTableBatchOperation batchOperation =\nrequest.asBatchOperation(deviceId);\nFlowTableProvider flowTableProvider = getProvider(deviceId);\nif (flowTableProvider != null) {\nflowTableProvider.executeBatch(batchOperation);\n}\nbreak;\ncase BATCH_OPERATION_COMPLETED:\nFlowOperationsProcessor fops = pendingFlowOperations.remove(\nevent.subject().batchId());\nif (event.result().isSuccess()) {\nif (fops != null) {\nfops.satisfy(event.deviceId());\n}\n} else {\nfops.fail(event.deviceId(), event.result().failedItems());\n}\nbreak;\ndefault:\nbreak;\n}\n}\n\n@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\n\n@Override\npublic void notify(FlowTableBatchEvent event) {\nfinal FlowTableBatchRequest request = event.subject();\nswitch (event.type()) {\ncase BATCH_OPERATION_REQUESTED:\n\/\/ Request has been forwarded to MASTER Node, and was\nrequest.ops().stream().forEach(\nop -> {\nswitch (op.operator()) {\ncase ADD:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_ADD_REQUESTED,\nop.target()));\nbreak;\ncase REMOVE:\npost(new FlowTableEvent(FlowTableEvent.Type.TABLE_REMOVE_REQUESTED,\nop.target()));\nbreak;\ncase MODIFY:\n\/\/TODO: do something here when the time comes.\nbreak;\ndefault:\nlog.warn(\"Unknown flow operation operator: {}\", op.operator());\n}\n}\n);\nDeviceId deviceId = event.deviceId();\nFlowTableBatchOperation batchOperation =\nrequest.asBatchOperation(deviceId);\nFlowTableProvider flowTableProvider = getProvider(deviceId);\nif (flowTableProvider != null) {\nflowTableProvider.executeBatch(batchOperation);\n}\nbreak;\ncase BATCH_OPERATION_COMPLETED:\nFlowOperationsProcessor fops = pendingFlowOperations.remove(\nevent.subject().batchId());\nif (event.result().isSuccess()) {\nif (fops != null) {\nfops.satisfy(event.deviceId());","label":[1,1,0,0]}
{"id":12923,"original_code":"public float angleInRadians() {\n        return (float) angle() \/ millimetersPerRadian;\n    }","code":"public float angleInRadians() {\n        return (float) angle() \/ millimetersPerRadian;\n    }","cleancode":"public float angleinradians() { return (float) angle() \/ millimetersperradian; }","comment":"\/** * angle since last read, but in radians *\/ \/\/ fixme i think this should be (2 * angle())\/258","repo":"timassman\/roomba","code_context_2":"public float angleInRadians() {\nreturn (float) angle() \/ millimetersPerRadian;\n}","code_context_10":"public float angleInRadians() {\nreturn (float) angle() \/ millimetersPerRadian;\n}","code_context_20":"public float angleInRadians() {\nreturn (float) angle() \/ millimetersPerRadian;\n}","label":[1,0,0,0]}
{"id":30005,"original_code":"protected final Preferences getPreferences(boolean allowGrouped) {\n        if (allowGrouped) {\n            Group act = Group.getActiveGroup();\n            if (act != null) {\n                \/\/TODO replace with NbPreferences.forModule()\n                return act.prefs().node(OpenProjectListSettings.class.getPackage().getName().replace(\".\", \"\/\"));\n            }   \n        }\n        return NbPreferences.forModule(OpenProjectListSettings.class);\n    }","code":"protected final Preferences getPreferences(boolean allowGrouped) {\n        if (allowGrouped) {\n            Group act = Group.getActiveGroup();\n            if (act != null) {\n               \n                return act.prefs().node(OpenProjectListSettings.class.getPackage().getName().replace(\".\", \"\/\"));\n            }   \n        }\n        return NbPreferences.forModule(OpenProjectListSettings.class);\n    }","cleancode":"protected final preferences getpreferences(boolean allowgrouped) { if (allowgrouped) { group act = group.getactivegroup(); if (act != null) { return act.prefs().node(openprojectlistsettings.class.getpackage().getname().replace(\".\", \"\/\")); } } return nbpreferences.formodule(openprojectlistsettings.class); }","comment":"\/\/todo replace with nbpreferences.formodule()","repo":"timfel\/netbeans","code_context_2":"Group act = Group.getActiveGroup();\nif (act != null) {\n\/\/TODO replace with NbPreferences.forModule()\nreturn act.prefs().node(OpenProjectListSettings.class.getPackage().getName().replace(\".\", \"\/\"));\n}","code_context_10":"protected final Preferences getPreferences(boolean allowGrouped) {\nif (allowGrouped) {\nGroup act = Group.getActiveGroup();\nif (act != null) {\n\/\/TODO replace with NbPreferences.forModule()\nreturn act.prefs().node(OpenProjectListSettings.class.getPackage().getName().replace(\".\", \"\/\"));\n}\n}\nreturn NbPreferences.forModule(OpenProjectListSettings.class);\n}","code_context_20":"protected final Preferences getPreferences(boolean allowGrouped) {\nif (allowGrouped) {\nGroup act = Group.getActiveGroup();\nif (act != null) {\n\/\/TODO replace with NbPreferences.forModule()\nreturn act.prefs().node(OpenProjectListSettings.class.getPackage().getName().replace(\".\", \"\/\"));\n}\n}\nreturn NbPreferences.forModule(OpenProjectListSettings.class);\n}","label":[1,0,0,0]}
{"id":30093,"original_code":"public static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n        \/\/ The annotation @CDIUI can have a value, so using it as the type\n        \/\/ parameter of AnnotationLiteral is somewhat problematic.\n        Set<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\n                new AnnotationLiteral<Any>() {\n                });\n        return uiBeans;\n    }","code":"public static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n       \n       \n        Set<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\n                new AnnotationLiteral<Any>() {\n                });\n        return uiBeans;\n    }","cleancode":"public static set<bean<?>> getuibeans(beanmanager beanmanager) { set<bean<?>> uibeans = beanmanager.getbeans(ui.class, new annotationliteral<any>() { }); return uibeans; }","comment":"\/** * list all ui beans (whether or not they have the {@link cdiui} annotation. * * @param beanmanager * @return set of ui beans *\/\n\/\/ the annotation @cdiui can have a value, so using it as the type \/\/ parameter of annotationliteral is somewhat problematic.","repo":"tomitribe\/cdi","code_context_2":"public static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {\n});\nreturn uiBeans;\n}\n\npublic static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {","code_context_10":"public static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {\n});\nreturn uiBeans;\n}\n\npublic static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {\n});\nreturn uiBeans;\n}","code_context_20":"public static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {\n});\nreturn uiBeans;\n}\n\npublic static Set<Bean<?>> getUiBeans(BeanManager beanManager) {\n\/\/ The annotation @CDIUI can have a value, so using it as the type\n\/\/ parameter of AnnotationLiteral is somewhat problematic.\nSet<Bean<?>> uiBeans = beanManager.getBeans(UI.class,\nnew AnnotationLiteral<Any>() {\n});\nreturn uiBeans;\n}","label":[0,0,1,0]}
{"id":30175,"original_code":"public Packet secureRequest(\n            Packet packet, Subject clientSubject, boolean isSCMessage) throws XWSSecurityException {\n        \/\/ invoke the Trust Plugin if necessary\n        Message msg = packet.getMessage();\n        invokeTrustPlugin(packet, isSCMessage);\n        ProcessingContext ctx = initializeOutgoingProcessingContext(packet, isSCMessage);\n        ((ProcessingContextImpl)ctx).setIssuedTokenContextMap(issuedTokenContextMap);\n        ((ProcessingContextImpl)ctx).setSCPolicyIDtoSctIdMap(scPolicyIDtoSctIdMap);\n        ctx.isClient(true);\n        if(hasKerberosTokenPolicy()){\n            populateKerberosContext(packet, (ProcessingContextImpl)ctx, isSCMessage);\n        }\n        if(isSCRenew(packet)){\n            SCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI());\n            config.getOtherOptions().put(\"MessagePolicy\", (MessagePolicy) ctx.getSecurityPolicy());\n            IssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());                    \n            try{\n                itm.renewIssuedToken(itc);\n            }catch(WSTrustException se){\n                log.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                throw new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n            }\n        }\n        \/\/TODO: replace this code with calls to the Module now\n        try {\n            if (!optimized) {\n                if (!isSCMessage) {\n                    cacheOperation(msg, packet);\n                }\n                SOAPMessage soapMessage = msg.readAsSOAPMessage();\n                soapMessage = secureOutboundMessage(soapMessage, ctx);\n                msg = Messages.create(soapMessage);\n            } else {\n                msg = secureOutboundMessage(msg, ctx);\n            }\n        } catch (WssSoapFaultException ex) {\n             log.log(Level.SEVERE,\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), ex);\n             throw new  WebServiceException(\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), getSOAPFaultException(ex));\n        } catch (SOAPException se) {\n            log.log(Level.SEVERE,\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\n            throw new WebServiceException(\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\n        }\n        packet.setMessage(msg);\n        if(isSCMessage){\n            if(isSCRenew(packet)){\n                Token scToken = (Token)packet.invocationProperties.get(SC_ASSERTION);\n                SCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI(), false);\n                config.getOtherOptions().put(\"MessagePolicy\", getOutgoingXWSBootstrapPolicy(scToken));\n                IssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\n                try{\n                    itm.renewIssuedToken(itc);\n                }catch(WSTrustException se){\n                    log.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                    throw new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                }                \n            }\n            Packet responsePacket = null;\n            if (nextPipe != null) {\n                \/\/legacy pipes in GF\n                responsePacket = nextPipe.process(packet);\n            } else {\n                if (nextTube != null) {\n                    responsePacket = Fiber.current().owner.createFiber().runSync(nextTube, packet);\n                }\n            }\n            packet = validateResponse(responsePacket, null, null);\n        }\n        return packet;\n    }","code":"public Packet secureRequest(\n            Packet packet, Subject clientSubject, boolean isSCMessage) throws XWSSecurityException {\n       \n        Message msg = packet.getMessage();\n        invokeTrustPlugin(packet, isSCMessage);\n        ProcessingContext ctx = initializeOutgoingProcessingContext(packet, isSCMessage);\n        ((ProcessingContextImpl)ctx).setIssuedTokenContextMap(issuedTokenContextMap);\n        ((ProcessingContextImpl)ctx).setSCPolicyIDtoSctIdMap(scPolicyIDtoSctIdMap);\n        ctx.isClient(true);\n        if(hasKerberosTokenPolicy()){\n            populateKerberosContext(packet, (ProcessingContextImpl)ctx, isSCMessage);\n        }\n        if(isSCRenew(packet)){\n            SCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI());\n            config.getOtherOptions().put(\"MessagePolicy\", (MessagePolicy) ctx.getSecurityPolicy());\n            IssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());                    \n            try{\n                itm.renewIssuedToken(itc);\n            }catch(WSTrustException se){\n                log.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                throw new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n            }\n        }\n       \n        try {\n            if (!optimized) {\n                if (!isSCMessage) {\n                    cacheOperation(msg, packet);\n                }\n                SOAPMessage soapMessage = msg.readAsSOAPMessage();\n                soapMessage = secureOutboundMessage(soapMessage, ctx);\n                msg = Messages.create(soapMessage);\n            } else {\n                msg = secureOutboundMessage(msg, ctx);\n            }\n        } catch (WssSoapFaultException ex) {\n             log.log(Level.SEVERE,\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), ex);\n             throw new  WebServiceException(\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), getSOAPFaultException(ex));\n        } catch (SOAPException se) {\n            log.log(Level.SEVERE,\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\n            throw new WebServiceException(\n                    LogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\n        }\n        packet.setMessage(msg);\n        if(isSCMessage){\n            if(isSCRenew(packet)){\n                Token scToken = (Token)packet.invocationProperties.get(SC_ASSERTION);\n                SCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI(), false);\n                config.getOtherOptions().put(\"MessagePolicy\", getOutgoingXWSBootstrapPolicy(scToken));\n                IssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\n                try{\n                    itm.renewIssuedToken(itc);\n                }catch(WSTrustException se){\n                    log.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                    throw new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n                }                \n            }\n            Packet responsePacket = null;\n            if (nextPipe != null) {\n               \n                responsePacket = nextPipe.process(packet);\n            } else {\n                if (nextTube != null) {\n                    responsePacket = Fiber.current().owner.createFiber().runSync(nextTube, packet);\n                }\n            }\n            packet = validateResponse(responsePacket, null, null);\n        }\n        return packet;\n    }","cleancode":"public packet securerequest( packet packet, subject clientsubject, boolean isscmessage) throws xwssecurityexception { message msg = packet.getmessage(); invoketrustplugin(packet, isscmessage); processingcontext ctx = initializeoutgoingprocessingcontext(packet, isscmessage); ((processingcontextimpl)ctx).setissuedtokencontextmap(issuedtokencontextmap); ((processingcontextimpl)ctx).setscpolicyidtosctidmap(scpolicyidtosctidmap); ctx.isclient(true); if(haskerberostokenpolicy()){ populatekerberoscontext(packet, (processingcontextimpl)ctx, isscmessage); } if(isscrenew(packet)){ sctokenconfiguration config = new defaultsctokenconfiguration(wsscver.getnamespaceuri()); config.getotheroptions().put(\"messagepolicy\", (messagepolicy) ctx.getsecuritypolicy()); issuedtokencontext itc =itm.createissuedtokencontext(config, packet.endpointaddress.tostring()); try{ itm.renewissuedtoken(itc); }catch(wstrustexception se){ log.log(level.severe, logstringsmessages.wsitpvd_0052_error_issuedtoken_creation(), se); throw new webserviceexception(logstringsmessages.wsitpvd_0052_error_issuedtoken_creation(), se); } } try { if (!optimized) { if (!isscmessage) { cacheoperation(msg, packet); } soapmessage soapmessage = msg.readassoapmessage(); soapmessage = secureoutboundmessage(soapmessage, ctx); msg = messages.create(soapmessage); } else { msg = secureoutboundmessage(msg, ctx); } } catch (wsssoapfaultexception ex) { log.log(level.severe, logstringsmessages.wsitpvd_0029_error_securing_outbound_msg(), ex); throw new webserviceexception( logstringsmessages.wsitpvd_0029_error_securing_outbound_msg(), getsoapfaultexception(ex)); } catch (soapexception se) { log.log(level.severe, logstringsmessages.wsitpvd_0029_error_securing_outbound_msg(), se); throw new webserviceexception( logstringsmessages.wsitpvd_0029_error_securing_outbound_msg(), se); } packet.setmessage(msg); if(isscmessage){ if(isscrenew(packet)){ token sctoken = (token)packet.invocationproperties.get(sc_assertion); sctokenconfiguration config = new defaultsctokenconfiguration(wsscver.getnamespaceuri(), false); config.getotheroptions().put(\"messagepolicy\", getoutgoingxwsbootstrappolicy(sctoken)); issuedtokencontext itc =itm.createissuedtokencontext(config, packet.endpointaddress.tostring()); try{ itm.renewissuedtoken(itc); }catch(wstrustexception se){ log.log(level.severe, logstringsmessages.wsitpvd_0052_error_issuedtoken_creation(), se); throw new webserviceexception(logstringsmessages.wsitpvd_0052_error_issuedtoken_creation(), se); } } packet responsepacket = null; if (nextpipe != null) { responsepacket = nextpipe.process(packet); } else { if (nexttube != null) { responsepacket = fiber.current().owner.createfiber().runsync(nexttube, packet); } } packet = validateresponse(responsepacket, null, null); } return packet; }","comment":"\/\/ invoke the trust plugin if necessary\n\/\/todo: replace this code with calls to the module now\n\/\/legacy pipes in gf","repo":"torstenwerner\/metro2.0","code_context_2":"public Packet secureRequest(\nPacket packet, Subject clientSubject, boolean isSCMessage) throws XWSSecurityException {\n\/\/ invoke the Trust Plugin if necessary\nMessage msg = packet.getMessage();\ninvokeTrustPlugin(packet, isSCMessage);\n\n}\n}\n\/\/TODO: replace this code with calls to the Module now\ntry {\nif (!optimized) {\n\nPacket responsePacket = null;\nif (nextPipe != null) {\n\/\/legacy pipes in GF\nresponsePacket = nextPipe.process(packet);\n} else {","code_context_10":"public Packet secureRequest(\nPacket packet, Subject clientSubject, boolean isSCMessage) throws XWSSecurityException {\n\/\/ invoke the Trust Plugin if necessary\nMessage msg = packet.getMessage();\ninvokeTrustPlugin(packet, isSCMessage);\nProcessingContext ctx = initializeOutgoingProcessingContext(packet, isSCMessage);\n((ProcessingContextImpl)ctx).setIssuedTokenContextMap(issuedTokenContextMap);\n((ProcessingContextImpl)ctx).setSCPolicyIDtoSctIdMap(scPolicyIDtoSctIdMap);\nctx.isClient(true);\nif(hasKerberosTokenPolicy()){\npopulateKerberosContext(packet, (ProcessingContextImpl)ctx, isSCMessage);\n}\nif(isSCRenew(packet)){\n\nSCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI());\nconfig.getOtherOptions().put(\"MessagePolicy\", (MessagePolicy) ctx.getSecurityPolicy());\nIssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\ntry{\nitm.renewIssuedToken(itc);\n}catch(WSTrustException se){\nlog.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\nthrow new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n}\n}\n\/\/TODO: replace this code with calls to the Module now\ntry {\nif (!optimized) {\nif (!isSCMessage) {\ncacheOperation(msg, packet);\n}\nSOAPMessage soapMessage = msg.readAsSOAPMessage();\nsoapMessage = secureOutboundMessage(soapMessage, ctx);\nmsg = Messages.create(soapMessage);\n} else {\nmsg = secureOutboundMessage(msg, ctx);\n\nIssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\ntry{\nitm.renewIssuedToken(itc);\n}catch(WSTrustException se){\nlog.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\nthrow new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n}\n}\nPacket responsePacket = null;\nif (nextPipe != null) {\n\/\/legacy pipes in GF\nresponsePacket = nextPipe.process(packet);\n} else {\nif (nextTube != null) {\nresponsePacket = Fiber.current().owner.createFiber().runSync(nextTube, packet);\n}\n}\npacket = validateResponse(responsePacket, null, null);\n}\nreturn packet;\n}","code_context_20":"public Packet secureRequest(\nPacket packet, Subject clientSubject, boolean isSCMessage) throws XWSSecurityException {\n\/\/ invoke the Trust Plugin if necessary\nMessage msg = packet.getMessage();\ninvokeTrustPlugin(packet, isSCMessage);\nProcessingContext ctx = initializeOutgoingProcessingContext(packet, isSCMessage);\n((ProcessingContextImpl)ctx).setIssuedTokenContextMap(issuedTokenContextMap);\n((ProcessingContextImpl)ctx).setSCPolicyIDtoSctIdMap(scPolicyIDtoSctIdMap);\nctx.isClient(true);\nif(hasKerberosTokenPolicy()){\npopulateKerberosContext(packet, (ProcessingContextImpl)ctx, isSCMessage);\n}\nif(isSCRenew(packet)){\nSCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI());\nconfig.getOtherOptions().put(\"MessagePolicy\", (MessagePolicy) ctx.getSecurityPolicy());\nIssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\ntry{\nitm.renewIssuedToken(itc);\n}catch(WSTrustException se){\nlog.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\nthrow new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n}\n}\n\nMessage msg = packet.getMessage();\ninvokeTrustPlugin(packet, isSCMessage);\nProcessingContext ctx = initializeOutgoingProcessingContext(packet, isSCMessage);\n((ProcessingContextImpl)ctx).setIssuedTokenContextMap(issuedTokenContextMap);\n((ProcessingContextImpl)ctx).setSCPolicyIDtoSctIdMap(scPolicyIDtoSctIdMap);\nctx.isClient(true);\nif(hasKerberosTokenPolicy()){\npopulateKerberosContext(packet, (ProcessingContextImpl)ctx, isSCMessage);\n}\nif(isSCRenew(packet)){\nSCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI());\nconfig.getOtherOptions().put(\"MessagePolicy\", (MessagePolicy) ctx.getSecurityPolicy());\nIssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\ntry{\nitm.renewIssuedToken(itc);\n}catch(WSTrustException se){\nlog.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\nthrow new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n}\n}\n\/\/TODO: replace this code with calls to the Module now\ntry {\nif (!optimized) {\nif (!isSCMessage) {\ncacheOperation(msg, packet);\n}\nSOAPMessage soapMessage = msg.readAsSOAPMessage();\nsoapMessage = secureOutboundMessage(soapMessage, ctx);\nmsg = Messages.create(soapMessage);\n} else {\nmsg = secureOutboundMessage(msg, ctx);\n}\n} catch (WssSoapFaultException ex) {\nlog.log(Level.SEVERE,\nLogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), ex);\nthrow new WebServiceException(\nLogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), getSOAPFaultException(ex));\n} catch (SOAPException se) {\nlog.log(Level.SEVERE,\nLogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\nthrow new WebServiceException(\n\nLogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\nthrow new WebServiceException(\nLogStringsMessages.WSITPVD_0029_ERROR_SECURING_OUTBOUND_MSG(), se);\n}\npacket.setMessage(msg);\nif(isSCMessage){\nif(isSCRenew(packet)){\nToken scToken = (Token)packet.invocationProperties.get(SC_ASSERTION);\nSCTokenConfiguration config = new DefaultSCTokenConfiguration(wsscVer.getNamespaceURI(), false);\nconfig.getOtherOptions().put(\"MessagePolicy\", getOutgoingXWSBootstrapPolicy(scToken));\nIssuedTokenContext itc =itm.createIssuedTokenContext(config, packet.endpointAddress.toString());\ntry{\nitm.renewIssuedToken(itc);\n}catch(WSTrustException se){\nlog.log(Level.SEVERE, LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\nthrow new WebServiceException(LogStringsMessages.WSITPVD_0052_ERROR_ISSUEDTOKEN_CREATION(), se);\n}\n}\nPacket responsePacket = null;\nif (nextPipe != null) {\n\/\/legacy pipes in GF\nresponsePacket = nextPipe.process(packet);\n} else {\nif (nextTube != null) {\nresponsePacket = Fiber.current().owner.createFiber().runSync(nextTube, packet);\n}\n}\npacket = validateResponse(responsePacket, null, null);\n}\nreturn packet;\n}","label":[1,0,0,0]}
{"id":30177,"original_code":"@Messages({\n        \"# {0} - variable name\",\n        \"ERR_NeitherReadOrWritten=Variable {0} is neither read or written to\",\n        \"# {0} - variable name\",\n        \"ERR_NotWritten=Variable {0} is never written to\",\n        \"# {0} - variable name\",\n        \"ERR_NotRead=Variable {0} is never read\",\n        \"# {0} - element name\",\n        \"ERR_NotUsed={0} is never used\",\n        \"ERR_NotUsedConstructor=Constructor is never used\",\n    })\n    private static ErrorDescription convertUnused(HintContext ctx, UnusedDescription ud) {\n        \/\/TODO: switch expression candidate!\n        String name = ud.unusedElement.getSimpleName().toString();\n        String message;\n        switch (ud.reason) {\n            case NOT_WRITTEN_READ: message = Bundle.ERR_NeitherReadOrWritten(name); break;\n            case NOT_WRITTEN: message = Bundle.ERR_NotWritten(name); break;\n            case NOT_READ: message = Bundle.ERR_NotRead(name); break;\n            case NOT_USED:\n                if (ud.unusedElement.getKind() == ElementKind.CONSTRUCTOR) {\n                    message = Bundle.ERR_NotUsedConstructor();\n                } else {\n                    message = Bundle.ERR_NotUsed(name);\n                }\n                break;\n            default:\n                throw new IllegalStateException(\"Unknown unused type: \" + ud.reason);\n        }\n        return ErrorDescriptionFactory.forName(ctx, ud.unusedElementPath, message);\n    }","code":"@Messages({\n        \"# {0} - variable name\",\n        \"ERR_NeitherReadOrWritten=Variable {0} is neither read or written to\",\n        \"# {0} - variable name\",\n        \"ERR_NotWritten=Variable {0} is never written to\",\n        \"# {0} - variable name\",\n        \"ERR_NotRead=Variable {0} is never read\",\n        \"# {0} - element name\",\n        \"ERR_NotUsed={0} is never used\",\n        \"ERR_NotUsedConstructor=Constructor is never used\",\n    })\n    private static ErrorDescription convertUnused(HintContext ctx, UnusedDescription ud) {\n       \n        String name = ud.unusedElement.getSimpleName().toString();\n        String message;\n        switch (ud.reason) {\n            case NOT_WRITTEN_READ: message = Bundle.ERR_NeitherReadOrWritten(name); break;\n            case NOT_WRITTEN: message = Bundle.ERR_NotWritten(name); break;\n            case NOT_READ: message = Bundle.ERR_NotRead(name); break;\n            case NOT_USED:\n                if (ud.unusedElement.getKind() == ElementKind.CONSTRUCTOR) {\n                    message = Bundle.ERR_NotUsedConstructor();\n                } else {\n                    message = Bundle.ERR_NotUsed(name);\n                }\n                break;\n            default:\n                throw new IllegalStateException(\"Unknown unused type: \" + ud.reason);\n        }\n        return ErrorDescriptionFactory.forName(ctx, ud.unusedElementPath, message);\n    }","cleancode":"@messages({ \"# {0} - variable name\", \"err_neitherreadorwritten=variable {0} is neither read or written to\", \"# {0} - variable name\", \"err_notwritten=variable {0} is never written to\", \"# {0} - variable name\", \"err_notread=variable {0} is never read\", \"# {0} - element name\", \"err_notused={0} is never used\", \"err_notusedconstructor=constructor is never used\", }) private static errordescription convertunused(hintcontext ctx, unuseddescription ud) { string name = ud.unusedelement.getsimplename().tostring(); string message; switch (ud.reason) { case not_written_read: message = bundle.err_neitherreadorwritten(name); break; case not_written: message = bundle.err_notwritten(name); break; case not_read: message = bundle.err_notread(name); break; case not_used: if (ud.unusedelement.getkind() == elementkind.constructor) { message = bundle.err_notusedconstructor(); } else { message = bundle.err_notused(name); } break; default: throw new illegalstateexception(\"unknown unused type: \" + ud.reason); } return errordescriptionfactory.forname(ctx, ud.unusedelementpath, message); }","comment":"\/\/todo: switch expression candidate!","repo":"timfel\/netbeans","code_context_2":"})\nprivate static ErrorDescription convertUnused(HintContext ctx, UnusedDescription ud) {\n\/\/TODO: switch expression candidate!\nString name = ud.unusedElement.getSimpleName().toString();\nString message;","code_context_10":"\"ERR_NeitherReadOrWritten=Variable {0} is neither read or written to\",\n\"# {0} - variable name\",\n\"ERR_NotWritten=Variable {0} is never written to\",\n\"# {0} - variable name\",\n\"ERR_NotRead=Variable {0} is never read\",\n\"# {0} - element name\",\n\"ERR_NotUsed={0} is never used\",\n\"ERR_NotUsedConstructor=Constructor is never used\",\n})\nprivate static ErrorDescription convertUnused(HintContext ctx, UnusedDescription ud) {\n\/\/TODO: switch expression candidate!\nString name = ud.unusedElement.getSimpleName().toString();\nString message;\nswitch (ud.reason) {\ncase NOT_WRITTEN_READ: message = Bundle.ERR_NeitherReadOrWritten(name); break;\ncase NOT_WRITTEN: message = Bundle.ERR_NotWritten(name); break;\ncase NOT_READ: message = Bundle.ERR_NotRead(name); break;\ncase NOT_USED:\nif (ud.unusedElement.getKind() == ElementKind.CONSTRUCTOR) {\nmessage = Bundle.ERR_NotUsedConstructor();\n} else {","code_context_20":"@Messages({\n\"# {0} - variable name\",\n\"ERR_NeitherReadOrWritten=Variable {0} is neither read or written to\",\n\"# {0} - variable name\",\n\"ERR_NotWritten=Variable {0} is never written to\",\n\"# {0} - variable name\",\n\"ERR_NotRead=Variable {0} is never read\",\n\"# {0} - element name\",\n\"ERR_NotUsed={0} is never used\",\n\"ERR_NotUsedConstructor=Constructor is never used\",\n})\nprivate static ErrorDescription convertUnused(HintContext ctx, UnusedDescription ud) {\n\/\/TODO: switch expression candidate!\nString name = ud.unusedElement.getSimpleName().toString();\nString message;\nswitch (ud.reason) {\ncase NOT_WRITTEN_READ: message = Bundle.ERR_NeitherReadOrWritten(name); break;\ncase NOT_WRITTEN: message = Bundle.ERR_NotWritten(name); break;\ncase NOT_READ: message = Bundle.ERR_NotRead(name); break;\ncase NOT_USED:\nif (ud.unusedElement.getKind() == ElementKind.CONSTRUCTOR) {\nmessage = Bundle.ERR_NotUsedConstructor();\n} else {\nmessage = Bundle.ERR_NotUsed(name);\n}\nbreak;\ndefault:\nthrow new IllegalStateException(\"Unknown unused type: \" + ud.reason);\n}\nreturn ErrorDescriptionFactory.forName(ctx, ud.unusedElementPath, message);\n}","label":[1,0,0,0]}
{"id":14028,"original_code":"public String getHost() {\n        return \"localhost\";\n    }","code":"public String getHost() {\n        return \"localhost\";\n    }","cleancode":"public string gethost() { return \"localhost\"; }","comment":"\/\/todo: custom host and port","repo":"timboudreau\/netbeans-contrib","code_context_2":"public String getHost() {\nreturn \"localhost\";\n}","code_context_10":"public String getHost() {\nreturn \"localhost\";\n}","code_context_20":"public String getHost() {\nreturn \"localhost\";\n}","label":[1,0,0,0]}
{"id":30445,"original_code":"private AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\n      AMQProducerBrokerExchange result = producerExchanges.get(id);\n      if (result == null) {\n         synchronized (producerExchanges) {\n            result = new AMQProducerBrokerExchange();\n            result.setConnectionContext(context);\n            \/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n            \/\/todo: this used to check for  && this.acceptorUsed.isAuditNetworkProducers()\n            if (context.isReconnect() || (context.isNetworkConnection())) {\n               \/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n               \/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n               \/\/ TBD during the implemetnation of ARTEMIS-194\n               result.setLastStoredSequenceId(0);\n            }\n            SessionState ss = state.getSessionState(id.getParentId());\n            if (ss != null) {\n               result.setProducerState(ss.getProducerState(id));\n               ProducerState producerState = ss.getProducerState(id);\n               if (producerState != null && producerState.getInfo() != null) {\n                  ProducerInfo info = producerState.getInfo();\n                  result.setMutable(info.getDestination() == null || info.getDestination().isComposite());\n               }\n            }\n            producerExchanges.put(id, result);\n         }\n      }\n      return result;\n   }","code":"private AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\n      AMQProducerBrokerExchange result = producerExchanges.get(id);\n      if (result == null) {\n         synchronized (producerExchanges) {\n            result = new AMQProducerBrokerExchange();\n            result.setConnectionContext(context);\n           \n           \n            if (context.isReconnect() || (context.isNetworkConnection())) {\n              \n              \n              \n               result.setLastStoredSequenceId(0);\n            }\n            SessionState ss = state.getSessionState(id.getParentId());\n            if (ss != null) {\n               result.setProducerState(ss.getProducerState(id));\n               ProducerState producerState = ss.getProducerState(id);\n               if (producerState != null && producerState.getInfo() != null) {\n                  ProducerInfo info = producerState.getInfo();\n                  result.setMutable(info.getDestination() == null || info.getDestination().isComposite());\n               }\n            }\n            producerExchanges.put(id, result);\n         }\n      }\n      return result;\n   }","cleancode":"private amqproducerbrokerexchange getproducerbrokerexchange(producerid id) throws ioexception { amqproducerbrokerexchange result = producerexchanges.get(id); if (result == null) { synchronized (producerexchanges) { result = new amqproducerbrokerexchange(); result.setconnectioncontext(context); if (context.isreconnect() || (context.isnetworkconnection())) { result.setlaststoredsequenceid(0); } sessionstate ss = state.getsessionstate(id.getparentid()); if (ss != null) { result.setproducerstate(ss.getproducerstate(id)); producerstate producerstate = ss.getproducerstate(id); if (producerstate != null && producerstate.getinfo() != null) { producerinfo info = producerstate.getinfo(); result.setmutable(info.getdestination() == null || info.getdestination().iscomposite()); } } producerexchanges.put(id, result); } } return result; }","comment":"\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/artemis-194 \/\/todo: this used to check for && this.acceptorused.isauditnetworkproducers()\n\/\/ once implemented artemis-194, we need to set the storedsequenceid here somehow \/\/ we have different semantics on artemis journal, but we could adapt something for this \/\/ tbd during the implemetnation of artemis-194","repo":"treblereel\/activemq-artemis-wildfly","code_context_2":"result = new AMQProducerBrokerExchange();\nresult.setConnectionContext(context);\n\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n\/\/ TBD during the implemetnation of ARTEMIS-194\nresult.setLastStoredSequenceId(0);\n}","code_context_10":"private AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\nAMQProducerBrokerExchange result = producerExchanges.get(id);\nif (result == null) {\nsynchronized (producerExchanges) {\nresult = new AMQProducerBrokerExchange();\nresult.setConnectionContext(context);\n\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n\/\/ TBD during the implemetnation of ARTEMIS-194\nresult.setLastStoredSequenceId(0);\n}\nSessionState ss = state.getSessionState(id.getParentId());\nif (ss != null) {\nresult.setProducerState(ss.getProducerState(id));\nProducerState producerState = ss.getProducerState(id);\n\nprivate AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\nAMQProducerBrokerExchange result = producerExchanges.get(id);\nif (result == null) {\nsynchronized (producerExchanges) {\nresult = new AMQProducerBrokerExchange();\nresult.setConnectionContext(context);\n\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n\/\/ TBD during the implemetnation of ARTEMIS-194\nresult.setLastStoredSequenceId(0);\n}\nSessionState ss = state.getSessionState(id.getParentId());\nif (ss != null) {\nresult.setProducerState(ss.getProducerState(id));\nProducerState producerState = ss.getProducerState(id);\nif (producerState != null && producerState.getInfo() != null) {\nProducerInfo info = producerState.getInfo();\nresult.setMutable(info.getDestination() == null || info.getDestination().isComposite());\n}","code_context_20":"private AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\nAMQProducerBrokerExchange result = producerExchanges.get(id);\nif (result == null) {\nsynchronized (producerExchanges) {\nresult = new AMQProducerBrokerExchange();\nresult.setConnectionContext(context);\n\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n\/\/ TBD during the implemetnation of ARTEMIS-194\nresult.setLastStoredSequenceId(0);\n}\nSessionState ss = state.getSessionState(id.getParentId());\nif (ss != null) {\nresult.setProducerState(ss.getProducerState(id));\nProducerState producerState = ss.getProducerState(id);\nif (producerState != null && producerState.getInfo() != null) {\nProducerInfo info = producerState.getInfo();\nresult.setMutable(info.getDestination() == null || info.getDestination().isComposite());\n}\n}\nproducerExchanges.put(id, result);\n}\n}\nreturn result;\n}\n\nprivate AMQProducerBrokerExchange getProducerBrokerExchange(ProducerId id) throws IOException {\nAMQProducerBrokerExchange result = producerExchanges.get(id);\nif (result == null) {\nsynchronized (producerExchanges) {\nresult = new AMQProducerBrokerExchange();\nresult.setConnectionContext(context);\n\/\/todo implement reconnect https:\/\/issues.apache.org\/jira\/browse\/ARTEMIS-194\n\/\/todo: this used to check for && this.acceptorUsed.isAuditNetworkProducers()\nif (context.isReconnect() || (context.isNetworkConnection())) {\n\/\/ once implemented ARTEMIS-194, we need to set the storedSequenceID here somehow\n\/\/ We have different semantics on Artemis Journal, but we could adapt something for this\n\/\/ TBD during the implemetnation of ARTEMIS-194\nresult.setLastStoredSequenceId(0);\n}\nSessionState ss = state.getSessionState(id.getParentId());\nif (ss != null) {\nresult.setProducerState(ss.getProducerState(id));\nProducerState producerState = ss.getProducerState(id);\nif (producerState != null && producerState.getInfo() != null) {\nProducerInfo info = producerState.getInfo();\nresult.setMutable(info.getDestination() == null || info.getDestination().isComposite());\n}\n}\nproducerExchanges.put(id, result);\n}\n}\nreturn result;\n}","label":[1,1,0,0]}
{"id":14150,"original_code":"@Override\npublic boolean shouldVisit(Page referringPage, WebURL url) {\nString href = url.getURL().toLowerCase();\nreturn !FILTERS.matcher(href).matches()\n&& href.startsWith(\"http:\/\/www.ics.uci.edu\/\");\n}","code":"@Override\npublic boolean shouldVisit(Page referringPage, WebURL url) {\nString href = url.getURL().toLowerCase();\nreturn !FILTERS.matcher(href).matches()\n&& href.startsWith(\"http:\/\/www.ics.uci.edu\/\");\n}","cleancode":"@override public boolean shouldvisit(page referringpage, weburl url) { string href = url.geturl().tolowercase(); return !filters.matcher(href).matches() && href.startswith(\"http:\/\/www.ics.uci.edu\/\"); }","comment":"\/** * this method receives two parameters. the first parameter is the page * in which we have discovered this new url and the second parameter is * the new url. you should implement this function to specify whether * the given url should be crawled or not (based on your crawling logic). * in this example, we are instructing the crawler to ignore urls that * have css, js, git, ... extensions and to only accept urls that start * with \"http:\/\/www.ics.uci.edu\/\". in this case, we didn't need the * referringpage parameter to make the decision. *\/","repo":"vjymits\/musicFinder","code_context_2":"@Override\npublic boolean shouldVisit(Page referringPage, WebURL url) {\nString href = url.getURL().toLowerCase();\nreturn !FILTERS.matcher(href).matches()\n&& href.startsWith(\"http:\/\/www.ics.uci.edu\/\");\n}","code_context_10":"@Override\npublic boolean shouldVisit(Page referringPage, WebURL url) {\nString href = url.getURL().toLowerCase();\nreturn !FILTERS.matcher(href).matches()\n&& href.startsWith(\"http:\/\/www.ics.uci.edu\/\");\n}","code_context_20":"@Override\npublic boolean shouldVisit(Page referringPage, WebURL url) {\nString href = url.getURL().toLowerCase();\nreturn !FILTERS.matcher(href).matches()\n&& href.startsWith(\"http:\/\/www.ics.uci.edu\/\");\n}","label":[0,1,0,0]}
{"id":22813,"original_code":"public boolean syncPingSupplicant(AsyncChannel channel) {\n        Message resultMsg = channel.sendMessageSynchronously(CMD_PING_SUPPLICANT);\n        boolean result = (resultMsg.arg1 != FAILURE);\n        resultMsg.recycle();\n        return result;\n    }","code":"public boolean syncPingSupplicant(AsyncChannel channel) {\n        Message resultMsg = channel.sendMessageSynchronously(CMD_PING_SUPPLICANT);\n        boolean result = (resultMsg.arg1 != FAILURE);\n        resultMsg.recycle();\n        return result;\n    }","cleancode":"public boolean syncpingsupplicant(asyncchannel channel) { message resultmsg = channel.sendmessagesynchronously(cmd_ping_supplicant); boolean result = (resultmsg.arg1 != failure); resultmsg.recycle(); return result; }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public boolean syncPingSupplicant(AsyncChannel channel) {\nMessage resultMsg = channel.sendMessageSynchronously(CMD_PING_SUPPLICANT);\nboolean result = (resultMsg.arg1 != FAILURE);\nresultMsg.recycle();\nreturn result;\n}","code_context_10":"public boolean syncPingSupplicant(AsyncChannel channel) {\nMessage resultMsg = channel.sendMessageSynchronously(CMD_PING_SUPPLICANT);\nboolean result = (resultMsg.arg1 != FAILURE);\nresultMsg.recycle();\nreturn result;\n}","code_context_20":"public boolean syncPingSupplicant(AsyncChannel channel) {\nMessage resultMsg = channel.sendMessageSynchronously(CMD_PING_SUPPLICANT);\nboolean result = (resultMsg.arg1 != FAILURE);\nresultMsg.recycle();\nreturn result;\n}","label":[0,0,0,0]}
{"id":22816,"original_code":"public void setSupplicantRunning(boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_SUPPLICANT);\n        } else {\n            sendMessage(CMD_STOP_SUPPLICANT);\n        }\n    }","code":"public void setSupplicantRunning(boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_SUPPLICANT);\n        } else {\n            sendMessage(CMD_STOP_SUPPLICANT);\n        }\n    }","cleancode":"public void setsupplicantrunning(boolean enable) { if (enable) { sendmessage(cmd_start_supplicant); } else { sendmessage(cmd_stop_supplicant); } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public void setSupplicantRunning(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_SUPPLICANT);\n} else {\nsendMessage(CMD_STOP_SUPPLICANT);\n}\n}","code_context_10":"public void setSupplicantRunning(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_SUPPLICANT);\n} else {\nsendMessage(CMD_STOP_SUPPLICANT);\n}\n}","code_context_20":"public void setSupplicantRunning(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_SUPPLICANT);\n} else {\nsendMessage(CMD_STOP_SUPPLICANT);\n}\n}","label":[0,0,0,0]}
{"id":22817,"original_code":"public void setHostApRunning(WifiConfiguration wifiConfig, boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_AP, wifiConfig);\n        } else {\n            sendMessage(CMD_STOP_AP);\n        }\n    }","code":"public void setHostApRunning(WifiConfiguration wifiConfig, boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_AP, wifiConfig);\n        } else {\n            sendMessage(CMD_STOP_AP);\n        }\n    }","cleancode":"public void sethostaprunning(wificonfiguration wificonfig, boolean enable) { if (enable) { sendmessage(cmd_start_ap, wificonfig); } else { sendmessage(cmd_stop_ap); } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public void setHostApRunning(WifiConfiguration wifiConfig, boolean enable) {\nif (enable) {\nsendMessage(CMD_START_AP, wifiConfig);\n} else {\nsendMessage(CMD_STOP_AP);\n}\n}","code_context_10":"public void setHostApRunning(WifiConfiguration wifiConfig, boolean enable) {\nif (enable) {\nsendMessage(CMD_START_AP, wifiConfig);\n} else {\nsendMessage(CMD_STOP_AP);\n}\n}","code_context_20":"public void setHostApRunning(WifiConfiguration wifiConfig, boolean enable) {\nif (enable) {\nsendMessage(CMD_START_AP, wifiConfig);\n} else {\nsendMessage(CMD_STOP_AP);\n}\n}","label":[0,0,0,0]}
{"id":22818,"original_code":"public int syncGetWifiState() {\n        return mWifiState.get();\n    }","code":"public int syncGetWifiState() {\n        return mWifiState.get();\n    }","cleancode":"public int syncgetwifistate() { return mwifistate.get(); }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public int syncGetWifiState() {\nreturn mWifiState.get();\n}","code_context_10":"public int syncGetWifiState() {\nreturn mWifiState.get();\n}","code_context_20":"public int syncGetWifiState() {\nreturn mWifiState.get();\n}","label":[0,0,0,0]}
{"id":22819,"original_code":"public String syncGetWifiStateByName() {\n        switch (mWifiState.get()) {\n            case WIFI_STATE_DISABLING:\n                return \"disabling\";\n            case WIFI_STATE_DISABLED:\n                return \"disabled\";\n            case WIFI_STATE_ENABLING:\n                return \"enabling\";\n            case WIFI_STATE_ENABLED:\n                return \"enabled\";\n            case WIFI_STATE_UNKNOWN:\n                return \"unknown state\";\n            default:\n                return \"[invalid state]\";\n        }\n    }","code":"public String syncGetWifiStateByName() {\n        switch (mWifiState.get()) {\n            case WIFI_STATE_DISABLING:\n                return \"disabling\";\n            case WIFI_STATE_DISABLED:\n                return \"disabled\";\n            case WIFI_STATE_ENABLING:\n                return \"enabling\";\n            case WIFI_STATE_ENABLED:\n                return \"enabled\";\n            case WIFI_STATE_UNKNOWN:\n                return \"unknown state\";\n            default:\n                return \"[invalid state]\";\n        }\n    }","cleancode":"public string syncgetwifistatebyname() { switch (mwifistate.get()) { case wifi_state_disabling: return \"disabling\"; case wifi_state_disabled: return \"disabled\"; case wifi_state_enabling: return \"enabling\"; case wifi_state_enabled: return \"enabled\"; case wifi_state_unknown: return \"unknown state\"; default: return \"[invalid state]\"; } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public String syncGetWifiStateByName() {\nswitch (mWifiState.get()) {\ncase WIFI_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_STATE_UNKNOWN:\nreturn \"unknown state\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","code_context_10":"public String syncGetWifiStateByName() {\nswitch (mWifiState.get()) {\ncase WIFI_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_STATE_UNKNOWN:\nreturn \"unknown state\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","code_context_20":"public String syncGetWifiStateByName() {\nswitch (mWifiState.get()) {\ncase WIFI_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_STATE_UNKNOWN:\nreturn \"unknown state\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","label":[0,0,0,0]}
{"id":22820,"original_code":"public int syncGetWifiApState() {\n        return mWifiApState.get();\n    }","code":"public int syncGetWifiApState() {\n        return mWifiApState.get();\n    }","cleancode":"public int syncgetwifiapstate() { return mwifiapstate.get(); }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public int syncGetWifiApState() {\nreturn mWifiApState.get();\n}","code_context_10":"public int syncGetWifiApState() {\nreturn mWifiApState.get();\n}","code_context_20":"public int syncGetWifiApState() {\nreturn mWifiApState.get();\n}","label":[0,0,0,0]}
{"id":22821,"original_code":"public String syncGetWifiApStateByName() {\n        switch (mWifiApState.get()) {\n            case WIFI_AP_STATE_DISABLING:\n                return \"disabling\";\n            case WIFI_AP_STATE_DISABLED:\n                return \"disabled\";\n            case WIFI_AP_STATE_ENABLING:\n                return \"enabling\";\n            case WIFI_AP_STATE_ENABLED:\n                return \"enabled\";\n            case WIFI_AP_STATE_FAILED:\n                return \"failed\";\n            default:\n                return \"[invalid state]\";\n        }\n    }","code":"public String syncGetWifiApStateByName() {\n        switch (mWifiApState.get()) {\n            case WIFI_AP_STATE_DISABLING:\n                return \"disabling\";\n            case WIFI_AP_STATE_DISABLED:\n                return \"disabled\";\n            case WIFI_AP_STATE_ENABLING:\n                return \"enabling\";\n            case WIFI_AP_STATE_ENABLED:\n                return \"enabled\";\n            case WIFI_AP_STATE_FAILED:\n                return \"failed\";\n            default:\n                return \"[invalid state]\";\n        }\n    }","cleancode":"public string syncgetwifiapstatebyname() { switch (mwifiapstate.get()) { case wifi_ap_state_disabling: return \"disabling\"; case wifi_ap_state_disabled: return \"disabled\"; case wifi_ap_state_enabling: return \"enabling\"; case wifi_ap_state_enabled: return \"enabled\"; case wifi_ap_state_failed: return \"failed\"; default: return \"[invalid state]\"; } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public String syncGetWifiApStateByName() {\nswitch (mWifiApState.get()) {\ncase WIFI_AP_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_AP_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_AP_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_AP_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_AP_STATE_FAILED:\nreturn \"failed\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","code_context_10":"public String syncGetWifiApStateByName() {\nswitch (mWifiApState.get()) {\ncase WIFI_AP_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_AP_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_AP_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_AP_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_AP_STATE_FAILED:\nreturn \"failed\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","code_context_20":"public String syncGetWifiApStateByName() {\nswitch (mWifiApState.get()) {\ncase WIFI_AP_STATE_DISABLING:\nreturn \"disabling\";\ncase WIFI_AP_STATE_DISABLED:\nreturn \"disabled\";\ncase WIFI_AP_STATE_ENABLING:\nreturn \"enabling\";\ncase WIFI_AP_STATE_ENABLED:\nreturn \"enabled\";\ncase WIFI_AP_STATE_FAILED:\nreturn \"failed\";\ndefault:\nreturn \"[invalid state]\";\n}\n}","label":[0,0,0,0]}
{"id":22822,"original_code":"public void setDriverStart(boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_DRIVER);\n        } else {\n            sendMessage(CMD_STOP_DRIVER);\n        }\n    }","code":"public void setDriverStart(boolean enable) {\n        if (enable) {\n            sendMessage(CMD_START_DRIVER);\n        } else {\n            sendMessage(CMD_STOP_DRIVER);\n        }\n    }","cleancode":"public void setdriverstart(boolean enable) { if (enable) { sendmessage(cmd_start_driver); } else { sendmessage(cmd_stop_driver); } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public void setDriverStart(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_DRIVER);\n} else {\nsendMessage(CMD_STOP_DRIVER);\n}\n}","code_context_10":"public void setDriverStart(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_DRIVER);\n} else {\nsendMessage(CMD_STOP_DRIVER);\n}\n}","code_context_20":"public void setDriverStart(boolean enable) {\nif (enable) {\nsendMessage(CMD_START_DRIVER);\n} else {\nsendMessage(CMD_STOP_DRIVER);\n}\n}","label":[0,0,0,0]}
{"id":22823,"original_code":"public void setOperationalMode(int mode) {\n        if (DBG) log(\"setting operational mode to \" + String.valueOf(mode));\n        sendMessage(CMD_SET_OPERATIONAL_MODE, mode, 0);\n    }","code":"public void setOperationalMode(int mode) {\n        if (DBG) log(\"setting operational mode to \" + String.valueOf(mode));\n        sendMessage(CMD_SET_OPERATIONAL_MODE, mode, 0);\n    }","cleancode":"public void setoperationalmode(int mode) { if (dbg) log(\"setting operational mode to \" + string.valueof(mode)); sendmessage(cmd_set_operational_mode, mode, 0); }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public void setOperationalMode(int mode) {\nif (DBG) log(\"setting operational mode to \" + String.valueOf(mode));\nsendMessage(CMD_SET_OPERATIONAL_MODE, mode, 0);\n}","code_context_10":"public void setOperationalMode(int mode) {\nif (DBG) log(\"setting operational mode to \" + String.valueOf(mode));\nsendMessage(CMD_SET_OPERATIONAL_MODE, mode, 0);\n}","code_context_20":"public void setOperationalMode(int mode) {\nif (DBG) log(\"setting operational mode to \" + String.valueOf(mode));\nsendMessage(CMD_SET_OPERATIONAL_MODE, mode, 0);\n}","label":[0,0,0,0]}
{"id":22824,"original_code":"public List<ScanResult> syncGetScanResultsList() {\n        synchronized (mScanResultsLock) {\n            List<ScanResult> scanList = new ArrayList<ScanResult>();\n            for (ScanDetail result : mScanResults) {\n                scanList.add(new ScanResult(result.getScanResult()));\n            }\n            return scanList;\n        }\n    }","code":"public List<ScanResult> syncGetScanResultsList() {\n        synchronized (mScanResultsLock) {\n            List<ScanResult> scanList = new ArrayList<ScanResult>();\n            for (ScanDetail result : mScanResults) {\n                scanList.add(new ScanResult(result.getScanResult()));\n            }\n            return scanList;\n        }\n    }","cleancode":"public list<scanresult> syncgetscanresultslist() { synchronized (mscanresultslock) { list<scanresult> scanlist = new arraylist<scanresult>(); for (scandetail result : mscanresults) { scanlist.add(new scanresult(result.getscanresult())); } return scanlist; } }","comment":"\/** * todo: doc *\/","repo":"zipated\/src","code_context_2":"public List<ScanResult> syncGetScanResultsList() {\nsynchronized (mScanResultsLock) {\nList<ScanResult> scanList = new ArrayList<ScanResult>();\nfor (ScanDetail result : mScanResults) {\nscanList.add(new ScanResult(result.getScanResult()));\n}\nreturn scanList;\n}\n}","code_context_10":"public List<ScanResult> syncGetScanResultsList() {\nsynchronized (mScanResultsLock) {\nList<ScanResult> scanList = new ArrayList<ScanResult>();\nfor (ScanDetail result : mScanResults) {\nscanList.add(new ScanResult(result.getScanResult()));\n}\nreturn scanList;\n}\n}","code_context_20":"public List<ScanResult> syncGetScanResultsList() {\nsynchronized (mScanResultsLock) {\nList<ScanResult> scanList = new ArrayList<ScanResult>();\nfor (ScanDetail result : mScanResults) {\nscanList.add(new ScanResult(result.getScanResult()));\n}\nreturn scanList;\n}\n}","label":[0,0,0,0]}
{"id":31206,"original_code":"public static void createAppointment(Appointment TemplateAppointment) {\n        \/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\n        String sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n        \/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\n        try {\n            PreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\n            ps.setString(1, TemplateAppointment.getTitle());\n            ps.setString(2, TemplateAppointment.getDescription());\n            ps.setString(3, TemplateAppointment.getLocation());\n            ps.setString(4, TemplateAppointment.getType());\n            LocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\n            start = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            LocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\n            end = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            Timestamp Tstart = Timestamp.valueOf(start);\n            Timestamp Tend = Timestamp.valueOf(end);\n            ps.setTimestamp(5, Tstart);\n            ps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\n            ps.setInt(7, TemplateAppointment.getCustomerid());\n            ps.setInt(8, TemplateAppointment.getUserid());\n            ps.setInt(9, TemplateAppointment.getContactid());\n            ps.execute();\n        } catch (SQLException ex) {\n            ex.printStackTrace();\n        }\n    }","code":"public static void createAppointment(Appointment TemplateAppointment) {\n       \n        String sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n       \n        try {\n            PreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\n            ps.setString(1, TemplateAppointment.getTitle());\n            ps.setString(2, TemplateAppointment.getDescription());\n            ps.setString(3, TemplateAppointment.getLocation());\n            ps.setString(4, TemplateAppointment.getType());\n            LocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\n            start = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            LocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\n            end = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            Timestamp Tstart = Timestamp.valueOf(start);\n            Timestamp Tend = Timestamp.valueOf(end);\n            ps.setTimestamp(5, Tstart);\n            ps.setTimestamp(6, Tend);\n            ps.setInt(7, TemplateAppointment.getCustomerid());\n            ps.setInt(8, TemplateAppointment.getUserid());\n            ps.setInt(9, TemplateAppointment.getContactid());\n            ps.execute();\n        } catch (SQLException ex) {\n            ex.printStackTrace();\n        }\n    }","cleancode":"public static void createappointment(appointment templateappointment) { string sql = \"insert into appointments values(null, ?, ?,?,?,?,?,now(),'',now(),'',?,?,?)\"; try { preparedstatement ps = dbconnection.getconnection().preparestatement(sql); ps.setstring(1, templateappointment.gettitle()); ps.setstring(2, templateappointment.getdescription()); ps.setstring(3, templateappointment.getlocation()); ps.setstring(4, templateappointment.gettype()); localdatetime start = localdatetime.of(templateappointment.getdate(), templateappointment.getstarttime()); start = washtimezone(start, zoneid.systemdefault(), zoneid.of(\"utc\")); localdatetime end = localdatetime.of(templateappointment.getdate(), templateappointment.getendtime()); end = washtimezone(end, zoneid.systemdefault(), zoneid.of(\"utc\")); timestamp tstart = timestamp.valueof(start); timestamp tend = timestamp.valueof(end); ps.settimestamp(5, tstart); ps.settimestamp(6, tend); ps.setint(7, templateappointment.getcustomerid()); ps.setint(8, templateappointment.getuserid()); ps.setint(9, templateappointment.getcontactid()); ps.execute(); } catch (sqlexception ex) { ex.printstacktrace(); } }","comment":"\/\/ look up key to keys and \"insert\" to make everything work; \/\/to change body of generated methods, choose tools | templates.\n\/\/ (appointment_id,title,description, type, phone, division_id) values (5, '', 'test', '', 'test','')\" ;\n\/\/timezone work needs to happen here","repo":"yinwil27\/PortfolioRepositorySQLJava","code_context_2":"public static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\n\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\n\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, TemplateAppointment.getCustomerid());\nps.setInt(8, TemplateAppointment.getUserid());","code_context_10":"public static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, TemplateAppointment.getTitle());\nps.setString(2, TemplateAppointment.getDescription());\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n\npublic static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, TemplateAppointment.getTitle());\nps.setString(2, TemplateAppointment.getDescription());\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, TemplateAppointment.getCustomerid());\nps.setInt(8, TemplateAppointment.getUserid());\nps.setInt(9, TemplateAppointment.getContactid());\nps.execute();\n} catch (SQLException ex) {\nex.printStackTrace();\n}\n}","code_context_20":"public static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, TemplateAppointment.getTitle());\nps.setString(2, TemplateAppointment.getDescription());\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, TemplateAppointment.getCustomerid());\nps.setInt(8, TemplateAppointment.getUserid());\nps.setInt(9, TemplateAppointment.getContactid());\n\npublic static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, TemplateAppointment.getTitle());\nps.setString(2, TemplateAppointment.getDescription());\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, TemplateAppointment.getCustomerid());\nps.setInt(8, TemplateAppointment.getUserid());\nps.setInt(9, TemplateAppointment.getContactid());\nps.execute();\n} catch (SQLException ex) {\n\npublic static void createAppointment(Appointment TemplateAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"INSERT INTO appointments Values(NULL, ?, ?,?,?,?,?,Now(),'',Now(),'',?,?,?)\";\n\/\/ (Appointment_ID,Title,Description, Type, Phone, Division_ID) VALUES (5, '', 'test', '', 'test','')\" ;\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, TemplateAppointment.getTitle());\nps.setString(2, TemplateAppointment.getDescription());\nps.setString(3, TemplateAppointment.getLocation());\nps.setString(4, TemplateAppointment.getType());\nLocalDateTime start = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(TemplateAppointment.getDate(), TemplateAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, TemplateAppointment.getCustomerid());\nps.setInt(8, TemplateAppointment.getUserid());\nps.setInt(9, TemplateAppointment.getContactid());\nps.execute();\n} catch (SQLException ex) {\nex.printStackTrace();\n}\n}","label":[0,1,0,0]}
{"id":31207,"original_code":"public static void updateAppointments(Appointment PlaceholderAppointment) {\n        \/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\n        String sql = \"UPDATE appointments SET Title =?,  Description=?,   Location=?,  Type=?,  start=?, end=?,   Customer_ID=?,  User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\n        try {\n            PreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\n            ps.setString(1, PlaceholderAppointment.getTitle());\n            ps.setString(2, PlaceholderAppointment.getDescription());\n            ps.setString(3, PlaceholderAppointment.getLocation());\n            ps.setString(4, PlaceholderAppointment.getType());\n            LocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\n            start = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            LocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\n            end = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            Timestamp Tstart = Timestamp.valueOf(start);\n            Timestamp Tend = Timestamp.valueOf(end);\n            ps.setTimestamp(5, Tstart);\n            ps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\n            ps.setInt(7, PlaceholderAppointment.getCustomerid());\n            ps.setInt(8, PlaceholderAppointment.getUserid());\n            ps.setInt(9, PlaceholderAppointment.getContactid());\n            ps.setInt(10, PlaceholderAppointment.getAppointment_ID());\n            ps.execute();\n        } catch (SQLException ex) {\n            ex.printStackTrace();\n        }\n    }","code":"public static void updateAppointments(Appointment PlaceholderAppointment) {\n       \n        String sql = \"UPDATE appointments SET Title =?,  Description=?,   Location=?,  Type=?,  start=?, end=?,   Customer_ID=?,  User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\n        try {\n            PreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\n            ps.setString(1, PlaceholderAppointment.getTitle());\n            ps.setString(2, PlaceholderAppointment.getDescription());\n            ps.setString(3, PlaceholderAppointment.getLocation());\n            ps.setString(4, PlaceholderAppointment.getType());\n            LocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\n            start = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            LocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\n            end = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\n            Timestamp Tstart = Timestamp.valueOf(start);\n            Timestamp Tend = Timestamp.valueOf(end);\n            ps.setTimestamp(5, Tstart);\n            ps.setTimestamp(6, Tend);\n            ps.setInt(7, PlaceholderAppointment.getCustomerid());\n            ps.setInt(8, PlaceholderAppointment.getUserid());\n            ps.setInt(9, PlaceholderAppointment.getContactid());\n            ps.setInt(10, PlaceholderAppointment.getAppointment_ID());\n            ps.execute();\n        } catch (SQLException ex) {\n            ex.printStackTrace();\n        }\n    }","cleancode":"public static void updateappointments(appointment placeholderappointment) { string sql = \"update appointments set title =?, description=?, location=?, type=?, start=?, end=?, customer_id=?, user_id=?, contact_id=? where appointment_id = ?\"; try { preparedstatement ps = dbconnection.getconnection().preparestatement(sql); ps.setstring(1, placeholderappointment.gettitle()); ps.setstring(2, placeholderappointment.getdescription()); ps.setstring(3, placeholderappointment.getlocation()); ps.setstring(4, placeholderappointment.gettype()); localdatetime start = localdatetime.of(placeholderappointment.getdate(), placeholderappointment.getstarttime()); start = washtimezone(start, zoneid.systemdefault(), zoneid.of(\"utc\")); localdatetime end = localdatetime.of(placeholderappointment.getdate(), placeholderappointment.getendtime()); end = washtimezone(end, zoneid.systemdefault(), zoneid.of(\"utc\")); timestamp tstart = timestamp.valueof(start); timestamp tend = timestamp.valueof(end); ps.settimestamp(5, tstart); ps.settimestamp(6, tend); ps.setint(7, placeholderappointment.getcustomerid()); ps.setint(8, placeholderappointment.getuserid()); ps.setint(9, placeholderappointment.getcontactid()); ps.setint(10, placeholderappointment.getappointment_id()); ps.execute(); } catch (sqlexception ex) { ex.printstacktrace(); } }","comment":"\/\/ look up key to keys and \"insert\" to make everything work; \/\/to change body of generated methods, choose tools | templates.\n\/\/timezone work needs to happen here","repo":"yinwil27\/PortfolioRepositorySQLJava","code_context_2":"public static void updateAppointments(Appointment PlaceholderAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"UPDATE appointments SET Title =?, Description=?, Location=?, Type=?, start=?, end=?, Customer_ID=?, User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\ntry {\n\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, PlaceholderAppointment.getCustomerid());\nps.setInt(8, PlaceholderAppointment.getUserid());","code_context_10":"public static void updateAppointments(Appointment PlaceholderAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"UPDATE appointments SET Title =?, Description=?, Location=?, Type=?, start=?, end=?, Customer_ID=?, User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, PlaceholderAppointment.getTitle());\nps.setString(2, PlaceholderAppointment.getDescription());\nps.setString(3, PlaceholderAppointment.getLocation());\nps.setString(4, PlaceholderAppointment.getType());\nLocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\n\nps.setString(3, PlaceholderAppointment.getLocation());\nps.setString(4, PlaceholderAppointment.getType());\nLocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, PlaceholderAppointment.getCustomerid());\nps.setInt(8, PlaceholderAppointment.getUserid());\nps.setInt(9, PlaceholderAppointment.getContactid());\nps.setInt(10, PlaceholderAppointment.getAppointment_ID());\nps.execute();\n} catch (SQLException ex) {\nex.printStackTrace();\n}\n}","code_context_20":"public static void updateAppointments(Appointment PlaceholderAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"UPDATE appointments SET Title =?, Description=?, Location=?, Type=?, start=?, end=?, Customer_ID=?, User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, PlaceholderAppointment.getTitle());\nps.setString(2, PlaceholderAppointment.getDescription());\nps.setString(3, PlaceholderAppointment.getLocation());\nps.setString(4, PlaceholderAppointment.getType());\nLocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, PlaceholderAppointment.getCustomerid());\nps.setInt(8, PlaceholderAppointment.getUserid());\nps.setInt(9, PlaceholderAppointment.getContactid());\nps.setInt(10, PlaceholderAppointment.getAppointment_ID());\n\npublic static void updateAppointments(Appointment PlaceholderAppointment) {\n\/\/ look up key to keys and \"insert\" to make everything work; \/\/To change body of generated methods, choose Tools | Templates.\nString sql = \"UPDATE appointments SET Title =?, Description=?, Location=?, Type=?, start=?, end=?, Customer_ID=?, User_ID=?, Contact_ID=? WHERE Appointment_ID = ?\";\ntry {\nPreparedStatement ps = DBConnection.getConnection().prepareStatement(sql);\nps.setString(1, PlaceholderAppointment.getTitle());\nps.setString(2, PlaceholderAppointment.getDescription());\nps.setString(3, PlaceholderAppointment.getLocation());\nps.setString(4, PlaceholderAppointment.getType());\nLocalDateTime start = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getStartTime());\nstart = WashTimeZone(start, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nLocalDateTime end = LocalDateTime.of(PlaceholderAppointment.getDate(), PlaceholderAppointment.getEndTime());\nend = WashTimeZone(end, ZoneId.systemDefault(), ZoneId.of(\"UTC\"));\nTimestamp Tstart = Timestamp.valueOf(start);\nTimestamp Tend = Timestamp.valueOf(end);\nps.setTimestamp(5, Tstart);\nps.setTimestamp(6, Tend);\n\/\/timezone work needs to happen here\nps.setInt(7, PlaceholderAppointment.getCustomerid());\nps.setInt(8, PlaceholderAppointment.getUserid());\nps.setInt(9, PlaceholderAppointment.getContactid());\nps.setInt(10, PlaceholderAppointment.getAppointment_ID());\nps.execute();\n} catch (SQLException ex) {\nex.printStackTrace();\n}\n}","label":[0,1,0,0]}
{"id":23126,"original_code":"public String replaceTokens(Pattern pattern, String userAgentString, String format)\n\t{\n\t\t\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\t\t\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\t\t\/\/ System.out.println(\"Replacement: \" + format);\n\t\tMatcher m = pattern.matcher(userAgentString);\t\n\t\t\/\/ Move the group content into an array\n\t\tList<String> groupContent = new ArrayList<String>();\n\t\t\/\/ System.out.println(\"Group Count: \"+m.groupCount());\n\t\tm.find();\n\t\tfor(int i=0; i<=m.groupCount(); i++)\n\t\t{\n\t\t\tString s = m.group(i);\n\t\t\t\/\/ System.out.println(\"--\"+s);\n\t\t\tgroupContent.add(s);\n\t\t}\n\t\t\/\/ Replace the tokens in the pattern \n\t\tfor(int i=0; i<groupContent.size(); i++)\n\t\t{\n\t\t\tString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\t\t\t\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\n\t\t\tformat = format.replaceAll(token, groupContent.get(i));\n\t\t}\n\t\t\/\/ System.out.println(\"Response: \"+format);\n\t\treturn format;\n\t}","code":"public String replaceTokens(Pattern pattern, String userAgentString, String format)\n\t{\n\t\n\t\n\t\n\t\tMatcher m = pattern.matcher(userAgentString);\t\n\t\n\t\tList<String> groupContent = new ArrayList<String>();\n\t\n\t\tm.find();\n\t\tfor(int i=0; i<=m.groupCount(); i++)\n\t\t{\n\t\t\tString s = m.group(i);\n\t\t\n\t\t\tgroupContent.add(s);\n\t\t}\n\t\n\t\tfor(int i=0; i<groupContent.size(); i++)\n\t\t{\n\t\t\tString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\t\t\n\t\t\tformat = format.replaceAll(token, groupContent.get(i));\n\t\t}\n\t\n\t\treturn format;\n\t}","cleancode":"public string replacetokens(pattern pattern, string useragentstring, string format) { matcher m = pattern.matcher(useragentstring); list<string> groupcontent = new arraylist<string>(); m.find(); for(int i=0; i<=m.groupcount(); i++) { string s = m.group(i); groupcontent.add(s); } for(int i=0; i<groupcontent.size(); i++) { string token = \"#\\\\{\\\\$\"+i+\"\\\\}\"; format = format.replaceall(token, groupcontent.get(i)); } return format; }","comment":"\/** * replaces the tokens within the format string with the content of the groups found within the useragentstring. * <p> * tokens within the format string are formatted as #{$i} where i is the index of the group in the pattern. * <p> * todo: i would expect that there is an easier way to do this. * * @param pattern the regexp pattern to search for groups within the useragentstring * @param useragentstring * @param format the string to replace the tokens within * @return the format string with the tokens replaced with the groups found in the useragentstring *\/\n\/\/ system.out.println(\"useragent: \" + useragentstring); \/\/ system.out.println(\"regexp: \" + pattern.tostring()); \/\/ system.out.println(\"replacement: \" + format);\n\/\/ move the group content into an array\n\/\/ system.out.println(\"group count: \"+m.groupcount());\n\/\/ system.out.println(\"--\"+s);\n\/\/ replace the tokens in the pattern\n\/\/ system.out.println(\"replacing [\"+token+\"] with [\"+groupcontent.get(i)+\"]\");\n\/\/ system.out.println(\"response: \"+format);","repo":"ysc972\/UserAgentParser","code_context_2":"public String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\n\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\n\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\n\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}","code_context_10":"public String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\n\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\n\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}","code_context_20":"public String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\npublic String replaceTokens(Pattern pattern, String userAgentString, String format)\n{\n\/\/ System.out.println(\"UserAgent: \" + userAgentString);\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}\n\n\/\/ System.out.println(\"Regexp: \" + pattern.toString());\n\/\/ System.out.println(\"Replacement: \" + format);\nMatcher m = pattern.matcher(userAgentString);\n\/\/ Move the group content into an array\nList<String> groupContent = new ArrayList<String>();\n\/\/ System.out.println(\"Group Count: \"+m.groupCount());\nm.find();\nfor(int i=0; i<=m.groupCount(); i++)\n{\nString s = m.group(i);\n\/\/ System.out.println(\"--\"+s);\ngroupContent.add(s);\n}\n\/\/ Replace the tokens in the pattern\nfor(int i=0; i<groupContent.size(); i++)\n{\nString token = \"#\\\\{\\\\$\"+i+\"\\\\}\";\n\/\/ System.out.println(\"Replacing [\"+token+\"] with [\"+groupContent.get(i)+\"]\");\nformat = format.replaceAll(token, groupContent.get(i));\n}\n\/\/ System.out.println(\"Response: \"+format);\nreturn format;\n}","label":[1,0,0,0]}
{"id":15012,"original_code":"private void doTestServerEventsInSystemClient() throws Exception {\n    \/\/ KIRK: this test fails intermittently with bug 37482\n    final boolean[] firedSystem = new boolean[3];\n    final DistributedMember[] memberSystem = new DistributedMember[3];\n    final String[] memberIdSystem = new String[3];\n    final boolean[] isClientSystem = new boolean[3];\n    final boolean[] firedAdapter = new boolean[3];\n    final DistributedMember[] memberAdapter = new DistributedMember[3];\n    final String[] memberIdAdapter = new String[3];\n    final boolean[] isClientAdapter = new boolean[3];\n    final boolean[] firedBridge = new boolean[3];\n    final DistributedMember[] memberBridge = new DistributedMember[3];\n    final String[] memberIdBridge = new String[3];\n    final boolean[] isClientBridge = new boolean[3];\n    final boolean[] firedSystemDuplicate = new boolean[3];\n    final boolean[] firedAdapterDuplicate = new boolean[3];\n    final boolean[] firedBridgeDuplicate = new boolean[3];\n    SystemMembershipListener systemListener = new SystemMembershipListener() {\n      public synchronized void memberJoined(SystemMembershipEvent event) {\n        firedSystemDuplicate[JOINED] = firedSystem[JOINED];\n        firedSystem[JOINED] = true;\n        memberSystem[JOINED] = event.getDistributedMember();\n        memberIdSystem[JOINED] = event.getMemberId();\n        notify();\n      }\n      public synchronized void memberLeft(SystemMembershipEvent event) {\n        firedSystemDuplicate[LEFT] = firedSystem[LEFT];\n        firedSystem[LEFT] = true;\n        memberSystem[LEFT] = event.getDistributedMember();\n        memberIdSystem[LEFT] = event.getMemberId();\n        notify();\n      }\n      public synchronized void memberCrashed(SystemMembershipEvent event) {\n        firedSystemDuplicate[CRASHED] = firedSystem[CRASHED];\n        firedSystem[CRASHED] = true;\n        memberSystem[CRASHED] = event.getDistributedMember();\n        memberIdSystem[CRASHED] = event.getMemberId();\n        notify();\n      }\n    };\n    UniversalMembershipListenerAdapter adapter = \n      new UniversalMembershipListenerAdapter() {\n      @Override\n      public synchronized void memberJoined(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberJoined >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[JOINED] = firedAdapter[JOINED];\n        firedAdapter[JOINED] = true;\n        memberAdapter[JOINED] = event.getDistributedMember();\n        memberIdAdapter[JOINED] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[JOINED] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n      @Override\n      public synchronized void memberLeft(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberLeft >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[LEFT] = firedAdapter[LEFT];\n        firedAdapter[LEFT] = true;\n        memberAdapter[LEFT] = event.getDistributedMember();\n        memberIdAdapter[LEFT] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[LEFT] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n      @Override\n      public synchronized void memberCrashed(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberCrashed >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[CRASHED] = firedAdapter[CRASHED];\n        firedAdapter[CRASHED] = true;\n        memberAdapter[CRASHED] = event.getDistributedMember();\n        memberIdAdapter[CRASHED] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[CRASHED] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n    };\n    BridgeMembershipListener bridgeListener = new BridgeMembershipListener() {\n      public synchronized void memberJoined(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[JOINED] = firedBridge[JOINED];\n        firedBridge[JOINED] = true;\n        memberBridge[JOINED] = event.getMember();\n        memberIdBridge[JOINED] = event.getMemberId();\n        isClientBridge[JOINED] = event.isClient();\n        notify();\n      }\n      public synchronized void memberLeft(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[LEFT] = firedBridge[LEFT];\n        firedBridge[LEFT] = true;\n        memberBridge[LEFT] = event.getMember();\n        memberIdBridge[LEFT] = event.getMemberId();\n        isClientBridge[LEFT] = event.isClient();\n        notify();\n      }\n      public synchronized void memberCrashed(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[CRASHED] = firedBridge[CRASHED];\n        firedBridge[CRASHED] = true;\n        memberBridge[CRASHED] = event.getMember();\n        memberIdBridge[CRASHED] = event.getMemberId();\n        isClientBridge[CRASHED] = event.isClient();\n        notify();\n      }\n    };\n    final Host host = Host.getHost(0);\n    final VM vm0 = host.getVM(0);\n    final String name = this.getUniqueName();\n    final int[] ports = new int[] \n      { AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\n    assertTrue(ports[0] != 0);\n\/\/    getLogWriter().info(\"[testServerEventsInSystemClient] create bridge client\");\n\/\/    Properties config = new Properties();\n\/\/    config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/    config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/    getSystem(config);\n\/\/    AttributesFactory factory = new AttributesFactory();\n\/\/    factory.setScope(Scope.LOCAL);\n\/\/    BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/    createRegion(name, factory.create());\n\/\/    assertNotNull(getRootRegion().getSubregion(name));\n    getLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\n    getSystem();\n    final Properties clientProperties = getSystemProperties();\n    \/\/ register the bridge listener\n    BridgeMembership.registerBridgeMembershipListener(bridgeListener);\n    DistributedSystemConfig config = \n      AdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\n    AdminDistributedSystem adminDS = \n      AdminDistributedSystemFactory.getDistributedSystem(config);\n    adminDS.connect();\n    assertTrue(adminDS.waitToBeConnected(5 * 1000));\n    \/\/ register the system listener\n    adminDS.addMembershipListener(systemListener);\n    \/\/ register the universal adapter\n    adapter.registerMembershipListener(adminDS);\n    \/\/ create BridgeServer in vm0...\n    SerializableRunnable createBridgeServer =\n    new CacheSerializableRunnable(\"Create BridgeServer\") {\n      @Override\n      public void run2() throws CacheException {\n        getLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\n        getSystem(clientProperties);\n        AttributesFactory factory = new AttributesFactory();\n        factory.setScope(Scope.LOCAL);\n        Region region = createRegion(name, factory.create());\n        assertNotNull(region);\n        assertNotNull(getRootRegion().getSubregion(name));\n        try {\n          testServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n        }\n        catch (IOException e) {\n          getLogWriter().error(e);\n          fail(e.getMessage());\n        }\n      }\n    };\n    vm0.invoke(createBridgeServer);\n    \/\/ gather details for later creation of BridgeLoader...\n    assertEquals(ports[0],\n                 vm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class, \n                               \"getTestServerEventsInSystemClient_port\"));\n    String serverMemberId = (String) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\n    DistributedMember serverMember = (DistributedMember) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\n    getLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n    \/\/ create region which connects to bridge server\n    AttributesFactory factory = new AttributesFactory();\n    factory.setScope(Scope.LOCAL);\n    BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n    createRegion(name, factory.create());\n    assertNotNull(getRootRegion().getSubregion(name));\n    synchronized(systemListener) {\n      if (!firedSystem[JOINED]) {\n        systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(adapter) {\n      if (!firedAdapter[JOINED]) {\n        adapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(bridgeListener) {\n      if (!firedBridge[JOINED]) {\n        bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\n    assertFalse(firedSystemDuplicate);\n    \/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n    \/\/ initial impl uses Endpoint.toString() for memberId of server; final\n    \/\/ impl should have server send its real memberId to client via HandShake\n    \/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n    \/\/           firedAdapterDuplicate);\n    assertFalse(firedBridgeDuplicate);\n    assertTrue(firedBridge[JOINED]);\n    assertEquals(serverMember, memberBridge[JOINED]);\n    assertEquals(serverMemberId, memberIdBridge[JOINED]);\n    assertNotNull(memberBridge[JOINED]);\n    assertNotNull(memberIdBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertFalse(firedBridge[CRASHED]);\n    assertNull(memberBridge[CRASHED]);\n    assertNull(memberIdBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertTrue(firedSystem[JOINED]);\n    assertEquals(serverMember, memberSystem[JOINED]);\n    assertEquals(serverMemberId, memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertFalse(firedSystem[LEFT]);\n    assertNull(memberSystem[LEFT]);\n    assertNull(memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertTrue(firedAdapter[JOINED]);\n    assertNotNull(memberAdapter[JOINED]);\n    assertNotNull(memberIdAdapter[JOINED]);\n    assertEquals(serverMember, memberAdapter[JOINED]);\n    assertEquals(serverMemberId, memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n    assertFalse(firedAdapter[LEFT]);\n    assertNull(memberAdapter[LEFT]);\n    assertNull(memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n    getLogWriter().info(\"[testServerEventsInSystemClient] wait for client to fully connect\");\n    final String pl =\n      getRootRegion().getSubregion(name).getAttributes().getPoolName();\n    PoolImpl pi = (PoolImpl)PoolManager.find(pl);\n    waitForClientToFullyConnect(pi);\n    LogWriter bgexecLogger =\n          new LocalLogWriter(LogWriterImpl.ALL_LEVEL, System.out);\n    bgexecLogger.info(\"<ExpectedException action=add>\" + \n        \"java.io.IOException\" + \"<\/ExpectedException>\");\n    final ExpectedException ex = addExpectedException(\n        ServerConnectivityException.class.getName());\n    try {\n      vm0.invoke(new SerializableRunnable(\"Disconnect bridge server\") {\n        public void run() {\n          getLogWriter().info(\"[testServerEventsInSystemClient] disconnect bridge server\");\n          closeCache();\n          disconnectFromDS();\n        }\n      });\n      synchronized(systemListener) {\n        if (!firedSystem[LEFT]) {\n          systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n        }\n      }\n      synchronized(adapter) {\n        if (!firedAdapter[LEFT]) {\n          adapter.wait(ASYNC_EVENT_WAIT_MILLIS); \/\/ KIRK: did increasing this solve problem on balrog?\n        }\n      }\n      synchronized(bridgeListener) {\n        if (!firedBridge[LEFT]) {\n          bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n        }\n      }\n    }\n    finally {\n      bgexecLogger.info(\"<ExpectedException action=remove>\" + \n          \"java.io.IOException\" + \"<\/ExpectedException>\");\n      ex.remove();\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server crashed\");\n    assertFalse(firedSystemDuplicate);\n    \/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n    \/\/ initial impl uses Endpoint.toString() for memberId of server; final\n    \/\/ impl should have server send its real memberId to client via HandShake\n    \/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n    \/\/           firedAdapterDuplicate);\n    assertFalse(firedAdapterDuplicate);\n    assertFalse(firedBridgeDuplicate);\n    assertFalse(firedBridge[JOINED]);\n    assertNull(memberIdBridge[JOINED]);\n    assertNull(memberBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(\"Please update testServerEventsInSystemClient to handle memberLeft for BridgeServer.\", \n                firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertTrue(firedBridge[CRASHED]);\n    assertNotNull(memberBridge[CRASHED]);\n    assertNotNull(memberIdBridge[CRASHED]);\n    assertEquals(serverMemberId, memberIdBridge[CRASHED]);\n    assertEquals(serverMember, memberBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertFalse(firedSystem[JOINED]);\n    assertNull(memberSystem[JOINED]);\n    assertNull(memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertTrue(firedSystem[LEFT]);\n    assertEquals(serverMember, memberSystem[LEFT]);\n    assertEquals(serverMemberId, memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\n    assertNull(memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n    \/\/ LEFT fired by System listener\n    assertTrue(firedAdapter[LEFT]);\n    assertEquals(serverMember, memberAdapter[LEFT]);\n    assertEquals(serverMemberId, memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n    \/\/ There won't be an adapter crashed event because since the two VMs\n    \/\/ are in the same distributed system, and the server's real member\n    \/\/ id is used now. In this case, two events are sent - one from\n    \/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n    \/\/ The memberCrashed event is deemed a duplicate and not sent - see \n    \/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n    \/\/ reconnect bridge client to test for crashed event\n    vm0.invoke(createBridgeServer);\n    \/\/ gather details for later creation of BridgeLoader...\n    assertEquals(ports[0],\n                 vm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class, \n                               \"getTestServerEventsInSystemClient_port\"));\n    serverMemberId = (String) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\n    serverMember = (DistributedMember) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\n    getLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n    synchronized(systemListener) {\n      if (!firedSystem[JOINED]) {\n        systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(adapter) {\n      if (!firedAdapter[JOINED]) {\n        adapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(bridgeListener) {\n      if (!firedBridge[JOINED]) {\n        bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server re-join\");\n    assertFalse(firedSystemDuplicate);\n    \/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n    \/\/ initial impl uses Endpoint.toString() for memberId of server; final\n    \/\/ impl should have server send its real memberId to client via HandShake\n    \/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n    \/\/           firedAdapterDuplicate);\n    assertFalse(firedBridgeDuplicate);\n    assertTrue(firedBridge[JOINED]);\n    assertNotNull(memberBridge[JOINED]);\n    assertNotNull(memberIdBridge[JOINED]);\n    assertEquals(serverMember, memberBridge[JOINED]);\n    assertEquals(serverMemberId, memberIdBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertFalse(firedBridge[CRASHED]);\n    assertNull(memberBridge[CRASHED]);\n    assertNull(memberIdBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertTrue(firedSystem[JOINED]);\n    assertEquals(serverMember, memberSystem[JOINED]);\n    assertEquals(serverMemberId, memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertFalse(firedSystem[LEFT]);\n    assertNull(memberSystem[LEFT]);\n    assertNull(memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertTrue(firedAdapter[JOINED]);\n    assertNotNull(memberAdapter[JOINED]);\n    assertNotNull(memberIdAdapter[JOINED]);\n    assertEquals(serverMember, memberAdapter[JOINED]);\n    assertEquals(serverMemberId, memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n    assertFalse(firedAdapter[LEFT]);\n    assertNull(memberAdapter[LEFT]);\n    assertNull(memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n  }","code":"private void doTestServerEventsInSystemClient() throws Exception {\n   \n    final boolean[] firedSystem = new boolean[3];\n    final DistributedMember[] memberSystem = new DistributedMember[3];\n    final String[] memberIdSystem = new String[3];\n    final boolean[] isClientSystem = new boolean[3];\n    final boolean[] firedAdapter = new boolean[3];\n    final DistributedMember[] memberAdapter = new DistributedMember[3];\n    final String[] memberIdAdapter = new String[3];\n    final boolean[] isClientAdapter = new boolean[3];\n    final boolean[] firedBridge = new boolean[3];\n    final DistributedMember[] memberBridge = new DistributedMember[3];\n    final String[] memberIdBridge = new String[3];\n    final boolean[] isClientBridge = new boolean[3];\n    final boolean[] firedSystemDuplicate = new boolean[3];\n    final boolean[] firedAdapterDuplicate = new boolean[3];\n    final boolean[] firedBridgeDuplicate = new boolean[3];\n    SystemMembershipListener systemListener = new SystemMembershipListener() {\n      public synchronized void memberJoined(SystemMembershipEvent event) {\n        firedSystemDuplicate[JOINED] = firedSystem[JOINED];\n        firedSystem[JOINED] = true;\n        memberSystem[JOINED] = event.getDistributedMember();\n        memberIdSystem[JOINED] = event.getMemberId();\n        notify();\n      }\n      public synchronized void memberLeft(SystemMembershipEvent event) {\n        firedSystemDuplicate[LEFT] = firedSystem[LEFT];\n        firedSystem[LEFT] = true;\n        memberSystem[LEFT] = event.getDistributedMember();\n        memberIdSystem[LEFT] = event.getMemberId();\n        notify();\n      }\n      public synchronized void memberCrashed(SystemMembershipEvent event) {\n        firedSystemDuplicate[CRASHED] = firedSystem[CRASHED];\n        firedSystem[CRASHED] = true;\n        memberSystem[CRASHED] = event.getDistributedMember();\n        memberIdSystem[CRASHED] = event.getMemberId();\n        notify();\n      }\n    };\n    UniversalMembershipListenerAdapter adapter = \n      new UniversalMembershipListenerAdapter() {\n      @Override\n      public synchronized void memberJoined(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberJoined >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[JOINED] = firedAdapter[JOINED];\n        firedAdapter[JOINED] = true;\n        memberAdapter[JOINED] = event.getDistributedMember();\n        memberIdAdapter[JOINED] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[JOINED] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n      @Override\n      public synchronized void memberLeft(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberLeft >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[LEFT] = firedAdapter[LEFT];\n        firedAdapter[LEFT] = true;\n        memberAdapter[LEFT] = event.getDistributedMember();\n        memberIdAdapter[LEFT] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[LEFT] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n      @Override\n      public synchronized void memberCrashed(SystemMembershipEvent event) {\n        getLogWriter().info(\"[testServerEventsInSystemClient] memberCrashed >\" + event.getMemberId() + \"<\");\n        firedAdapterDuplicate[CRASHED] = firedAdapter[CRASHED];\n        firedAdapter[CRASHED] = true;\n        memberAdapter[CRASHED] = event.getDistributedMember();\n        memberIdAdapter[CRASHED] = event.getMemberId();\n        if (event instanceof UniversalMembershipListenerAdapter.AdaptedMembershipEvent) {\n          isClientAdapter[CRASHED] = \n            ((UniversalMembershipListenerAdapter.AdaptedMembershipEvent)event).isClient();\n        }\n        notify();\n      }\n    };\n    BridgeMembershipListener bridgeListener = new BridgeMembershipListener() {\n      public synchronized void memberJoined(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[JOINED] = firedBridge[JOINED];\n        firedBridge[JOINED] = true;\n        memberBridge[JOINED] = event.getMember();\n        memberIdBridge[JOINED] = event.getMemberId();\n        isClientBridge[JOINED] = event.isClient();\n        notify();\n      }\n      public synchronized void memberLeft(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[LEFT] = firedBridge[LEFT];\n        firedBridge[LEFT] = true;\n        memberBridge[LEFT] = event.getMember();\n        memberIdBridge[LEFT] = event.getMemberId();\n        isClientBridge[LEFT] = event.isClient();\n        notify();\n      }\n      public synchronized void memberCrashed(BridgeMembershipEvent event) {\n        firedBridgeDuplicate[CRASHED] = firedBridge[CRASHED];\n        firedBridge[CRASHED] = true;\n        memberBridge[CRASHED] = event.getMember();\n        memberIdBridge[CRASHED] = event.getMemberId();\n        isClientBridge[CRASHED] = event.isClient();\n        notify();\n      }\n    };\n    final Host host = Host.getHost(0);\n    final VM vm0 = host.getVM(0);\n    final String name = this.getUniqueName();\n    final int[] ports = new int[] \n      { AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\n    assertTrue(ports[0] != 0);\n    getLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\n    getSystem();\n    final Properties clientProperties = getSystemProperties();\n   \n    BridgeMembership.registerBridgeMembershipListener(bridgeListener);\n    DistributedSystemConfig config = \n      AdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\n    AdminDistributedSystem adminDS = \n      AdminDistributedSystemFactory.getDistributedSystem(config);\n    adminDS.connect();\n    assertTrue(adminDS.waitToBeConnected(5 * 1000));\n   \n    adminDS.addMembershipListener(systemListener);\n   \n    adapter.registerMembershipListener(adminDS);\n   \n    SerializableRunnable createBridgeServer =\n    new CacheSerializableRunnable(\"Create BridgeServer\") {\n      @Override\n      public void run2() throws CacheException {\n        getLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\n        getSystem(clientProperties);\n        AttributesFactory factory = new AttributesFactory();\n        factory.setScope(Scope.LOCAL);\n        Region region = createRegion(name, factory.create());\n        assertNotNull(region);\n        assertNotNull(getRootRegion().getSubregion(name));\n        try {\n          testServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n        }\n        catch (IOException e) {\n          getLogWriter().error(e);\n          fail(e.getMessage());\n        }\n      }\n    };\n    vm0.invoke(createBridgeServer);\n   \n    assertEquals(ports[0],\n                 vm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class, \n                               \"getTestServerEventsInSystemClient_port\"));\n    String serverMemberId = (String) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\n    DistributedMember serverMember = (DistributedMember) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\n    getLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n   \n    AttributesFactory factory = new AttributesFactory();\n    factory.setScope(Scope.LOCAL);\n    BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n    createRegion(name, factory.create());\n    assertNotNull(getRootRegion().getSubregion(name));\n    synchronized(systemListener) {\n      if (!firedSystem[JOINED]) {\n        systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(adapter) {\n      if (!firedAdapter[JOINED]) {\n        adapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(bridgeListener) {\n      if (!firedBridge[JOINED]) {\n        bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\n    assertFalse(firedSystemDuplicate);\n   \n   \n   \n   \n   \n    assertFalse(firedBridgeDuplicate);\n    assertTrue(firedBridge[JOINED]);\n    assertEquals(serverMember, memberBridge[JOINED]);\n    assertEquals(serverMemberId, memberIdBridge[JOINED]);\n    assertNotNull(memberBridge[JOINED]);\n    assertNotNull(memberIdBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertFalse(firedBridge[CRASHED]);\n    assertNull(memberBridge[CRASHED]);\n    assertNull(memberIdBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertTrue(firedSystem[JOINED]);\n    assertEquals(serverMember, memberSystem[JOINED]);\n    assertEquals(serverMemberId, memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertFalse(firedSystem[LEFT]);\n    assertNull(memberSystem[LEFT]);\n    assertNull(memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertTrue(firedAdapter[JOINED]);\n    assertNotNull(memberAdapter[JOINED]);\n    assertNotNull(memberIdAdapter[JOINED]);\n    assertEquals(serverMember, memberAdapter[JOINED]);\n    assertEquals(serverMemberId, memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n    assertFalse(firedAdapter[LEFT]);\n    assertNull(memberAdapter[LEFT]);\n    assertNull(memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n    getLogWriter().info(\"[testServerEventsInSystemClient] wait for client to fully connect\");\n    final String pl =\n      getRootRegion().getSubregion(name).getAttributes().getPoolName();\n    PoolImpl pi = (PoolImpl)PoolManager.find(pl);\n    waitForClientToFullyConnect(pi);\n    LogWriter bgexecLogger =\n          new LocalLogWriter(LogWriterImpl.ALL_LEVEL, System.out);\n    bgexecLogger.info(\"<ExpectedException action=add>\" + \n        \"java.io.IOException\" + \"<\/ExpectedException>\");\n    final ExpectedException ex = addExpectedException(\n        ServerConnectivityException.class.getName());\n    try {\n      vm0.invoke(new SerializableRunnable(\"Disconnect bridge server\") {\n        public void run() {\n          getLogWriter().info(\"[testServerEventsInSystemClient] disconnect bridge server\");\n          closeCache();\n          disconnectFromDS();\n        }\n      });\n      synchronized(systemListener) {\n        if (!firedSystem[LEFT]) {\n          systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n        }\n      }\n      synchronized(adapter) {\n        if (!firedAdapter[LEFT]) {\n          adapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n        }\n      }\n      synchronized(bridgeListener) {\n        if (!firedBridge[LEFT]) {\n          bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n        }\n      }\n    }\n    finally {\n      bgexecLogger.info(\"<ExpectedException action=remove>\" + \n          \"java.io.IOException\" + \"<\/ExpectedException>\");\n      ex.remove();\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server crashed\");\n    assertFalse(firedSystemDuplicate);\n   \n   \n   \n   \n   \n    assertFalse(firedAdapterDuplicate);\n    assertFalse(firedBridgeDuplicate);\n    assertFalse(firedBridge[JOINED]);\n    assertNull(memberIdBridge[JOINED]);\n    assertNull(memberBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(\"Please update testServerEventsInSystemClient to handle memberLeft for BridgeServer.\", \n                firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertTrue(firedBridge[CRASHED]);\n    assertNotNull(memberBridge[CRASHED]);\n    assertNotNull(memberIdBridge[CRASHED]);\n    assertEquals(serverMemberId, memberIdBridge[CRASHED]);\n    assertEquals(serverMember, memberBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertFalse(firedSystem[JOINED]);\n    assertNull(memberSystem[JOINED]);\n    assertNull(memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertTrue(firedSystem[LEFT]);\n    assertEquals(serverMember, memberSystem[LEFT]);\n    assertEquals(serverMemberId, memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertFalse(\"this intermittently fails\", firedAdapter[JOINED]);\n    assertNull(memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n   \n    assertTrue(firedAdapter[LEFT]);\n    assertEquals(serverMember, memberAdapter[LEFT]);\n    assertEquals(serverMemberId, memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n   \n   \n   \n   \n   \n   \n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n   \n    vm0.invoke(createBridgeServer);\n   \n    assertEquals(ports[0],\n                 vm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class, \n                               \"getTestServerEventsInSystemClient_port\"));\n    serverMemberId = (String) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\n    serverMember = (DistributedMember) vm0.invoke(\n      UniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\n    getLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\n    getLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n    synchronized(systemListener) {\n      if (!firedSystem[JOINED]) {\n        systemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(adapter) {\n      if (!firedAdapter[JOINED]) {\n        adapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    synchronized(bridgeListener) {\n      if (!firedBridge[JOINED]) {\n        bridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n      }\n    }\n    getLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server re-join\");\n    assertFalse(firedSystemDuplicate);\n   \n   \n   \n   \n   \n    assertFalse(firedBridgeDuplicate);\n    assertTrue(firedBridge[JOINED]);\n    assertNotNull(memberBridge[JOINED]);\n    assertNotNull(memberIdBridge[JOINED]);\n    assertEquals(serverMember, memberBridge[JOINED]);\n    assertEquals(serverMemberId, memberIdBridge[JOINED]);\n    assertFalse(isClientBridge[JOINED]);\n    assertFalse(firedBridge[LEFT]);\n    assertNull(memberBridge[LEFT]);\n    assertNull(memberIdBridge[LEFT]);\n    assertFalse(isClientBridge[LEFT]);\n    assertFalse(firedBridge[CRASHED]);\n    assertNull(memberBridge[CRASHED]);\n    assertNull(memberIdBridge[CRASHED]);\n    assertFalse(isClientBridge[CRASHED]);\n    resetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\n    assertTrue(firedSystem[JOINED]);\n    assertEquals(serverMember, memberSystem[JOINED]);\n    assertEquals(serverMemberId, memberIdSystem[JOINED]);\n    assertFalse(isClientSystem[JOINED]);\n    assertFalse(firedSystem[LEFT]);\n    assertNull(memberSystem[LEFT]);\n    assertNull(memberIdSystem[LEFT]);\n    assertFalse(isClientSystem[LEFT]);\n    assertFalse(firedSystem[CRASHED]);\n    assertNull(memberSystem[CRASHED]);\n    assertNull(memberIdSystem[CRASHED]);\n    assertFalse(isClientSystem[CRASHED]);\n    resetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\n    assertTrue(firedAdapter[JOINED]);\n    assertNotNull(memberAdapter[JOINED]);\n    assertNotNull(memberIdAdapter[JOINED]);\n    assertEquals(serverMember, memberAdapter[JOINED]);\n    assertEquals(serverMemberId, memberIdAdapter[JOINED]);\n    assertFalse(isClientAdapter[JOINED]);\n    assertFalse(firedAdapter[LEFT]);\n    assertNull(memberAdapter[LEFT]);\n    assertNull(memberIdAdapter[LEFT]);\n    assertFalse(isClientAdapter[LEFT]);\n    assertFalse(firedAdapter[CRASHED]);\n    assertNull(memberAdapter[CRASHED]);\n    assertNull(memberIdAdapter[CRASHED]);\n    assertFalse(isClientAdapter[CRASHED]);\n    resetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n  }","cleancode":"private void dotestservereventsinsystemclient() throws exception { final boolean[] firedsystem = new boolean[3]; final distributedmember[] membersystem = new distributedmember[3]; final string[] memberidsystem = new string[3]; final boolean[] isclientsystem = new boolean[3]; final boolean[] firedadapter = new boolean[3]; final distributedmember[] memberadapter = new distributedmember[3]; final string[] memberidadapter = new string[3]; final boolean[] isclientadapter = new boolean[3]; final boolean[] firedbridge = new boolean[3]; final distributedmember[] memberbridge = new distributedmember[3]; final string[] memberidbridge = new string[3]; final boolean[] isclientbridge = new boolean[3]; final boolean[] firedsystemduplicate = new boolean[3]; final boolean[] firedadapterduplicate = new boolean[3]; final boolean[] firedbridgeduplicate = new boolean[3]; systemmembershiplistener systemlistener = new systemmembershiplistener() { public synchronized void memberjoined(systemmembershipevent event) { firedsystemduplicate[joined] = firedsystem[joined]; firedsystem[joined] = true; membersystem[joined] = event.getdistributedmember(); memberidsystem[joined] = event.getmemberid(); notify(); } public synchronized void memberleft(systemmembershipevent event) { firedsystemduplicate[left] = firedsystem[left]; firedsystem[left] = true; membersystem[left] = event.getdistributedmember(); memberidsystem[left] = event.getmemberid(); notify(); } public synchronized void membercrashed(systemmembershipevent event) { firedsystemduplicate[crashed] = firedsystem[crashed]; firedsystem[crashed] = true; membersystem[crashed] = event.getdistributedmember(); memberidsystem[crashed] = event.getmemberid(); notify(); } }; universalmembershiplisteneradapter adapter = new universalmembershiplisteneradapter() { @override public synchronized void memberjoined(systemmembershipevent event) { getlogwriter().info(\"[testservereventsinsystemclient] memberjoined >\" + event.getmemberid() + \"<\"); firedadapterduplicate[joined] = firedadapter[joined]; firedadapter[joined] = true; memberadapter[joined] = event.getdistributedmember(); memberidadapter[joined] = event.getmemberid(); if (event instanceof universalmembershiplisteneradapter.adaptedmembershipevent) { isclientadapter[joined] = ((universalmembershiplisteneradapter.adaptedmembershipevent)event).isclient(); } notify(); } @override public synchronized void memberleft(systemmembershipevent event) { getlogwriter().info(\"[testservereventsinsystemclient] memberleft >\" + event.getmemberid() + \"<\"); firedadapterduplicate[left] = firedadapter[left]; firedadapter[left] = true; memberadapter[left] = event.getdistributedmember(); memberidadapter[left] = event.getmemberid(); if (event instanceof universalmembershiplisteneradapter.adaptedmembershipevent) { isclientadapter[left] = ((universalmembershiplisteneradapter.adaptedmembershipevent)event).isclient(); } notify(); } @override public synchronized void membercrashed(systemmembershipevent event) { getlogwriter().info(\"[testservereventsinsystemclient] membercrashed >\" + event.getmemberid() + \"<\"); firedadapterduplicate[crashed] = firedadapter[crashed]; firedadapter[crashed] = true; memberadapter[crashed] = event.getdistributedmember(); memberidadapter[crashed] = event.getmemberid(); if (event instanceof universalmembershiplisteneradapter.adaptedmembershipevent) { isclientadapter[crashed] = ((universalmembershiplisteneradapter.adaptedmembershipevent)event).isclient(); } notify(); } }; bridgemembershiplistener bridgelistener = new bridgemembershiplistener() { public synchronized void memberjoined(bridgemembershipevent event) { firedbridgeduplicate[joined] = firedbridge[joined]; firedbridge[joined] = true; memberbridge[joined] = event.getmember(); memberidbridge[joined] = event.getmemberid(); isclientbridge[joined] = event.isclient(); notify(); } public synchronized void memberleft(bridgemembershipevent event) { firedbridgeduplicate[left] = firedbridge[left]; firedbridge[left] = true; memberbridge[left] = event.getmember(); memberidbridge[left] = event.getmemberid(); isclientbridge[left] = event.isclient(); notify(); } public synchronized void membercrashed(bridgemembershipevent event) { firedbridgeduplicate[crashed] = firedbridge[crashed]; firedbridge[crashed] = true; memberbridge[crashed] = event.getmember(); memberidbridge[crashed] = event.getmemberid(); isclientbridge[crashed] = event.isclient(); notify(); } }; final host host = host.gethost(0); final vm vm0 = host.getvm(0); final string name = this.getuniquename(); final int[] ports = new int[] { availableport.getrandomavailableport(availableport.socket) }; asserttrue(ports[0] != 0); getlogwriter().info(\"[testservereventsinsystemclient] create system bridge client\"); getsystem(); final properties clientproperties = getsystemproperties(); bridgemembership.registerbridgemembershiplistener(bridgelistener); distributedsystemconfig config = admindistributedsystemfactory.definedistributedsystem(getsystem(), null); admindistributedsystem adminds = admindistributedsystemfactory.getdistributedsystem(config); adminds.connect(); asserttrue(adminds.waittobeconnected(5 * 1000)); adminds.addmembershiplistener(systemlistener); adapter.registermembershiplistener(adminds); serializablerunnable createbridgeserver = new cacheserializablerunnable(\"create bridgeserver\") { @override public void run2() throws cacheexception { getlogwriter().info(\"[testservereventsinsystemclient] create bridgeserver\"); getsystem(clientproperties); attributesfactory factory = new attributesfactory(); factory.setscope(scope.local); region region = createregion(name, factory.create()); assertnotnull(region); assertnotnull(getrootregion().getsubregion(name)); try { testservereventsinsystemclient_port = startbridgeserver(ports[0]); } catch (ioexception e) { getlogwriter().error(e); fail(e.getmessage()); } } }; vm0.invoke(createbridgeserver); assertequals(ports[0], vm0.invokeint(universalmembershiplisteneradapterdunittest.class, \"gettestservereventsinsystemclient_port\")); string servermemberid = (string) vm0.invoke( universalmembershiplisteneradapterdunittest.class, \"getmemberid\"); distributedmember servermember = (distributedmember) vm0.invoke( universalmembershiplisteneradapterdunittest.class, \"getdistributedmember\"); getlogwriter().info(\"[testservereventsinsystemclient] ports[0]=\" + ports[0]); getlogwriter().info(\"[testservereventsinsystemclient] servermemberid=\" + servermemberid); getlogwriter().info(\"[testservereventsinsystemclient] servermember=\" + servermember); attributesfactory factory = new attributesfactory(); factory.setscope(scope.local); bridgetestcase.configureconnectionpool(factory, getserverhostname(host), ports, false, -1, -1, null); createregion(name, factory.create()); assertnotnull(getrootregion().getsubregion(name)); synchronized(systemlistener) { if (!firedsystem[joined]) { systemlistener.wait(async_event_wait_millis); } } synchronized(adapter) { if (!firedadapter[joined]) { adapter.wait(async_event_wait_millis); } } synchronized(bridgelistener) { if (!firedbridge[joined]) { bridgelistener.wait(async_event_wait_millis); } } getlogwriter().info(\"[testservereventsinsystemclient] assert client detected server join\"); assertfalse(firedsystemduplicate); assertfalse(firedbridgeduplicate); asserttrue(firedbridge[joined]); assertequals(servermember, memberbridge[joined]); assertequals(servermemberid, memberidbridge[joined]); assertnotnull(memberbridge[joined]); assertnotnull(memberidbridge[joined]); assertfalse(isclientbridge[joined]); assertfalse(firedbridge[left]); assertnull(memberbridge[left]); assertnull(memberidbridge[left]); assertfalse(isclientbridge[left]); assertfalse(firedbridge[crashed]); assertnull(memberbridge[crashed]); assertnull(memberidbridge[crashed]); assertfalse(isclientbridge[crashed]); resetarraysfortesting(firedbridge, memberbridge, memberidbridge, isclientbridge); asserttrue(firedsystem[joined]); assertequals(servermember, membersystem[joined]); assertequals(servermemberid, memberidsystem[joined]); assertfalse(isclientsystem[joined]); assertfalse(firedsystem[left]); assertnull(membersystem[left]); assertnull(memberidsystem[left]); assertfalse(isclientsystem[left]); assertfalse(firedsystem[crashed]); assertnull(membersystem[crashed]); assertnull(memberidsystem[crashed]); assertfalse(isclientsystem[crashed]); resetarraysfortesting(firedsystem, membersystem, memberidsystem, isclientsystem); asserttrue(firedadapter[joined]); assertnotnull(memberadapter[joined]); assertnotnull(memberidadapter[joined]); assertequals(servermember, memberadapter[joined]); assertequals(servermemberid, memberidadapter[joined]); assertfalse(isclientadapter[joined]); assertfalse(firedadapter[left]); assertnull(memberadapter[left]); assertnull(memberidadapter[left]); assertfalse(isclientadapter[left]); assertfalse(firedadapter[crashed]); assertnull(memberadapter[crashed]); assertnull(memberidadapter[crashed]); assertfalse(isclientadapter[crashed]); resetarraysfortesting(firedadapter, memberadapter, memberidadapter, isclientadapter); getlogwriter().info(\"[testservereventsinsystemclient] wait for client to fully connect\"); final string pl = getrootregion().getsubregion(name).getattributes().getpoolname(); poolimpl pi = (poolimpl)poolmanager.find(pl); waitforclienttofullyconnect(pi); logwriter bgexeclogger = new locallogwriter(logwriterimpl.all_level, system.out); bgexeclogger.info(\"<expectedexception action=add>\" + \"java.io.ioexception\" + \"<\/expectedexception>\"); final expectedexception ex = addexpectedexception( serverconnectivityexception.class.getname()); try { vm0.invoke(new serializablerunnable(\"disconnect bridge server\") { public void run() { getlogwriter().info(\"[testservereventsinsystemclient] disconnect bridge server\"); closecache(); disconnectfromds(); } }); synchronized(systemlistener) { if (!firedsystem[left]) { systemlistener.wait(async_event_wait_millis); } } synchronized(adapter) { if (!firedadapter[left]) { adapter.wait(async_event_wait_millis); } } synchronized(bridgelistener) { if (!firedbridge[left]) { bridgelistener.wait(async_event_wait_millis); } } } finally { bgexeclogger.info(\"<expectedexception action=remove>\" + \"java.io.ioexception\" + \"<\/expectedexception>\"); ex.remove(); } getlogwriter().info(\"[testservereventsinsystemclient] assert client detected server crashed\"); assertfalse(firedsystemduplicate); assertfalse(firedadapterduplicate); assertfalse(firedbridgeduplicate); assertfalse(firedbridge[joined]); assertnull(memberidbridge[joined]); assertnull(memberbridge[joined]); assertfalse(isclientbridge[joined]); assertfalse(\"please update testservereventsinsystemclient to handle memberleft for bridgeserver.\", firedbridge[left]); assertnull(memberbridge[left]); assertnull(memberidbridge[left]); assertfalse(isclientbridge[left]); asserttrue(firedbridge[crashed]); assertnotnull(memberbridge[crashed]); assertnotnull(memberidbridge[crashed]); assertequals(servermemberid, memberidbridge[crashed]); assertequals(servermember, memberbridge[crashed]); assertfalse(isclientbridge[crashed]); resetarraysfortesting(firedbridge, memberbridge, memberidbridge, isclientbridge); assertfalse(firedsystem[joined]); assertnull(membersystem[joined]); assertnull(memberidsystem[joined]); assertfalse(isclientsystem[joined]); asserttrue(firedsystem[left]); assertequals(servermember, membersystem[left]); assertequals(servermemberid, memberidsystem[left]); assertfalse(isclientsystem[left]); assertfalse(firedsystem[crashed]); assertnull(membersystem[crashed]); assertnull(memberidsystem[crashed]); assertfalse(isclientsystem[crashed]); resetarraysfortesting(firedsystem, membersystem, memberidsystem, isclientsystem); assertfalse(\"this intermittently fails\", firedadapter[joined]); assertnull(memberidadapter[joined]); assertfalse(isclientadapter[joined]); asserttrue(firedadapter[left]); assertequals(servermember, memberadapter[left]); assertequals(servermemberid, memberidadapter[left]); assertfalse(isclientadapter[left]); assertfalse(firedadapter[crashed]); assertnull(memberadapter[crashed]); assertnull(memberidadapter[crashed]); assertfalse(isclientadapter[crashed]); resetarraysfortesting(firedadapter, memberadapter, memberidadapter, isclientadapter); vm0.invoke(createbridgeserver); assertequals(ports[0], vm0.invokeint(universalmembershiplisteneradapterdunittest.class, \"gettestservereventsinsystemclient_port\")); servermemberid = (string) vm0.invoke( universalmembershiplisteneradapterdunittest.class, \"getmemberid\"); servermember = (distributedmember) vm0.invoke( universalmembershiplisteneradapterdunittest.class, \"getdistributedmember\"); getlogwriter().info(\"[testservereventsinsystemclient] ports[0]=\" + ports[0]); getlogwriter().info(\"[testservereventsinsystemclient] servermemberid=\" + servermemberid); getlogwriter().info(\"[testservereventsinsystemclient] servermember=\" + servermember); synchronized(systemlistener) { if (!firedsystem[joined]) { systemlistener.wait(async_event_wait_millis); } } synchronized(adapter) { if (!firedadapter[joined]) { adapter.wait(async_event_wait_millis); } } synchronized(bridgelistener) { if (!firedbridge[joined]) { bridgelistener.wait(async_event_wait_millis); } } getlogwriter().info(\"[testservereventsinsystemclient] assert client detected server re-join\"); assertfalse(firedsystemduplicate); assertfalse(firedbridgeduplicate); asserttrue(firedbridge[joined]); assertnotnull(memberbridge[joined]); assertnotnull(memberidbridge[joined]); assertequals(servermember, memberbridge[joined]); assertequals(servermemberid, memberidbridge[joined]); assertfalse(isclientbridge[joined]); assertfalse(firedbridge[left]); assertnull(memberbridge[left]); assertnull(memberidbridge[left]); assertfalse(isclientbridge[left]); assertfalse(firedbridge[crashed]); assertnull(memberbridge[crashed]); assertnull(memberidbridge[crashed]); assertfalse(isclientbridge[crashed]); resetarraysfortesting(firedbridge, memberbridge, memberidbridge, isclientbridge); asserttrue(firedsystem[joined]); assertequals(servermember, membersystem[joined]); assertequals(servermemberid, memberidsystem[joined]); assertfalse(isclientsystem[joined]); assertfalse(firedsystem[left]); assertnull(membersystem[left]); assertnull(memberidsystem[left]); assertfalse(isclientsystem[left]); assertfalse(firedsystem[crashed]); assertnull(membersystem[crashed]); assertnull(memberidsystem[crashed]); assertfalse(isclientsystem[crashed]); resetarraysfortesting(firedsystem, membersystem, memberidsystem, isclientsystem); asserttrue(firedadapter[joined]); assertnotnull(memberadapter[joined]); assertnotnull(memberidadapter[joined]); assertequals(servermember, memberadapter[joined]); assertequals(servermemberid, memberidadapter[joined]); assertfalse(isclientadapter[joined]); assertfalse(firedadapter[left]); assertnull(memberadapter[left]); assertnull(memberidadapter[left]); assertfalse(isclientadapter[left]); assertfalse(firedadapter[crashed]); assertnull(memberadapter[crashed]); assertnull(memberidadapter[crashed]); assertfalse(isclientadapter[crashed]); resetarraysfortesting(firedadapter, memberadapter, memberidadapter, isclientadapter); }","comment":"\/\/ kirk: this test fails intermittently with bug 37482\n\/\/ getlogwriter().info(\"[testservereventsinsystemclient] create bridge client\"); \/\/ properties config = new properties(); \/\/ config.setproperty(distributionconfig.mcast_port_name, \"0\"); \/\/ config.setproperty(distributionconfig.locators_name, \"\"); \/\/ getsystem(config); \/\/ attributesfactory factory = new attributesfactory(); \/\/ factory.setscope(scope.local); \/\/ bridgetestcase.configureconnectionpool(factory, getserverhostname(host), ports, false, -1, -1, null); \/\/ createregion(name, factory.create()); \/\/ assertnotnull(getrootregion().getsubregion(name));\n\/\/ register the bridge listener\n\/\/ register the system listener\n\/\/ register the universal adapter\n\/\/ create bridgeserver in vm0...\n\/\/ gather details for later creation of bridgeloader...\n\/\/ create region which connects to bridge server\n\/\/ todo: sometimes get adapter duplicate since memberid isn't endpoint \/\/ initial impl uses endpoint.tostring() for memberid of server; final \/\/ impl should have server send its real memberid to client via handshake \/\/assertfalse(\"please update testbridgemembershipeventsinclient to use bridgeserver memberid.\", \/\/ firedadapterduplicate);\n\/\/ kirk: did increasing this solve problem on balrog?\n\/\/ todo: sometimes get adapter duplicate since memberid isn't endpoint \/\/ initial impl uses endpoint.tostring() for memberid of server; final \/\/ impl should have server send its real memberid to client via handshake \/\/assertfalse(\"please update testbridgemembershipeventsinclient to use bridgeserver memberid.\", \/\/ firedadapterduplicate);\n\/\/ kirk --> this fails on balrog occasionally\n\/\/ left fired by system listener\n\/\/ there won't be an adapter crashed event because since the two vms \/\/ are in the same distributed system, and the server's real member \/\/ id is used now. in this case, two events are sent - one from \/\/ jgroups (memberdeparted), and one from the server (a membercrshed). \/\/ the membercrashed event is deemed a duplicate and not sent - see \/\/ universalmembershiplisteneradapter.systemmembershiplistener.isduplicate\n\/\/ reconnect bridge client to test for crashed event\n\/\/ gather details for later creation of bridgeloader...\n\/\/ todo: sometimes get adapter duplicate since memberid isn't endpoint \/\/ initial impl uses endpoint.tostring() for memberid of server; final \/\/ impl should have server send its real memberid to client via handshake \/\/assertfalse(\"please update testbridgemembershipeventsinclient to use bridgeserver memberid.\", \/\/ firedadapterduplicate);","repo":"xyxiaoyou\/snappy-store","code_context_2":"private void doTestServerEventsInSystemClient() throws Exception {\n\/\/ KIRK: this test fails intermittently with bug 37482\nfinal boolean[] firedSystem = new boolean[3];\nfinal DistributedMember[] memberSystem = new DistributedMember[3];\n\n{ AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\nassertTrue(ports[0] != 0);\n\/\/ getLogWriter().info(\"[testServerEventsInSystemClient] create bridge client\");\n\/\/ Properties config = new Properties();\n\/\/ config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\n\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\n\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\n\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\n\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\/\/ create region which connects to bridge server\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\n\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\n\nsynchronized(adapter) {\nif (!firedAdapter[LEFT]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS); \/\/ KIRK: did increasing this solve problem on balrog?\n}\n}\n\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\n\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\n\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\n\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\n\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);","code_context_10":"private void doTestServerEventsInSystemClient() throws Exception {\n\/\/ KIRK: this test fails intermittently with bug 37482\nfinal boolean[] firedSystem = new boolean[3];\nfinal DistributedMember[] memberSystem = new DistributedMember[3];\nfinal String[] memberIdSystem = new String[3];\nfinal boolean[] isClientSystem = new boolean[3];\nfinal boolean[] firedAdapter = new boolean[3];\nfinal DistributedMember[] memberAdapter = new DistributedMember[3];\nfinal String[] memberIdAdapter = new String[3];\nfinal boolean[] isClientAdapter = new boolean[3];\nfinal boolean[] firedBridge = new boolean[3];\nfinal DistributedMember[] memberBridge = new DistributedMember[3];\n\nisClientBridge[CRASHED] = event.isClient();\nnotify();\n}\n};\nfinal Host host = Host.getHost(0);\nfinal VM vm0 = host.getVM(0);\nfinal String name = this.getUniqueName();\nfinal int[] ports = new int[]\n{ AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\nassertTrue(ports[0] != 0);\n\/\/ getLogWriter().info(\"[testServerEventsInSystemClient] create bridge client\");\n\/\/ Properties config = new Properties();\n\/\/ config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\n\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\n\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\n\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\n\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\n\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\/\/ create region which connects to bridge server\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\n\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);\n\ndisconnectFromDS();\n}\n});\nsynchronized(systemListener) {\nif (!firedSystem[LEFT]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[LEFT]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS); \/\/ KIRK: did increasing this solve problem on balrog?\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[LEFT]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\n}\nfinally {\nbgexecLogger.info(\"<ExpectedException action=remove>\" +\n\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);\n\nassertFalse(isClientSystem[JOINED]);\nassertTrue(firedSystem[LEFT]);\nassertEquals(serverMember, memberSystem[LEFT]);\nassertEquals(serverMemberId, memberIdSystem[LEFT]);\nassertFalse(isClientSystem[LEFT]);\nassertFalse(firedSystem[CRASHED]);\nassertNull(memberSystem[CRASHED]);\nassertNull(memberIdSystem[CRASHED]);\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\nassertEquals(serverMemberId, memberIdSystem[LEFT]);\nassertFalse(isClientSystem[LEFT]);\nassertFalse(firedSystem[CRASHED]);\nassertNull(memberSystem[CRASHED]);\nassertNull(memberIdSystem[CRASHED]);\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\n\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nserverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nserverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\n\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);","code_context_20":"private void doTestServerEventsInSystemClient() throws Exception {\n\/\/ KIRK: this test fails intermittently with bug 37482\nfinal boolean[] firedSystem = new boolean[3];\nfinal DistributedMember[] memberSystem = new DistributedMember[3];\nfinal String[] memberIdSystem = new String[3];\nfinal boolean[] isClientSystem = new boolean[3];\nfinal boolean[] firedAdapter = new boolean[3];\nfinal DistributedMember[] memberAdapter = new DistributedMember[3];\nfinal String[] memberIdAdapter = new String[3];\nfinal boolean[] isClientAdapter = new boolean[3];\nfinal boolean[] firedBridge = new boolean[3];\nfinal DistributedMember[] memberBridge = new DistributedMember[3];\nfinal String[] memberIdBridge = new String[3];\nfinal boolean[] isClientBridge = new boolean[3];\nfinal boolean[] firedSystemDuplicate = new boolean[3];\nfinal boolean[] firedAdapterDuplicate = new boolean[3];\nfinal boolean[] firedBridgeDuplicate = new boolean[3];\nSystemMembershipListener systemListener = new SystemMembershipListener() {\npublic synchronized void memberJoined(SystemMembershipEvent event) {\nfiredSystemDuplicate[JOINED] = firedSystem[JOINED];\nfiredSystem[JOINED] = true;\nmemberSystem[JOINED] = event.getDistributedMember();\n\nmemberBridge[LEFT] = event.getMember();\nmemberIdBridge[LEFT] = event.getMemberId();\nisClientBridge[LEFT] = event.isClient();\nnotify();\n}\npublic synchronized void memberCrashed(BridgeMembershipEvent event) {\nfiredBridgeDuplicate[CRASHED] = firedBridge[CRASHED];\nfiredBridge[CRASHED] = true;\nmemberBridge[CRASHED] = event.getMember();\nmemberIdBridge[CRASHED] = event.getMemberId();\nisClientBridge[CRASHED] = event.isClient();\nnotify();\n}\n};\nfinal Host host = Host.getHost(0);\nfinal VM vm0 = host.getVM(0);\nfinal String name = this.getUniqueName();\nfinal int[] ports = new int[]\n{ AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\nassertTrue(ports[0] != 0);\n\/\/ getLogWriter().info(\"[testServerEventsInSystemClient] create bridge client\");\n\/\/ Properties config = new Properties();\n\/\/ config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\n\n};\nfinal Host host = Host.getHost(0);\nfinal VM vm0 = host.getVM(0);\nfinal String name = this.getUniqueName();\nfinal int[] ports = new int[]\n{ AvailablePort.getRandomAvailablePort(AvailablePort.SOCKET) };\nassertTrue(ports[0] != 0);\n\/\/ getLogWriter().info(\"[testServerEventsInSystemClient] create bridge client\");\n\/\/ Properties config = new Properties();\n\/\/ config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\n\n\/\/ Properties config = new Properties();\n\/\/ config.setProperty(DistributionConfig.MCAST_PORT_NAME, \"0\");\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\nassertNotNull(getRootRegion().getSubregion(name));\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\n\n\/\/ config.setProperty(DistributionConfig.LOCATORS_NAME, \"\");\n\/\/ getSystem(config);\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\nassertNotNull(getRootRegion().getSubregion(name));\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n\n\/\/ AttributesFactory factory = new AttributesFactory();\n\/\/ factory.setScope(Scope.LOCAL);\n\/\/ BridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\n\/\/ createRegion(name, factory.create());\n\/\/ assertNotNull(getRootRegion().getSubregion(name));\ngetLogWriter().info(\"[testServerEventsInSystemClient] create system bridge client\");\ngetSystem();\nfinal Properties clientProperties = getSystemProperties();\n\/\/ register the bridge listener\nBridgeMembership.registerBridgeMembershipListener(bridgeListener);\nDistributedSystemConfig config =\nAdminDistributedSystemFactory.defineDistributedSystem(getSystem(), null);\nAdminDistributedSystem adminDS =\nAdminDistributedSystemFactory.getDistributedSystem(config);\nadminDS.connect();\nassertTrue(adminDS.waitToBeConnected(5 * 1000));\n\/\/ register the system listener\nadminDS.addMembershipListener(systemListener);\n\/\/ register the universal adapter\nadapter.registerMembershipListener(adminDS);\n\/\/ create BridgeServer in vm0...\nSerializableRunnable createBridgeServer =\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\nassertNotNull(getRootRegion().getSubregion(name));\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\n\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\nassertNotNull(getRootRegion().getSubregion(name));\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\/\/ create region which connects to bridge server\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\/\/ create region which connects to bridge server\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[JOINED]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\n\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[JOINED]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);\nassertFalse(isClientBridge[LEFT]);\nassertFalse(firedBridge[CRASHED]);\nassertNull(memberBridge[CRASHED]);\nassertNull(memberIdBridge[CRASHED]);\nassertFalse(isClientBridge[CRASHED]);\nresetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\nassertTrue(firedSystem[JOINED]);\nassertEquals(serverMember, memberSystem[JOINED]);\nassertEquals(serverMemberId, memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);\n\nnew LocalLogWriter(LogWriterImpl.ALL_LEVEL, System.out);\nbgexecLogger.info(\"<ExpectedException action=add>\" +\n\"java.io.IOException\" + \"<\/ExpectedException>\");\nfinal ExpectedException ex = addExpectedException(\nServerConnectivityException.class.getName());\ntry {\nvm0.invoke(new SerializableRunnable(\"Disconnect bridge server\") {\npublic void run() {\ngetLogWriter().info(\"[testServerEventsInSystemClient] disconnect bridge server\");\ncloseCache();\ndisconnectFromDS();\n}\n});\nsynchronized(systemListener) {\nif (!firedSystem[LEFT]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[LEFT]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS); \/\/ KIRK: did increasing this solve problem on balrog?\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[LEFT]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\n}\nfinally {\nbgexecLogger.info(\"<ExpectedException action=remove>\" +\n\"java.io.IOException\" + \"<\/ExpectedException>\");\nex.remove();\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server crashed\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\n\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[JOINED]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);\nassertFalse(isClientBridge[LEFT]);\nassertFalse(firedBridge[CRASHED]);\nassertNull(memberBridge[CRASHED]);\nassertNull(memberIdBridge[CRASHED]);\nassertFalse(isClientBridge[CRASHED]);\nresetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\nassertTrue(firedSystem[JOINED]);\nassertEquals(serverMember, memberSystem[JOINED]);\nassertEquals(serverMemberId, memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);\n\nassertTrue(firedBridge[CRASHED]);\nassertNotNull(memberBridge[CRASHED]);\nassertNotNull(memberIdBridge[CRASHED]);\nassertEquals(serverMemberId, memberIdBridge[CRASHED]);\nassertEquals(serverMember, memberBridge[CRASHED]);\nassertFalse(isClientBridge[CRASHED]);\nresetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\nassertFalse(firedSystem[JOINED]);\nassertNull(memberSystem[JOINED]);\nassertNull(memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);\nassertTrue(firedSystem[LEFT]);\nassertEquals(serverMember, memberSystem[LEFT]);\nassertEquals(serverMemberId, memberIdSystem[LEFT]);\nassertFalse(isClientSystem[LEFT]);\nassertFalse(firedSystem[CRASHED]);\nassertNull(memberSystem[CRASHED]);\nassertNull(memberIdSystem[CRASHED]);\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\nassertEquals(serverMemberId, memberIdBridge[CRASHED]);\nassertEquals(serverMember, memberBridge[CRASHED]);\nassertFalse(isClientBridge[CRASHED]);\nresetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\nassertFalse(firedSystem[JOINED]);\nassertNull(memberSystem[JOINED]);\nassertNull(memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);\nassertTrue(firedSystem[LEFT]);\nassertEquals(serverMember, memberSystem[LEFT]);\nassertEquals(serverMemberId, memberIdSystem[LEFT]);\nassertFalse(isClientSystem[LEFT]);\nassertFalse(firedSystem[CRASHED]);\nassertNull(memberSystem[CRASHED]);\nassertNull(memberIdSystem[CRASHED]);\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\nassertNull(memberSystem[JOINED]);\nassertNull(memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);\nassertTrue(firedSystem[LEFT]);\nassertEquals(serverMember, memberSystem[LEFT]);\nassertEquals(serverMemberId, memberIdSystem[LEFT]);\nassertFalse(isClientSystem[LEFT]);\nassertFalse(firedSystem[CRASHED]);\nassertNull(memberSystem[CRASHED]);\nassertNull(memberIdSystem[CRASHED]);\nassertFalse(isClientSystem[CRASHED]);\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nserverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nserverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\n\nresetArraysForTesting(firedSystem, memberSystem, memberIdSystem, isClientSystem);\nassertFalse(\"this intermittently fails\", firedAdapter[JOINED]); \/\/ KIRK --> this fails on balrog occasionally\nassertNull(memberIdAdapter[JOINED]);\nassertFalse(isClientAdapter[JOINED]);\n\/\/ LEFT fired by System listener\nassertTrue(firedAdapter[LEFT]);\nassertEquals(serverMember, memberAdapter[LEFT]);\nassertEquals(serverMemberId, memberIdAdapter[LEFT]);\nassertFalse(isClientAdapter[LEFT]);\n\/\/ There won't be an adapter crashed event because since the two VMs\n\/\/ are in the same distributed system, and the server's real member\n\/\/ id is used now. In this case, two events are sent - one from\n\/\/ jgroups (memberDeparted), and one from the server (a memberCrshed).\n\/\/ The memberCrashed event is deemed a duplicate and not sent - see\n\/\/ UniversalMembershipListenerAdapter.SystemMembershipListener.isDuplicate\nassertFalse(firedAdapter[CRASHED]);\nassertNull(memberAdapter[CRASHED]);\nassertNull(memberIdAdapter[CRASHED]);\nassertFalse(isClientAdapter[CRASHED]);\nresetArraysForTesting(firedAdapter, memberAdapter, memberIdAdapter, isClientAdapter);\n\/\/ reconnect bridge client to test for crashed event\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nserverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nserverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[JOINED]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n\nnew CacheSerializableRunnable(\"Create BridgeServer\") {\n@Override\npublic void run2() throws CacheException {\ngetLogWriter().info(\"[testServerEventsInSystemClient] Create BridgeServer\");\ngetSystem(clientProperties);\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nRegion region = createRegion(name, factory.create());\nassertNotNull(region);\nassertNotNull(getRootRegion().getSubregion(name));\ntry {\ntestServerEventsInSystemClient_port = startBridgeServer(ports[0]);\n}\ncatch (IOException e) {\ngetLogWriter().error(e);\nfail(e.getMessage());\n}\n}\n};\nvm0.invoke(createBridgeServer);\n\/\/ gather details for later creation of BridgeLoader...\nassertEquals(ports[0],\nvm0.invokeInt(UniversalMembershipListenerAdapterDUnitTest.class,\n\"getTestServerEventsInSystemClient_port\"));\nString serverMemberId = (String) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getMemberId\");\nDistributedMember serverMember = (DistributedMember) vm0.invoke(\nUniversalMembershipListenerAdapterDUnitTest.class, \"getDistributedMember\");\ngetLogWriter().info(\"[testServerEventsInSystemClient] ports[0]=\" + ports[0]);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMemberId=\" + serverMemberId);\ngetLogWriter().info(\"[testServerEventsInSystemClient] serverMember=\" + serverMember);\n\/\/ create region which connects to bridge server\nAttributesFactory factory = new AttributesFactory();\nfactory.setScope(Scope.LOCAL);\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n\nBridgeTestCase.configureConnectionPool(factory, getServerHostName(host), ports, false, -1, -1, null);\ncreateRegion(name, factory.create());\nassertNotNull(getRootRegion().getSubregion(name));\nsynchronized(systemListener) {\nif (!firedSystem[JOINED]) {\nsystemListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(adapter) {\nif (!firedAdapter[JOINED]) {\nadapter.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\nsynchronized(bridgeListener) {\nif (!firedBridge[JOINED]) {\nbridgeListener.wait(ASYNC_EVENT_WAIT_MILLIS);\n}\n}\ngetLogWriter().info(\"[testServerEventsInSystemClient] assert client detected server join\");\nassertFalse(firedSystemDuplicate);\n\/\/ TODO: sometimes get adapter duplicate since memberId isn't endpoint\n\/\/ initial impl uses Endpoint.toString() for memberId of server; final\n\/\/ impl should have server send its real memberId to client via HandShake\n\/\/assertFalse(\"Please update testBridgeMembershipEventsInClient to use BridgeServer memberId.\",\n\/\/ firedAdapterDuplicate);\nassertFalse(firedBridgeDuplicate);\nassertTrue(firedBridge[JOINED]);\nassertEquals(serverMember, memberBridge[JOINED]);\nassertEquals(serverMemberId, memberIdBridge[JOINED]);\nassertNotNull(memberBridge[JOINED]);\nassertNotNull(memberIdBridge[JOINED]);\nassertFalse(isClientBridge[JOINED]);\nassertFalse(firedBridge[LEFT]);\nassertNull(memberBridge[LEFT]);\nassertNull(memberIdBridge[LEFT]);\nassertFalse(isClientBridge[LEFT]);\nassertFalse(firedBridge[CRASHED]);\nassertNull(memberBridge[CRASHED]);\nassertNull(memberIdBridge[CRASHED]);\nassertFalse(isClientBridge[CRASHED]);\nresetArraysForTesting(firedBridge, memberBridge, memberIdBridge, isClientBridge);\nassertTrue(firedSystem[JOINED]);\nassertEquals(serverMember, memberSystem[JOINED]);\nassertEquals(serverMemberId, memberIdSystem[JOINED]);\nassertFalse(isClientSystem[JOINED]);","label":[1,0,0,1]}
{"id":23257,"original_code":"@Override protected void onReset() {\n        super.onReset();\n        \/\/ Ensure the loader is stopped\n        onStopLoading();\n        \/\/ TODO: manage mem if needed\n        mTransactionModel.getTransactionsList().clear();\n        mTransactionModel = null;\n    }","code":"@Override protected void onReset() {\n        super.onReset();\n       \n        onStopLoading();\n       \n        mTransactionModel.getTransactionsList().clear();\n        mTransactionModel = null;\n    }","cleancode":"@override protected void onreset() { super.onreset(); onstoploading(); mtransactionmodel.gettransactionslist().clear(); mtransactionmodel = null; }","comment":"\/** * handles a request to completely reset the loader. *\/\n\/\/ ensure the loader is stopped\n\/\/ todo: manage mem if needed","repo":"vulko\/TransactionsTestTask","code_context_2":"@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}\n\n@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\n\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;","code_context_10":"@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}\n\n@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}\n\n@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}","code_context_20":"@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}\n\n@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}\n\n@Override protected void onReset() {\nsuper.onReset();\n\/\/ Ensure the loader is stopped\nonStopLoading();\n\/\/ TODO: manage mem if needed\nmTransactionModel.getTransactionsList().clear();\nmTransactionModel = null;\n}","label":[0,1,0,0]}
{"id":23465,"original_code":"public IResource loadResource(IRestfulClient theClient) throws IOException {\n\t\tif (myResource != null) {\n\t\t\treturn myResource;\n\t\t}\n\t\tIdDt resourceId = getReference();\n\t\tif (resourceId == null) {\n\t\t\tthrow new IllegalStateException(\"Reference has no resource ID defined\");\n\t\t}\n\t\tString resourceUrl = resourceId.getValue();\n\t\tourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\n\t\tHttpClient httpClient = theClient.getHttpClient();\n\t\tFhirContext context = theClient.getFhirContext();\n\t\tif (!resourceUrl.startsWith(\"http\")) {\n\t\t\tresourceUrl = theClient.getServerBase() + resourceUrl;\n\t\t}\n\t\tHttpGet get = new HttpGet(resourceUrl);\n\t\tHttpResponse response = httpClient.execute(get);\n\t\ttry {\n\t\t\t\/\/ TODO: choose appropriate parser based on response CT\n\t\t\tIParser parser = context.newXmlParser();\n\t\t\tReader responseReader = BaseClient.createReaderFromResponse(response);\n\t\t\tmyResource = parser.parseResource(responseReader);\n\t\t} finally {\n\t\t\tif (response instanceof CloseableHttpResponse) {\n\t\t\t\t((CloseableHttpResponse) response).close();\n\t\t\t}\n\t\t}\n\t\treturn myResource;\n\t}","code":"public IResource loadResource(IRestfulClient theClient) throws IOException {\n\t\tif (myResource != null) {\n\t\t\treturn myResource;\n\t\t}\n\t\tIdDt resourceId = getReference();\n\t\tif (resourceId == null) {\n\t\t\tthrow new IllegalStateException(\"Reference has no resource ID defined\");\n\t\t}\n\t\tString resourceUrl = resourceId.getValue();\n\t\tourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\n\t\tHttpClient httpClient = theClient.getHttpClient();\n\t\tFhirContext context = theClient.getFhirContext();\n\t\tif (!resourceUrl.startsWith(\"http\")) {\n\t\t\tresourceUrl = theClient.getServerBase() + resourceUrl;\n\t\t}\n\t\tHttpGet get = new HttpGet(resourceUrl);\n\t\tHttpResponse response = httpClient.execute(get);\n\t\ttry {\n\t\t\n\t\t\tIParser parser = context.newXmlParser();\n\t\t\tReader responseReader = BaseClient.createReaderFromResponse(response);\n\t\t\tmyResource = parser.parseResource(responseReader);\n\t\t} finally {\n\t\t\tif (response instanceof CloseableHttpResponse) {\n\t\t\t\t((CloseableHttpResponse) response).close();\n\t\t\t}\n\t\t}\n\t\treturn myResource;\n\t}","cleancode":"public iresource loadresource(irestfulclient theclient) throws ioexception { if (myresource != null) { return myresource; } iddt resourceid = getreference(); if (resourceid == null) { throw new illegalstateexception(\"reference has no resource id defined\"); } string resourceurl = resourceid.getvalue(); ourlog.debug(\"loading resource at url: {}\", resourceurl); httpclient httpclient = theclient.gethttpclient(); fhircontext context = theclient.getfhircontext(); if (!resourceurl.startswith(\"http\")) { resourceurl = theclient.getserverbase() + resourceurl; } httpget get = new httpget(resourceurl); httpresponse response = httpclient.execute(get); try { iparser parser = context.newxmlparser(); reader responsereader = baseclient.createreaderfromresponse(response); myresource = parser.parseresource(responsereader); } finally { if (response instanceof closeablehttpresponse) { ((closeablehttpresponse) response).close(); } } return myresource; }","comment":"\/** * returns the referenced resource, fetching it <b>if it has not already been loaded<\/b>. this method invokes the http client to retrieve the resource unless it has already been loaded, or was a * contained resource in which case it is simply returned. *\/\n\/\/ todo: choose appropriate parser based on response ct","repo":"wdebeau1\/hapi-fhir","code_context_2":"public IResource loadResource(IRestfulClient theClient) throws IOException {\nif (myResource != null) {\nreturn myResource;\n}\nIdDt resourceId = getReference();\nif (resourceId == null) {\nthrow new IllegalStateException(\"Reference has no resource ID defined\");\n}\nString resourceUrl = resourceId.getValue();\nourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\nHttpClient httpClient = theClient.getHttpClient();\nFhirContext context = theClient.getFhirContext();\nif (!resourceUrl.startsWith(\"http\")) {\nresourceUrl = theClient.getServerBase() + resourceUrl;\n}\nHttpGet get = new HttpGet(resourceUrl);\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);\nmyResource = parser.parseResource(responseReader);\n} finally {\nif (response instanceof CloseableHttpResponse) {\n((CloseableHttpResponse) response).close();\n}\n}\nreturn myResource;\n}\n\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);","code_context_10":"public IResource loadResource(IRestfulClient theClient) throws IOException {\nif (myResource != null) {\nreturn myResource;\n}\nIdDt resourceId = getReference();\nif (resourceId == null) {\nthrow new IllegalStateException(\"Reference has no resource ID defined\");\n}\nString resourceUrl = resourceId.getValue();\nourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\nHttpClient httpClient = theClient.getHttpClient();\nFhirContext context = theClient.getFhirContext();\nif (!resourceUrl.startsWith(\"http\")) {\nresourceUrl = theClient.getServerBase() + resourceUrl;\n}\nHttpGet get = new HttpGet(resourceUrl);\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);\nmyResource = parser.parseResource(responseReader);\n} finally {\nif (response instanceof CloseableHttpResponse) {\n((CloseableHttpResponse) response).close();\n}\n}\nreturn myResource;\n}\n\nString resourceUrl = resourceId.getValue();\nourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\nHttpClient httpClient = theClient.getHttpClient();\nFhirContext context = theClient.getFhirContext();\nif (!resourceUrl.startsWith(\"http\")) {\nresourceUrl = theClient.getServerBase() + resourceUrl;\n}\nHttpGet get = new HttpGet(resourceUrl);\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);\nmyResource = parser.parseResource(responseReader);\n} finally {\nif (response instanceof CloseableHttpResponse) {\n((CloseableHttpResponse) response).close();\n}\n}\nreturn myResource;\n}","code_context_20":"public IResource loadResource(IRestfulClient theClient) throws IOException {\nif (myResource != null) {\nreturn myResource;\n}\nIdDt resourceId = getReference();\nif (resourceId == null) {\nthrow new IllegalStateException(\"Reference has no resource ID defined\");\n}\nString resourceUrl = resourceId.getValue();\nourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\nHttpClient httpClient = theClient.getHttpClient();\nFhirContext context = theClient.getFhirContext();\nif (!resourceUrl.startsWith(\"http\")) {\nresourceUrl = theClient.getServerBase() + resourceUrl;\n}\nHttpGet get = new HttpGet(resourceUrl);\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);\nmyResource = parser.parseResource(responseReader);\n} finally {\nif (response instanceof CloseableHttpResponse) {\n((CloseableHttpResponse) response).close();\n}\n}\nreturn myResource;\n}\n\npublic IResource loadResource(IRestfulClient theClient) throws IOException {\nif (myResource != null) {\nreturn myResource;\n}\nIdDt resourceId = getReference();\nif (resourceId == null) {\nthrow new IllegalStateException(\"Reference has no resource ID defined\");\n}\nString resourceUrl = resourceId.getValue();\nourLog.debug(\"Loading resource at URL: {}\", resourceUrl);\nHttpClient httpClient = theClient.getHttpClient();\nFhirContext context = theClient.getFhirContext();\nif (!resourceUrl.startsWith(\"http\")) {\nresourceUrl = theClient.getServerBase() + resourceUrl;\n}\nHttpGet get = new HttpGet(resourceUrl);\nHttpResponse response = httpClient.execute(get);\ntry {\n\/\/ TODO: choose appropriate parser based on response CT\nIParser parser = context.newXmlParser();\nReader responseReader = BaseClient.createReaderFromResponse(response);\nmyResource = parser.parseResource(responseReader);\n} finally {\nif (response instanceof CloseableHttpResponse) {\n((CloseableHttpResponse) response).close();\n}\n}\nreturn myResource;\n}","label":[0,1,0,0]}
{"id":31699,"original_code":"public static String weekdayCodeToString(int weekday) {\n        String[] weekdays = DATE_FORMAT_SYMBOLS.getWeekdays();\n        return weekdays[weekday];\n    }","code":"public static String weekdayCodeToString(int weekday) {\n        String[] weekdays = DATE_FORMAT_SYMBOLS.getWeekdays();\n        return weekdays[weekday];\n    }","cleancode":"public static string weekdaycodetostring(int weekday) { string[] weekdays = date_format_symbols.getweekdays(); return weekdays[weekday]; }","comment":"\/** * returns a string representing the supplied day-of-the-week. * <p> * need to find a better approach. * * @param weekday the day of the week. * * @return a string representing the supplied day-of-the-week. *\/","repo":"tovganesh\/metastudio","code_context_2":"public static String weekdayCodeToString(int weekday) {\nString[] weekdays = DATE_FORMAT_SYMBOLS.getWeekdays();\nreturn weekdays[weekday];\n}","code_context_10":"public static String weekdayCodeToString(int weekday) {\nString[] weekdays = DATE_FORMAT_SYMBOLS.getWeekdays();\nreturn weekdays[weekday];\n}","code_context_20":"public static String weekdayCodeToString(int weekday) {\nString[] weekdays = DATE_FORMAT_SYMBOLS.getWeekdays();\nreturn weekdays[weekday];\n}","label":[1,0,0,0]}
{"id":31700,"original_code":"public static String weekInMonthToString(int count) {\n        switch (count) {\n            case SerialDate.FIRST_WEEK_IN_MONTH : return \"First\";\n            case SerialDate.SECOND_WEEK_IN_MONTH : return \"Second\";\n            case SerialDate.THIRD_WEEK_IN_MONTH : return \"Third\";\n            case SerialDate.FOURTH_WEEK_IN_MONTH : return \"Fourth\";\n            case SerialDate.LAST_WEEK_IN_MONTH : return \"Last\";\n            default :\n                return \"SerialDate.weekInMonthToString(...): invalid code.\";\n        }\n    }","code":"public static String weekInMonthToString(int count) {\n        switch (count) {\n            case SerialDate.FIRST_WEEK_IN_MONTH : return \"First\";\n            case SerialDate.SECOND_WEEK_IN_MONTH : return \"Second\";\n            case SerialDate.THIRD_WEEK_IN_MONTH : return \"Third\";\n            case SerialDate.FOURTH_WEEK_IN_MONTH : return \"Fourth\";\n            case SerialDate.LAST_WEEK_IN_MONTH : return \"Last\";\n            default :\n                return \"SerialDate.weekInMonthToString(...): invalid code.\";\n        }\n    }","cleancode":"public static string weekinmonthtostring(int count) { switch (count) { case serialdate.first_week_in_month : return \"first\"; case serialdate.second_week_in_month : return \"second\"; case serialdate.third_week_in_month : return \"third\"; case serialdate.fourth_week_in_month : return \"fourth\"; case serialdate.last_week_in_month : return \"last\"; default : return \"serialdate.weekinmonthtostring(...): invalid code.\"; } }","comment":"\/** * returns a string corresponding to the week-in-the-month code. * <p> * need to find a better approach. * * @param count an integer code representing the week-in-the-month. * * @return a string corresponding to the week-in-the-month code. *\/","repo":"tovganesh\/metastudio","code_context_2":"public static String weekInMonthToString(int count) {\nswitch (count) {\ncase SerialDate.FIRST_WEEK_IN_MONTH : return \"First\";\ncase SerialDate.SECOND_WEEK_IN_MONTH : return \"Second\";\ncase SerialDate.THIRD_WEEK_IN_MONTH : return \"Third\";\ncase SerialDate.FOURTH_WEEK_IN_MONTH : return \"Fourth\";\ncase SerialDate.LAST_WEEK_IN_MONTH : return \"Last\";\ndefault :\nreturn \"SerialDate.weekInMonthToString(...): invalid code.\";\n}\n}","code_context_10":"public static String weekInMonthToString(int count) {\nswitch (count) {\ncase SerialDate.FIRST_WEEK_IN_MONTH : return \"First\";\ncase SerialDate.SECOND_WEEK_IN_MONTH : return \"Second\";\ncase SerialDate.THIRD_WEEK_IN_MONTH : return \"Third\";\ncase SerialDate.FOURTH_WEEK_IN_MONTH : return \"Fourth\";\ncase SerialDate.LAST_WEEK_IN_MONTH : return \"Last\";\ndefault :\nreturn \"SerialDate.weekInMonthToString(...): invalid code.\";\n}\n}","code_context_20":"public static String weekInMonthToString(int count) {\nswitch (count) {\ncase SerialDate.FIRST_WEEK_IN_MONTH : return \"First\";\ncase SerialDate.SECOND_WEEK_IN_MONTH : return \"Second\";\ncase SerialDate.THIRD_WEEK_IN_MONTH : return \"Third\";\ncase SerialDate.FOURTH_WEEK_IN_MONTH : return \"Fourth\";\ncase SerialDate.LAST_WEEK_IN_MONTH : return \"Last\";\ndefault :\nreturn \"SerialDate.weekInMonthToString(...): invalid code.\";\n}\n}","label":[1,0,0,0]}
{"id":31761,"original_code":"@Override\n      public KeyringConfig build()\n          throws NoSuchAlgorithmException, PGPException, NoSuchProviderException,\n          InvalidAlgorithmParameterException, IOException {\n        \/\/ Hash Calculator\n        final PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n            .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n            .build()\n            .get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n        \/\/ Encryptor for encrypting secret keys\n        final boolean withPassphrase = !passphrase.isEmpty();\n        @Nullable final PBESecretKeyEncryptor encryptor;\n        if (withPassphrase) {\n          \/\/ AES-256 encrypted\n          encryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n              .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n              .build(passphrase.getChars());\n        } else {\n          \/\/ unencrypted key pair\n          encryptor = null;\n        }\n        \/\/ First key is the Master Key\n        final KeySpec certKeySpec = keySpecs.get(0);\n        \/\/ Remove master key, so that we later only add sub keys.\n        keySpecs.remove(0);\n        \/\/ Generate Master Key\n        final PGPKeyPair certKey = generateKeyPair(certKeySpec);\n        \/\/ Signer for creating self-signature\n        final PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\n            certKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n            .setProvider(BouncyCastleProvider.PROVIDER_NAME);\n        final PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n        \/\/ Generator which the user can get the key pair from\n        final PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\n            PGPSignature.POSITIVE_CERTIFICATION, certKey,\n            userId, calculator,\n            hashedSubPackets, null, signer, encryptor);\n        for (final KeySpec subKeySpec : keySpecs) {\n          final PGPKeyPair subKey = generateKeyPair(subKeySpec);\n          if (subKeySpec.isInheritedSubPackets()) {\n            ringGenerator.addSubKey(subKey);\n          } else {\n            ringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n          }\n        }\n        final PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\n        PGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n        \/\/ TODO: Remove once BC 1.61 is released\n        final PBESecretKeyDecryptor decryptor;\n        if (withPassphrase) {\n          \/\/ AES-256 encrypted\n          decryptor = new JcePBESecretKeyDecryptorBuilder(\n              new JcaPGPDigestCalculatorProviderBuilder()\n                  .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n                  .build()).build(passphrase.getChars());\n        } else {\n          \/\/ unencrypted key pair\n          decryptor = null;\n        }\n        secretKeys = KeyRingSubKeyFixUtil.repairSubkeyPackets(secretKeys, decryptor, encryptor);\n        final InMemoryKeyring keyring;\n        if (passphrase.isEmpty()) {\n          keyring = KeyringConfigs\n              .forGpgExportedKeys(KeyringConfigCallbacks.withUnprotectedKeys());\n        } else {\n          keyring = KeyringConfigs\n              .forGpgExportedKeys(KeyringConfigCallbacks.withPassword(passphrase.getChars()));\n        }\n        keyring.addSecretKeyRing(secretKeys);\n        keyring.addPublicKeyRing(publicKeys);\n        passphrase.clear();\n        return keyring;\n      }","code":"@Override\n      public KeyringConfig build()\n          throws NoSuchAlgorithmException, PGPException, NoSuchProviderException,\n          InvalidAlgorithmParameterException, IOException {\n       \n        final PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n            .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n            .build()\n            .get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n       \n        final boolean withPassphrase = !passphrase.isEmpty();\n        @Nullable final PBESecretKeyEncryptor encryptor;\n        if (withPassphrase) {\n         \n          encryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n              .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n              .build(passphrase.getChars());\n        } else {\n         \n          encryptor = null;\n        }\n       \n        final KeySpec certKeySpec = keySpecs.get(0);\n       \n        keySpecs.remove(0);\n       \n        final PGPKeyPair certKey = generateKeyPair(certKeySpec);\n       \n        final PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\n            certKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n            .setProvider(BouncyCastleProvider.PROVIDER_NAME);\n        final PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n       \n        final PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\n            PGPSignature.POSITIVE_CERTIFICATION, certKey,\n            userId, calculator,\n            hashedSubPackets, null, signer, encryptor);\n        for (final KeySpec subKeySpec : keySpecs) {\n          final PGPKeyPair subKey = generateKeyPair(subKeySpec);\n          if (subKeySpec.isInheritedSubPackets()) {\n            ringGenerator.addSubKey(subKey);\n          } else {\n            ringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n          }\n        }\n        final PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\n        PGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n       \n        final PBESecretKeyDecryptor decryptor;\n        if (withPassphrase) {\n         \n          decryptor = new JcePBESecretKeyDecryptorBuilder(\n              new JcaPGPDigestCalculatorProviderBuilder()\n                  .setProvider(BouncyCastleProvider.PROVIDER_NAME)\n                  .build()).build(passphrase.getChars());\n        } else {\n         \n          decryptor = null;\n        }\n        secretKeys = KeyRingSubKeyFixUtil.repairSubkeyPackets(secretKeys, decryptor, encryptor);\n        final InMemoryKeyring keyring;\n        if (passphrase.isEmpty()) {\n          keyring = KeyringConfigs\n              .forGpgExportedKeys(KeyringConfigCallbacks.withUnprotectedKeys());\n        } else {\n          keyring = KeyringConfigs\n              .forGpgExportedKeys(KeyringConfigCallbacks.withPassword(passphrase.getChars()));\n        }\n        keyring.addSecretKeyRing(secretKeys);\n        keyring.addPublicKeyRing(publicKeys);\n        passphrase.clear();\n        return keyring;\n      }","cleancode":"@override public keyringconfig build() throws nosuchalgorithmexception, pgpexception, nosuchproviderexception, invalidalgorithmparameterexception, ioexception { final pgpdigestcalculator calculator = new jcapgpdigestcalculatorproviderbuilder() .setprovider(bouncycastleprovider.provider_name) .build() .get(pgphashalgorithms.sha1.getalgorithmid()); final boolean withpassphrase = !passphrase.isempty(); @nullable final pbesecretkeyencryptor encryptor; if (withpassphrase) { encryptor = new jcepbesecretkeyencryptorbuilder(pgpencrypteddata.aes_256, calculator) .setprovider(bouncycastleprovider.provider_name) .build(passphrase.getchars()); } else { encryptor = null; } final keyspec certkeyspec = keyspecs.get(0); keyspecs.remove(0); final pgpkeypair certkey = generatekeypair(certkeyspec); final pgpcontentsignerbuilder signer = new jcapgpcontentsignerbuilder( certkey.getpublickey().getalgorithm(), pgphashalgorithms.sha_512.getalgorithmid()) .setprovider(bouncycastleprovider.provider_name); final pgpsignaturesubpacketvector hashedsubpackets = certkeyspec.getsubpackets(); final pgpkeyringgenerator ringgenerator = new pgpkeyringgenerator( pgpsignature.positive_certification, certkey, userid, calculator, hashedsubpackets, null, signer, encryptor); for (final keyspec subkeyspec : keyspecs) { final pgpkeypair subkey = generatekeypair(subkeyspec); if (subkeyspec.isinheritedsubpackets()) { ringgenerator.addsubkey(subkey); } else { ringgenerator.addsubkey(subkey, subkeyspec.getsubpackets(), null); } } final pgppublickeyring publickeys = ringgenerator.generatepublickeyring(); pgpsecretkeyring secretkeys = ringgenerator.generatesecretkeyring(); final pbesecretkeydecryptor decryptor; if (withpassphrase) { decryptor = new jcepbesecretkeydecryptorbuilder( new jcapgpdigestcalculatorproviderbuilder() .setprovider(bouncycastleprovider.provider_name) .build()).build(passphrase.getchars()); } else { decryptor = null; } secretkeys = keyringsubkeyfixutil.repairsubkeypackets(secretkeys, decryptor, encryptor); final inmemorykeyring keyring; if (passphrase.isempty()) { keyring = keyringconfigs .forgpgexportedkeys(keyringconfigcallbacks.withunprotectedkeys()); } else { keyring = keyringconfigs .forgpgexportedkeys(keyringconfigcallbacks.withpassword(passphrase.getchars())); } keyring.addsecretkeyring(secretkeys); keyring.addpublickeyring(publickeys); passphrase.clear(); return keyring; }","comment":"\/\/ hash calculator\n\/\/ encryptor for encrypting secret keys\n\/\/ aes-256 encrypted\n\/\/ unencrypted key pair\n\/\/ first key is the master key\n\/\/ remove master key, so that we later only add sub keys.\n\/\/ generate master key\n\/\/ signer for creating self-signature\n\/\/ generator which the user can get the key pair from\n\/\/ todo: remove once bc 1.61 is released\n\/\/ aes-256 encrypted\n\/\/ unencrypted key pair","repo":"user9209\/bouncy-gpg","code_context_2":"throws NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\n\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\n\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\n\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\n\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\n\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\nPGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n\/\/ TODO: Remove once BC 1.61 is released\nfinal PBESecretKeyDecryptor decryptor;\nif (withPassphrase) {\n\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}","code_context_10":"@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\n\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\n\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\n\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\n\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\n\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n}\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\nPGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n\/\/ TODO: Remove once BC 1.61 is released\nfinal PBESecretKeyDecryptor decryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\ndecryptor = new JcePBESecretKeyDecryptorBuilder(\nnew JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()).build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\ndecryptor = null;\n\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\n\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(","code_context_20":"@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\n\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\n\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n}\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\n\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n}\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\nPGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n\/\/ TODO: Remove once BC 1.61 is released\n\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n}\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\nPGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n\/\/ TODO: Remove once BC 1.61 is released\nfinal PBESecretKeyDecryptor decryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\ndecryptor = new JcePBESecretKeyDecryptorBuilder(\nnew JcaPGPDigestCalculatorProviderBuilder()\n\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);\nif (subKeySpec.isInheritedSubPackets()) {\nringGenerator.addSubKey(subKey);\n} else {\nringGenerator.addSubKey(subKey, subKeySpec.getSubpackets(), null);\n}\n}\nfinal PGPPublicKeyRing publicKeys = ringGenerator.generatePublicKeyRing();\nPGPSecretKeyRing secretKeys = ringGenerator.generateSecretKeyRing();\n\/\/ TODO: Remove once BC 1.61 is released\nfinal PBESecretKeyDecryptor decryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\ndecryptor = new JcePBESecretKeyDecryptorBuilder(\nnew JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()).build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\ndecryptor = null;\n}\nsecretKeys = KeyRingSubKeyFixUtil.repairSubkeyPackets(secretKeys, decryptor, encryptor);\nfinal InMemoryKeyring keyring;\nif (passphrase.isEmpty()) {\nkeyring = KeyringConfigs\n.forGpgExportedKeys(KeyringConfigCallbacks.withUnprotectedKeys());\n} else {\nkeyring = KeyringConfigs\n.forGpgExportedKeys(KeyringConfigCallbacks.withPassword(passphrase.getChars()));\n}\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\n\n@Override\npublic KeyringConfig build()\nthrows NoSuchAlgorithmException, PGPException, NoSuchProviderException,\nInvalidAlgorithmParameterException, IOException {\n\/\/ Hash Calculator\nfinal PGPDigestCalculator calculator = new JcaPGPDigestCalculatorProviderBuilder()\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build()\n.get(PGPHashAlgorithms.SHA1.getAlgorithmId());\n\/\/ Encryptor for encrypting secret keys\nfinal boolean withPassphrase = !passphrase.isEmpty();\n@Nullable final PBESecretKeyEncryptor encryptor;\nif (withPassphrase) {\n\/\/ AES-256 encrypted\nencryptor = new JcePBESecretKeyEncryptorBuilder(PGPEncryptedData.AES_256, calculator)\n.setProvider(BouncyCastleProvider.PROVIDER_NAME)\n.build(passphrase.getChars());\n} else {\n\/\/ unencrypted key pair\nencryptor = null;\n}\n\/\/ First key is the Master Key\nfinal KeySpec certKeySpec = keySpecs.get(0);\n\/\/ Remove master key, so that we later only add sub keys.\nkeySpecs.remove(0);\n\/\/ Generate Master Key\nfinal PGPKeyPair certKey = generateKeyPair(certKeySpec);\n\/\/ Signer for creating self-signature\nfinal PGPContentSignerBuilder signer = new JcaPGPContentSignerBuilder(\ncertKey.getPublicKey().getAlgorithm(), PGPHashAlgorithms.SHA_512.getAlgorithmId())\n.setProvider(BouncyCastleProvider.PROVIDER_NAME);\nfinal PGPSignatureSubpacketVector hashedSubPackets = certKeySpec.getSubpackets();\n\/\/ Generator which the user can get the key pair from\nfinal PGPKeyRingGenerator ringGenerator = new PGPKeyRingGenerator(\nPGPSignature.POSITIVE_CERTIFICATION, certKey,\nuserId, calculator,\nhashedSubPackets, null, signer, encryptor);\nfor (final KeySpec subKeySpec : keySpecs) {\nfinal PGPKeyPair subKey = generateKeyPair(subKeySpec);","label":[1,0,0,0]}
{"id":31979,"original_code":"public Map<SkbShellArgument, Object> getArgMap(SkbShellArgument[] arguments){\n\t\tMap<SkbShellArgument, Object> ret = new LinkedHashMap<SkbShellArgument, Object>();\n\t\tif(arguments!=null){\n\t\t\tfor(Entry<String, String> entry : this.getArgMap().entrySet()){\n\t\t\t\tfor(SkbShellArgument ssa : arguments){\n\t\t\t\t\tif(ssa.getKey().equals(entry.getKey())){\n\t\t\t\t\t\tswitch(ssa.getType()){\n\t\t\t\t\t\t\tcase Boolean:\n\t\t\t\t\t\t\t\tret.put(ssa, Boolean.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase Double:\n\t\t\t\t\t\t\t\tret.put(ssa, Double.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase Integer:\n\t\t\t\t\t\t\t\tret.put(ssa, Integer.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase String:\n\t\t\t\t\t\t\t\tret.put(ssa, entry.getValue());\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase ListString:\n\t\t\t\t\t\t\t\tString[] ar = StringUtils.split(entry.getValue(), ';');\n\t\t\t\t\t\t\t\tif(ar!=null){\n\t\t\t\t\t\t\t\t\tList<String> val = new ArrayList<>();\n\t\t\t\t\t\t\t\t\tfor(String s : ar){\n\t\t\t\t\t\t\t\t\t\tval.add(s);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tret.put(ssa, val);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase ListInteger:\n\t\t\t\t\t\t\t\tString[] arInt = StringUtils.split(entry.getValue(), ';');\n\t\t\t\t\t\t\t\tif(arInt!=null){\n\t\t\t\t\t\t\t\t\tList<Integer> valInt = new ArrayList<>();\n\t\t\t\t\t\t\t\t\tfor(String s : arInt){\n\t\t\t\t\t\t\t\t\t\tvalInt.add(Integer.valueOf(s));\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tret.put(ssa, valInt);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t}","code":"public Map<SkbShellArgument, Object> getArgMap(SkbShellArgument[] arguments){\n\t\tMap<SkbShellArgument, Object> ret = new LinkedHashMap<SkbShellArgument, Object>();\n\t\tif(arguments!=null){\n\t\t\tfor(Entry<String, String> entry : this.getArgMap().entrySet()){\n\t\t\t\tfor(SkbShellArgument ssa : arguments){\n\t\t\t\t\tif(ssa.getKey().equals(entry.getKey())){\n\t\t\t\t\t\tswitch(ssa.getType()){\n\t\t\t\t\t\t\tcase Boolean:\n\t\t\t\t\t\t\t\tret.put(ssa, Boolean.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase Double:\n\t\t\t\t\t\t\t\tret.put(ssa, Double.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase Integer:\n\t\t\t\t\t\t\t\tret.put(ssa, Integer.valueOf(entry.getValue()));\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase String:\n\t\t\t\t\t\t\t\tret.put(ssa, entry.getValue());\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase ListString:\n\t\t\t\t\t\t\t\tString[] ar = StringUtils.split(entry.getValue(), ';');\n\t\t\t\t\t\t\t\tif(ar!=null){\n\t\t\t\t\t\t\t\t\tList<String> val = new ArrayList<>();\n\t\t\t\t\t\t\t\t\tfor(String s : ar){\n\t\t\t\t\t\t\t\t\t\tval.add(s);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tret.put(ssa, val);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase ListInteger:\n\t\t\t\t\t\t\t\tString[] arInt = StringUtils.split(entry.getValue(), ';');\n\t\t\t\t\t\t\t\tif(arInt!=null){\n\t\t\t\t\t\t\t\t\tList<Integer> valInt = new ArrayList<>();\n\t\t\t\t\t\t\t\t\tfor(String s : arInt){\n\t\t\t\t\t\t\t\t\t\tvalInt.add(Integer.valueOf(s));\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tret.put(ssa, valInt);\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType())\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn ret;\n\t}","cleancode":"public map<skbshellargument, object> getargmap(skbshellargument[] arguments){ map<skbshellargument, object> ret = new linkedhashmap<skbshellargument, object>(); if(arguments!=null){ for(entry<string, string> entry : this.getargmap().entryset()){ for(skbshellargument ssa : arguments){ if(ssa.getkey().equals(entry.getkey())){ switch(ssa.gettype()){ case boolean: ret.put(ssa, boolean.valueof(entry.getvalue())); break; case double: ret.put(ssa, double.valueof(entry.getvalue())); break; case integer: ret.put(ssa, integer.valueof(entry.getvalue())); break; case string: ret.put(ssa, entry.getvalue()); break; case liststring: string[] ar = stringutils.split(entry.getvalue(), ';'); if(ar!=null){ list<string> val = new arraylist<>(); for(string s : ar){ val.add(s); } ret.put(ssa, val); } break; case listinteger: string[] arint = stringutils.split(entry.getvalue(), ';'); if(arint!=null){ list<integer> valint = new arraylist<>(); for(string s : arint){ valint.add(integer.valueof(s)); } ret.put(ssa, valint); } break; default: system.err.println(\"parser.getargmap --> argument type not yet supported: \" + ssa.gettype()) break; } } } } } return ret; }","comment":"\/** * returns an argument map fitting the given value key set (using defined types). * @param arguments input arguments to test arguments against * @return argument map with correct value types *\/\n\/\/todo do not use syserr prints","repo":"vdmeer\/skb-java-base","code_context_2":"public Map<SkbShellArgument, Object> getArgMap(SkbShellArgument[] arguments){\nMap<SkbShellArgument, Object> ret = new LinkedHashMap<SkbShellArgument, Object>();\nif(arguments!=null){\nfor(Entry<String, String> entry : this.getArgMap().entrySet()){\nfor(SkbShellArgument ssa : arguments){\nif(ssa.getKey().equals(entry.getKey())){\nswitch(ssa.getType()){\ncase Boolean:\nret.put(ssa, Boolean.valueOf(entry.getValue()));\nbreak;\ncase Double:\nret.put(ssa, Double.valueOf(entry.getValue()));\nbreak;\ncase Integer:\nret.put(ssa, Integer.valueOf(entry.getValue()));\nbreak;\ncase String:\nret.put(ssa, entry.getValue());\nbreak;\ncase ListString:\nString[] ar = StringUtils.split(entry.getValue(), ';');\nif(ar!=null){\nList<String> val = new ArrayList<>();\nfor(String s : ar){\nval.add(s);\n}\nret.put(ssa, val);\n}\nbreak;\ncase ListInteger:\nString[] arInt = StringUtils.split(entry.getValue(), ';');\nif(arInt!=null){\nList<Integer> valInt = new ArrayList<>();\nfor(String s : arInt){\nvalInt.add(Integer.valueOf(s));\n}\nret.put(ssa, valInt);\n}\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}\n}\n}\n}\n}\nreturn ret;\n}\n\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}","code_context_10":"public Map<SkbShellArgument, Object> getArgMap(SkbShellArgument[] arguments){\nMap<SkbShellArgument, Object> ret = new LinkedHashMap<SkbShellArgument, Object>();\nif(arguments!=null){\nfor(Entry<String, String> entry : this.getArgMap().entrySet()){\nfor(SkbShellArgument ssa : arguments){\nif(ssa.getKey().equals(entry.getKey())){\nswitch(ssa.getType()){\ncase Boolean:\nret.put(ssa, Boolean.valueOf(entry.getValue()));\nbreak;\ncase Double:\nret.put(ssa, Double.valueOf(entry.getValue()));\nbreak;\ncase Integer:\nret.put(ssa, Integer.valueOf(entry.getValue()));\nbreak;\ncase String:\nret.put(ssa, entry.getValue());\nbreak;\ncase ListString:\nString[] ar = StringUtils.split(entry.getValue(), ';');\nif(ar!=null){\nList<String> val = new ArrayList<>();\nfor(String s : ar){\nval.add(s);\n}\nret.put(ssa, val);\n}\nbreak;\ncase ListInteger:\nString[] arInt = StringUtils.split(entry.getValue(), ';');\nif(arInt!=null){\nList<Integer> valInt = new ArrayList<>();\nfor(String s : arInt){\nvalInt.add(Integer.valueOf(s));\n}\nret.put(ssa, valInt);\n}\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}\n}\n}\n}\n}\nreturn ret;\n}\n\nString[] arInt = StringUtils.split(entry.getValue(), ';');\nif(arInt!=null){\nList<Integer> valInt = new ArrayList<>();\nfor(String s : arInt){\nvalInt.add(Integer.valueOf(s));\n}\nret.put(ssa, valInt);\n}\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}\n}\n}\n}\n}\nreturn ret;\n}","code_context_20":"public Map<SkbShellArgument, Object> getArgMap(SkbShellArgument[] arguments){\nMap<SkbShellArgument, Object> ret = new LinkedHashMap<SkbShellArgument, Object>();\nif(arguments!=null){\nfor(Entry<String, String> entry : this.getArgMap().entrySet()){\nfor(SkbShellArgument ssa : arguments){\nif(ssa.getKey().equals(entry.getKey())){\nswitch(ssa.getType()){\ncase Boolean:\nret.put(ssa, Boolean.valueOf(entry.getValue()));\nbreak;\ncase Double:\nret.put(ssa, Double.valueOf(entry.getValue()));\nbreak;\ncase Integer:\nret.put(ssa, Integer.valueOf(entry.getValue()));\nbreak;\ncase String:\nret.put(ssa, entry.getValue());\nbreak;\ncase ListString:\nString[] ar = StringUtils.split(entry.getValue(), ';');\nif(ar!=null){\nList<String> val = new ArrayList<>();\nfor(String s : ar){\nval.add(s);\n}\nret.put(ssa, val);\n}\nbreak;\ncase ListInteger:\nString[] arInt = StringUtils.split(entry.getValue(), ';');\nif(arInt!=null){\nList<Integer> valInt = new ArrayList<>();\nfor(String s : arInt){\nvalInt.add(Integer.valueOf(s));\n}\nret.put(ssa, valInt);\n}\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}\n}\n}\n}\n}\nreturn ret;\n}\n\nString[] ar = StringUtils.split(entry.getValue(), ';');\nif(ar!=null){\nList<String> val = new ArrayList<>();\nfor(String s : ar){\nval.add(s);\n}\nret.put(ssa, val);\n}\nbreak;\ncase ListInteger:\nString[] arInt = StringUtils.split(entry.getValue(), ';');\nif(arInt!=null){\nList<Integer> valInt = new ArrayList<>();\nfor(String s : arInt){\nvalInt.add(Integer.valueOf(s));\n}\nret.put(ssa, valInt);\n}\nbreak;\ndefault:\nSystem.err.println(\"parser.getArgMap --> argument type not yet supported: \" + ssa.getType());\/\/TODO do not use syserr prints\nbreak;\n}\n}\n}\n}\n}\nreturn ret;\n}","label":[1,0,0,0]}
{"id":15630,"original_code":"protected void rename(String oldName, String newName) throws IOException {\n        File of = getFile (oldName);\n        File nf = getFile (newName);\n        \/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\n        if ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\n            FSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n        }\n    }","code":"protected void rename(String oldName, String newName) throws IOException {\n        File of = getFile (oldName);\n        File nf = getFile (newName);\n       \n        if ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\n            FSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName);\n        }\n    }","cleancode":"protected void rename(string oldname, string newname) throws ioexception { file of = getfile (oldname); file nf = getfile (newname); if ((nf.exists() && !nf.equals(of)) || !of.renameto (nf)) { fsexception.io (\"exc_cannotrename\", oldname, getdisplayname (), newname); } }","comment":"\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for win32\n\/\/ noi18n","repo":"tszielin\/q-lab-editor","code_context_2":"File of = getFile (oldName);\nFile nf = getFile (newName);\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n}\n}","code_context_10":"protected void rename(String oldName, String newName) throws IOException {\nFile of = getFile (oldName);\nFile nf = getFile (newName);\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n}\n}\n\nprotected void rename(String oldName, String newName) throws IOException {\nFile of = getFile (oldName);\nFile nf = getFile (newName);\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n}\n}","code_context_20":"protected void rename(String oldName, String newName) throws IOException {\nFile of = getFile (oldName);\nFile nf = getFile (newName);\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n}\n}\n\nprotected void rename(String oldName, String newName) throws IOException {\nFile of = getFile (oldName);\nFile nf = getFile (newName);\n\/\/ #7086 - (nf.exists() && !nf.equals(of)) instead of nf.exists() - fix for Win32\nif ((nf.exists() && !nf.equals(of)) || !of.renameTo (nf)) {\nFSException.io (\"EXC_CannotRename\", oldName, getDisplayName (), newName); \/\/ NOI18N\n}\n}","label":[0,0,0,0]}
{"id":32069,"original_code":"private void init() throws Exception {\n        loadDB();\/\/deserialize the database\n        outer:\n        while (true) {\n            \/\/show options\n            System.out.println(\"Main menu:\");\n            System.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\n            switch (Integer.parseInt(br.readLine())) {\n                case 1:\/\/start the parser\n                    BufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\n                    String s = br2.readLine();\n                    while (s != null) {\n                        ar.add(s);\/\/read the options in the parser configuration file\n                        s = br2.readLine();\n                    }\n                    Codes.fixInput(ar);\/\/same as before\n                    Parser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\n                    p.parse();\/\/handing control to the parser\n                    break;\n                case 2:\/\/start the editor\n                    Editor e = new Editor(db, auto_entry);\/\/initializing the editor\n                    e.browse();\n                    break;\/\/the editor is capable of returning to the main menu\n                case 3:\/\/configure everything again?\n                    ConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\n                    break outer;\/\/that's all, after configuration, the program needs to be restarted anyway\n                case 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\n                    new ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\n                    break;\/\/we can come back to the main menu\n                case 5:\/\/import an existing exported database(using this program on a different computer?)\n                    new ExportImport().importer(db, auto_entry);\/\/now it's the import system\n                    break;\/\/same as case 4\n                case 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\n                    System.out.println(\"Exiting...\");\n                    System.exit(0);\/\/Bye-Bye\n                default:\/\/Stop making mistakes in input!\n                    \/\/I'm very considerate, I give everybody infinite chances\n            }\n        }\n    }","code":"private void init() throws Exception {\n        loadDB()\n        outer:\n        while (true) {\n           \n            System.out.println(\"Main menu:\");\n            System.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\n            switch (Integer.parseInt(br.readLine())) {\n                case 1\n                    BufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\n                    String s = br2.readLine();\n                    while (s != null) {\n                        ar.add(s)\n                        s = br2.readLine();\n                    }\n                    Codes.fixInput(ar)\n                    Parser p = new Parser(db, ar.toArray(new String[ar.size()]), status)\n                    p.parse()\n                    break;\n                case 2\n                    Editor e = new Editor(db, auto_entry)\n                    e.browse();\n                    break\n                case 3\n                    ConfigCLI.init()\n                    break outer\n                case 4\n                    new ExportImport().exporter(db, auto_entry)\n                    break\n                case 5\n                    new ExportImport().importer(db, auto_entry)\n                    break\n                case 6\n                    System.out.println(\"Exiting...\");\n                    System.exit(0)\n                default\n                   \n            }\n        }\n    }","cleancode":"private void init() throws exception { loaddb() outer: while (true) { system.out.println(\"main menu:\"); system.out.println(\"1:start parsing\\n2:start browsing\\n3:start configuration system\\n4:export current database\\n5:import a database\\n6:exit\"); switch (integer.parseint(br.readline())) { case 1 bufferedreader br2 = new bufferedreader(new filereader(files[2])); string s = br2.readline(); while (s != null) { ar.add(s) s = br2.readline(); } codes.fixinput(ar) parser p = new parser(db, ar.toarray(new string[ar.size()]), status) p.parse() break; case 2 editor e = new editor(db, auto_entry) e.browse(); break case 3 configcli.init() break outer case 4 new exportimport().exporter(db, auto_entry) break case 5 new exportimport().importer(db, auto_entry) break case 6 system.out.println(\"exiting...\"); system.exit(0) default } } }","comment":"\/** * internal method to load the other classes as requires by the user *\/\n\/\/deserialize the database\n\/\/show options\n\/\/start the parser\n\/\/read the options in the parser configuration file\n\/\/same as before\n\/\/initializing the database parser\n\/\/handing control to the parser\n\/\/start the editor\n\/\/initializing the editor\n\/\/the editor is capable of returning to the main menu\n\/\/configure everything again?\n\/\/configuration system is self-initialising, just hand over control to it\n\/\/that's all, after configuration, the program needs to be restarted anyway\n\/\/export the current database to a database_exported.csv file,which opens in ms excel\n\/\/initializing the export system and handing over control to it!\n\/\/we can come back to the main menu\n\/\/import an existing exported database(using this program on a different computer?)\n\/\/now it's the import system\n\/\/same as case 4\n\/\/no!!! don't leave me behind!(can't do anything about it anyway, can i?)\n\/\/bye-bye\n\/\/stop making mistakes in input!\n\/\/i'm very considerate, i give everybody infinite chances","repo":"tamchow\/inventory-management","code_context_2":"private void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\n\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\n\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\n\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\n\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\n\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\n\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\n\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\n\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\n\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\n\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\n\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\n\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\n\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\n\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\n\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\n\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\n\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\n\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\n\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}","code_context_10":"private void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\n\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\n\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\n\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\n\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\n\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\n\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\n\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\n\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\n\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\n\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}","code_context_20":"private void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nprivate void init() throws Exception {\nloadDB();\/\/deserialize the database\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nouter:\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nwhile (true) {\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\n\/\/show options\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nSystem.out.println(\"Main menu:\");\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nSystem.out.println(\"1:Start Parsing\\n2:Start Browsing\\n3:Start Configuration System\\n4:Export Current Database\\n5:Import a database\\n6:Exit\");\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nswitch (Integer.parseInt(br.readLine())) {\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\ncase 1:\/\/start the parser\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nBufferedReader br2 = new BufferedReader(new FileReader(FILES[2]));\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nString s = br2.readLine();\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nwhile (s != null) {\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nar.add(s);\/\/read the options in the parser configuration file\ns = br2.readLine();\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\n}\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nCodes.fixInput(ar);\/\/same as before\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}\n\nParser p = new Parser(db, ar.toArray(new String[ar.size()]), status);\/\/initializing the database parser\np.parse();\/\/handing control to the parser\nbreak;\ncase 2:\/\/start the editor\nEditor e = new Editor(db, auto_entry);\/\/initializing the editor\ne.browse();\nbreak;\/\/the editor is capable of returning to the main menu\ncase 3:\/\/configure everything again?\nConfigCLI.init();\/\/configuration system is self-initialising, just hand over control to it\nbreak outer;\/\/that's all, after configuration, the program needs to be restarted anyway\ncase 4:\/\/export the current database to a Database_Exported.csv file,which opens in MS Excel\nnew ExportImport().exporter(db, auto_entry);\/\/initializing the export system and handing over control to it!\nbreak;\/\/we can come back to the main menu\ncase 5:\/\/import an existing exported database(using this program on a different computer?)\nnew ExportImport().importer(db, auto_entry);\/\/now it's the import system\nbreak;\/\/same as case 4\ncase 6:\/\/No!!! Don't leave me behind!(Can't do anything about it anyway, can I?)\nSystem.out.println(\"Exiting...\");\nSystem.exit(0);\/\/Bye-Bye\ndefault:\/\/Stop making mistakes in input!\n\/\/I'm very considerate, I give everybody infinite chances\n}\n}\n}","label":[0,0,0,0]}
{"id":15703,"original_code":"private StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\n            final EmailContent.Account account, final EmailContent.Mailbox folder)\n            throws MessagingException {\n        Log.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\n        ContentResolver resolver = mContext.getContentResolver();\n        \/\/ 0.  We do not ever sync DRAFTS or OUTBOX (down or up)\n        if (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\n            int totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\n            return new StoreSynchronizer.SyncResults(totalMessages, 0);\n        }\n        \/\/ 1.  Get the message list from the local store and create an index of the uids\n        Cursor localUidCursor = null;\n        HashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\n        try {\n            localUidCursor = resolver.query(\n                    EmailContent.Message.CONTENT_URI,\n                    LocalMessageInfo.PROJECTION,\n                    EmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n                    \" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\n                    new String[] {\n                            String.valueOf(account.mId),\n                            String.valueOf(folder.mId)\n                    },\n                    null);\n            while (localUidCursor.moveToNext()) {\n                LocalMessageInfo info = new LocalMessageInfo(localUidCursor);\n                localMessageMap.put(info.mServerId, info);\n            }\n        } finally {\n            if (localUidCursor != null) {\n                localUidCursor.close();\n            }\n        }\n        \/\/ 1a. Count the unread messages before changing anything\n        int localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\n                EmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n                \" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n                \" AND \" + MessageColumns.FLAG_READ + \"=0\",\n                new String[] {\n                        String.valueOf(account.mId),\n                        String.valueOf(folder.mId)\n                });\n        \/\/ 2.  Open the remote folder and create the remote folder if necessary\n        Store remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\n        Folder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n        \/*\n         * If the folder is a \"special\" folder we need to see if it exists\n         * on the remote server. It if does not exist we'll try to create it. If we\n         * can't create we'll abort. This will happen on every single Pop3 folder as\n         * designed and on Imap folders during error conditions. This allows us\n         * to treat Pop3 and Imap the same in this code.\n         *\/\n        if (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n                || folder.mType == Mailbox.TYPE_DRAFTS) {\n            if (!remoteFolder.exists()) {\n                if (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\n                    return new StoreSynchronizer.SyncResults(0, 0);\n                }\n            }\n        }\n        \/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\n        remoteFolder.open(OpenMode.READ_WRITE, null);\n        \/\/ 4. Trash any remote messages that are marked as trashed locally.\n        \/\/ TODO - this comment was here, but no code was here.\n        \/\/ 5. Get the remote message count.\n        int remoteMessageCount = remoteFolder.getMessageCount();\n        \/\/ 6. Determine the limit # of messages to download\n        int visibleLimit = folder.mVisibleLimit;\n        if (visibleLimit <= 0) {\n            Store.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\n                    mContext);\n            visibleLimit = info.mVisibleLimitDefault;\n        }\n        \/\/ 7.  Create a list of messages to download\n        Message[] remoteMessages = new Message[0];\n        final ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\n        HashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\n        int newMessageCount = 0;\n        if (remoteMessageCount > 0) {\n            \/*\n             * Message numbers start at 1.\n             *\/\n            int remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\n            int remoteEnd = remoteMessageCount;\n            remoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\n            for (Message message : remoteMessages) {\n                remoteUidMap.put(message.getUid(), message);\n            }\n            \/*\n             * Get a list of the messages that are in the remote list but not on the\n             * local store, or messages that are in the local store but failed to download\n             * on the last sync. These are the new messages that we will download.\n             * Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n             * because they are locally deleted and we don't need or want the old message from\n             * the server.\n             *\/\n            for (Message message : remoteMessages) {\n                LocalMessageInfo localMessage = localMessageMap.get(message.getUid());\n                if (localMessage == null) {\n                    newMessageCount++;\n                }\n                \/\/ localMessage == null -> message has never been created (not even headers)\n                \/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n                \/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n                \/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n                \/\/ mFlagLoaded = DELETED -> message has been deleted\n                \/\/ Only the first two of these are \"unsynced\", so let's retrieve them\n                if (localMessage == null ||\n                        (localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\n                    unsyncedMessages.add(message);\n                }\n            }\n        }\n        \/\/ 8.  Download basic info about the new\/unloaded messages (if any)\n        \/*\n         * A list of messages that were downloaded and which did not have the Seen flag set.\n         * This will serve to indicate the true \"new\" message count that will be reported to\n         * the user via notification.\n         *\/\n        final ArrayList<Message> newMessages = new ArrayList<Message>();\n        \/*\n         * Fetch the flags and envelope only of the new messages. This is intended to get us\n         * critical data as fast as possible, and then we'll fill in the details.\n         *\/\n        if (unsyncedMessages.size() > 0) {\n            FetchProfile fp = new FetchProfile();\n            fp.add(FetchProfile.Item.FLAGS);\n            fp.add(FetchProfile.Item.ENVELOPE);\n            final HashMap<String, LocalMessageInfo> localMapCopy =\n                new HashMap<String, LocalMessageInfo>(localMessageMap);\n            remoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\n                    new MessageRetrievalListener() {\n                        public void messageRetrieved(Message message) {\n                            try {\n                                \/\/ Determine if the new message was already known (e.g. partial)\n                                \/\/ And create or reload the full message info\n                                LocalMessageInfo localMessageInfo =\n                                    localMapCopy.get(message.getUid());\n                                EmailContent.Message localMessage = null;\n                                if (localMessageInfo == null) {\n                                    localMessage = new EmailContent.Message();\n                                } else {\n                                    localMessage = EmailContent.Message.restoreMessageWithId(\n                                            mContext, localMessageInfo.mId);\n                                }\n                                if (localMessage != null) {\n                                    try {\n                                        \/\/ Copy the fields that are available into the message\n                                        LegacyConversions.updateMessageFields(localMessage,\n                                                message, account.mId, folder.mId);\n                                        \/\/ Commit the message to the local store\n                                        saveOrUpdate(localMessage);\n                                        \/\/ Track the \"new\" ness of the downloaded message\n                                        if (!message.isSet(Flag.SEEN)) {\n                                            newMessages.add(message);\n                                        }\n                                    } catch (MessagingException me) {\n                                        Log.e(Email.LOG_TAG,\n                                                \"Error while copying downloaded message.\" + me);\n                                    }\n                                }\n                            }\n                            catch (Exception e) {\n                                Log.e(Email.LOG_TAG,\n                                        \"Error while storing downloaded message.\" + e.toString());\n                            }\n                        }\n                    });\n        }\n        \/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\n        FetchProfile fp = new FetchProfile();\n        fp.add(FetchProfile.Item.FLAGS);\n        remoteFolder.fetch(remoteMessages, fp, null);\n        boolean remoteSupportsSeen = false;\n        boolean remoteSupportsFlagged = false;\n        for (Flag flag : remoteFolder.getPermanentFlags()) {\n            if (flag == Flag.SEEN) {\n                remoteSupportsSeen = true;\n            }\n            if (flag == Flag.FLAGGED) {\n                remoteSupportsFlagged = true;\n            }\n        }\n        \/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\n        if (remoteSupportsSeen || remoteSupportsFlagged) {\n            for (Message remoteMessage : remoteMessages) {\n                LocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\n                if (localMessageInfo == null) {\n                    continue;\n                }\n                boolean localSeen = localMessageInfo.mFlagRead;\n                boolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\n                boolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\n                boolean localFlagged = localMessageInfo.mFlagFavorite;\n                boolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\n                boolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\n                if (newSeen || newFlagged) {\n                    Uri uri = ContentUris.withAppendedId(\n                            EmailContent.Message.CONTENT_URI, localMessageInfo.mId);\n                    ContentValues updateValues = new ContentValues();\n                    updateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\n                    updateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\n                    resolver.update(uri, updateValues, null, null);\n                }\n            }\n        }\n        \/\/ 10. Compute and store the unread message count.\n        \/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/        int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/        if (remoteUnreadMessageCount == -1) {\n\/\/            if (remoteSupportsSeenFlag) {\n\/\/                \/*\n\/\/                 * If remote folder doesn't supported unread message count but supports\n\/\/                 * seen flag, use local folder's unread message count and the size of\n\/\/                 * new messages. This mode is not used for POP3, or IMAP.\n\/\/                 *\/\n\/\/\n\/\/                remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/            } else {\n\/\/                \/*\n\/\/                 * If remote folder doesn't supported unread message count and doesn't\n\/\/                 * support seen flag, use localUnreadCount and newMessageCount which\n\/\/                 * don't rely on remote SEEN flag.  This mode is used by POP3.\n\/\/                 *\/\n\/\/                remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/            }\n\/\/        } else {\n\/\/            \/*\n\/\/             * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/             * This mode is used by IMAP.\n\/\/             *\/\n\/\/         }\n\/\/        Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/        ContentValues updateValues = new ContentValues();\n\/\/        updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/        resolver.update(uri, updateValues, null, null);\n        \/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\n        HashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\n        localUidsToDelete.removeAll(remoteUidMap.keySet());\n        for (String uidToDelete : localUidsToDelete) {\n            LocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n            \/\/ Delete associated data (attachment files)\n            \/\/ Attachment & Body records are auto-deleted when we delete the Message record\n            AttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n            \/\/ Delete the message itself\n            Uri uriToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.CONTENT_URI, infoToDelete.mId);\n            resolver.delete(uriToDelete, null, null);\n            \/\/ Delete extra rows (e.g. synced or deleted)\n            Uri syncRowToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\n            resolver.delete(syncRowToDelete, null, null);\n            Uri deletERowToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\n            resolver.delete(deletERowToDelete, null, null);\n        }\n        \/\/ 12. Divide the unsynced messages into small & large (by size)\n        \/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n        \/\/ from affecting the order (e.g. download a message because the user requested it.)  Much\n        \/\/ of this logic should move out to a different sync loop that attempts to update small\n        \/\/ groups of messages at a time, as a background task.  However, we can't just return\n        \/\/ (yet) because POP messages don't have an envelope yet....\n        ArrayList<Message> largeMessages = new ArrayList<Message>();\n        ArrayList<Message> smallMessages = new ArrayList<Message>();\n        for (Message message : unsyncedMessages) {\n            if (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\n                largeMessages.add(message);\n            } else {\n                smallMessages.add(message);\n            }\n        }\n        \/\/ 13. Download small messages\n        \/\/ TODO Problems with this implementation.  1. For IMAP, where we get a real envelope,\n        \/\/ this is going to be inefficient and duplicate work we've already done.  2.  It's going\n        \/\/ back to the DB for a local message that we already had (and discarded).\n        \/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\n        fp = new FetchProfile();\n        fp.add(FetchProfile.Item.BODY);\n        remoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\n                new MessageRetrievalListener() {\n                    public void messageRetrieved(Message message) {\n                        \/\/ Store the updated message locally and mark it fully loaded\n                        copyOneMessageToProvider(message, account, folder,\n                                EmailContent.Message.FLAG_LOADED_COMPLETE);\n                    }\n        });\n        \/\/ 14. Download large messages.  We ask the server to give us the message structure,\n        \/\/ but not all of the attachments.\n        fp.clear();\n        fp.add(FetchProfile.Item.STRUCTURE);\n        remoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\n        for (Message message : largeMessages) {\n            if (message.getBody() == null) {\n                \/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n                \/\/ (hopefully enough to see some\/all of the body) and mark the message for\n                \/\/ further download.\n                fp.clear();\n                fp.add(FetchProfile.Item.BODY_SANE);\n                \/\/  TODO a good optimization here would be to make sure that all Stores set\n                \/\/  the proper size after this fetch and compare the before and after size. If\n                \/\/  they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\n                remoteFolder.fetch(new Message[] { message }, fp, null);\n                \/\/ Store the partially-loaded message and mark it partially loaded\n                copyOneMessageToProvider(message, account, folder,\n                        EmailContent.Message.FLAG_LOADED_PARTIAL);\n            } else {\n                \/\/ We have a structure to deal with, from which\n                \/\/ we can pull down the parts we want to actually store.\n                \/\/ Build a list of parts we are interested in. Text parts will be downloaded\n                \/\/ right now, attachments will be left for later.\n                ArrayList<Part> viewables = new ArrayList<Part>();\n                ArrayList<Part> attachments = new ArrayList<Part>();\n                MimeUtility.collectParts(message, viewables, attachments);\n                \/\/ Download the viewables immediately\n                for (Part part : viewables) {\n                    fp.clear();\n                    fp.add(part);\n                    \/\/ TODO what happens if the network connection dies? We've got partial\n                    \/\/ messages with incorrect status stored.\n                    remoteFolder.fetch(new Message[] { message }, fp, null);\n                }\n                \/\/ Store the updated message locally and mark it fully loaded\n                copyOneMessageToProvider(message, account, folder,\n                        EmailContent.Message.FLAG_LOADED_COMPLETE);\n            }\n        }\n        \/\/ 15. Clean up and report results\n        remoteFolder.close(false);\n        \/\/ TODO - more\n        \/\/ Original sync code.  Using for reference, will delete when done.\n        if (false) {\n        \/*\n         * Now do the large messages that require more round trips.\n         *\/\n        fp.clear();\n        fp.add(FetchProfile.Item.STRUCTURE);\n        remoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\n                fp, null);\n        for (Message message : largeMessages) {\n            if (message.getBody() == null) {\n                \/*\n                 * The provider was unable to get the structure of the message, so\n                 * we'll download a reasonable portion of the messge and mark it as\n                 * incomplete so the entire thing can be downloaded later if the user\n                 * wishes to download it.\n                 *\/\n                fp.clear();\n                fp.add(FetchProfile.Item.BODY_SANE);\n                \/*\n                 *  TODO a good optimization here would be to make sure that all Stores set\n                 *  the proper size after this fetch and compare the before and after size. If\n                 *  they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\n                 *\/\n                remoteFolder.fetch(new Message[] { message }, fp, null);\n                \/\/ Store the updated message locally\n\/\/                localFolder.appendMessages(new Message[] {\n\/\/                    message\n\/\/                });\n\/\/                Message localMessage = localFolder.getMessage(message.getUid());\n                \/\/ Set a flag indicating that the message has been partially downloaded and\n                \/\/ is ready for view.\n\/\/                localMessage.setFlag(Flag.X_DOWNLOADED_PARTIAL, true);\n            } else {\n                \/*\n                 * We have a structure to deal with, from which\n                 * we can pull down the parts we want to actually store.\n                 * Build a list of parts we are interested in. Text parts will be downloaded\n                 * right now, attachments will be left for later.\n                 *\/\n                ArrayList<Part> viewables = new ArrayList<Part>();\n                ArrayList<Part> attachments = new ArrayList<Part>();\n                MimeUtility.collectParts(message, viewables, attachments);\n                \/*\n                 * Now download the parts we're interested in storing.\n                 *\/\n                for (Part part : viewables) {\n                    fp.clear();\n                    fp.add(part);\n                    \/\/ TODO what happens if the network connection dies? We've got partial\n                    \/\/ messages with incorrect status stored.\n                    remoteFolder.fetch(new Message[] { message }, fp, null);\n                }\n                \/\/ Store the updated message locally\n\/\/                localFolder.appendMessages(new Message[] {\n\/\/                    message\n\/\/                });\n\/\/                Message localMessage = localFolder.getMessage(message.getUid());\n                \/\/ Set a flag indicating this message has been fully downloaded and can be\n                \/\/ viewed.\n\/\/                localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n            }\n            \/\/ Update the listener with what we've found\n\/\/            synchronized (mListeners) {\n\/\/                for (MessagingListener l : mListeners) {\n\/\/                    l.synchronizeMailboxNewMessage(\n\/\/                            account,\n\/\/                            folder,\n\/\/                            localFolder.getMessage(message.getUid()));\n\/\/                }\n\/\/            }\n        }\n        \/*\n         * Report successful sync\n         *\/\n        StoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\n                remoteFolder.getMessageCount(), newMessages.size());\n        remoteFolder.close(false);\n\/\/        localFolder.close(false);\n        return results;\n        }\n        return new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n    }","code":"private StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\n            final EmailContent.Account account, final EmailContent.Mailbox folder)\n            throws MessagingException {\n        Log.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\n        ContentResolver resolver = mContext.getContentResolver();\n       \n        if (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\n            int totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\n            return new StoreSynchronizer.SyncResults(totalMessages, 0);\n        }\n       \n        Cursor localUidCursor = null;\n        HashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\n        try {\n            localUidCursor = resolver.query(\n                    EmailContent.Message.CONTENT_URI,\n                    LocalMessageInfo.PROJECTION,\n                    EmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n                    \" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\n                    new String[] {\n                            String.valueOf(account.mId),\n                            String.valueOf(folder.mId)\n                    },\n                    null);\n            while (localUidCursor.moveToNext()) {\n                LocalMessageInfo info = new LocalMessageInfo(localUidCursor);\n                localMessageMap.put(info.mServerId, info);\n            }\n        } finally {\n            if (localUidCursor != null) {\n                localUidCursor.close();\n            }\n        }\n       \n        int localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\n                EmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n                \" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n                \" AND \" + MessageColumns.FLAG_READ + \"=0\",\n                new String[] {\n                        String.valueOf(account.mId),\n                        String.valueOf(folder.mId)\n                });\n       \n        Store remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\n        Folder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n       \n        if (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n                || folder.mType == Mailbox.TYPE_DRAFTS) {\n            if (!remoteFolder.exists()) {\n                if (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\n                    return new StoreSynchronizer.SyncResults(0, 0);\n                }\n            }\n        }\n       \n        remoteFolder.open(OpenMode.READ_WRITE, null);\n       \n       \n       \n        int remoteMessageCount = remoteFolder.getMessageCount();\n       \n        int visibleLimit = folder.mVisibleLimit;\n        if (visibleLimit <= 0) {\n            Store.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\n                    mContext);\n            visibleLimit = info.mVisibleLimitDefault;\n        }\n       \n        Message[] remoteMessages = new Message[0];\n        final ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\n        HashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\n        int newMessageCount = 0;\n        if (remoteMessageCount > 0) {\n           \n            int remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\n            int remoteEnd = remoteMessageCount;\n            remoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\n            for (Message message : remoteMessages) {\n                remoteUidMap.put(message.getUid(), message);\n            }\n           \n            for (Message message : remoteMessages) {\n                LocalMessageInfo localMessage = localMessageMap.get(message.getUid());\n                if (localMessage == null) {\n                    newMessageCount++;\n                }\n               \n               \n               \n               \n               \n               \n                if (localMessage == null ||\n                        (localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\n                    unsyncedMessages.add(message);\n                }\n            }\n        }\n       \n       \n        final ArrayList<Message> newMessages = new ArrayList<Message>();\n       \n        if (unsyncedMessages.size() > 0) {\n            FetchProfile fp = new FetchProfile();\n            fp.add(FetchProfile.Item.FLAGS);\n            fp.add(FetchProfile.Item.ENVELOPE);\n            final HashMap<String, LocalMessageInfo> localMapCopy =\n                new HashMap<String, LocalMessageInfo>(localMessageMap);\n            remoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\n                    new MessageRetrievalListener() {\n                        public void messageRetrieved(Message message) {\n                            try {\n                               \n                               \n                                LocalMessageInfo localMessageInfo =\n                                    localMapCopy.get(message.getUid());\n                                EmailContent.Message localMessage = null;\n                                if (localMessageInfo == null) {\n                                    localMessage = new EmailContent.Message();\n                                } else {\n                                    localMessage = EmailContent.Message.restoreMessageWithId(\n                                            mContext, localMessageInfo.mId);\n                                }\n                                if (localMessage != null) {\n                                    try {\n                                       \n                                        LegacyConversions.updateMessageFields(localMessage,\n                                                message, account.mId, folder.mId);\n                                       \n                                        saveOrUpdate(localMessage);\n                                       \n                                        if (!message.isSet(Flag.SEEN)) {\n                                            newMessages.add(message);\n                                        }\n                                    } catch (MessagingException me) {\n                                        Log.e(Email.LOG_TAG,\n                                                \"Error while copying downloaded message.\" + me);\n                                    }\n                                }\n                            }\n                            catch (Exception e) {\n                                Log.e(Email.LOG_TAG,\n                                        \"Error while storing downloaded message.\" + e.toString());\n                            }\n                        }\n                    });\n        }\n       \n        FetchProfile fp = new FetchProfile();\n        fp.add(FetchProfile.Item.FLAGS);\n        remoteFolder.fetch(remoteMessages, fp, null);\n        boolean remoteSupportsSeen = false;\n        boolean remoteSupportsFlagged = false;\n        for (Flag flag : remoteFolder.getPermanentFlags()) {\n            if (flag == Flag.SEEN) {\n                remoteSupportsSeen = true;\n            }\n            if (flag == Flag.FLAGGED) {\n                remoteSupportsFlagged = true;\n            }\n        }\n       \n        if (remoteSupportsSeen || remoteSupportsFlagged) {\n            for (Message remoteMessage : remoteMessages) {\n                LocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\n                if (localMessageInfo == null) {\n                    continue;\n                }\n                boolean localSeen = localMessageInfo.mFlagRead;\n                boolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\n                boolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\n                boolean localFlagged = localMessageInfo.mFlagFavorite;\n                boolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\n                boolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\n                if (newSeen || newFlagged) {\n                    Uri uri = ContentUris.withAppendedId(\n                            EmailContent.Message.CONTENT_URI, localMessageInfo.mId);\n                    ContentValues updateValues = new ContentValues();\n                    updateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\n                    updateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\n                    resolver.update(uri, updateValues, null, null);\n                }\n            }\n        }\n       \n       \n       \n        HashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\n        localUidsToDelete.removeAll(remoteUidMap.keySet());\n        for (String uidToDelete : localUidsToDelete) {\n            LocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n           \n           \n            AttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n           \n            Uri uriToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.CONTENT_URI, infoToDelete.mId);\n            resolver.delete(uriToDelete, null, null);\n           \n            Uri syncRowToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\n            resolver.delete(syncRowToDelete, null, null);\n            Uri deletERowToDelete = ContentUris.withAppendedId(\n                    EmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\n            resolver.delete(deletERowToDelete, null, null);\n        }\n       \n       \n       \n       \n       \n       \n        ArrayList<Message> largeMessages = new ArrayList<Message>();\n        ArrayList<Message> smallMessages = new ArrayList<Message>();\n        for (Message message : unsyncedMessages) {\n            if (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\n                largeMessages.add(message);\n            } else {\n                smallMessages.add(message);\n            }\n        }\n       \n       \n       \n       \n       \n        fp = new FetchProfile();\n        fp.add(FetchProfile.Item.BODY);\n        remoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\n                new MessageRetrievalListener() {\n                    public void messageRetrieved(Message message) {\n                       \n                        copyOneMessageToProvider(message, account, folder,\n                                EmailContent.Message.FLAG_LOADED_COMPLETE);\n                    }\n        });\n       \n       \n        fp.clear();\n        fp.add(FetchProfile.Item.STRUCTURE);\n        remoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\n        for (Message message : largeMessages) {\n            if (message.getBody() == null) {\n               \n               \n               \n                fp.clear();\n                fp.add(FetchProfile.Item.BODY_SANE);\n               \n               \n               \n                remoteFolder.fetch(new Message[] { message }, fp, null);\n               \n                copyOneMessageToProvider(message, account, folder,\n                        EmailContent.Message.FLAG_LOADED_PARTIAL);\n            } else {\n               \n               \n               \n               \n                ArrayList<Part> viewables = new ArrayList<Part>();\n                ArrayList<Part> attachments = new ArrayList<Part>();\n                MimeUtility.collectParts(message, viewables, attachments);\n               \n                for (Part part : viewables) {\n                    fp.clear();\n                    fp.add(part);\n                   \n                   \n                    remoteFolder.fetch(new Message[] { message }, fp, null);\n                }\n               \n                copyOneMessageToProvider(message, account, folder,\n                        EmailContent.Message.FLAG_LOADED_COMPLETE);\n            }\n        }\n       \n        remoteFolder.close(false);\n       \n       \n        if (false) {\n       \n        fp.clear();\n        fp.add(FetchProfile.Item.STRUCTURE);\n        remoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\n                fp, null);\n        for (Message message : largeMessages) {\n            if (message.getBody() == null) {\n               \n                fp.clear();\n                fp.add(FetchProfile.Item.BODY_SANE);\n               \n                remoteFolder.fetch(new Message[] { message }, fp, null);\n               \n               \n               \n            } else {\n               \n                ArrayList<Part> viewables = new ArrayList<Part>();\n                ArrayList<Part> attachments = new ArrayList<Part>();\n                MimeUtility.collectParts(message, viewables, attachments);\n               \n                for (Part part : viewables) {\n                    fp.clear();\n                    fp.add(part);\n                   \n                   \n                    remoteFolder.fetch(new Message[] { message }, fp, null);\n                }\n               \n               \n               \n            }\n           \n        }\n       \n        StoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\n                remoteFolder.getMessageCount(), newMessages.size());\n        remoteFolder.close(false);\n        return results;\n        }\n        return new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n    }","cleancode":"private storesynchronizer.syncresults synchronizemailboxgeneric( final emailcontent.account account, final emailcontent.mailbox folder) throws messagingexception { log.d(email.log_tag, \"*** synchronizemailboxgeneric ***\"); contentresolver resolver = mcontext.getcontentresolver(); if (folder.mtype == mailbox.type_drafts || folder.mtype == mailbox.type_outbox) { int totalmessages = emailcontent.count(mcontext, folder.geturi(), null, null); return new storesynchronizer.syncresults(totalmessages, 0); } cursor localuidcursor = null; hashmap<string, localmessageinfo> localmessagemap = new hashmap<string, localmessageinfo>(); try { localuidcursor = resolver.query( emailcontent.message.content_uri, localmessageinfo.projection, emailcontent.messagecolumns.account_key + \"=?\" + \" and \" + messagecolumns.mailbox_key + \"=?\", new string[] { string.valueof(account.mid), string.valueof(folder.mid) }, null); while (localuidcursor.movetonext()) { localmessageinfo info = new localmessageinfo(localuidcursor); localmessagemap.put(info.mserverid, info); } } finally { if (localuidcursor != null) { localuidcursor.close(); } } int localunreadcount = emailcontent.count(mcontext, emailcontent.message.content_uri, emailcontent.messagecolumns.account_key + \"=?\" + \" and \" + messagecolumns.mailbox_key + \"=?\" + \" and \" + messagecolumns.flag_read + \"=0\", new string[] { string.valueof(account.mid), string.valueof(folder.mid) }); store remotestore = store.getinstance(account.getstoreuri(mcontext), mcontext, null); folder remotefolder = remotestore.getfolder(folder.mdisplayname); if (folder.mtype == mailbox.type_trash || folder.mtype == mailbox.type_sent || folder.mtype == mailbox.type_drafts) { if (!remotefolder.exists()) { if (!remotefolder.create(foldertype.holds_messages)) { return new storesynchronizer.syncresults(0, 0); } } } remotefolder.open(openmode.read_write, null); int remotemessagecount = remotefolder.getmessagecount(); int visiblelimit = folder.mvisiblelimit; if (visiblelimit <= 0) { store.storeinfo info = store.storeinfo.getstoreinfo(account.getstoreuri(mcontext), mcontext); visiblelimit = info.mvisiblelimitdefault; } message[] remotemessages = new message[0]; final arraylist<message> unsyncedmessages = new arraylist<message>(); hashmap<string, message> remoteuidmap = new hashmap<string, message>(); int newmessagecount = 0; if (remotemessagecount > 0) { int remotestart = math.max(0, remotemessagecount - visiblelimit) + 1; int remoteend = remotemessagecount; remotemessages = remotefolder.getmessages(remotestart, remoteend, null); for (message message : remotemessages) { remoteuidmap.put(message.getuid(), message); } for (message message : remotemessages) { localmessageinfo localmessage = localmessagemap.get(message.getuid()); if (localmessage == null) { newmessagecount++; } if (localmessage == null || (localmessage.mflagloaded == emailcontent.message.flag_loaded_unloaded)) { unsyncedmessages.add(message); } } } final arraylist<message> newmessages = new arraylist<message>(); if (unsyncedmessages.size() > 0) { fetchprofile fp = new fetchprofile(); fp.add(fetchprofile.item.flags); fp.add(fetchprofile.item.envelope); final hashmap<string, localmessageinfo> localmapcopy = new hashmap<string, localmessageinfo>(localmessagemap); remotefolder.fetch(unsyncedmessages.toarray(new message[0]), fp, new messageretrievallistener() { public void messageretrieved(message message) { try { localmessageinfo localmessageinfo = localmapcopy.get(message.getuid()); emailcontent.message localmessage = null; if (localmessageinfo == null) { localmessage = new emailcontent.message(); } else { localmessage = emailcontent.message.restoremessagewithid( mcontext, localmessageinfo.mid); } if (localmessage != null) { try { legacyconversions.updatemessagefields(localmessage, message, account.mid, folder.mid); saveorupdate(localmessage); if (!message.isset(flag.seen)) { newmessages.add(message); } } catch (messagingexception me) { log.e(email.log_tag, \"error while copying downloaded message.\" + me); } } } catch (exception e) { log.e(email.log_tag, \"error while storing downloaded message.\" + e.tostring()); } } }); } fetchprofile fp = new fetchprofile(); fp.add(fetchprofile.item.flags); remotefolder.fetch(remotemessages, fp, null); boolean remotesupportsseen = false; boolean remotesupportsflagged = false; for (flag flag : remotefolder.getpermanentflags()) { if (flag == flag.seen) { remotesupportsseen = true; } if (flag == flag.flagged) { remotesupportsflagged = true; } } if (remotesupportsseen || remotesupportsflagged) { for (message remotemessage : remotemessages) { localmessageinfo localmessageinfo = localmessagemap.get(remotemessage.getuid()); if (localmessageinfo == null) { continue; } boolean localseen = localmessageinfo.mflagread; boolean remoteseen = remotemessage.isset(flag.seen); boolean newseen = (remotesupportsseen && (remoteseen != localseen)); boolean localflagged = localmessageinfo.mflagfavorite; boolean remoteflagged = remotemessage.isset(flag.flagged); boolean newflagged = (remotesupportsflagged && (localflagged != remoteflagged)); if (newseen || newflagged) { uri uri = contenturis.withappendedid( emailcontent.message.content_uri, localmessageinfo.mid); contentvalues updatevalues = new contentvalues(); updatevalues.put(emailcontent.message.flag_read, remoteseen); updatevalues.put(emailcontent.message.flag_favorite, remoteflagged); resolver.update(uri, updatevalues, null, null); } } } hashset<string> localuidstodelete = new hashset<string>(localmessagemap.keyset()); localuidstodelete.removeall(remoteuidmap.keyset()); for (string uidtodelete : localuidstodelete) { localmessageinfo infotodelete = localmessagemap.get(uidtodelete); attachmentprovider.deleteallattachmentfiles(mcontext, account.mid, infotodelete.mid); uri uritodelete = contenturis.withappendedid( emailcontent.message.content_uri, infotodelete.mid); resolver.delete(uritodelete, null, null); uri syncrowtodelete = contenturis.withappendedid( emailcontent.message.updated_content_uri, infotodelete.mid); resolver.delete(syncrowtodelete, null, null); uri deleterowtodelete = contenturis.withappendedid( emailcontent.message.updated_content_uri, infotodelete.mid); resolver.delete(deleterowtodelete, null, null); } arraylist<message> largemessages = new arraylist<message>(); arraylist<message> smallmessages = new arraylist<message>(); for (message message : unsyncedmessages) { if (message.getsize() > (max_small_message_size)) { largemessages.add(message); } else { smallmessages.add(message); } } fp = new fetchprofile(); fp.add(fetchprofile.item.body); remotefolder.fetch(smallmessages.toarray(new message[smallmessages.size()]), fp, new messageretrievallistener() { public void messageretrieved(message message) { copyonemessagetoprovider(message, account, folder, emailcontent.message.flag_loaded_complete); } }); fp.clear(); fp.add(fetchprofile.item.structure); remotefolder.fetch(largemessages.toarray(new message[largemessages.size()]), fp, null); for (message message : largemessages) { if (message.getbody() == null) { fp.clear(); fp.add(fetchprofile.item.body_sane); remotefolder.fetch(new message[] { message }, fp, null); copyonemessagetoprovider(message, account, folder, emailcontent.message.flag_loaded_partial); } else { arraylist<part> viewables = new arraylist<part>(); arraylist<part> attachments = new arraylist<part>(); mimeutility.collectparts(message, viewables, attachments); for (part part : viewables) { fp.clear(); fp.add(part); remotefolder.fetch(new message[] { message }, fp, null); } copyonemessagetoprovider(message, account, folder, emailcontent.message.flag_loaded_complete); } } remotefolder.close(false); if (false) { fp.clear(); fp.add(fetchprofile.item.structure); remotefolder.fetch(largemessages.toarray(new message[largemessages.size()]), fp, null); for (message message : largemessages) { if (message.getbody() == null) { fp.clear(); fp.add(fetchprofile.item.body_sane); remotefolder.fetch(new message[] { message }, fp, null); } else { arraylist<part> viewables = new arraylist<part>(); arraylist<part> attachments = new arraylist<part>(); mimeutility.collectparts(message, viewables, attachments); for (part part : viewables) { fp.clear(); fp.add(part); remotefolder.fetch(new message[] { message }, fp, null); } } } storesynchronizer.syncresults results = new storesynchronizer.syncresults( remotefolder.getmessagecount(), newmessages.size()); remotefolder.close(false); return results; } return new storesynchronizer.syncresults(remotemessagecount, newmessages.size()); }","comment":"\/** * generic synchronizer - used for pop3 and imap. * * todo break this method up into smaller chunks. * * @param account the account to sync * @param folder the mailbox to sync * @return results of the sync pass * @throws messagingexception *\/\n\/\/ 0. we do not ever sync drafts or outbox (down or up)\n\/\/ 1. get the message list from the local store and create an index of the uids\n\/\/ 1a. count the unread messages before changing anything\n\/\/ 2. open the remote folder and create the remote folder if necessary\n\/* * if the folder is a \"special\" folder we need to see if it exists * on the remote server. it if does not exist we'll try to create it. if we * can't create we'll abort. this will happen on every single pop3 folder as * designed and on imap folders during error conditions. this allows us * to treat pop3 and imap the same in this code. *\/\n\/\/ 3, open the remote folder. this pre-loads certain metadata like message count.\n\/\/ 4. trash any remote messages that are marked as trashed locally. \/\/ todo - this comment was here, but no code was here. \/\/ 5. get the remote message count.\n\/\/ 6. determine the limit # of messages to download\n\/\/ 7. create a list of messages to download\n\/* * message numbers start at 1. *\/\n\/* * get a list of the messages that are in the remote list but not on the * local store, or messages that are in the local store but failed to download * on the last sync. these are the new messages that we will download. * note, we also skip syncing messages which are flagged as \"deleted message\" sentinels, * because they are locally deleted and we don't need or want the old message from * the server. *\/\n\/\/ localmessage == null -> message has never been created (not even headers) \/\/ mflagloaded = unloaded -> message created, but none of body loaded \/\/ mflagloaded = partial -> message created, a \"sane\" amt of body has been loaded \/\/ mflagloaded = complete -> message body has been completely loaded \/\/ mflagloaded = deleted -> message has been deleted \/\/ only the first two of these are \"unsynced\", so let's retrieve them\n\/\/ 8. download basic info about the new\/unloaded messages (if any) \/* * a list of messages that were downloaded and which did not have the seen flag set. * this will serve to indicate the true \"new\" message count that will be reported to * the user via notification. *\/\n\/* * fetch the flags and envelope only of the new messages. this is intended to get us * critical data as fast as possible, and then we'll fill in the details. *\/\n\/\/ determine if the new message was already known (e.g. partial) \/\/ and create or reload the full message info\n\/\/ copy the fields that are available into the message\n\/\/ commit the message to the local store\n\/\/ track the \"new\" ness of the downloaded message\n\/\/ 9. refresh the flags for any messages in the local store that we didn't just download.\n\/\/ update the seen & flagged (star) flags (if supported remotely - e.g. not for pop3)\n\/\/ 10. compute and store the unread message count. \/\/ -- no longer necessary - provider uses db triggers to keep track \/\/ int remoteunreadmessagecount = remotefolder.getunreadmessagecount(); \/\/ if (remoteunreadmessagecount == -1) { \/\/ if (remotesupportsseenflag) { \/\/ \/* \/\/ * if remote folder doesn't supported unread message count but supports \/\/ * seen flag, use local folder's unread message count and the size of \/\/ * new messages. this mode is not used for pop3, or imap. \/\/ *\/ \/\/ \/\/ remoteunreadmessagecount = folder.munreadcount + newmessages.size(); \/\/ } else { \/\/ \/* \/\/ * if remote folder doesn't supported unread message count and doesn't \/\/ * support seen flag, use localunreadcount and newmessagecount which \/\/ * don't rely on remote seen flag. this mode is used by pop3. \/\/ *\/ \/\/ remoteunreadmessagecount = localunreadcount + newmessagecount; \/\/ } \/\/ } else { \/\/ \/* \/\/ * if remote folder supports unread message count, use remoteunreadmessagecount. \/\/ * this mode is used by imap. \/\/ *\/ \/\/ } \/\/ uri uri = contenturis.withappendedid(emailcontent.mailbox.content_uri, folder.mid); \/\/ contentvalues updatevalues = new contentvalues(); \/\/ updatevalues.put(emailcontent.mailbox.unread_count, remoteunreadmessagecount); \/\/ resolver.update(uri, updatevalues, null, null); \/\/ 11. remove any messages that are in the local store but no longer on the remote store.\n\/\/ delete associated data (attachment files) \/\/ attachment & body records are auto-deleted when we delete the message record\n\/\/ delete the message itself\n\/\/ delete extra rows (e.g. synced or deleted)\n\/\/ 12. divide the unsynced messages into small & large (by size) \/\/ todo doing this work here (synchronously) is problematic because it prevents the ui \/\/ from affecting the order (e.g. download a message because the user requested it.) much \/\/ of this logic should move out to a different sync loop that attempts to update small \/\/ groups of messages at a time, as a background task. however, we can't just return \/\/ (yet) because pop messages don't have an envelope yet....\n\/\/ 13. download small messages \/\/ todo problems with this implementation. 1. for imap, where we get a real envelope, \/\/ this is going to be inefficient and duplicate work we've already done. 2. it's going \/\/ back to the db for a local message that we already had (and discarded). \/\/ for small messages, we specify \"body\", which returns everything (incl. attachments)\n\/\/ store the updated message locally and mark it fully loaded\n\/\/ 14. download large messages. we ask the server to give us the message structure, \/\/ but not all of the attachments.\n\/\/ pop doesn't support structure mode, so we'll just do a partial download \/\/ (hopefully enough to see some\/all of the body) and mark the message for \/\/ further download.\n\/\/ todo a good optimization here would be to make sure that all stores set \/\/ the proper size after this fetch and compare the before and after size. if \/\/ they equal we can mark this synchronized instead of partially_synchronized\n\/\/ store the partially-loaded message and mark it partially loaded\n\/\/ we have a structure to deal with, from which \/\/ we can pull down the parts we want to actually store. \/\/ build a list of parts we are interested in. text parts will be downloaded \/\/ right now, attachments will be left for later.\n\/\/ download the viewables immediately\n\/\/ todo what happens if the network connection dies? we've got partial \/\/ messages with incorrect status stored.\n\/\/ store the updated message locally and mark it fully loaded\n\/\/ 15. clean up and report results\n\/\/ todo - more \/\/ original sync code. using for reference, will delete when done.\n\/* * now do the large messages that require more round trips. *\/\n\/* * the provider was unable to get the structure of the message, so * we'll download a reasonable portion of the messge and mark it as * incomplete so the entire thing can be downloaded later if the user * wishes to download it. *\/\n\/* * todo a good optimization here would be to make sure that all stores set * the proper size after this fetch and compare the before and after size. if * they equal we can mark this synchronized instead of partially_synchronized *\/\n\/\/ store the updated message locally \/\/ localfolder.appendmessages(new message[] { \/\/ message \/\/ }); \/\/ message localmessage = localfolder.getmessage(message.getuid()); \/\/ set a flag indicating that the message has been partially downloaded and \/\/ is ready for view. \/\/ localmessage.setflag(flag.x_downloaded_partial, true);\n\/* * we have a structure to deal with, from which * we can pull down the parts we want to actually store. * build a list of parts we are interested in. text parts will be downloaded * right now, attachments will be left for later. *\/\n\/* * now download the parts we're interested in storing. *\/\n\/\/ todo what happens if the network connection dies? we've got partial \/\/ messages with incorrect status stored.\n\/\/ store the updated message locally \/\/ localfolder.appendmessages(new message[] { \/\/ message \/\/ }); \/\/ message localmessage = localfolder.getmessage(message.getuid()); \/\/ set a flag indicating this message has been fully downloaded and can be \/\/ viewed. \/\/ localmessage.setflag(flag.x_downloaded_full, true);\n\/\/ update the listener with what we've found \/\/ synchronized (mlisteners) { \/\/ for (messaginglistener l : mlisteners) { \/\/ l.synchronizemailboxnewmessage( \/\/ account, \/\/ folder, \/\/ localfolder.getmessage(message.getuid())); \/\/ } \/\/ }\n\/* * report successful sync *\/\n\/\/ localfolder.close(false);","repo":"xie-wenjie\/AndroidBaseApplicationSourse","code_context_2":"private StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n}\n\/*\n* Get a list of the messages that are in the remote list but not on the\n* local store, or messages that are in the local store but failed to download\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\nboolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\nboolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/*\n* The provider was unable to get the structure of the message, so\n* we'll download a reasonable portion of the messge and mark it as\n* incomplete so the entire thing can be downloaded later if the user\n* wishes to download it.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/*\n* TODO a good optimization here would be to make sure that all Stores set\n* the proper size after this fetch and compare the before and after size. If\n* they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\n*\/\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating that the message has been partially downloaded and\n\/\/ is ready for view.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_PARTIAL, true);\n} else {\n\/*\n* We have a structure to deal with, from which\n* we can pull down the parts we want to actually store.\n* Build a list of parts we are interested in. Text parts will be downloaded\n* right now, attachments will be left for later.\n*\/\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/*\n* Now download the parts we're interested in storing.\n*\/\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}\n\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\n\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\n\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\n\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\n\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\n\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\n\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\n\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\n\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\n\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\n\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\n\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\n\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\n\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\n\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\n\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\n\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\n\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\n\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\n\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\n\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\n\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\n\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\n\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}","code_context_10":"private StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n}\n\/*\n* Get a list of the messages that are in the remote list but not on the\n* local store, or messages that are in the local store but failed to download\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\nboolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\nboolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/*\n* The provider was unable to get the structure of the message, so\n* we'll download a reasonable portion of the messge and mark it as\n* incomplete so the entire thing can be downloaded later if the user\n* wishes to download it.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/*\n* TODO a good optimization here would be to make sure that all Stores set\n* the proper size after this fetch and compare the before and after size. If\n* they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\n*\/\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating that the message has been partially downloaded and\n\/\/ is ready for view.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_PARTIAL, true);\n} else {\n\/*\n* We have a structure to deal with, from which\n* we can pull down the parts we want to actually store.\n* Build a list of parts we are interested in. Text parts will be downloaded\n* right now, attachments will be left for later.\n*\/\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/*\n* Now download the parts we're interested in storing.\n*\/\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}\n\nprivate StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\n\nprivate StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\n\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\n\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\n\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\n\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\n\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\n\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\n\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\n\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\n\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\n\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\n\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\n\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\n\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\n\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\n\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\n}\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\n\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}","code_context_20":"private StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n}\n\/*\n* Get a list of the messages that are in the remote list but not on the\n* local store, or messages that are in the local store but failed to download\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\nboolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\nboolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/*\n* The provider was unable to get the structure of the message, so\n* we'll download a reasonable portion of the messge and mark it as\n* incomplete so the entire thing can be downloaded later if the user\n* wishes to download it.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/*\n* TODO a good optimization here would be to make sure that all Stores set\n* the proper size after this fetch and compare the before and after size. If\n* they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\n*\/\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating that the message has been partially downloaded and\n\/\/ is ready for view.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_PARTIAL, true);\n} else {\n\/*\n* We have a structure to deal with, from which\n* we can pull down the parts we want to actually store.\n* Build a list of parts we are interested in. Text parts will be downloaded\n* right now, attachments will be left for later.\n*\/\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/*\n* Now download the parts we're interested in storing.\n*\/\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}\n\nprivate StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\n\nprivate StoreSynchronizer.SyncResults synchronizeMailboxGeneric(\nfinal EmailContent.Account account, final EmailContent.Mailbox folder)\nthrows MessagingException {\nLog.d(Email.LOG_TAG, \"*** synchronizeMailboxGeneric ***\");\nContentResolver resolver = mContext.getContentResolver();\n\/\/ 0. We do not ever sync DRAFTS or OUTBOX (down or up)\nif (folder.mType == Mailbox.TYPE_DRAFTS || folder.mType == Mailbox.TYPE_OUTBOX) {\nint totalMessages = EmailContent.count(mContext, folder.getUri(), null, null);\nreturn new StoreSynchronizer.SyncResults(totalMessages, 0);\n}\n\/\/ 1. Get the message list from the local store and create an index of the uids\nCursor localUidCursor = null;\nHashMap<String, LocalMessageInfo> localMessageMap = new HashMap<String, LocalMessageInfo>();\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n\ntry {\nlocalUidCursor = resolver.query(\nEmailContent.Message.CONTENT_URI,\nLocalMessageInfo.PROJECTION,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\n\n},\nnull);\nwhile (localUidCursor.moveToNext()) {\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\n\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\/\/ 7. Create a list of messages to download\nMessage[] remoteMessages = new Message[0];\nfinal ArrayList<Message> unsyncedMessages = new ArrayList<Message>();\nHashMap<String, Message> remoteUidMap = new HashMap<String, Message>();\nint newMessageCount = 0;\nif (remoteMessageCount > 0) {\n\/*\n* Message numbers start at 1.\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n}\n\/*\n* Get a list of the messages that are in the remote list but not on the\n* local store, or messages that are in the local store but failed to download\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\nvisibleLimit = info.mVisibleLimitDefault;\n}\n\n*\/\nint remoteStart = Math.max(0, remoteMessageCount - visibleLimit) + 1;\nint remoteEnd = remoteMessageCount;\nremoteMessages = remoteFolder.getMessages(remoteStart, remoteEnd, null);\nfor (Message message : remoteMessages) {\nremoteUidMap.put(message.getUid(), message);\n}\n\/*\n* Get a list of the messages that are in the remote list but not on the\n* local store, or messages that are in the local store but failed to download\n* on the last sync. These are the new messages that we will download.\n* Note, we also skip syncing messages which are flagged as \"deleted message\" sentinels,\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\n\n* because they are locally deleted and we don't need or want the old message from\n* the server.\n*\/\nfor (Message message : remoteMessages) {\nLocalMessageInfo localMessage = localMessageMap.get(message.getUid());\nif (localMessage == null) {\nnewMessageCount++;\n}\n\/\/ localMessage == null -> message has never been created (not even headers)\n\/\/ mFlagLoaded = UNLOADED -> message created, but none of body loaded\n\/\/ mFlagLoaded = PARTIAL -> message created, a \"sane\" amt of body has been loaded\n\/\/ mFlagLoaded = COMPLETE -> message body has been completely loaded\n\/\/ mFlagLoaded = DELETED -> message has been deleted\n\/\/ Only the first two of these are \"unsynced\", so let's retrieve them\nif (localMessage == null ||\n(localMessage.mFlagLoaded == EmailContent.Message.FLAG_LOADED_UNLOADED)) {\nunsyncedMessages.add(message);\n}\n}\n}\n\/\/ 8. Download basic info about the new\/unloaded messages (if any)\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\n\n\/*\n* A list of messages that were downloaded and which did not have the Seen flag set.\n* This will serve to indicate the true \"new\" message count that will be reported to\n* the user via notification.\n*\/\nfinal ArrayList<Message> newMessages = new ArrayList<Message>();\n\/*\n* Fetch the flags and envelope only of the new messages. This is intended to get us\n* critical data as fast as possible, and then we'll fill in the details.\n*\/\nif (unsyncedMessages.size() > 0) {\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n\nfp.add(FetchProfile.Item.ENVELOPE);\nfinal HashMap<String, LocalMessageInfo> localMapCopy =\nnew HashMap<String, LocalMessageInfo>(localMessageMap);\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n\nremoteFolder.fetch(unsyncedMessages.toArray(new Message[0]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\n\npublic void messageRetrieved(Message message) {\ntry {\n\/\/ Determine if the new message was already known (e.g. partial)\n\/\/ And create or reload the full message info\nLocalMessageInfo localMessageInfo =\nlocalMapCopy.get(message.getUid());\nEmailContent.Message localMessage = null;\nif (localMessageInfo == null) {\nlocalMessage = new EmailContent.Message();\n} else {\nlocalMessage = EmailContent.Message.restoreMessageWithId(\nmContext, localMessageInfo.mId);\n}\nif (localMessage != null) {\ntry {\n\/\/ Copy the fields that are available into the message\nLegacyConversions.updateMessageFields(localMessage,\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\n\nmessage, account.mId, folder.mId);\n\/\/ Commit the message to the local store\nsaveOrUpdate(localMessage);\n\/\/ Track the \"new\" ness of the downloaded message\nif (!message.isSet(Flag.SEEN)) {\nnewMessages.add(message);\n}\n} catch (MessagingException me) {\nLog.e(Email.LOG_TAG,\n\"Error while copying downloaded message.\" + me);\n}\n}\n}\ncatch (Exception e) {\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\n\nLog.e(Email.LOG_TAG,\n\"Error while storing downloaded message.\" + e.toString());\n}\n}\n});\n}\n\/\/ 9. Refresh the flags for any messages in the local store that we didn't just download.\nFetchProfile fp = new FetchProfile();\nfp.add(FetchProfile.Item.FLAGS);\nremoteFolder.fetch(remoteMessages, fp, null);\nboolean remoteSupportsSeen = false;\nboolean remoteSupportsFlagged = false;\nfor (Flag flag : remoteFolder.getPermanentFlags()) {\nif (flag == Flag.SEEN) {\nremoteSupportsSeen = true;\n}\nif (flag == Flag.FLAGGED) {\nremoteSupportsFlagged = true;\n}\n}\n\/\/ Update the SEEN & FLAGGED (star) flags (if supported remotely - e.g. not for POP3)\nif (remoteSupportsSeen || remoteSupportsFlagged) {\nfor (Message remoteMessage : remoteMessages) {\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\nboolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\nboolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n\nLocalMessageInfo localMessageInfo = localMessageMap.get(remoteMessage.getUid());\nif (localMessageInfo == null) {\ncontinue;\n}\nboolean localSeen = localMessageInfo.mFlagRead;\nboolean remoteSeen = remoteMessage.isSet(Flag.SEEN);\nboolean newSeen = (remoteSupportsSeen && (remoteSeen != localSeen));\nboolean localFlagged = localMessageInfo.mFlagFavorite;\nboolean remoteFlagged = remoteMessage.isSet(Flag.FLAGGED);\nboolean newFlagged = (remoteSupportsFlagged && (localFlagged != remoteFlagged));\nif (newSeen || newFlagged) {\nUri uri = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, localMessageInfo.mId);\nContentValues updateValues = new ContentValues();\nupdateValues.put(EmailContent.Message.FLAG_READ, remoteSeen);\nupdateValues.put(EmailContent.Message.FLAG_FAVORITE, remoteFlagged);\nresolver.update(uri, updateValues, null, null);\n}\n}\n}\n\/\/ 10. Compute and store the unread message count.\n\/\/ -- no longer necessary - Provider uses DB triggers to keep track\n\/\/ int remoteUnreadMessageCount = remoteFolder.getUnreadMessageCount();\n\/\/ if (remoteUnreadMessageCount == -1) {\n\/\/ if (remoteSupportsSeenFlag) {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count but supports\n\/\/ * seen flag, use local folder's unread message count and the size of\n\/\/ * new messages. This mode is not used for POP3, or IMAP.\n\/\/ *\/\n\/\/\n\/\/ remoteUnreadMessageCount = folder.mUnreadCount + newMessages.size();\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder doesn't supported unread message count and doesn't\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\n\/\/ * support seen flag, use localUnreadCount and newMessageCount which\n\/\/ * don't rely on remote SEEN flag. This mode is used by POP3.\n\/\/ *\/\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\n\n\/\/ remoteUnreadMessageCount = localUnreadCount + newMessageCount;\n\/\/ }\n\/\/ } else {\n\/\/ \/*\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\n\n\/\/ * If remote folder supports unread message count, use remoteUnreadMessageCount.\n\/\/ * This mode is used by IMAP.\n\/\/ *\/\n\/\/ }\n\/\/ Uri uri = ContentUris.withAppendedId(EmailContent.Mailbox.CONTENT_URI, folder.mId);\n\/\/ ContentValues updateValues = new ContentValues();\n\/\/ updateValues.put(EmailContent.Mailbox.UNREAD_COUNT, remoteUnreadMessageCount);\n\/\/ resolver.update(uri, updateValues, null, null);\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n\n\/\/ 11. Remove any messages that are in the local store but no longer on the remote store.\nHashSet<String> localUidsToDelete = new HashSet<String>(localMessageMap.keySet());\nlocalUidsToDelete.removeAll(remoteUidMap.keySet());\nfor (String uidToDelete : localUidsToDelete) {\nLocalMessageInfo infoToDelete = localMessageMap.get(uidToDelete);\n\/\/ Delete associated data (attachment files)\n\/\/ Attachment & Body records are auto-deleted when we delete the Message record\nAttachmentProvider.deleteAllAttachmentFiles(mContext, account.mId, infoToDelete.mId);\n\/\/ Delete the message itself\nUri uriToDelete = ContentUris.withAppendedId(\nEmailContent.Message.CONTENT_URI, infoToDelete.mId);\nresolver.delete(uriToDelete, null, null);\n\/\/ Delete extra rows (e.g. synced or deleted)\nUri syncRowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\n\nresolver.delete(syncRowToDelete, null, null);\nUri deletERowToDelete = ContentUris.withAppendedId(\nEmailContent.Message.UPDATED_CONTENT_URI, infoToDelete.mId);\nresolver.delete(deletERowToDelete, null, null);\n}\n\/\/ 12. Divide the unsynced messages into small & large (by size)\n\/\/ TODO doing this work here (synchronously) is problematic because it prevents the UI\n\/\/ from affecting the order (e.g. download a message because the user requested it.) Much\n\/\/ of this logic should move out to a different sync loop that attempts to update small\n\/\/ groups of messages at a time, as a background task. However, we can't just return\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\n\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\n\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\n\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\n\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\n\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\n\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/*\n* The provider was unable to get the structure of the message, so\n* we'll download a reasonable portion of the messge and mark it as\n* incomplete so the entire thing can be downloaded later if the user\n* wishes to download it.\n*\/\nfp.clear();\n\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/*\n* The provider was unable to get the structure of the message, so\n* we'll download a reasonable portion of the messge and mark it as\n* incomplete so the entire thing can be downloaded later if the user\n* wishes to download it.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/*\n* TODO a good optimization here would be to make sure that all Stores set\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\n\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\nif (visibleLimit <= 0) {\nStore.StoreInfo info = Store.StoreInfo.getStoreInfo(account.getStoreUri(mContext),\nmContext);\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\n\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\/\/ right now, attachments will be left for later.\nArrayList<Part> viewables = new ArrayList<Part>();\nArrayList<Part> attachments = new ArrayList<Part>();\nMimeUtility.collectParts(message, viewables, attachments);\n\/\/ Download the viewables immediately\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n}\n\/\/ 15. Clean up and report results\nremoteFolder.close(false);\n\/\/ TODO - more\n\/\/ Original sync code. Using for reference, will delete when done.\nif (false) {\n\/*\n* Now do the large messages that require more round trips.\n*\/\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]),\nfp, null);\nfor (Message message : largeMessages) {\n\n\/\/ (yet) because POP messages don't have an envelope yet....\nArrayList<Message> largeMessages = new ArrayList<Message>();\nArrayList<Message> smallMessages = new ArrayList<Message>();\nfor (Message message : unsyncedMessages) {\nif (message.getSize() > (MAX_SMALL_MESSAGE_SIZE)) {\nlargeMessages.add(message);\n} else {\nsmallMessages.add(message);\n}\n}\n\/\/ 13. Download small messages\n\/\/ TODO Problems with this implementation. 1. For IMAP, where we get a real envelope,\n\/\/ this is going to be inefficient and duplicate work we've already done. 2. It's going\n\/\/ back to the DB for a local message that we already had (and discarded).\n\/\/ For small messages, we specify \"body\", which returns everything (incl. attachments)\nfp = new FetchProfile();\nfp.add(FetchProfile.Item.BODY);\nremoteFolder.fetch(smallMessages.toArray(new Message[smallMessages.size()]), fp,\nnew MessageRetrievalListener() {\npublic void messageRetrieved(Message message) {\n\/\/ Store the updated message locally and mark it fully loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_COMPLETE);\n}\n});\n\/\/ 14. Download large messages. We ask the server to give us the message structure,\n\/\/ but not all of the attachments.\nfp.clear();\nfp.add(FetchProfile.Item.STRUCTURE);\nremoteFolder.fetch(largeMessages.toArray(new Message[largeMessages.size()]), fp, null);\nfor (Message message : largeMessages) {\nif (message.getBody() == null) {\n\/\/ POP doesn't support STRUCTURE mode, so we'll just do a partial download\n\/\/ (hopefully enough to see some\/all of the body) and mark the message for\n\/\/ further download.\nfp.clear();\nfp.add(FetchProfile.Item.BODY_SANE);\n\/\/ TODO a good optimization here would be to make sure that all Stores set\n\/\/ the proper size after this fetch and compare the before and after size. If\n\/\/ they equal we can mark this SYNCHRONIZED instead of PARTIALLY_SYNCHRONIZED\nremoteFolder.fetch(new Message[] { message }, fp, null);\n\/\/ Store the partially-loaded message and mark it partially loaded\ncopyOneMessageToProvider(message, account, folder,\nEmailContent.Message.FLAG_LOADED_PARTIAL);\n} else {\n\/\/ We have a structure to deal with, from which\n\/\/ we can pull down the parts we want to actually store.\n\/\/ Build a list of parts we are interested in. Text parts will be downloaded\n\nMimeUtility.collectParts(message, viewables, attachments);\n\/*\n* Now download the parts we're interested in storing.\n*\/\nfor (Part part : viewables) {\nfp.clear();\nfp.add(part);\n\/\/ TODO what happens if the network connection dies? We've got partial\n\/\/ messages with incorrect status stored.\nremoteFolder.fetch(new Message[] { message }, fp, null);\n}\n\/\/ Store the updated message locally\n\/\/ localFolder.appendMessages(new Message[] {\n\/\/ message\n\/\/ });\n\/\/ Message localMessage = localFolder.getMessage(message.getUid());\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}\n\nLocalMessageInfo info = new LocalMessageInfo(localUidCursor);\nlocalMessageMap.put(info.mServerId, info);\n}\n} finally {\nif (localUidCursor != null) {\nlocalUidCursor.close();\n}\n}\n\/\/ 1a. Count the unread messages before changing anything\nint localUnreadCount = EmailContent.count(mContext, EmailContent.Message.CONTENT_URI,\nEmailContent.MessageColumns.ACCOUNT_KEY + \"=?\" +\n\" AND \" + MessageColumns.MAILBOX_KEY + \"=?\" +\n\" AND \" + MessageColumns.FLAG_READ + \"=0\",\nnew String[] {\nString.valueOf(account.mId),\nString.valueOf(folder.mId)\n});\n\/\/ 2. Open the remote folder and create the remote folder if necessary\nStore remoteStore = Store.getInstance(account.getStoreUri(mContext), mContext, null);\nFolder remoteFolder = remoteStore.getFolder(folder.mDisplayName);\n\/*\n* If the folder is a \"special\" folder we need to see if it exists\n* on the remote server. It if does not exist we'll try to create it. If we\n* can't create we'll abort. This will happen on every single Pop3 folder as\n* designed and on Imap folders during error conditions. This allows us\n* to treat Pop3 and Imap the same in this code.\n*\/\nif (folder.mType == Mailbox.TYPE_TRASH || folder.mType == Mailbox.TYPE_SENT\n|| folder.mType == Mailbox.TYPE_DRAFTS) {\nif (!remoteFolder.exists()) {\nif (!remoteFolder.create(FolderType.HOLDS_MESSAGES)) {\nreturn new StoreSynchronizer.SyncResults(0, 0);\n}\n}\n}\n\/\/ 3, Open the remote folder. This pre-loads certain metadata like message count.\nremoteFolder.open(OpenMode.READ_WRITE, null);\n\/\/ 4. Trash any remote messages that are marked as trashed locally.\n\/\/ TODO - this comment was here, but no code was here.\n\/\/ 5. Get the remote message count.\nint remoteMessageCount = remoteFolder.getMessageCount();\n\/\/ 6. Determine the limit # of messages to download\nint visibleLimit = folder.mVisibleLimit;\n\n\/\/ Set a flag indicating this message has been fully downloaded and can be\n\/\/ viewed.\n\/\/ localMessage.setFlag(Flag.X_DOWNLOADED_FULL, true);\n}\n\/\/ Update the listener with what we've found\n\/\/ synchronized (mListeners) {\n\/\/ for (MessagingListener l : mListeners) {\n\/\/ l.synchronizeMailboxNewMessage(\n\/\/ account,\n\/\/ folder,\n\/\/ localFolder.getMessage(message.getUid()));\n\/\/ }\n\/\/ }\n}\n\/*\n* Report successful sync\n*\/\nStoreSynchronizer.SyncResults results = new StoreSynchronizer.SyncResults(\nremoteFolder.getMessageCount(), newMessages.size());\nremoteFolder.close(false);\n\/\/ localFolder.close(false);\nreturn results;\n}\nreturn new StoreSynchronizer.SyncResults(remoteMessageCount, newMessages.size());\n}","label":[1,1,1,0]}
{"id":15705,"original_code":"private void processPendingMoveToTrash(Store remoteStore,\n            EmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\n            final EmailContent.Message newMessage) throws MessagingException {\n        \/\/ 0. No remote move if the message is local-only\n        if (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n                || newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\n            return;\n        }\n        \/\/ 1. Escape early if we can't find the local mailbox\n        \/\/ TODO smaller projection here\n        Mailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\n        if (oldMailbox == null) {\n            \/\/ can't find old mailbox, it may have been deleted.  just return.\n            return;\n        }\n        \/\/ 2. We don't support delete-from-trash here\n        if (oldMailbox.mType == Mailbox.TYPE_TRASH) {\n            return;\n        }\n        \/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n        \/\/\n        \/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n        \/\/ by inhibiting future sync or display of the message.  It will eventually go out of\n        \/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n        \/\/ will clean it up for us.\n        if (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\n            EmailContent.Message sentinel = new EmailContent.Message();\n            sentinel.mAccountKey = oldMessage.mAccountKey;\n            sentinel.mMailboxKey = oldMessage.mMailboxKey;\n            sentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\n            sentinel.mFlagRead = true;\n            sentinel.mServerId = oldMessage.mServerId;\n            sentinel.save(mContext);\n            return;\n        }\n        \/\/ The rest of this method handles server-side deletion\n        \/\/ 4.  Find the remote mailbox (that we deleted from), and open it\n        Folder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\n        if (!remoteFolder.exists()) {\n            return;\n        }\n        remoteFolder.open(OpenMode.READ_WRITE, null);\n        if (remoteFolder.getMode() != OpenMode.READ_WRITE) {\n            remoteFolder.close(false);\n            return;\n        }\n        \/\/ 5. Find the remote original message\n        Message remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\n        if (remoteMessage == null) {\n            remoteFolder.close(false);\n            return;\n        }\n        \/\/ 6. Find the remote trash folder, and create it if not found\n        Folder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\n        if (!remoteTrashFolder.exists()) {\n            \/*\n             * If the remote trash folder doesn't exist we try to create it.\n             *\/\n            remoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n        }\n        \/\/ 7.  Try to copy the message into the remote trash folder\n        \/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\n        if (remoteTrashFolder.exists()) {\n            \/*\n             * Because remoteTrashFolder may be new, we need to explicitly open it\n             *\/\n            remoteTrashFolder.open(OpenMode.READ_WRITE, null);\n            if (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\n                remoteFolder.close(false);\n                remoteTrashFolder.close(false);\n                return;\n            }\n            remoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\n                    new Folder.MessageUpdateCallbacks() {\n                public void onMessageUidChange(Message message, String newUid) {\n                    \/\/ update the UID in the local trash folder, because some stores will\n                    \/\/ have to change it when copying to remoteTrashFolder\n                    ContentValues cv = new ContentValues();\n                    cv.put(EmailContent.Message.SERVER_ID, newUid);\n                    mContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n                }\n                \/**\n                 * This will be called if the deleted message doesn't exist and can't be\n                 * deleted (e.g. it was already deleted from the server.)  In this case,\n                 * attempt to delete the local copy as well.\n                 *\/\n                public void onMessageNotFound(Message message) {\n                    mContext.getContentResolver().delete(newMessage.getUri(), null, null);\n                }\n            }\n            );\n            remoteTrashFolder.close(false);\n        }\n        \/\/ 8. Delete the message from the remote source folder\n        remoteMessage.setFlag(Flag.DELETED, true);\n        remoteFolder.expunge();\n        remoteFolder.close(false);\n    }","code":"private void processPendingMoveToTrash(Store remoteStore,\n            EmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\n            final EmailContent.Message newMessage) throws MessagingException {\n       \n        if (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n                || newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\n            return;\n        }\n       \n       \n        Mailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\n        if (oldMailbox == null) {\n           \n            return;\n        }\n       \n        if (oldMailbox.mType == Mailbox.TYPE_TRASH) {\n            return;\n        }\n       \n       \n       \n       \n       \n       \n        if (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\n            EmailContent.Message sentinel = new EmailContent.Message();\n            sentinel.mAccountKey = oldMessage.mAccountKey;\n            sentinel.mMailboxKey = oldMessage.mMailboxKey;\n            sentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\n            sentinel.mFlagRead = true;\n            sentinel.mServerId = oldMessage.mServerId;\n            sentinel.save(mContext);\n            return;\n        }\n       \n       \n        Folder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\n        if (!remoteFolder.exists()) {\n            return;\n        }\n        remoteFolder.open(OpenMode.READ_WRITE, null);\n        if (remoteFolder.getMode() != OpenMode.READ_WRITE) {\n            remoteFolder.close(false);\n            return;\n        }\n       \n        Message remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\n        if (remoteMessage == null) {\n            remoteFolder.close(false);\n            return;\n        }\n       \n        Folder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\n        if (!remoteTrashFolder.exists()) {\n           \n            remoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n        }\n       \n       \n        if (remoteTrashFolder.exists()) {\n           \n            remoteTrashFolder.open(OpenMode.READ_WRITE, null);\n            if (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\n                remoteFolder.close(false);\n                remoteTrashFolder.close(false);\n                return;\n            }\n            remoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\n                    new Folder.MessageUpdateCallbacks() {\n                public void onMessageUidChange(Message message, String newUid) {\n                   \n                   \n                    ContentValues cv = new ContentValues();\n                    cv.put(EmailContent.Message.SERVER_ID, newUid);\n                    mContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n                }\n               \n                public void onMessageNotFound(Message message) {\n                    mContext.getContentResolver().delete(newMessage.getUri(), null, null);\n                }\n            }\n            );\n            remoteTrashFolder.close(false);\n        }\n       \n        remoteMessage.setFlag(Flag.DELETED, true);\n        remoteFolder.expunge();\n        remoteFolder.close(false);\n    }","cleancode":"private void processpendingmovetotrash(store remotestore, emailcontent.account account, mailbox newmailbox, emailcontent.message oldmessage, final emailcontent.message newmessage) throws messagingexception { if (newmessage.mserverid == null || newmessage.mserverid.equals(\"\") || newmessage.mserverid.startswith(local_serverid_prefix)) { return; } mailbox oldmailbox = mailbox.restoremailboxwithid(mcontext, oldmessage.mmailboxkey); if (oldmailbox == null) { return; } if (oldmailbox.mtype == mailbox.type_trash) { return; } if (account.getdeletepolicy() == account.delete_policy_never) { emailcontent.message sentinel = new emailcontent.message(); sentinel.maccountkey = oldmessage.maccountkey; sentinel.mmailboxkey = oldmessage.mmailboxkey; sentinel.mflagloaded = emailcontent.message.flag_loaded_deleted; sentinel.mflagread = true; sentinel.mserverid = oldmessage.mserverid; sentinel.save(mcontext); return; } folder remotefolder = remotestore.getfolder(oldmailbox.mdisplayname); if (!remotefolder.exists()) { return; } remotefolder.open(openmode.read_write, null); if (remotefolder.getmode() != openmode.read_write) { remotefolder.close(false); return; } message remotemessage = remotefolder.getmessage(oldmessage.mserverid); if (remotemessage == null) { remotefolder.close(false); return; } folder remotetrashfolder = remotestore.getfolder(newmailbox.mdisplayname); if (!remotetrashfolder.exists()) { remotetrashfolder.create(foldertype.holds_messages); } if (remotetrashfolder.exists()) { remotetrashfolder.open(openmode.read_write, null); if (remotetrashfolder.getmode() != openmode.read_write) { remotefolder.close(false); remotetrashfolder.close(false); return; } remotefolder.copymessages(new message[] { remotemessage }, remotetrashfolder, new folder.messageupdatecallbacks() { public void onmessageuidchange(message message, string newuid) { contentvalues cv = new contentvalues(); cv.put(emailcontent.message.server_id, newuid); mcontext.getcontentresolver().update(newmessage.geturi(), cv, null, null); } public void onmessagenotfound(message message) { mcontext.getcontentresolver().delete(newmessage.geturi(), null, null); } } ); remotetrashfolder.close(false); } remotemessage.setflag(flag.deleted, true); remotefolder.expunge(); remotefolder.close(false); }","comment":"\/** * process a pending trash message command. * * @param remotestore the remote store we're working in * @param account the account in which we are working * @param newmailbox the local trash mailbox * @param oldmessage the message copy that was saved in the updates shadow table * @param newmessage the message that was moved to the mailbox *\/\n\/\/ 0. no remote move if the message is local-only\n\/\/ 1. escape early if we can't find the local mailbox \/\/ todo smaller projection here\n\/\/ can't find old mailbox, it may have been deleted. just return.\n\/\/ 2. we don't support delete-from-trash here\n\/\/ 3. if delete_policy_never, simply write back the deleted sentinel and return \/\/ \/\/ this sentinel takes the place of the server-side message, and locally \"deletes\" it \/\/ by inhibiting future sync or display of the message. it will eventually go out of \/\/ scope when it becomes old, or is deleted on the server, and the regular sync code \/\/ will clean it up for us.\n\/\/ the rest of this method handles server-side deletion \/\/ 4. find the remote mailbox (that we deleted from), and open it\n\/\/ 5. find the remote original message\n\/\/ 6. find the remote trash folder, and create it if not found\n\/* * if the remote trash folder doesn't exist we try to create it. *\/\n\/\/ 7. try to copy the message into the remote trash folder \/\/ note, this entire section will be skipped for pop3 because there's no remote trash\n\/* * because remotetrashfolder may be new, we need to explicitly open it *\/\n\/\/ update the uid in the local trash folder, because some stores will \/\/ have to change it when copying to remotetrashfolder\n\/** * this will be called if the deleted message doesn't exist and can't be * deleted (e.g. it was already deleted from the server.) in this case, * attempt to delete the local copy as well. *\/\n\/\/ 8. delete the message from the remote source folder","repo":"xie-wenjie\/AndroidBaseApplicationSourse","code_context_2":"private void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}\n\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\n\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\n\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\n\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\n\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\n\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();","code_context_10":"private void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\n\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\n\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\n\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\n\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\n\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\n\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\n\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}","code_context_20":"private void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\nprivate void processPendingMoveToTrash(Store remoteStore,\nEmailContent.Account account, Mailbox newMailbox, EmailContent.Message oldMessage,\nfinal EmailContent.Message newMessage) throws MessagingException {\n\/\/ 0. No remote move if the message is local-only\nif (newMessage.mServerId == null || newMessage.mServerId.equals(\"\")\n|| newMessage.mServerId.startsWith(LOCAL_SERVERID_PREFIX)) {\nreturn;\n}\n\/\/ 1. Escape early if we can't find the local mailbox\n\/\/ TODO smaller projection here\nMailbox oldMailbox = Mailbox.restoreMailboxWithId(mContext, oldMessage.mMailboxKey);\nif (oldMailbox == null) {\n\/\/ can't find old mailbox, it may have been deleted. just return.\nreturn;\n}\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n\n\/\/ 2. We don't support delete-from-trash here\nif (oldMailbox.mType == Mailbox.TYPE_TRASH) {\nreturn;\n}\n\/\/ 3. If DELETE_POLICY_NEVER, simply write back the deleted sentinel and return\n\/\/\n\/\/ This sentinel takes the place of the server-side message, and locally \"deletes\" it\n\/\/ by inhibiting future sync or display of the message. It will eventually go out of\n\/\/ scope when it becomes old, or is deleted on the server, and the regular sync code\n\/\/ will clean it up for us.\nif (account.getDeletePolicy() == Account.DELETE_POLICY_NEVER) {\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n\nEmailContent.Message sentinel = new EmailContent.Message();\nsentinel.mAccountKey = oldMessage.mAccountKey;\nsentinel.mMailboxKey = oldMessage.mMailboxKey;\nsentinel.mFlagLoaded = EmailContent.Message.FLAG_LOADED_DELETED;\nsentinel.mFlagRead = true;\nsentinel.mServerId = oldMessage.mServerId;\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\n\nsentinel.save(mContext);\nreturn;\n}\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\n\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\n\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n\n\/\/ The rest of this method handles server-side deletion\n\/\/ 4. Find the remote mailbox (that we deleted from), and open it\nFolder remoteFolder = remoteStore.getFolder(oldMailbox.mDisplayName);\nif (!remoteFolder.exists()) {\nreturn;\n}\nremoteFolder.open(OpenMode.READ_WRITE, null);\nif (remoteFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 5. Find the remote original message\nMessage remoteMessage = remoteFolder.getMessage(oldMessage.mServerId);\nif (remoteMessage == null) {\nremoteFolder.close(false);\nreturn;\n}\n\/\/ 6. Find the remote trash folder, and create it if not found\nFolder remoteTrashFolder = remoteStore.getFolder(newMailbox.mDisplayName);\nif (!remoteTrashFolder.exists()) {\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\n\n\/*\n* If the remote trash folder doesn't exist we try to create it.\n*\/\nremoteTrashFolder.create(FolderType.HOLDS_MESSAGES);\n}\n\/\/ 7. Try to copy the message into the remote trash folder\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n\n\/\/ Note, this entire section will be skipped for POP3 because there's no remote trash\nif (remoteTrashFolder.exists()) {\n\/*\n* Because remoteTrashFolder may be new, we need to explicitly open it\n*\/\nremoteTrashFolder.open(OpenMode.READ_WRITE, null);\nif (remoteTrashFolder.getMode() != OpenMode.READ_WRITE) {\nremoteFolder.close(false);\nremoteTrashFolder.close(false);\nreturn;\n}\nremoteFolder.copyMessages(new Message[] { remoteMessage }, remoteTrashFolder,\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}\n\nnew Folder.MessageUpdateCallbacks() {\npublic void onMessageUidChange(Message message, String newUid) {\n\/\/ update the UID in the local trash folder, because some stores will\n\/\/ have to change it when copying to remoteTrashFolder\nContentValues cv = new ContentValues();\ncv.put(EmailContent.Message.SERVER_ID, newUid);\nmContext.getContentResolver().update(newMessage.getUri(), cv, null, null);\n}\n\/**\n* This will be called if the deleted message doesn't exist and can't be\n* deleted (e.g. it was already deleted from the server.) In this case,\n* attempt to delete the local copy as well.\n*\/\npublic void onMessageNotFound(Message message) {\nmContext.getContentResolver().delete(newMessage.getUri(), null, null);\n}\n}\n);\nremoteTrashFolder.close(false);\n}\n\/\/ 8. Delete the message from the remote source folder\nremoteMessage.setFlag(Flag.DELETED, true);\nremoteFolder.expunge();\nremoteFolder.close(false);\n}","label":[0,1,0,0]}
{"id":32108,"original_code":"private static boolean step(int faceIndex) {\n\t\tTriangle t = faces.get(faceIndex);\n\t\t\/\/ 2. Get most distant point of the face's point set\n\t\tVector3f furthestPoint = null;\n\t\tint furthestPointID = -1;\n\t\tVector3f A = vertices.get(t.a);\n\t\tList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\n\t\tfloat distance = 0;\n\t\tfor (int i = 0; i < facepoints.size(); i++) {\n\t\t\tVector3f P = facepoints.get(i);\n\t\t\tfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\n\t\t\tif (dist >= distance) {\n\t\t\t\tdistance = dist;\n\t\t\t\tfurthestPoint = P;\n\t\t\t\tfurthestPointID = i;\n\t\t\t}\n\t\t}\n\t\tif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\n\t\t\treturn true;\n\t\t}\n\t\tfacepoints.remove(furthestPointID);\n\t\tvertices.add(furthestPoint);\n\t\tfurthestPointID = vertices.size() - 1;\n\t\tlastremovedTriangles.clear();\n\t\tlastremovedTriangles.add(faces.remove(faceIndex));\n\t\tlistsOfFacePoints.remove(faceIndex);\n\t\t\/\/ 3. Find all faces that can be seen from this point\n\t\tHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\n\t\tlightFaceVertices.add(t.a);\n\t\tlightFaceVertices.add(t.b);\n\t\tlightFaceVertices.add(t.c);\n\t\tList<Triangle> vertsA = new ArrayList<Triangle>();\n\t\tList<Triangle> vertsB = new ArrayList<Triangle>();\n\t\tList<Triangle> vertsC = new ArrayList<Triangle>();\n\t\tvertsA.add(t);\n\t\tvertsB.add(t);\n\t\tvertsC.add(t);\n\t\tlightFaceVerticesToTriangles.clear();\n\t\tlightFaceVerticesToTriangles.put(t.a, vertsA);\n\t\tlightFaceVerticesToTriangles.put(t.b, vertsB);\n\t\tlightFaceVerticesToTriangles.put(t.c, vertsC);\n\t\tfor (int i = faces.size() - 1; i >= 0; i--) {\n\t\t\tTriangle tri = faces.get(i);\n\t\t\tVector3f triA = vertices.get(tri.a);\n\t\t\tif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\n\t\t\t\tlastremovedTriangles.add(faces.remove(i));\n\t\t\t\tlightFaceVertices.add(tri.a);\n\t\t\t\tlightFaceVertices.add(tri.b);\n\t\t\t\tlightFaceVertices.add(tri.c);\n\t\t\t\tif ((vertsA = lightFaceVerticesToTriangles.get(tri.a)) != null) {\n\t\t\t\t\tvertsA.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsA = new ArrayList<Triangle>();\n\t\t\t\t\tvertsA.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.a, vertsA);\n\t\t\t\t}\n\t\t\t\tif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\n\t\t\t\t\tvertsB.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsB = new ArrayList<Triangle>();\n\t\t\t\t\tvertsB.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.b, vertsB);\n\t\t\t\t}\n\t\t\t\tif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\n\t\t\t\t\tvertsC.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsC = new ArrayList<Triangle>();\n\t\t\t\t\tvertsC.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.c, vertsC);\n\t\t\t\t}\n\t\t\t\tfacepoints.addAll(listsOfFacePoints.remove(i));\n\t\t\t}\n\t\t}\n\t\t\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\n\t\tIterator<Integer> iter = lightFaceVertices.iterator();\n\t\ttoRemove.clear();\n\t\tfor (int i = 0; i < lightFaceVertices.size(); i++) {\n\t\t\tint vert = iter.next(); \/\/ TODO: check\n\t\t\tif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\n\t\t\t\ttoRemove.add(vert);\n\t\t\t}\n\t\t}\n\t\tfor (Integer i : toRemove) {\n\t\t\tfor (Integer adj : adjacentsMap.get(i)) {\n\t\t\t\tadjacentsMap.get(adj).remove(i);\n\t\t\t\ttmppair.set(i, adj);\n\t\t\t\tedgesToTriangles.remove(tmppair);\n\t\t\t}\n\t\t\tlightFaceVertices.remove((int) i);\n\t\t\tvertices.set((int) i, null);\n\t\t\tfreeVertexPositions.add(i);\n\t\t}\n\t\t\/\/ 4.1 Get vertices on border between lit and unlit triangles\n\t\tHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\n\t\tfor (Integer vert : lightFaceVertices) {\n\t\t\tvertsOnEdge.add(vert);\n\t\t}\n\t\t\/\/ 4.2 Get edges on border\n\t\tint currentVert = vertsOnEdge.iterator().next();\n\t\tedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\n\t\tfor (int i = 0; i < vertsOnEdge.size(); i++) {\n\t\t\tedge.add(currentVert);\n\t\t\tArrayList<Integer> adjs = adjacentsMap.get(currentVert);\n\t\t\tList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\n\t\t\tfor (int j = 0; j < adjs.size(); j++) {\n\t\t\t\tInteger currAdj = adjs.get(j);\n\t\t\t\tif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\n\t\t\t\t\tint tricount = 0;\n\t\t\t\t\tfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\n\t\t\t\t\t\tTriangle kTri = vertexLightTriangles.get(k);\n\t\t\t\t\t\tif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\n\t\t\t\t\t\t\ttricount++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (tricount == 1) {\n\t\t\t\t\t\tcurrentVert = currAdj;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\n\t\tint edgesize = edge.size();\n\t\tint edgesizeMinusOne = edgesize - 1;\n\t\tfor (int i = 0; i < edgesize; i++) {\n\t\t\tcurrentVert = edge.get(i);\n\t\t\tremoveAdj.clear();\n\t\t\tfor (Integer adj : adjacentsMap.get(currentVert)) {\n\t\t\t\tif (edge.contains(adj)) {\n\t\t\t\t\tint adjIndexOnEdge = edge.indexOf(adj);\n\t\t\t\t\tif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n\t\t\t\t\t\t\t&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\n\t\t\t\t\t\ttmppair.set(currentVert, adj);\n\t\t\t\t\t\tPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\t\t\t\t\t\t\/\/ TODO: performance\n\t\t\t\t\t\tif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n\t\t\t\t\t\t\t\t&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\n\t\t\t\t\t\t\tremoveAdj.add(adj);\n\t\t\t\t\t\t\tedgesToTriangles.remove(edgeTriangles);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\n\t\t\t\tadjacentsMap.get(currentVert).remove(removAdjacent);\n\t\t\t}\n\t\t}\n\t\t\/\/ 4.3 Stitch holes using edge\n\t\tnewLightFaces.clear();\n\t\tArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\n\t\tA = vertices.get(edge.get(0));\n\t\tVector3f B = vertices.get(edge.get(1));\n\t\tVector3f C = vertices.get(edge.get(2));\n\t\tfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\n\t\t\tC = vertices.get(edge.get(i));\n\t\t}\n\t\tVector3f normal = VecMath.computeNormal(A, B, C);\n\t\tboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\n\t\tint vertIDb = edge.get(0);\n\t\tfor (int i = 0; i < edge.size(); i++) {\n\t\t\tint vertIDa = vertIDb;\n\t\t\tif (i < edge.size() - 1) {\n\t\t\t\tvertIDb = edge.get(i + 1);\n\t\t\t} else {\n\t\t\t\tvertIDb = edge.get(0);\n\t\t\t}\n\t\t\tVector3f vA = vertices.get(vertIDa);\n\t\t\tVector3f vB = vertices.get(vertIDb);\n\t\t\tVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\n\t\t\tTriangle stitchTriangle;\n\t\t\tif (correctOrientation) {\n\t\t\t\tstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n\t\t\t} else {\n\t\t\t\tnorm.negate();\n\t\t\t\tstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n\t\t\t}\n\t\t\tfaces.add(0, stitchTriangle);\n\t\t\tnewLightFaces.add(stitchTriangle);\n\t\t\t\/\/ Update adjacents map\n\t\t\tadjacentsMap.get(vertIDa).add(furthestPointID);\n\t\t\ttmppair.set(vertIDa, vertIDb);\n\t\t\tPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\t\/\/ find out which triangle got deleted\n\t\t\tif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\n\t\t\t\toldEdgeInfo.setFirst(stitchTriangle);\n\t\t\t} else {\n\t\t\t\toldEdgeInfo.setSecond(stitchTriangle);\n\t\t\t}\n\t\t\ttmppair.set(vertIDa, furthestPointID);\n\t\t\toldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\tif (oldEdgeInfo != null) {\n\t\t\t\toldEdgeInfo.setSecond(stitchTriangle);\n\t\t\t} else {\n\t\t\t\t\/\/ TODO: just relevant for first iteration, move before loop\n\t\t\t\tedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\n\t\t\t\t\t\tnew Pair<Triangle, Triangle>(null, stitchTriangle));\n\t\t\t}\n\t\t\ttmppair.set(vertIDb, furthestPointID);\n\t\t\toldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\tif (oldEdgeInfo != null) {\n\t\t\t\t\/\/ TODO: just relevant for last iteration\n\t\t\t\toldEdgeInfo.setFirst(stitchTriangle);\n\t\t\t} else {\n\t\t\t\tedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\n\t\t\t\t\t\tnew Pair<Triangle, Triangle>(stitchTriangle, null));\n\t\t\t}\n\t\t\tfurthestPointNeighbours.add(vertIDa);\n\t\t}\n\t\t\/\/ 5. Assign all points of all light-faces to the new created faces\n\t\tadjacentsMap.put(furthestPointID, furthestPointNeighbours);\n\t\tfor (Triangle tri : newLightFaces) {\n\t\t\tlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n\t\t}\n\t\t\/\/ 6. Push new created faces on the stack and start at (1))\n\t\treturn false;\n\t}","code":"private static boolean step(int faceIndex) {\n\t\tTriangle t = faces.get(faceIndex);\n\t\n\t\tVector3f furthestPoint = null;\n\t\tint furthestPointID = -1;\n\t\tVector3f A = vertices.get(t.a);\n\t\tList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\n\t\tfloat distance = 0;\n\t\tfor (int i = 0; i < facepoints.size(); i++) {\n\t\t\tVector3f P = facepoints.get(i);\n\t\t\tfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\n\t\t\tif (dist >= distance) {\n\t\t\t\tdistance = dist;\n\t\t\t\tfurthestPoint = P;\n\t\t\t\tfurthestPointID = i;\n\t\t\t}\n\t\t}\n\t\tif (furthestPointID == -1 || vertices.contains(furthestPoint)) {\n\t\t\treturn true;\n\t\t}\n\t\tfacepoints.remove(furthestPointID);\n\t\tvertices.add(furthestPoint);\n\t\tfurthestPointID = vertices.size() - 1;\n\t\tlastremovedTriangles.clear();\n\t\tlastremovedTriangles.add(faces.remove(faceIndex));\n\t\tlistsOfFacePoints.remove(faceIndex);\n\t\n\t\tHashSet<Integer> lightFaceVertices = new HashSet<Integer>();\n\t\tlightFaceVertices.add(t.a);\n\t\tlightFaceVertices.add(t.b);\n\t\tlightFaceVertices.add(t.c);\n\t\tList<Triangle> vertsA = new ArrayList<Triangle>();\n\t\tList<Triangle> vertsB = new ArrayList<Triangle>();\n\t\tList<Triangle> vertsC = new ArrayList<Triangle>();\n\t\tvertsA.add(t);\n\t\tvertsB.add(t);\n\t\tvertsC.add(t);\n\t\tlightFaceVerticesToTriangles.clear();\n\t\tlightFaceVerticesToTriangles.put(t.a, vertsA);\n\t\tlightFaceVerticesToTriangles.put(t.b, vertsB);\n\t\tlightFaceVerticesToTriangles.put(t.c, vertsC);\n\t\tfor (int i = faces.size() - 1; i >= 0; i--) {\n\t\t\tTriangle tri = faces.get(i);\n\t\t\tVector3f triA = vertices.get(tri.a);\n\t\t\tif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\n\t\t\t\tlastremovedTriangles.add(faces.remove(i));\n\t\t\t\tlightFaceVertices.add(tri.a);\n\t\t\t\tlightFaceVertices.add(tri.b);\n\t\t\t\tlightFaceVertices.add(tri.c);\n\t\t\t\tif ((vertsA = lightFaceVerticesToTriangles.get(tri.a)) != null) {\n\t\t\t\t\tvertsA.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsA = new ArrayList<Triangle>();\n\t\t\t\t\tvertsA.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.a, vertsA);\n\t\t\t\t}\n\t\t\t\tif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\n\t\t\t\t\tvertsB.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsB = new ArrayList<Triangle>();\n\t\t\t\t\tvertsB.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.b, vertsB);\n\t\t\t\t}\n\t\t\t\tif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\n\t\t\t\t\tvertsC.add(tri);\n\t\t\t\t} else {\n\t\t\t\t\tvertsC = new ArrayList<Triangle>();\n\t\t\t\t\tvertsC.add(tri);\n\t\t\t\t\tlightFaceVerticesToTriangles.put(tri.c, vertsC);\n\t\t\t\t}\n\t\t\t\tfacepoints.addAll(listsOfFacePoints.remove(i));\n\t\t\t}\n\t\t}\n\t\n\t\tIterator<Integer> iter = lightFaceVertices.iterator();\n\t\ttoRemove.clear();\n\t\tfor (int i = 0; i < lightFaceVertices.size(); i++) {\n\t\t\tint vert = iter.next();\n\t\t\tif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\n\t\t\t\ttoRemove.add(vert);\n\t\t\t}\n\t\t}\n\t\tfor (Integer i : toRemove) {\n\t\t\tfor (Integer adj : adjacentsMap.get(i)) {\n\t\t\t\tadjacentsMap.get(adj).remove(i);\n\t\t\t\ttmppair.set(i, adj);\n\t\t\t\tedgesToTriangles.remove(tmppair);\n\t\t\t}\n\t\t\tlightFaceVertices.remove((int) i);\n\t\t\tvertices.set((int) i, null);\n\t\t\tfreeVertexPositions.add(i);\n\t\t}\n\t\n\t\tHashSet<Integer> vertsOnEdge = new HashSet<Integer>();\n\t\tfor (Integer vert : lightFaceVertices) {\n\t\t\tvertsOnEdge.add(vert);\n\t\t}\n\t\n\t\tint currentVert = vertsOnEdge.iterator().next();\n\t\tedge.clear();\n\t\tfor (int i = 0; i < vertsOnEdge.size(); i++) {\n\t\t\tedge.add(currentVert);\n\t\t\tArrayList<Integer> adjs = adjacentsMap.get(currentVert);\n\t\t\tList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\n\t\t\tfor (int j = 0; j < adjs.size(); j++) {\n\t\t\t\tInteger currAdj = adjs.get(j);\n\t\t\t\tif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\n\t\t\t\t\tint tricount = 0;\n\t\t\t\t\tfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\n\t\t\t\t\t\tTriangle kTri = vertexLightTriangles.get(k);\n\t\t\t\t\t\tif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\n\t\t\t\t\t\t\ttricount++;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tif (tricount == 1) {\n\t\t\t\t\t\tcurrentVert = currAdj;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\n\t\tint edgesize = edge.size();\n\t\tint edgesizeMinusOne = edgesize - 1;\n\t\tfor (int i = 0; i < edgesize; i++) {\n\t\t\tcurrentVert = edge.get(i);\n\t\t\tremoveAdj.clear();\n\t\t\tfor (Integer adj : adjacentsMap.get(currentVert)) {\n\t\t\t\tif (edge.contains(adj)) {\n\t\t\t\t\tint adjIndexOnEdge = edge.indexOf(adj);\n\t\t\t\t\tif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n\t\t\t\t\t\t\t&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\n\t\t\t\t\t\ttmppair.set(currentVert, adj);\n\t\t\t\t\t\tPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\t\t\t\t\t\n\t\t\t\t\t\tif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n\t\t\t\t\t\t\t\t&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\n\t\t\t\t\t\t\tremoveAdj.add(adj);\n\t\t\t\t\t\t\tedgesToTriangles.remove(edgeTriangles);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (Integer removAdjacent : removeAdj) {\n\t\t\t\tadjacentsMap.get(currentVert).remove(removAdjacent);\n\t\t\t}\n\t\t}\n\t\n\t\tnewLightFaces.clear();\n\t\tArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\n\t\tA = vertices.get(edge.get(0));\n\t\tVector3f B = vertices.get(edge.get(1));\n\t\tVector3f C = vertices.get(edge.get(2));\n\t\tfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\n\t\t\tC = vertices.get(edge.get(i));\n\t\t}\n\t\tVector3f normal = VecMath.computeNormal(A, B, C);\n\t\tboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\n\t\tint vertIDb = edge.get(0);\n\t\tfor (int i = 0; i < edge.size(); i++) {\n\t\t\tint vertIDa = vertIDb;\n\t\t\tif (i < edge.size() - 1) {\n\t\t\t\tvertIDb = edge.get(i + 1);\n\t\t\t} else {\n\t\t\t\tvertIDb = edge.get(0);\n\t\t\t}\n\t\t\tVector3f vA = vertices.get(vertIDa);\n\t\t\tVector3f vB = vertices.get(vertIDb);\n\t\t\tVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\n\t\t\tTriangle stitchTriangle;\n\t\t\tif (correctOrientation) {\n\t\t\t\tstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n\t\t\t} else {\n\t\t\t\tnorm.negate();\n\t\t\t\tstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n\t\t\t}\n\t\t\tfaces.add(0, stitchTriangle);\n\t\t\tnewLightFaces.add(stitchTriangle);\n\t\t\n\t\t\tadjacentsMap.get(vertIDa).add(furthestPointID);\n\t\t\ttmppair.set(vertIDa, vertIDb);\n\t\t\tPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\n\t\t\tif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\n\t\t\t\toldEdgeInfo.setFirst(stitchTriangle);\n\t\t\t} else {\n\t\t\t\toldEdgeInfo.setSecond(stitchTriangle);\n\t\t\t}\n\t\t\ttmppair.set(vertIDa, furthestPointID);\n\t\t\toldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\tif (oldEdgeInfo != null) {\n\t\t\t\toldEdgeInfo.setSecond(stitchTriangle);\n\t\t\t} else {\n\t\t\t\n\t\t\t\tedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\n\t\t\t\t\t\tnew Pair<Triangle, Triangle>(null, stitchTriangle));\n\t\t\t}\n\t\t\ttmppair.set(vertIDb, furthestPointID);\n\t\t\toldEdgeInfo = edgesToTriangles.get(tmppair);\n\t\t\tif (oldEdgeInfo != null) {\n\t\t\t\n\t\t\t\toldEdgeInfo.setFirst(stitchTriangle);\n\t\t\t} else {\n\t\t\t\tedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\n\t\t\t\t\t\tnew Pair<Triangle, Triangle>(stitchTriangle, null));\n\t\t\t}\n\t\t\tfurthestPointNeighbours.add(vertIDa);\n\t\t}\n\t\n\t\tadjacentsMap.put(furthestPointID, furthestPointNeighbours);\n\t\tfor (Triangle tri : newLightFaces) {\n\t\t\tlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n\t\t}\n\t\n\t\treturn false;\n\t}","cleancode":"private static boolean step(int faceindex) { triangle t = faces.get(faceindex); vector3f furthestpoint = null; int furthestpointid = -1; vector3f a = vertices.get(t.a); list<vector3f> facepoints = listsoffacepoints.get(faceindex); float distance = 0; for (int i = 0; i < facepoints.size(); i++) { vector3f p = facepoints.get(i); float dist = vecmath.dotproduct(vecmath.subtraction(p, a, tmpvec), t.normal); if (dist >= distance) { distance = dist; furthestpoint = p; furthestpointid = i; } } if (furthestpointid == -1 || vertices.contains(furthestpoint)) { return true; } facepoints.remove(furthestpointid); vertices.add(furthestpoint); furthestpointid = vertices.size() - 1; lastremovedtriangles.clear(); lastremovedtriangles.add(faces.remove(faceindex)); listsoffacepoints.remove(faceindex); hashset<integer> lightfacevertices = new hashset<integer>(); lightfacevertices.add(t.a); lightfacevertices.add(t.b); lightfacevertices.add(t.c); list<triangle> vertsa = new arraylist<triangle>(); list<triangle> vertsb = new arraylist<triangle>(); list<triangle> vertsc = new arraylist<triangle>(); vertsa.add(t); vertsb.add(t); vertsc.add(t); lightfaceverticestotriangles.clear(); lightfaceverticestotriangles.put(t.a, vertsa); lightfaceverticestotriangles.put(t.b, vertsb); lightfaceverticestotriangles.put(t.c, vertsc); for (int i = faces.size() - 1; i >= 0; i--) { triangle tri = faces.get(i); vector3f tria = vertices.get(tri.a); if (vecmath.dotproduct(tri.normal, vecmath.subtraction(furthestpoint, tria, tmpvec)) > 0) { lastremovedtriangles.add(faces.remove(i)); lightfacevertices.add(tri.a); lightfacevertices.add(tri.b); lightfacevertices.add(tri.c); if ((vertsa = lightfaceverticestotriangles.get(tri.a)) != null) { vertsa.add(tri); } else { vertsa = new arraylist<triangle>(); vertsa.add(tri); lightfaceverticestotriangles.put(tri.a, vertsa); } if ((vertsb = lightfaceverticestotriangles.get(tri.b)) != null) { vertsb.add(tri); } else { vertsb = new arraylist<triangle>(); vertsb.add(tri); lightfaceverticestotriangles.put(tri.b, vertsb); } if ((vertsc = lightfaceverticestotriangles.get(tri.c)) != null) { vertsc.add(tri); } else { vertsc = new arraylist<triangle>(); vertsc.add(tri); lightfaceverticestotriangles.put(tri.c, vertsc); } facepoints.addall(listsoffacepoints.remove(i)); } } iterator<integer> iter = lightfacevertices.iterator(); toremove.clear(); for (int i = 0; i < lightfacevertices.size(); i++) { int vert = iter.next(); if (lightfaceverticestotriangles.get(vert).size() == adjacentsmap.get(vert).size()) { toremove.add(vert); } } for (integer i : toremove) { for (integer adj : adjacentsmap.get(i)) { adjacentsmap.get(adj).remove(i); tmppair.set(i, adj); edgestotriangles.remove(tmppair); } lightfacevertices.remove((int) i); vertices.set((int) i, null); freevertexpositions.add(i); } hashset<integer> vertsonedge = new hashset<integer>(); for (integer vert : lightfacevertices) { vertsonedge.add(vert); } int currentvert = vertsonedge.iterator().next(); edge.clear(); for (int i = 0; i < vertsonedge.size(); i++) { edge.add(currentvert); arraylist<integer> adjs = adjacentsmap.get(currentvert); list<triangle> vertexlighttriangles = lightfaceverticestotriangles.get(currentvert); for (int j = 0; j < adjs.size(); j++) { integer curradj = adjs.get(j); if (vertsonedge.contains(curradj) && !edge.contains(curradj)) { int tricount = 0; for (int k = 0; k < vertexlighttriangles.size() && tricount < 2; k++) { triangle ktri = vertexlighttriangles.get(k); if (ktri.a == curradj || ktri.b == curradj || ktri.c == curradj) { tricount++; } } if (tricount == 1) { currentvert = curradj; break; } } } } int edgesize = edge.size(); int edgesizeminusone = edgesize - 1; for (int i = 0; i < edgesize; i++) { currentvert = edge.get(i); removeadj.clear(); for (integer adj : adjacentsmap.get(currentvert)) { if (edge.contains(adj)) { int adjindexonedge = edge.indexof(adj); if (math.abs(i - adjindexonedge) > 1 && !(i == 0 && adjindexonedge == edgesizeminusone) && !(i == edgesizeminusone && adjindexonedge == 0)) { tmppair.set(currentvert, adj); pair<triangle, triangle> edgetriangles = edgestotriangles.get(tmppair); if (lastremovedtriangles.contains(edgetriangles.getfirst()) && lastremovedtriangles.contains(edgetriangles.getsecond())) { removeadj.add(adj); edgestotriangles.remove(edgetriangles); } } } } for (integer removadjacent : removeadj) { adjacentsmap.get(currentvert).remove(removadjacent); } } newlightfaces.clear(); arraylist<integer> furthestpointneighbours = new arraylist<integer>(edge.size()); a = vertices.get(edge.get(0)); vector3f b = vertices.get(edge.get(1)); vector3f c = vertices.get(edge.get(2)); for (int i = 3; i < edge.size() && !linearindependent(a, b, c); i++) { c = vertices.get(edge.get(i)); } vector3f normal = vecmath.computenormal(a, b, c); boolean correctorientation = vecmath.dotproduct(normal, vecmath.subtraction(a, furthestpoint, tmpvec)) < 0; int vertidb = edge.get(0); for (int i = 0; i < edge.size(); i++) { int vertida = vertidb; if (i < edge.size() - 1) { vertidb = edge.get(i + 1); } else { vertidb = edge.get(0); } vector3f va = vertices.get(vertida); vector3f vb = vertices.get(vertidb); vector3f norm = vecmath.computenormal(va, vb, furthestpoint); triangle stitchtriangle; if (correctorientation) { stitchtriangle = new triangle(vertida, vertidb, furthestpointid, norm); } else { norm.negate(); stitchtriangle = new triangle(vertida, furthestpointid, vertidb, norm); } faces.add(0, stitchtriangle); newlightfaces.add(stitchtriangle); adjacentsmap.get(vertida).add(furthestpointid); tmppair.set(vertida, vertidb); pair<triangle, triangle> oldedgeinfo = edgestotriangles.get(tmppair); if (lastremovedtriangles.contains(oldedgeinfo.getfirst())) { oldedgeinfo.setfirst(stitchtriangle); } else { oldedgeinfo.setsecond(stitchtriangle); } tmppair.set(vertida, furthestpointid); oldedgeinfo = edgestotriangles.get(tmppair); if (oldedgeinfo != null) { oldedgeinfo.setsecond(stitchtriangle); } else { edgestotriangles.put(new pair<integer, integer>(vertida, furthestpointid), new pair<triangle, triangle>(null, stitchtriangle)); } tmppair.set(vertidb, furthestpointid); oldedgeinfo = edgestotriangles.get(tmppair); if (oldedgeinfo != null) { oldedgeinfo.setfirst(stitchtriangle); } else { edgestotriangles.put(new pair<integer, integer>(vertidb, furthestpointid), new pair<triangle, triangle>(stitchtriangle, null)); } furthestpointneighbours.add(vertida); } adjacentsmap.put(furthestpointid, furthestpointneighbours); for (triangle tri : newlightfaces) { listsoffacepoints.add(0, getlightpoints(tri, facepoints)); } return false; }","comment":"\/\/ welcome to madness\n\/\/ 2. get most distant point of the face's point set\n\/\/ todo: check\n\/\/ 3. find all faces that can be seen from this point\n\/\/ has to be reinitialized... don't ask why.\n\/\/ 4.0 remove all vertices that are only connected to lightfacevertices\n\/\/ todo: check\n\/\/ 4.1 get vertices on border between lit and unlit triangles\n\/\/ has to be reinitialized\n\/\/ 4.2 get edges on border\n\/\/ todo: make hashset (no! has to be ordered list!)\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\n\/\/ todo: performance\n\/\/ todo: make faster\n\/\/ 4.3 stitch holes using edge\n\/\/ update adjacents map\n\/\/ find out which triangle got deleted\n\/\/ todo: just relevant for first iteration, move before loop\n\/\/ todo: just relevant for last iteration\n\/\/ 5. assign all points of all light-faces to the new created faces\n\/\/ 6. push new created faces on the stack and start at (1))","repo":"tdc22\/JAwesomeEngine","code_context_2":"private static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\nlightFaceVertices.add(tri.b);\nlightFaceVertices.add(tri.c);\nif ((vertsA = lightFaceVerticesToTriangles.get(tri.a)) != null) {\nvertsA.add(tri);\n} else {\nvertsA = new ArrayList<Triangle>();\nvertsA.add(tri);\nlightFaceVerticesToTriangles.put(tri.a, vertsA);\n}\nif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\nvertsB.add(tri);\n} else {\nvertsB = new ArrayList<Triangle>();\nvertsB.add(tri);\nlightFaceVerticesToTriangles.put(tri.b, vertsB);\n}\nif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\nvertsC.add(tri);\n} else {\nvertsC = new ArrayList<Triangle>();\nvertsC.add(tri);\nlightFaceVerticesToTriangles.put(tri.c, vertsC);\n}\nfacepoints.addAll(listsOfFacePoints.remove(i));\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\nprivate static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\n\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\n\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\n\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\n\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\n\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\n\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\n\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\n\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\n\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\n\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\n\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\n\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\n\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\n\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\n\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\n\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}","code_context_10":"private static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\nlightFaceVertices.add(tri.b);\nlightFaceVertices.add(tri.c);\nif ((vertsA = lightFaceVerticesToTriangles.get(tri.a)) != null) {\nvertsA.add(tri);\n} else {\nvertsA = new ArrayList<Triangle>();\nvertsA.add(tri);\nlightFaceVerticesToTriangles.put(tri.a, vertsA);\n}\nif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\nvertsB.add(tri);\n} else {\nvertsB = new ArrayList<Triangle>();\nvertsB.add(tri);\nlightFaceVerticesToTriangles.put(tri.b, vertsB);\n}\nif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\nvertsC.add(tri);\n} else {\nvertsC = new ArrayList<Triangle>();\nvertsC.add(tri);\nlightFaceVerticesToTriangles.put(tri.c, vertsC);\n}\nfacepoints.addAll(listsOfFacePoints.remove(i));\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\nprivate static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\n\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\n\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\n\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\n\nif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\nvertsC.add(tri);\n} else {\nvertsC = new ArrayList<Triangle>();\nvertsC.add(tri);\nlightFaceVerticesToTriangles.put(tri.c, vertsC);\n}\nfacepoints.addAll(listsOfFacePoints.remove(i));\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\n\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\n\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\n\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\n\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\n\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\n\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\n\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\n\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\n\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\n\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\n\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\n\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}","code_context_20":"private static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\nlightFaceVertices.add(tri.b);\nlightFaceVertices.add(tri.c);\nif ((vertsA = lightFaceVerticesToTriangles.get(tri.a)) != null) {\nvertsA.add(tri);\n} else {\nvertsA = new ArrayList<Triangle>();\nvertsA.add(tri);\nlightFaceVerticesToTriangles.put(tri.a, vertsA);\n}\nif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\nvertsB.add(tri);\n} else {\nvertsB = new ArrayList<Triangle>();\nvertsB.add(tri);\nlightFaceVerticesToTriangles.put(tri.b, vertsB);\n}\nif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\nvertsC.add(tri);\n} else {\nvertsC = new ArrayList<Triangle>();\nvertsC.add(tri);\nlightFaceVerticesToTriangles.put(tri.c, vertsC);\n}\nfacepoints.addAll(listsOfFacePoints.remove(i));\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\nprivate static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\n\nprivate static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\n\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\n\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\nlightFaceVertices.add(tri.b);\n\nvertsA.add(tri);\nlightFaceVerticesToTriangles.put(tri.a, vertsA);\n}\nif ((vertsB = lightFaceVerticesToTriangles.get(tri.b)) != null) {\nvertsB.add(tri);\n} else {\nvertsB = new ArrayList<Triangle>();\nvertsB.add(tri);\nlightFaceVerticesToTriangles.put(tri.b, vertsB);\n}\nif ((vertsC = lightFaceVerticesToTriangles.get(tri.c)) != null) {\nvertsC.add(tri);\n} else {\nvertsC = new ArrayList<Triangle>();\nvertsC.add(tri);\nlightFaceVerticesToTriangles.put(tri.c, vertsC);\n}\nfacepoints.addAll(listsOfFacePoints.remove(i));\n}\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\n\nprivate static boolean step(int faceIndex) {\nTriangle t = faces.get(faceIndex);\n\/\/ 2. Get most distant point of the face's point set\nVector3f furthestPoint = null;\nint furthestPointID = -1;\nVector3f A = vertices.get(t.a);\nList<Vector3f> facepoints = listsOfFacePoints.get(faceIndex);\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\n\n}\n\/\/ 4.0 Remove all vertices that are only connected to lightFaceVertices\nIterator<Integer> iter = lightFaceVertices.iterator();\ntoRemove.clear();\nfor (int i = 0; i < lightFaceVertices.size(); i++) {\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n\nfloat distance = 0;\nfor (int i = 0; i < facepoints.size(); i++) {\nVector3f P = facepoints.get(i);\nfloat dist = VecMath.dotproduct(VecMath.subtraction(P, A, tmpvec), t.normal);\nif (dist >= distance) {\ndistance = dist;\nfurthestPoint = P;\nfurthestPointID = i;\n}\n}\nif (furthestPointID == -1 || vertices.contains(furthestPoint)) { \/\/ TODO: check\nreturn true;\n}\nfacepoints.remove(furthestPointID);\nvertices.add(furthestPoint);\nfurthestPointID = vertices.size() - 1;\nlastremovedTriangles.clear();\nlastremovedTriangles.add(faces.remove(faceIndex));\nlistsOfFacePoints.remove(faceIndex);\n\/\/ 3. Find all faces that can be seen from this point\nHashSet<Integer> lightFaceVertices = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED... don't ask why.\nlightFaceVertices.add(t.a);\nlightFaceVertices.add(t.b);\nlightFaceVertices.add(t.c);\nList<Triangle> vertsA = new ArrayList<Triangle>();\nList<Triangle> vertsB = new ArrayList<Triangle>();\nList<Triangle> vertsC = new ArrayList<Triangle>();\nvertsA.add(t);\nvertsB.add(t);\nvertsC.add(t);\nlightFaceVerticesToTriangles.clear();\nlightFaceVerticesToTriangles.put(t.a, vertsA);\nlightFaceVerticesToTriangles.put(t.b, vertsB);\nlightFaceVerticesToTriangles.put(t.c, vertsC);\nfor (int i = faces.size() - 1; i >= 0; i--) {\nTriangle tri = faces.get(i);\nVector3f triA = vertices.get(tri.a);\nif (VecMath.dotproduct(tri.normal, VecMath.subtraction(furthestPoint, triA, tmpvec)) > 0) {\nlastremovedTriangles.add(faces.remove(i));\nlightFaceVertices.add(tri.a);\nlightFaceVertices.add(tri.b);\n\nint vert = iter.next(); \/\/ TODO: check\nif (lightFaceVerticesToTriangles.get(vert).size() == adjacentsMap.get(vert).size()) {\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n\ntoRemove.add(vert);\n}\n}\nfor (Integer i : toRemove) {\nfor (Integer adj : adjacentsMap.get(i)) {\nadjacentsMap.get(adj).remove(i);\ntmppair.set(i, adj);\nedgesToTriangles.remove(tmppair);\n}\nlightFaceVertices.remove((int) i);\nvertices.set((int) i, null);\nfreeVertexPositions.add(i);\n}\n\/\/ 4.1 Get vertices on border between lit and unlit triangles\nHashSet<Integer> vertsOnEdge = new HashSet<Integer>(); \/\/ HAS TO BE REINITIALIZED\nfor (Integer vert : lightFaceVertices) {\nvertsOnEdge.add(vert);\n}\n\/\/ 4.2 Get edges on border\nint currentVert = vertsOnEdge.iterator().next();\nedge.clear(); \/\/ TODO: make HashSet (no! has to be ordered list!)\nfor (int i = 0; i < vertsOnEdge.size(); i++) {\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n\nedge.add(currentVert);\nArrayList<Integer> adjs = adjacentsMap.get(currentVert);\nList<Triangle> vertexLightTriangles = lightFaceVerticesToTriangles.get(currentVert);\nfor (int j = 0; j < adjs.size(); j++) {\nInteger currAdj = adjs.get(j);\nif (vertsOnEdge.contains(currAdj) && !edge.contains(currAdj)) {\nint tricount = 0;\nfor (int k = 0; k < vertexLightTriangles.size() && tricount < 2; k++) {\nTriangle kTri = vertexLightTriangles.get(k);\nif (kTri.a == currAdj || kTri.b == currAdj || kTri.c == currAdj) {\ntricount++;\n}\n}\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n\nif (tricount == 1) {\ncurrentVert = currAdj;\nbreak;\n}\n}\n}\n}\n\/\/ 4.2.1 remove old adjacents (crossing triangle hole)\nint edgesize = edge.size();\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n\nint edgesizeMinusOne = edgesize - 1;\nfor (int i = 0; i < edgesize; i++) {\ncurrentVert = edge.get(i);\nremoveAdj.clear();\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\n\nfor (Integer adj : adjacentsMap.get(currentVert)) {\nif (edge.contains(adj)) {\nint adjIndexOnEdge = edge.indexOf(adj);\nif (Math.abs(i - adjIndexOnEdge) > 1 && !(i == 0 && adjIndexOnEdge == edgesizeMinusOne)\n&& !(i == edgesizeMinusOne && adjIndexOnEdge == 0)) {\ntmppair.set(currentVert, adj);\nPair<Triangle, Triangle> edgeTriangles = edgesToTriangles.get(tmppair);\n\/\/ TODO: performance\nif (lastremovedTriangles.contains(edgeTriangles.getFirst())\n&& lastremovedTriangles.contains(edgeTriangles.getSecond())) {\nremoveAdj.add(adj);\nedgesToTriangles.remove(edgeTriangles);\n}\n}\n}\n}\nfor (Integer removAdjacent : removeAdj) { \/\/ TODO: make faster\nadjacentsMap.get(currentVert).remove(removAdjacent);\n}\n}\n\/\/ 4.3 Stitch holes using edge\nnewLightFaces.clear();\nArrayList<Integer> furthestPointNeighbours = new ArrayList<Integer>(edge.size());\nA = vertices.get(edge.get(0));\nVector3f B = vertices.get(edge.get(1));\nVector3f C = vertices.get(edge.get(2));\nfor (int i = 3; i < edge.size() && !linearIndependent(A, B, C); i++) {\nC = vertices.get(edge.get(i));\n}\nVector3f normal = VecMath.computeNormal(A, B, C);\nboolean correctOrientation = VecMath.dotproduct(normal, VecMath.subtraction(A, furthestPoint, tmpvec)) < 0;\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\n\nint vertIDb = edge.get(0);\nfor (int i = 0; i < edge.size(); i++) {\nint vertIDa = vertIDb;\nif (i < edge.size() - 1) {\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\n\nvertIDb = edge.get(i + 1);\n} else {\nvertIDb = edge.get(0);\n}\nVector3f vA = vertices.get(vertIDa);\nVector3f vB = vertices.get(vertIDb);\nVector3f norm = VecMath.computeNormal(vA, vB, furthestPoint);\nTriangle stitchTriangle;\nif (correctOrientation) {\nstitchTriangle = new Triangle(vertIDa, vertIDb, furthestPointID, norm);\n} else {\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\n\nnorm.negate();\nstitchTriangle = new Triangle(vertIDa, furthestPointID, vertIDb, norm);\n}\nfaces.add(0, stitchTriangle);\nnewLightFaces.add(stitchTriangle);\n\/\/ Update adjacents map\nadjacentsMap.get(vertIDa).add(furthestPointID);\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\n\ntmppair.set(vertIDa, vertIDb);\nPair<Triangle, Triangle> oldEdgeInfo = edgesToTriangles.get(tmppair);\n\/\/ find out which triangle got deleted\nif (lastremovedTriangles.contains(oldEdgeInfo.getFirst())) {\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\noldEdgeInfo.setSecond(stitchTriangle);\n}\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\ntmppair.set(vertIDa, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\noldEdgeInfo.setSecond(stitchTriangle);\n} else {\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}\n\n\/\/ TODO: just relevant for first iteration, move before loop\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDa, furthestPointID),\nnew Pair<Triangle, Triangle>(null, stitchTriangle));\n}\ntmppair.set(vertIDb, furthestPointID);\noldEdgeInfo = edgesToTriangles.get(tmppair);\nif (oldEdgeInfo != null) {\n\/\/ TODO: just relevant for last iteration\noldEdgeInfo.setFirst(stitchTriangle);\n} else {\nedgesToTriangles.put(new Pair<Integer, Integer>(vertIDb, furthestPointID),\nnew Pair<Triangle, Triangle>(stitchTriangle, null));\n}\nfurthestPointNeighbours.add(vertIDa);\n}\n\/\/ 5. Assign all points of all light-faces to the new created faces\nadjacentsMap.put(furthestPointID, furthestPointNeighbours);\nfor (Triangle tri : newLightFaces) {\nlistsOfFacePoints.add(0, getLightPoints(tri, facepoints));\n}\n\/\/ 6. Push new created faces on the stack and start at (1))\nreturn false;\n}","label":[1,0,0,0]}
{"id":32153,"original_code":"@Override\n    public void addContentView(View view, ViewGroup.LayoutParams params) {\n        if (mContentParent == null) {\n            installDecor();\n        }\n        if (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n            \/\/ TODO Augment the scenes\/transitions API to support this.\n            Log.v(TAG, \"addContentView does not support content transitions\");\n        }\n        mContentParent.addView(view, params);\n        mContentParent.requestApplyInsets();\n        final Callback cb = getCallback();\n        if (cb != null && !isDestroyed()) {\n            cb.onContentChanged();\n        }\n    }","code":"@Override\n    public void addContentView(View view, ViewGroup.LayoutParams params) {\n        if (mContentParent == null) {\n            installDecor();\n        }\n        if (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n           \n            Log.v(TAG, \"addContentView does not support content transitions\");\n        }\n        mContentParent.addView(view, params);\n        mContentParent.requestApplyInsets();\n        final Callback cb = getCallback();\n        if (cb != null && !isDestroyed()) {\n            cb.onContentChanged();\n        }\n    }","cleancode":"@override public void addcontentview(view view, viewgroup.layoutparams params) { if (mcontentparent == null) { installdecor(); } if (hasfeature(feature_content_transitions)) { log.v(tag, \"addcontentview does not support content transitions\"); } mcontentparent.addview(view, params); mcontentparent.requestapplyinsets(); final callback cb = getcallback(); if (cb != null && !isdestroyed()) { cb.oncontentchanged(); } }","comment":"\/\/ todo augment the scenes\/transitions api to support this.","repo":"yujintao529\/android_practice","code_context_2":"}\nif (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n\/\/ TODO Augment the scenes\/transitions API to support this.\nLog.v(TAG, \"addContentView does not support content transitions\");\n}","code_context_10":"@Override\npublic void addContentView(View view, ViewGroup.LayoutParams params) {\nif (mContentParent == null) {\ninstallDecor();\n}\nif (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n\/\/ TODO Augment the scenes\/transitions API to support this.\nLog.v(TAG, \"addContentView does not support content transitions\");\n}\nmContentParent.addView(view, params);\nmContentParent.requestApplyInsets();\nfinal Callback cb = getCallback();\nif (cb != null && !isDestroyed()) {\ncb.onContentChanged();\n}\n}","code_context_20":"@Override\npublic void addContentView(View view, ViewGroup.LayoutParams params) {\nif (mContentParent == null) {\ninstallDecor();\n}\nif (hasFeature(FEATURE_CONTENT_TRANSITIONS)) {\n\/\/ TODO Augment the scenes\/transitions API to support this.\nLog.v(TAG, \"addContentView does not support content transitions\");\n}\nmContentParent.addView(view, params);\nmContentParent.requestApplyInsets();\nfinal Callback cb = getCallback();\nif (cb != null && !isDestroyed()) {\ncb.onContentChanged();\n}\n}","label":[1,0,0,0]}
{"id":16350,"original_code":"public PostSubmitCallbackResponse handle(\n        Callback<AsylumCase> callback\n    ) {\n        if (!canHandle(callback)) {\n            throw new IllegalStateException(\"Cannot handle callback\");\n        }\n        PostSubmitCallbackResponse postSubmitResponse =\n            new PostSubmitCallbackResponse();\n        AsylumCase asylumCase = callback.getCaseDetails().getCaseData();\n        TimeExtensionDecision decision = getTimeExtensionDecision(asylumCase);\n        String confirmationHeader = decision == GRANTED\n            ? \"# You have granted a time extension\"\n            : \"# You have refused a time extension\";\n        postSubmitResponse.setConfirmationHeader(confirmationHeader);\n        \/\/TODO: Next step Direction name should be dynamic too.\n        postSubmitResponse.setConfirmationBody(\n            \"#### What happens next\\n\\n\"\n            + \"The appellant has been notified that their request has been \"\n            + decision.toString()\n            + \" and that they must submit their Appeal Reasons by the new due date.<br>\"\n            + \"You will be notified when it is ready to review.\\n\"\n        );\n        return postSubmitResponse;\n    }","code":"public PostSubmitCallbackResponse handle(\n        Callback<AsylumCase> callback\n    ) {\n        if (!canHandle(callback)) {\n            throw new IllegalStateException(\"Cannot handle callback\");\n        }\n        PostSubmitCallbackResponse postSubmitResponse =\n            new PostSubmitCallbackResponse();\n        AsylumCase asylumCase = callback.getCaseDetails().getCaseData();\n        TimeExtensionDecision decision = getTimeExtensionDecision(asylumCase);\n        String confirmationHeader = decision == GRANTED\n            ? \"# You have granted a time extension\"\n            : \"# You have refused a time extension\";\n        postSubmitResponse.setConfirmationHeader(confirmationHeader);\n       \n        postSubmitResponse.setConfirmationBody(\n            \"#### What happens next\\n\\n\"\n            + \"The appellant has been notified that their request has been \"\n            + decision.toString()\n            + \" and that they must submit their Appeal Reasons by the new due date.<br>\"\n            + \"You will be notified when it is ready to review.\\n\"\n        );\n        return postSubmitResponse;\n    }","cleancode":"public postsubmitcallbackresponse handle( callback<asylumcase> callback ) { if (!canhandle(callback)) { throw new illegalstateexception(\"cannot handle callback\"); } postsubmitcallbackresponse postsubmitresponse = new postsubmitcallbackresponse(); asylumcase asylumcase = callback.getcasedetails().getcasedata(); timeextensiondecision decision = gettimeextensiondecision(asylumcase); string confirmationheader = decision == granted ? \"# you have granted a time extension\" : \"# you have refused a time extension\"; postsubmitresponse.setconfirmationheader(confirmationheader); postsubmitresponse.setconfirmationbody( \"#### what happens next\\n\\n\" + \"the appellant has been notified that their request has been \" + decision.tostring() + \" and that they must submit their appeal reasons by the new due date.<br>\" + \"you will be notified when it is ready to review.\\n\" ); return postsubmitresponse; }","comment":"\/\/todo: next step direction name should be dynamic too.","repo":"uk-gov-mirror\/hmcts.ia-case-api","code_context_2":": \"# You have refused a time extension\";\npostSubmitResponse.setConfirmationHeader(confirmationHeader);\n\/\/TODO: Next step Direction name should be dynamic too.\npostSubmitResponse.setConfirmationBody(\n\"#### What happens next\\n\\n\"","code_context_10":"throw new IllegalStateException(\"Cannot handle callback\");\n}\nPostSubmitCallbackResponse postSubmitResponse =\nnew PostSubmitCallbackResponse();\nAsylumCase asylumCase = callback.getCaseDetails().getCaseData();\nTimeExtensionDecision decision = getTimeExtensionDecision(asylumCase);\nString confirmationHeader = decision == GRANTED\n? \"# You have granted a time extension\"\n: \"# You have refused a time extension\";\npostSubmitResponse.setConfirmationHeader(confirmationHeader);\n\/\/TODO: Next step Direction name should be dynamic too.\npostSubmitResponse.setConfirmationBody(\n\"#### What happens next\\n\\n\"\n+ \"The appellant has been notified that their request has been \"\n+ decision.toString()\n+ \" and that they must submit their Appeal Reasons by the new due date.<br>\"\n+ \"You will be notified when it is ready to review.\\n\"\n);\nreturn postSubmitResponse;\n}","code_context_20":"public PostSubmitCallbackResponse handle(\nCallback<AsylumCase> callback\n) {\nif (!canHandle(callback)) {\nthrow new IllegalStateException(\"Cannot handle callback\");\n}\nPostSubmitCallbackResponse postSubmitResponse =\nnew PostSubmitCallbackResponse();\nAsylumCase asylumCase = callback.getCaseDetails().getCaseData();\nTimeExtensionDecision decision = getTimeExtensionDecision(asylumCase);\nString confirmationHeader = decision == GRANTED\n? \"# You have granted a time extension\"\n: \"# You have refused a time extension\";\npostSubmitResponse.setConfirmationHeader(confirmationHeader);\n\/\/TODO: Next step Direction name should be dynamic too.\npostSubmitResponse.setConfirmationBody(\n\"#### What happens next\\n\\n\"\n+ \"The appellant has been notified that their request has been \"\n+ decision.toString()\n+ \" and that they must submit their Appeal Reasons by the new due date.<br>\"\n+ \"You will be notified when it is ready to review.\\n\"\n);\nreturn postSubmitResponse;\n}","label":[0,1,0,0]}
